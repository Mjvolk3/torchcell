<!DOCTYPE html><html><head>
      <title>Versus Delta Speed</title>
      <meta charset="utf-8">
      <meta name="viewport" content="width=device-width, initial-scale=1.0">
      
      <link rel="stylesheet" href="file:////Users/michaelvolk/.vscode/extensions/shd101wyy.markdown-preview-enhanced-0.8.14/crossnote/dependencies/katex/katex.min.css">
      
      
      
      
      
      <style>
      code[class*=language-],pre[class*=language-]{color:#333;background:0 0;font-family:Consolas,"Liberation Mono",Menlo,Courier,monospace;text-align:left;white-space:pre;word-spacing:normal;word-break:normal;word-wrap:normal;line-height:1.4;-moz-tab-size:8;-o-tab-size:8;tab-size:8;-webkit-hyphens:none;-moz-hyphens:none;-ms-hyphens:none;hyphens:none}pre[class*=language-]{padding:.8em;overflow:auto;border-radius:3px;background:#f5f5f5}:not(pre)>code[class*=language-]{padding:.1em;border-radius:.3em;white-space:normal;background:#f5f5f5}.token.blockquote,.token.comment{color:#969896}.token.cdata{color:#183691}.token.doctype,.token.macro.property,.token.punctuation,.token.variable{color:#333}.token.builtin,.token.important,.token.keyword,.token.operator,.token.rule{color:#a71d5d}.token.attr-value,.token.regex,.token.string,.token.url{color:#183691}.token.atrule,.token.boolean,.token.code,.token.command,.token.constant,.token.entity,.token.number,.token.property,.token.symbol{color:#0086b3}.token.prolog,.token.selector,.token.tag{color:#63a35c}.token.attr-name,.token.class,.token.class-name,.token.function,.token.id,.token.namespace,.token.pseudo-class,.token.pseudo-element,.token.url-reference .token.variable{color:#795da3}.token.entity{cursor:help}.token.title,.token.title .token.punctuation{font-weight:700;color:#1d3e81}.token.list{color:#ed6a43}.token.inserted{background-color:#eaffea;color:#55a532}.token.deleted{background-color:#ffecec;color:#bd2c00}.token.bold{font-weight:700}.token.italic{font-style:italic}.language-json .token.property{color:#183691}.language-markup .token.tag .token.punctuation{color:#333}.language-css .token.function,code.language-css{color:#0086b3}.language-yaml .token.atrule{color:#63a35c}code.language-yaml{color:#183691}.language-ruby .token.function{color:#333}.language-markdown .token.url{color:#795da3}.language-makefile .token.symbol{color:#795da3}.language-makefile .token.variable{color:#183691}.language-makefile .token.builtin{color:#0086b3}.language-bash .token.keyword{color:#0086b3}pre[data-line]{position:relative;padding:1em 0 1em 3em}pre[data-line] .line-highlight-wrapper{position:absolute;top:0;left:0;background-color:transparent;display:block;width:100%}pre[data-line] .line-highlight{position:absolute;left:0;right:0;padding:inherit 0;margin-top:1em;background:hsla(24,20%,50%,.08);background:linear-gradient(to right,hsla(24,20%,50%,.1) 70%,hsla(24,20%,50%,0));pointer-events:none;line-height:inherit;white-space:pre}pre[data-line] .line-highlight:before,pre[data-line] .line-highlight[data-end]:after{content:attr(data-start);position:absolute;top:.4em;left:.6em;min-width:1em;padding:0 .5em;background-color:hsla(24,20%,50%,.4);color:#f4f1ef;font:bold 65%/1.5 sans-serif;text-align:center;vertical-align:.3em;border-radius:999px;text-shadow:none;box-shadow:0 1px #fff}pre[data-line] .line-highlight[data-end]:after{content:attr(data-end);top:auto;bottom:.4em}html body{font-family:'Helvetica Neue',Helvetica,'Segoe UI',Arial,freesans,sans-serif;font-size:16px;line-height:1.6;color:#333;background-color:#fff;overflow:initial;box-sizing:border-box;word-wrap:break-word}html body>:first-child{margin-top:0}html body h1,html body h2,html body h3,html body h4,html body h5,html body h6{line-height:1.2;margin-top:1em;margin-bottom:16px;color:#000}html body h1{font-size:2.25em;font-weight:300;padding-bottom:.3em}html body h2{font-size:1.75em;font-weight:400;padding-bottom:.3em}html body h3{font-size:1.5em;font-weight:500}html body h4{font-size:1.25em;font-weight:600}html body h5{font-size:1.1em;font-weight:600}html body h6{font-size:1em;font-weight:600}html body h1,html body h2,html body h3,html body h4,html body h5{font-weight:600}html body h5{font-size:1em}html body h6{color:#5c5c5c}html body strong{color:#000}html body del{color:#5c5c5c}html body a:not([href]){color:inherit;text-decoration:none}html body a{color:#08c;text-decoration:none}html body a:hover{color:#00a3f5;text-decoration:none}html body img{max-width:100%}html body>p{margin-top:0;margin-bottom:16px;word-wrap:break-word}html body>ol,html body>ul{margin-bottom:16px}html body ol,html body ul{padding-left:2em}html body ol.no-list,html body ul.no-list{padding:0;list-style-type:none}html body ol ol,html body ol ul,html body ul ol,html body ul ul{margin-top:0;margin-bottom:0}html body li{margin-bottom:0}html body li.task-list-item{list-style:none}html body li>p{margin-top:0;margin-bottom:0}html body .task-list-item-checkbox{margin:0 .2em .25em -1.8em;vertical-align:middle}html body .task-list-item-checkbox:hover{cursor:pointer}html body blockquote{margin:16px 0;font-size:inherit;padding:0 15px;color:#5c5c5c;background-color:#f0f0f0;border-left:4px solid #d6d6d6}html body blockquote>:first-child{margin-top:0}html body blockquote>:last-child{margin-bottom:0}html body hr{height:4px;margin:32px 0;background-color:#d6d6d6;border:0 none}html body table{margin:10px 0 15px 0;border-collapse:collapse;border-spacing:0;display:block;width:100%;overflow:auto;word-break:normal;word-break:keep-all}html body table th{font-weight:700;color:#000}html body table td,html body table th{border:1px solid #d6d6d6;padding:6px 13px}html body dl{padding:0}html body dl dt{padding:0;margin-top:16px;font-size:1em;font-style:italic;font-weight:700}html body dl dd{padding:0 16px;margin-bottom:16px}html body code{font-family:Menlo,Monaco,Consolas,'Courier New',monospace;font-size:.85em;color:#000;background-color:#f0f0f0;border-radius:3px;padding:.2em 0}html body code::after,html body code::before{letter-spacing:-.2em;content:'\00a0'}html body pre>code{padding:0;margin:0;word-break:normal;white-space:pre;background:0 0;border:0}html body .highlight{margin-bottom:16px}html body .highlight pre,html body pre{padding:1em;overflow:auto;line-height:1.45;border:#d6d6d6;border-radius:3px}html body .highlight pre{margin-bottom:0;word-break:normal}html body pre code,html body pre tt{display:inline;max-width:initial;padding:0;margin:0;overflow:initial;line-height:inherit;word-wrap:normal;background-color:transparent;border:0}html body pre code:after,html body pre code:before,html body pre tt:after,html body pre tt:before{content:normal}html body blockquote,html body dl,html body ol,html body p,html body pre,html body ul{margin-top:0;margin-bottom:16px}html body kbd{color:#000;border:1px solid #d6d6d6;border-bottom:2px solid #c7c7c7;padding:2px 4px;background-color:#f0f0f0;border-radius:3px}@media print{html body{background-color:#fff}html body h1,html body h2,html body h3,html body h4,html body h5,html body h6{color:#000;page-break-after:avoid}html body blockquote{color:#5c5c5c}html body pre{page-break-inside:avoid}html body table{display:table}html body img{display:block;max-width:100%;max-height:100%}html body code,html body pre{word-wrap:break-word;white-space:pre}}.markdown-preview{width:100%;height:100%;box-sizing:border-box}.markdown-preview ul{list-style:disc}.markdown-preview ul ul{list-style:circle}.markdown-preview ul ul ul{list-style:square}.markdown-preview ol{list-style:decimal}.markdown-preview ol ol,.markdown-preview ul ol{list-style-type:lower-roman}.markdown-preview ol ol ol,.markdown-preview ol ul ol,.markdown-preview ul ol ol,.markdown-preview ul ul ol{list-style-type:lower-alpha}.markdown-preview .newpage,.markdown-preview .pagebreak{page-break-before:always}.markdown-preview pre.line-numbers{position:relative;padding-left:3.8em;counter-reset:linenumber}.markdown-preview pre.line-numbers>code{position:relative}.markdown-preview pre.line-numbers .line-numbers-rows{position:absolute;pointer-events:none;top:1em;font-size:100%;left:0;width:3em;letter-spacing:-1px;border-right:1px solid #999;-webkit-user-select:none;-moz-user-select:none;-ms-user-select:none;user-select:none}.markdown-preview pre.line-numbers .line-numbers-rows>span{pointer-events:none;display:block;counter-increment:linenumber}.markdown-preview pre.line-numbers .line-numbers-rows>span:before{content:counter(linenumber);color:#999;display:block;padding-right:.8em;text-align:right}.markdown-preview .mathjax-exps .MathJax_Display{text-align:center!important}.markdown-preview:not([data-for=preview]) .code-chunk .code-chunk-btn-group{display:none}.markdown-preview:not([data-for=preview]) .code-chunk .status{display:none}.markdown-preview:not([data-for=preview]) .code-chunk .output-div{margin-bottom:16px}.markdown-preview .md-toc{padding:0}.markdown-preview .md-toc .md-toc-link-wrapper .md-toc-link{display:inline;padding:.25rem 0}.markdown-preview .md-toc .md-toc-link-wrapper .md-toc-link div,.markdown-preview .md-toc .md-toc-link-wrapper .md-toc-link p{display:inline}.markdown-preview .md-toc .md-toc-link-wrapper.highlighted .md-toc-link{font-weight:800}.scrollbar-style::-webkit-scrollbar{width:8px}.scrollbar-style::-webkit-scrollbar-track{border-radius:10px;background-color:transparent}.scrollbar-style::-webkit-scrollbar-thumb{border-radius:5px;background-color:rgba(150,150,150,.66);border:4px solid rgba(150,150,150,.66);background-clip:content-box}html body[for=html-export]:not([data-presentation-mode]){position:relative;width:100%;height:100%;top:0;left:0;margin:0;padding:0;overflow:auto}html body[for=html-export]:not([data-presentation-mode]) .markdown-preview{position:relative;top:0;min-height:100vh}@media screen and (min-width:914px){html body[for=html-export]:not([data-presentation-mode]) .markdown-preview{padding:2em calc(50% - 457px + 2em)}}@media screen and (max-width:914px){html body[for=html-export]:not([data-presentation-mode]) .markdown-preview{padding:2em}}@media screen and (max-width:450px){html body[for=html-export]:not([data-presentation-mode]) .markdown-preview{font-size:14px!important;padding:1em}}@media print{html body[for=html-export]:not([data-presentation-mode]) #sidebar-toc-btn{display:none}}html body[for=html-export]:not([data-presentation-mode]) #sidebar-toc-btn{position:fixed;bottom:8px;left:8px;font-size:28px;cursor:pointer;color:inherit;z-index:99;width:32px;text-align:center;opacity:.4}html body[for=html-export]:not([data-presentation-mode])[html-show-sidebar-toc] #sidebar-toc-btn{opacity:1}html body[for=html-export]:not([data-presentation-mode])[html-show-sidebar-toc] .md-sidebar-toc{position:fixed;top:0;left:0;width:300px;height:100%;padding:32px 0 48px 0;font-size:14px;box-shadow:0 0 4px rgba(150,150,150,.33);box-sizing:border-box;overflow:auto;background-color:inherit}html body[for=html-export]:not([data-presentation-mode])[html-show-sidebar-toc] .md-sidebar-toc::-webkit-scrollbar{width:8px}html body[for=html-export]:not([data-presentation-mode])[html-show-sidebar-toc] .md-sidebar-toc::-webkit-scrollbar-track{border-radius:10px;background-color:transparent}html body[for=html-export]:not([data-presentation-mode])[html-show-sidebar-toc] .md-sidebar-toc::-webkit-scrollbar-thumb{border-radius:5px;background-color:rgba(150,150,150,.66);border:4px solid rgba(150,150,150,.66);background-clip:content-box}html body[for=html-export]:not([data-presentation-mode])[html-show-sidebar-toc] .md-sidebar-toc a{text-decoration:none}html body[for=html-export]:not([data-presentation-mode])[html-show-sidebar-toc] .md-sidebar-toc .md-toc{padding:0 16px}html body[for=html-export]:not([data-presentation-mode])[html-show-sidebar-toc] .md-sidebar-toc .md-toc .md-toc-link-wrapper .md-toc-link{display:inline;padding:.25rem 0}html body[for=html-export]:not([data-presentation-mode])[html-show-sidebar-toc] .md-sidebar-toc .md-toc .md-toc-link-wrapper .md-toc-link div,html body[for=html-export]:not([data-presentation-mode])[html-show-sidebar-toc] .md-sidebar-toc .md-toc .md-toc-link-wrapper .md-toc-link p{display:inline}html body[for=html-export]:not([data-presentation-mode])[html-show-sidebar-toc] .md-sidebar-toc .md-toc .md-toc-link-wrapper.highlighted .md-toc-link{font-weight:800}html body[for=html-export]:not([data-presentation-mode])[html-show-sidebar-toc] .markdown-preview{left:300px;width:calc(100% - 300px);padding:2em calc(50% - 457px - 300px / 2);margin:0;box-sizing:border-box}@media screen and (max-width:1274px){html body[for=html-export]:not([data-presentation-mode])[html-show-sidebar-toc] .markdown-preview{padding:2em}}@media screen and (max-width:450px){html body[for=html-export]:not([data-presentation-mode])[html-show-sidebar-toc] .markdown-preview{width:100%}}html body[for=html-export]:not([data-presentation-mode]):not([html-show-sidebar-toc]) .markdown-preview{left:50%;transform:translateX(-50%)}html body[for=html-export]:not([data-presentation-mode]):not([html-show-sidebar-toc]) .md-sidebar-toc{display:none}
/* Please visit the URL below for more information: */
/*   https://shd101wyy.github.io/markdown-preview-enhanced/#/customize-css */

      </style>
      <!-- The content below will be included at the end of the <head> element. --><script type="text/javascript">
  document.addEventListener("DOMContentLoaded", function () {
    // your code here
  });
</script></head><body for="html-export">
    
    
      <div class="crossnote markdown-preview  " id="smsdkks3gq1pwyr5jdz1zd7">
      
<h2 id="20240918---workstation-and-delta-cpu">2024.09.18 - Workstation and Delta CPU </h2>
<p><code>Workstation</code></p>
<pre data-role="codeBlock" data-info="bash" class="language-bash bash"><code><span class="token punctuation">(</span>base<span class="token punctuation">)</span> michaelvolk@gilahyper torchcell % lscpu                                                                                                                     <span class="token number">13</span>:49
Architecture:            x86_64
  CPU op-mode<span class="token punctuation">(</span>s<span class="token punctuation">)</span>:        <span class="token number">32</span>-bit, <span class="token number">64</span>-bit
  Address sizes:         <span class="token number">48</span> bits physical, <span class="token number">48</span> bits virtual
  Byte Order:            Little Endian
CPU<span class="token punctuation">(</span>s<span class="token punctuation">)</span>:                  <span class="token number">128</span>
  On-line CPU<span class="token punctuation">(</span>s<span class="token punctuation">)</span> list:   <span class="token number">0</span>-127
Vendor ID:               AuthenticAMD
  Model name:            AMD Ryzen Threadripper PRO 5995WX <span class="token number">64</span>-Cores
    CPU family:          <span class="token number">25</span>
    Model:               <span class="token number">8</span>
    Thread<span class="token punctuation">(</span>s<span class="token punctuation">)</span> per core:  <span class="token number">2</span>
    Core<span class="token punctuation">(</span>s<span class="token punctuation">)</span> per socket:  <span class="token number">64</span>
    Socket<span class="token punctuation">(</span>s<span class="token punctuation">)</span>:           <span class="token number">1</span>
    Stepping:            <span class="token number">2</span>
    Frequency boost:     enabled
    CPU<span class="token punctuation">(</span>s<span class="token punctuation">)</span> scaling MHz:  <span class="token number">39</span>%
    CPU max MHz:         <span class="token number">7024.2178</span>
    CPU min MHz:         <span class="token number">1800.0000</span>
    BogoMIPS:            <span class="token number">5389.89</span>
    Flags:               fpu vme de pse tsc msr pae mce cx8 apic sep mtrr pge mca cmov pat pse36 clflush mmx fxsr sse sse2 ht syscall nx mmxext fxsr_opt pdpe1gb rdtscp l
                         m constant_tsc rep_good nopl nonstop_tsc cpuid extd_apicid aperfmperf rapl pni pclmulqdq monitor ssse3 fma cx16 pcid sse4_1 sse4_2 x2apic movbe 
                         popcnt aes xsave avx f16c rdrand lahf_lm cmp_legacy svm extapic cr8_legacy abm sse4a misalignsse 3dnowprefetch osvw ibs skinit wdt tce topoext p
                         erfctr_core perfctr_nb bpext perfctr_llc mwaitx cpb cat_l3 cdp_l3 hw_pstate ssbd mba ibrs ibpb stibp vmmcall fsgsbase bmi1 avx2 smep bmi2 erms i
                         nvpcid cqm rdt_a rdseed adx smap clflushopt clwb sha_ni xsaveopt xsavec xgetbv1 xsaves cqm_llc cqm_occup_llc cqm_mbm_total cqm_mbm_local clzero 
                         irperf xsaveerptr rdpru wbnoinvd amd_ppin brs arat npt lbrv svm_lock nrip_save tsc_scale vmcb_clean flushbyasid decodeassists pausefilter pfthre
                         shold avic v_vmsave_vmload vgif v_spec_ctrl umip pku ospke vaes vpclmulqdq rdpid overflow_recov succor smca fsrm debug_swap
Virtualization features: 
  Virtualization:        AMD-V
Caches <span class="token punctuation">(</span>sum of all<span class="token punctuation">)</span>:     
  L1d:                   <span class="token number">2</span> MiB <span class="token punctuation">(</span><span class="token number">64</span> instances<span class="token punctuation">)</span>
  L1i:                   <span class="token number">2</span> MiB <span class="token punctuation">(</span><span class="token number">64</span> instances<span class="token punctuation">)</span>
  L2:                    <span class="token number">32</span> MiB <span class="token punctuation">(</span><span class="token number">64</span> instances<span class="token punctuation">)</span>
  L3:                    <span class="token number">256</span> MiB <span class="token punctuation">(</span><span class="token number">8</span> instances<span class="token punctuation">)</span>
NUMA:                    
  NUMA node<span class="token punctuation">(</span>s<span class="token punctuation">)</span>:          <span class="token number">1</span>
  NUMA node0 CPU<span class="token punctuation">(</span>s<span class="token punctuation">)</span>:     <span class="token number">0</span>-127
Vulnerabilities:         
  Gather data sampling:  Not affected
  Itlb multihit:         Not affected
  L1tf:                  Not affected
  Mds:                   Not affected
  Meltdown:              Not affected
  Mmio stale data:       Not affected
  Retbleed:              Not affected
  Spec rstack overflow:  Mitigation<span class="token punctuation">;</span> Safe RET
  Spec store bypass:     Mitigation<span class="token punctuation">;</span> Speculative Store Bypass disabled via prctl
  Spectre v1:            Mitigation<span class="token punctuation">;</span> usercopy/swapgs barriers and __user pointer sanitization
  Spectre v2:            Mitigation<span class="token punctuation">;</span> Retpolines, IBPB conditional, IBRS_FW, STIBP always-on, RSB filling, PBRSB-eIBRS Not affected
  Srbds:                 Not affected
  Tsx async abort:       Not affected
</code></pre><p><code>Delta</code></p>
<pre data-role="codeBlock" data-info="bash" class="language-bash bash"><code>lscpu
Architecture:        x86_64
CPU op-mode<span class="token punctuation">(</span>s<span class="token punctuation">)</span>:      <span class="token number">32</span>-bit, <span class="token number">64</span>-bit
Byte Order:          Little Endian
CPU<span class="token punctuation">(</span>s<span class="token punctuation">)</span>:              <span class="token number">128</span>
On-line CPU<span class="token punctuation">(</span>s<span class="token punctuation">)</span> list: <span class="token number">0</span>-127
Thread<span class="token punctuation">(</span>s<span class="token punctuation">)</span> per core:  <span class="token number">1</span>
Core<span class="token punctuation">(</span>s<span class="token punctuation">)</span> per socket:  <span class="token number">64</span>
Socket<span class="token punctuation">(</span>s<span class="token punctuation">)</span>:           <span class="token number">2</span>
NUMA node<span class="token punctuation">(</span>s<span class="token punctuation">)</span>:        <span class="token number">8</span>
Vendor ID:           AuthenticAMD
CPU family:          <span class="token number">25</span>
Model:               <span class="token number">1</span>
Model name:          AMD EPYC <span class="token number">7763</span> <span class="token number">64</span>-Core Processor
Stepping:            <span class="token number">1</span>
CPU MHz:             <span class="token number">2450.000</span>
CPU max MHz:         <span class="token number">2450.0000</span>
CPU min MHz:         <span class="token number">1500.0000</span>
BogoMIPS:            <span class="token number">4891.28</span>
Virtualization:      AMD-V
L1d cache:           32K
L1i cache:           32K
L2 cache:            512K
L3 cache:            32768K
NUMA node0 CPU<span class="token punctuation">(</span>s<span class="token punctuation">)</span>:   <span class="token number">0</span>-15
NUMA node1 CPU<span class="token punctuation">(</span>s<span class="token punctuation">)</span>:   <span class="token number">16</span>-31
NUMA node2 CPU<span class="token punctuation">(</span>s<span class="token punctuation">)</span>:   <span class="token number">32</span>-47
NUMA node3 CPU<span class="token punctuation">(</span>s<span class="token punctuation">)</span>:   <span class="token number">48</span>-63
NUMA node4 CPU<span class="token punctuation">(</span>s<span class="token punctuation">)</span>:   <span class="token number">64</span>-79
NUMA node5 CPU<span class="token punctuation">(</span>s<span class="token punctuation">)</span>:   <span class="token number">80</span>-95
NUMA node6 CPU<span class="token punctuation">(</span>s<span class="token punctuation">)</span>:   <span class="token number">96</span>-111
NUMA node7 CPU<span class="token punctuation">(</span>s<span class="token punctuation">)</span>:   <span class="token number">112</span>-127
Flags:               fpu vme de pse tsc msr pae mce cx8 apic sep mtrr pge mca cmov pat pse36 clflush mmx fxsr sse sse2 ht syscall nx mmxext fxsr_opt pdpe1gb rdtscp lm constant_tsc rep_good nopl nonstop_tsc cpuid extd_apicid aperfmperf pni pclmulqdq monitor ssse3 fma cx16 pcid sse4_1 sse4_2 x2apic movbe popcnt aes xsave avx f16c rdrand lahf_lm cmp_legacy svm extapic cr8_legacy abm sse4a misalignsse 3dnowprefetch osvw ibs skinit wdt tce topoext perfctr_core perfctr_nb bpext perfctr_llc mwaitx cpb cat_l3 cdp_l3 invpcid_single hw_pstate ssbd mba ibrs ibpb stibp vmmcall fsgsbase bmi1 avx2 smep bmi2 erms invpcid cqm rdt_a rdseed adx smap clflushopt clwb sha_ni xsaveopt xsavec xgetbv1 xsaves cqm_llc cqm_occup_llc cqm_mbm_total cqm_mbm_local clzero irperf xsaveerptr wbnoinvd amd_ppin brs arat npt lbrv svm_lock nrip_save tsc_scale vmcb_clean flushbyasid decodeassists pausefilter pfthreshold v_vmsave_vmload vgif v_spec_ctrl umip pku ospke vaes vpclmulqdq rdpid overflow_recov succor smca fsrm
MemTotal:       <span class="token number">263821940</span> kB
MemFree:        <span class="token number">246258700</span> kB
MemAvailable:   <span class="token number">246533224</span> kB
Buffers:            <span class="token number">2112</span> kB
Cached:         <span class="token number">13324416</span> kB
SwapCached:            <span class="token number">0</span> kB
Active:          <span class="token number">7362400</span> kB
Inactive:        <span class="token number">6536256</span> kB
Active<span class="token punctuation">(</span>anon<span class="token punctuation">)</span>:    <span class="token number">6538876</span> kB
Inactive<span class="token punctuation">(</span>anon<span class="token punctuation">)</span>:  <span class="token number">5965656</span> kB
Active<span class="token punctuation">(</span>file<span class="token punctuation">)</span>:     <span class="token number">823524</span> kB
Inactive<span class="token punctuation">(</span>file<span class="token punctuation">)</span>:   <span class="token number">570600</span> kB
Unevictable:       <span class="token number">95736</span> kB
Mlocked:           <span class="token number">92688</span> kB
SwapTotal:             <span class="token number">0</span> kB
SwapFree:              <span class="token number">0</span> kB
Dirty:                 <span class="token number">8</span> kB
Writeback:             <span class="token number">0</span> kB
AnonPages:        <span class="token number">665696</span> kB
Mapped:           <span class="token number">411872</span> kB
Shmem:          <span class="token number">11932404</span> kB
KReclaimable:     <span class="token number">709024</span> kB
Slab:            <span class="token number">2554028</span> kB
SReclaimable:     <span class="token number">709024</span> kB
SUnreclaim:      <span class="token number">1845004</span> kB
KernelStack:       <span class="token number">29376</span> kB
PageTables:        <span class="token number">12644</span> kB
NFS_Unstable:          <span class="token number">0</span> kB
Bounce:                <span class="token number">0</span> kB
WritebackTmp:          <span class="token number">0</span> kB
CommitLimit:    <span class="token number">131910968</span> kB
Committed_AS:   <span class="token number">14212520</span> kB
VmallocTotal:   <span class="token number">34359738367</span> kB
VmallocUsed:      <span class="token number">295032</span> kB
VmallocChunk:          <span class="token number">0</span> kB
Percpu:           <span class="token number">231936</span> kB
HardwareCorrupted:     <span class="token number">0</span> kB
AnonHugePages:    <span class="token number">419840</span> kB
ShmemHugePages:        <span class="token number">0</span> kB
ShmemPmdMapped:        <span class="token number">0</span> kB
FileHugePages:         <span class="token number">0</span> kB
FilePmdMapped:         <span class="token number">0</span> kB
HugePages_Total:       <span class="token number">0</span>
HugePages_Free:        <span class="token number">0</span>
HugePages_Rsvd:        <span class="token number">0</span>
HugePages_Surp:        <span class="token number">0</span>
Hugepagesize:       <span class="token number">2048</span> kB
Hugetlb:               <span class="token number">0</span> kB
DirectMap4k:      <span class="token number">414644</span> kB
DirectMap2M:    <span class="token number">27623424</span> kB
DirectMap1G:    <span class="token number">240123904</span> kB
</code></pre><h3 id="speed-setup">Speed Setup </h3>
<p>We have significant speed difference. Delta is much faster for this script.</p>
<pre data-role="codeBlock" data-info="python" class="language-python python"><code><span class="token keyword keyword-import">import</span> concurrent<span class="token punctuation">.</span>futures
<span class="token keyword keyword-import">import</span> time
<span class="token keyword keyword-import">import</span> numpy <span class="token keyword keyword-as">as</span> np
<span class="token keyword keyword-import">import</span> multiprocessing


<span class="token keyword keyword-def">def</span> <span class="token function">matrix_multiply</span><span class="token punctuation">(</span>size<span class="token punctuation">:</span> <span class="token builtin">int</span><span class="token punctuation">)</span> <span class="token operator">-</span><span class="token operator">&gt;</span> <span class="token boolean">None</span><span class="token punctuation">:</span>
    <span class="token triple-quoted-string string">"""Performs matrix multiplication of two random matrices."""</span>
    A <span class="token operator">=</span> np<span class="token punctuation">.</span>random<span class="token punctuation">.</span>rand<span class="token punctuation">(</span>size<span class="token punctuation">,</span> size<span class="token punctuation">)</span>
    B <span class="token operator">=</span> np<span class="token punctuation">.</span>random<span class="token punctuation">.</span>rand<span class="token punctuation">(</span>size<span class="token punctuation">,</span> size<span class="token punctuation">)</span>
    np<span class="token punctuation">.</span>dot<span class="token punctuation">(</span>A<span class="token punctuation">,</span> B<span class="token punctuation">)</span>  <span class="token comment"># Perform the matrix multiplication</span>


<span class="token keyword keyword-def">def</span> <span class="token function">benchmark</span><span class="token punctuation">(</span>num_jobs<span class="token punctuation">:</span> <span class="token builtin">int</span><span class="token punctuation">,</span> matrix_size<span class="token punctuation">:</span> <span class="token builtin">int</span><span class="token punctuation">)</span> <span class="token operator">-</span><span class="token operator">&gt;</span> <span class="token builtin">float</span><span class="token punctuation">:</span>
    <span class="token triple-quoted-string string">"""Run the benchmark with a specified number of jobs and matrix size."""</span>
    start_time <span class="token operator">=</span> time<span class="token punctuation">.</span>time<span class="token punctuation">(</span><span class="token punctuation">)</span>

    <span class="token comment"># Use all cores with ProcessPoolExecutor</span>
    <span class="token keyword keyword-with">with</span> concurrent<span class="token punctuation">.</span>futures<span class="token punctuation">.</span>ProcessPoolExecutor<span class="token punctuation">(</span>max_workers<span class="token operator">=</span>num_jobs<span class="token punctuation">)</span> <span class="token keyword keyword-as">as</span> executor<span class="token punctuation">:</span>
        executor<span class="token punctuation">.</span><span class="token builtin">map</span><span class="token punctuation">(</span>matrix_multiply<span class="token punctuation">,</span> <span class="token punctuation">[</span>matrix_size<span class="token punctuation">]</span> <span class="token operator">*</span> num_jobs<span class="token punctuation">)</span>

    end_time <span class="token operator">=</span> time<span class="token punctuation">.</span>time<span class="token punctuation">(</span><span class="token punctuation">)</span>
    <span class="token keyword keyword-return">return</span> end_time <span class="token operator">-</span> start_time


<span class="token keyword keyword-def">def</span> <span class="token function">run_benchmark</span><span class="token punctuation">(</span>repeats<span class="token punctuation">:</span> <span class="token builtin">int</span><span class="token punctuation">,</span> matrix_size<span class="token punctuation">:</span> <span class="token builtin">int</span><span class="token punctuation">)</span> <span class="token operator">-</span><span class="token operator">&gt;</span> <span class="token builtin">list</span><span class="token punctuation">:</span>
    <span class="token triple-quoted-string string">"""Run the benchmark multiple times and return the results."""</span>
    cpu_count <span class="token operator">=</span> multiprocessing<span class="token punctuation">.</span>cpu_count<span class="token punctuation">(</span><span class="token punctuation">)</span>
    times <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token punctuation">]</span>

    <span class="token keyword keyword-for">for</span> _ <span class="token keyword keyword-in">in</span> <span class="token builtin">range</span><span class="token punctuation">(</span>repeats<span class="token punctuation">)</span><span class="token punctuation">:</span>
        duration <span class="token operator">=</span> benchmark<span class="token punctuation">(</span>cpu_count<span class="token punctuation">,</span> matrix_size<span class="token punctuation">)</span>
        times<span class="token punctuation">.</span>append<span class="token punctuation">(</span>duration<span class="token punctuation">)</span>

    <span class="token keyword keyword-return">return</span> times


<span class="token comment"># Running benchmark 5 times with matrix size 1000</span>
repeats <span class="token operator">=</span> <span class="token number">5</span>
matrix_size <span class="token operator">=</span> <span class="token number">4000</span>
results <span class="token operator">=</span> run_benchmark<span class="token punctuation">(</span>repeats<span class="token punctuation">,</span> matrix_size<span class="token punctuation">)</span>

<span class="token comment"># Calculate mean and standard deviation</span>
mean_time <span class="token operator">=</span> np<span class="token punctuation">.</span>mean<span class="token punctuation">(</span>results<span class="token punctuation">)</span>
std_time <span class="token operator">=</span> np<span class="token punctuation">.</span>std<span class="token punctuation">(</span>results<span class="token punctuation">)</span>

<span class="token keyword keyword-print">print</span><span class="token punctuation">(</span><span class="token string-interpolation"><span class="token string">f"Raw Data: </span><span class="token interpolation"><span class="token punctuation">{</span>results<span class="token punctuation">}</span></span><span class="token string">"</span></span><span class="token punctuation">)</span>
<span class="token keyword keyword-print">print</span><span class="token punctuation">(</span><span class="token string-interpolation"><span class="token string">f"Mean Time: </span><span class="token interpolation"><span class="token punctuation">{</span>mean_time<span class="token punctuation">:</span><span class="token format-spec">.2f</span><span class="token punctuation">}</span></span><span class="token string"> seconds"</span></span><span class="token punctuation">)</span>
<span class="token keyword keyword-print">print</span><span class="token punctuation">(</span><span class="token string-interpolation"><span class="token string">f"Standard Deviation: </span><span class="token interpolation"><span class="token punctuation">{</span>std_time<span class="token punctuation">:</span><span class="token format-spec">.2f</span><span class="token punctuation">}</span></span><span class="token string"> seconds"</span></span><span class="token punctuation">)</span>
</code></pre><h3 id="first-experiment">First Experiment </h3>
<pre data-role="codeBlock" data-info="python" class="language-python python"><code>repeats <span class="token operator">=</span> <span class="token number">5</span>
matrix_size <span class="token operator">=</span> <span class="token number">1000</span>
</code></pre><p>Workstation no Slurm</p>
<pre data-role="codeBlock" data-info="bash" class="language-bash bash"><code><span class="token punctuation">(</span>torchcell<span class="token punctuation">)</span> michaelvolk@gilahyper torchcell % /home/michaelvolk/miniconda3/envs/torchcell/bin/python /home/michaelvolk/Documents/projects/torchcell/torc
hcell/scratch/cpu_performance_benchmark.py
Raw Data: <span class="token punctuation">[</span><span class="token number">20.143832683563232</span>, <span class="token number">19.094918727874756</span>, <span class="token number">20.667733669281006</span>, <span class="token number">19.605305671691895</span>, <span class="token number">19.61408519744873</span><span class="token punctuation">]</span>
Mean Time: <span class="token number">19.83</span> seconds
Standard Deviation: <span class="token number">0.54</span> seconds
</code></pre><p>Workstation Slurm. There is a slight overhead.</p>
<pre data-role="codeBlock" data-info="bash" class="language-bash bash"><code>Raw Data: <span class="token punctuation">[</span><span class="token number">20.507216453552246</span>, <span class="token number">20.640620231628418</span>, <span class="token number">20.882274389266968</span>, <span class="token number">21.411606311798096</span>, <span class="token number">20.875935316085815</span><span class="token punctuation">]</span>
Mean Time: <span class="token number">20.86</span> seconds
Standard Deviation: <span class="token number">0.31</span> seconds
</code></pre><p>Delta Slurm</p>
<pre data-role="codeBlock" data-info="bash" class="language-bash bash"><code>Raw Data: <span class="token punctuation">[</span><span class="token number">1.1937663555145264</span>, <span class="token number">1.5070643424987793</span>, <span class="token number">1.3696041107177734</span>, <span class="token number">1.2952206134796143</span>, <span class="token number">1.2181971073150635</span><span class="token punctuation">]</span>
Mean Time: <span class="token number">1.32</span> seconds
Standard Deviation: <span class="token number">0.11</span> seconds
</code></pre><h3 id="second-experiment">Second Experiment </h3>
<pre data-role="codeBlock" data-info="python" class="language-python python"><code>repeats <span class="token operator">=</span> <span class="token number">5</span>
matrix_size <span class="token operator">=</span> <span class="token number">4000</span>
</code></pre><p>Workstation Slurm.</p>
<pre data-role="codeBlock" data-info="bash" class="language-bash bash"><code>Raw Data: <span class="token punctuation">[</span><span class="token number">2717.3176045417786</span>, <span class="token number">2077.3530197143555</span>, <span class="token number">2640.1949455738068</span>, <span class="token number">2294.7787528038025</span>, <span class="token number">2614.683986902237</span><span class="token punctuation">]</span>
Mean Time: <span class="token number">2468.87</span> seconds
Standard Deviation: <span class="token number">243.28</span> seconds
</code></pre><p>Delta Slurm</p>
<pre data-role="codeBlock" data-info="bash" class="language-bash bash"><code>Raw Data: <span class="token punctuation">[</span><span class="token number">15.837791681289673</span>, <span class="token number">9.31566071510315</span>, <span class="token number">12.116915702819824</span>, <span class="token number">9.68659520149231</span>, <span class="token number">9.873022317886353</span><span class="token punctuation">]</span>
Mean Time: <span class="token number">11.37</span> seconds
Standard Deviation: <span class="token number">2.44</span> seconds
</code></pre><h2 id="20241025---rtx6000-ada-vs-a40">2024.10.25 - RTX6000 Ada vs A40 </h2>
<p><a href="https://docs.ncsa.illinois.edu/systems/delta/en/latest/index.html">Delta Cluster</a> has A40 gpus available which I used for these comparisons. The speed differences are concerning considering RTX6000 should be faster. Maybe the difference is due to slow data loading from cpus... I copy paste the start of model training. The thing to pay attention to is that the models are the same size and we are training on the same data. These scripts use <code>pytorch</code>, and <code>pytorch lightning</code>. They are the exact same scripts with the same configuration and we see significant differences in training perfoormance. Can skip to the bottom of the code block to see summaries of times differences.</p>
<h3 id="20241025---rtx6000-ada---slow">2024.10.25 - RTX6000 Ada - Slow </h3>
<pre data-role="codeBlock" data-info="bash" class="language-bash bash"><code><span class="token punctuation">(</span>torchcell<span class="token punctuation">)</span> michaelvolk@gilahyper torchcell % <span class="token assign-left variable">CUDA_VISIBLE_DEVICES</span><span class="token operator">=</span><span class="token number">0</span> wandb agent zhao-group/torchcell_003-fit-int_cell_diffpool_dense_5e4/5psxol79
wandb: Starting wandb agent 🕵️
<span class="token number">2024</span>-10-24 <span class="token number">15</span>:05:39,157 - wandb.wandb_agent - INFO - Running runs: <span class="token punctuation">[</span><span class="token punctuation">]</span>
<span class="token number">2024</span>-10-24 <span class="token number">15</span>:05:39,556 - wandb.wandb_agent - INFO - Agent received command: run
<span class="token number">2024</span>-10-24 <span class="token number">15</span>:05:39,556 - wandb.wandb_agent - INFO - Agent starting run with config:
        cell_dataset: <span class="token punctuation">{</span><span class="token string">'graphs'</span><span class="token builtin class-name">:</span> <span class="token punctuation">[</span><span class="token string">'physical'</span>, <span class="token string">'regulatory'</span><span class="token punctuation">]</span>, <span class="token string">'node_embeddings'</span><span class="token builtin class-name">:</span> <span class="token punctuation">[</span><span class="token string">'codon_frequency'</span><span class="token punctuation">]</span><span class="token punctuation">}</span>
        data_module: <span class="token punctuation">{</span><span class="token string">'batch_size'</span><span class="token builtin class-name">:</span> <span class="token number">6</span>, <span class="token string">'is_perturbation_subset'</span><span class="token builtin class-name">:</span> True, <span class="token string">'num_workers'</span><span class="token builtin class-name">:</span> <span class="token number">6</span>, <span class="token string">'perturbation_subset_size'</span><span class="token builtin class-name">:</span> <span class="token number">50000</span>, <span class="token string">'pin_memory'</span><span class="token builtin class-name">:</span> True, <span class="token string">'prefetch'</span><span class="token builtin class-name">:</span> True<span class="token punctuation">}</span>
        model: <span class="token punctuation">{</span><span class="token string">'activation'</span><span class="token builtin class-name">:</span> <span class="token string">'relu'</span>, <span class="token string">'cluster_size_decay_factor'</span><span class="token builtin class-name">:</span> <span class="token number">6</span>, <span class="token string">'concat'</span><span class="token builtin class-name">:</span> False, <span class="token string">'dropout'</span><span class="token builtin class-name">:</span> <span class="token number">0.2</span>, <span class="token string">'embed_gat_hidden_channels'</span><span class="token builtin class-name">:</span> <span class="token number">4</span>, <span class="token string">'heads'</span><span class="token builtin class-name">:</span> <span class="token number">1</span>, <span class="token string">'norm'</span><span class="token builtin class-name">:</span> <span class="token string">'batch'</span>, <span class="token string">'num_embed_gat_layers'</span><span class="token builtin class-name">:</span> <span class="token number">2</span>, <span class="token string">'num_pool_gat_layers'</span><span class="token builtin class-name">:</span> <span class="token number">2</span>, <span class="token string">'num_pooling_layers'</span><span class="token builtin class-name">:</span> <span class="token number">5</span>, <span class="token string">'pool_gat_hidden_channels'</span><span class="token builtin class-name">:</span> <span class="token number">4</span>, <span class="token string">'target_dim'</span><span class="token builtin class-name">:</span> <span class="token number">2</span><span class="token punctuation">}</span>
        regression_task: <span class="token punctuation">{</span><span class="token string">'boxplot_every_n_epochs'</span><span class="token builtin class-name">:</span> <span class="token number">1</span>, <span class="token string">'clip_grad_norm'</span><span class="token builtin class-name">:</span> True, <span class="token string">'clip_grad_norm_max_norm'</span><span class="token builtin class-name">:</span> <span class="token number">0.1</span>, <span class="token string">'cluster_loss_weight'</span><span class="token builtin class-name">:</span> <span class="token number">1</span>, <span class="token string">'entropy_loss_weight'</span><span class="token builtin class-name">:</span> <span class="token number">0.1</span>, <span class="token string">'grad_accumulation_schedule'</span><span class="token builtin class-name">:</span> None, <span class="token string">'link_pred_loss_weight'</span><span class="token builtin class-name">:</span> <span class="token number">0.1</span>, <span class="token string">'loss_type'</span><span class="token builtin class-name">:</span> <span class="token string">'mse'</span>, <span class="token string">'lr_scheduler'</span><span class="token builtin class-name">:</span> <span class="token punctuation">{</span><span class="token string">'cooldown'</span><span class="token builtin class-name">:</span> <span class="token number">2</span>, <span class="token string">'eps'</span><span class="token builtin class-name">:</span> 1e-10, <span class="token string">'factor'</span><span class="token builtin class-name">:</span> <span class="token number">0.2</span>, <span class="token string">'min_lr'</span><span class="token builtin class-name">:</span> 1e-09, <span class="token string">'mode'</span><span class="token builtin class-name">:</span> <span class="token string">'min'</span>, <span class="token string">'patience'</span><span class="token builtin class-name">:</span> <span class="token number">3</span>, <span class="token string">'threshold'</span><span class="token builtin class-name">:</span> <span class="token number">0.0001</span>, <span class="token string">'threshold_mode'</span><span class="token builtin class-name">:</span> <span class="token string">'rel'</span>, <span class="token string">'type'</span><span class="token builtin class-name">:</span> <span class="token string">'ReduceLROnPlateau'</span><span class="token punctuation">}</span>, <span class="token string">'optimizer'</span><span class="token builtin class-name">:</span> <span class="token punctuation">{</span><span class="token string">'lr'</span><span class="token builtin class-name">:</span> 1e-05, <span class="token string">'type'</span><span class="token builtin class-name">:</span> <span class="token string">'AdamW'</span>, <span class="token string">'weight_decay'</span><span class="token builtin class-name">:</span> <span class="token number">0.0001</span><span class="token punctuation">}</span><span class="token punctuation">}</span>
        trainer: <span class="token punctuation">{</span><span class="token string">'accelerator'</span><span class="token builtin class-name">:</span> <span class="token string">'gpu'</span>, <span class="token string">'devices'</span><span class="token builtin class-name">:</span> <span class="token string">'auto'</span>, <span class="token string">'max_epochs'</span><span class="token builtin class-name">:</span> <span class="token number">30</span>, <span class="token string">'strategy'</span><span class="token builtin class-name">:</span> <span class="token string">'auto'</span><span class="token punctuation">}</span>
<span class="token number">2024</span>-10-24 <span class="token number">15</span>:05:39,558 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python experiments/003-fit-int/scripts/cell_diffpool_dense.py
Starting GatDiffPool 🌋
wandb_cfg <span class="token punctuation">{</span><span class="token string">'hydra_logging'</span><span class="token builtin class-name">:</span> <span class="token punctuation">{</span><span class="token string">'loggers'</span><span class="token builtin class-name">:</span> <span class="token punctuation">{</span><span class="token string">'logging_example'</span><span class="token builtin class-name">:</span> <span class="token punctuation">{</span><span class="token string">'level'</span><span class="token builtin class-name">:</span> <span class="token string">'INFO'</span><span class="token punctuation">}</span><span class="token punctuation">}</span><span class="token punctuation">}</span>, <span class="token string">'wandb'</span><span class="token builtin class-name">:</span> <span class="token punctuation">{</span><span class="token string">'project'</span><span class="token builtin class-name">:</span> <span class="token string">'torchcell_test_cell_diffpool_dense'</span>, <span class="token string">'tags'</span><span class="token builtin class-name">:</span> <span class="token punctuation">[</span><span class="token punctuation">]</span><span class="token punctuation">}</span>, <span class="token string">'cell_dataset'</span><span class="token builtin class-name">:</span> <span class="token punctuation">{</span><span class="token string">'graphs'</span><span class="token builtin class-name">:</span> <span class="token punctuation">[</span><span class="token string">'physical'</span>, <span class="token string">'regulatory'</span><span class="token punctuation">]</span>, <span class="token string">'node_embeddings'</span><span class="token builtin class-name">:</span> <span class="token punctuation">[</span><span class="token string">'codon_frequency'</span><span class="token punctuation">]</span><span class="token punctuation">}</span>, <span class="token string">'data_module'</span><span class="token builtin class-name">:</span> <span class="token punctuation">{</span><span class="token string">'is_perturbation_subset'</span><span class="token builtin class-name">:</span> True, <span class="token string">'perturbation_subset_size'</span><span class="token builtin class-name">:</span> <span class="token number">50000.0</span>, <span class="token string">'num_workers'</span><span class="token builtin class-name">:</span> <span class="token number">10</span>, <span class="token string">'batch_size'</span><span class="token builtin class-name">:</span> <span class="token number">5</span>, <span class="token string">'pin_memory'</span><span class="token builtin class-name">:</span> True, <span class="token string">'prefetch'</span><span class="token builtin class-name">:</span> True<span class="token punctuation">}</span>, <span class="token string">'trainer'</span><span class="token builtin class-name">:</span> <span class="token punctuation">{</span><span class="token string">'max_epochs'</span><span class="token builtin class-name">:</span> <span class="token number">2</span>, <span class="token string">'strategy'</span><span class="token builtin class-name">:</span> <span class="token string">'auto'</span>, <span class="token string">'accelerator'</span><span class="token builtin class-name">:</span> <span class="token string">'gpu'</span>, <span class="token string">'devices'</span><span class="token builtin class-name">:</span> <span class="token number">1</span><span class="token punctuation">}</span>, <span class="token string">'model'</span><span class="token builtin class-name">:</span> <span class="token punctuation">{</span><span class="token string">'pool_gat_hidden_channels'</span><span class="token builtin class-name">:</span> <span class="token number">16</span>, <span class="token string">'num_pool_gat_layers'</span><span class="token builtin class-name">:</span> <span class="token number">2</span>, <span class="token string">'embed_gat_hidden_channels'</span><span class="token builtin class-name">:</span> <span class="token number">16</span>, <span class="token string">'num_embed_gat_layers'</span><span class="token builtin class-name">:</span> <span class="token number">2</span>, <span class="token string">'num_pooling_layers'</span><span class="token builtin class-name">:</span> <span class="token number">5</span>, <span class="token string">'cluster_size_decay_factor'</span><span class="token builtin class-name">:</span> <span class="token number">5.0</span>, <span class="token string">'activation'</span><span class="token builtin class-name">:</span> <span class="token string">'relu'</span>, <span class="token string">'norm'</span><span class="token builtin class-name">:</span> <span class="token string">'batch'</span>, <span class="token string">'target_dim'</span><span class="token builtin class-name">:</span> <span class="token number">2</span>, <span class="token string">'heads'</span><span class="token builtin class-name">:</span> <span class="token number">1</span>, <span class="token string">'concat'</span><span class="token builtin class-name">:</span> False, <span class="token string">'dropout'</span><span class="token builtin class-name">:</span> <span class="token number">0.1</span><span class="token punctuation">}</span>, <span class="token string">'regression_task'</span><span class="token builtin class-name">:</span> <span class="token punctuation">{</span><span class="token string">'loss_type'</span><span class="token builtin class-name">:</span> <span class="token string">'mse'</span>, <span class="token string">'optimizer'</span><span class="token builtin class-name">:</span> <span class="token punctuation">{</span><span class="token string">'type'</span><span class="token builtin class-name">:</span> <span class="token string">'AdamW'</span>, <span class="token string">'lr'</span><span class="token builtin class-name">:</span> 1e-05, <span class="token string">'weight_decay'</span><span class="token builtin class-name">:</span> <span class="token number">0.0001</span><span class="token punctuation">}</span>, <span class="token string">'lr_scheduler'</span><span class="token builtin class-name">:</span> <span class="token punctuation">{</span><span class="token string">'type'</span><span class="token builtin class-name">:</span> <span class="token string">'ReduceLROnPlateau'</span>, <span class="token string">'mode'</span><span class="token builtin class-name">:</span> <span class="token string">'min'</span>, <span class="token string">'factor'</span><span class="token builtin class-name">:</span> <span class="token number">0.2</span>, <span class="token string">'patience'</span><span class="token builtin class-name">:</span> <span class="token number">3</span>, <span class="token string">'threshold'</span><span class="token builtin class-name">:</span> <span class="token number">0.0001</span>, <span class="token string">'threshold_mode'</span><span class="token builtin class-name">:</span> <span class="token string">'rel'</span>, <span class="token string">'cooldown'</span><span class="token builtin class-name">:</span> <span class="token number">2</span>, <span class="token string">'min_lr'</span><span class="token builtin class-name">:</span> 1e-09, <span class="token string">'eps'</span><span class="token builtin class-name">:</span> 1e-10<span class="token punctuation">}</span>, <span class="token string">'boxplot_every_n_epochs'</span><span class="token builtin class-name">:</span> <span class="token number">1</span>, <span class="token string">'clip_grad_norm'</span><span class="token builtin class-name">:</span> True, <span class="token string">'clip_grad_norm_max_norm'</span><span class="token builtin class-name">:</span> <span class="token number">1.0</span>, <span class="token string">'cluster_loss_weight'</span><span class="token builtin class-name">:</span> <span class="token number">1.0</span>, <span class="token string">'link_pred_loss_weight'</span><span class="token builtin class-name">:</span> <span class="token number">1.0</span>, <span class="token string">'entropy_loss_weight'</span><span class="token builtin class-name">:</span> <span class="token number">1.0</span>, <span class="token string">'grad_accumulation_schedule'</span><span class="token builtin class-name">:</span> None<span class="token punctuation">}</span><span class="token punctuation">}</span>
<span class="token number">2024</span>-10-24 <span class="token number">15</span>:05:44,578 - wandb.wandb_agent - INFO - Running runs: <span class="token punctuation">[</span><span class="token string">'l3ldupxp'</span><span class="token punctuation">]</span>
wandb: WARNING Ignored wandb.init<span class="token punctuation">(</span><span class="token punctuation">)</span> arg project when running a sweep.
wandb: Tracking run with wandb version <span class="token number">0.18</span>.3
wandb: W<span class="token operator">&amp;</span>B syncing is <span class="token builtin class-name">set</span> to <span class="token variable"><span class="token variable">`</span>offline<span class="token variable">`</span></span> <span class="token keyword keyword-in">in</span> this directory.  
wandb: Run <span class="token variable"><span class="token variable">`</span>wandb online<span class="token variable">`</span></span> or <span class="token builtin class-name">set</span> <span class="token assign-left variable">WANDB_MODE</span><span class="token operator">=</span>online to <span class="token builtin class-name">enable</span> cloud syncing.
data/go/go.obo: fmt<span class="token punctuation">(</span><span class="token number">1.2</span><span class="token punctuation">)</span> rel<span class="token punctuation">(</span><span class="token number">2024</span>-09-08<span class="token punctuation">)</span> <span class="token number">44,296</span> Terms
/home/michaelvolk/Documents/projects/torchcell/torchcell/data/embedding.py:34: FutureWarning: You are using <span class="token variable"><span class="token variable">`</span>torch.load<span class="token variable">`</span></span> with <span class="token variable"><span class="token variable">`</span><span class="token assign-left variable">weights_only</span><span class="token operator">=</span>False<span class="token variable">`</span></span> <span class="token punctuation">(</span>the current default value<span class="token punctuation">)</span>, <span class="token function">which</span> uses the default pickle module implicitly. It is possible to construct malicious pickle data <span class="token function">which</span> will execute arbitrary code during unpickling <span class="token punctuation">(</span>See https://github.com/pytorch/pytorch/blob/main/SECURITY.md<span class="token comment">#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.</span>
  self.data, self.slices <span class="token operator">=</span> torch.load<span class="token punctuation">(</span>
<span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">=</span>
node.embeddings
<span class="token punctuation">{</span><span class="token string">'codon_frequency'</span><span class="token builtin class-name">:</span> CodonFrequencyDataset<span class="token punctuation">(</span><span class="token number">6607</span><span class="token punctuation">)</span><span class="token punctuation">}</span>
<span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">=</span>
<span class="token punctuation">[</span><span class="token number">2024</span>-10-24 <span class="token number">15</span>:06:06,702<span class="token punctuation">]</span><span class="token punctuation">[</span>torchcell.datamodules.cell<span class="token punctuation">]</span><span class="token punctuation">[</span>INFO<span class="token punctuation">]</span> - Loading index from /scratch/projects/torchcell/data/torchcell/experiments/003-fit-int/001-small-build/data_module_cache/index_seed_42.json
<span class="token punctuation">[</span><span class="token number">2024</span>-10-24 <span class="token number">15</span>:06:07,367<span class="token punctuation">]</span><span class="token punctuation">[</span>torchcell.datamodules.cell<span class="token punctuation">]</span><span class="token punctuation">[</span>INFO<span class="token punctuation">]</span> - Loading index details from /scratch/projects/torchcell/data/torchcell/experiments/003-fit-int/001-small-build/data_module_cache/index_details_seed_42.json
Setting up PerturbationSubsetDataModule<span class="token punctuation">..</span>.
Creating subset datasets<span class="token punctuation">..</span>.
Setup complete.
Cluster sizes: <span class="token punctuation">[</span><span class="token number">1096</span>, <span class="token number">182</span>, <span class="token number">30</span>, <span class="token number">5</span>, <span class="token number">1</span><span class="token punctuation">]</span>
Cluster sizes: <span class="token punctuation">[</span><span class="token number">1096</span>, <span class="token number">182</span>, <span class="token number">30</span>, <span class="token number">5</span>, <span class="token number">1</span><span class="token punctuation">]</span>
Parameters per model: <span class="token number">12,906</span>
Expected total parameters: <span class="token number">25,842</span>
Actual total parameters: <span class="token number">25,842</span>
/home/michaelvolk/miniconda3/envs/torchcell/lib/python3.11/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: Metric <span class="token variable"><span class="token variable">`</span>SpearmanCorrcoef<span class="token variable">`</span></span> will save all targets and predictions <span class="token keyword keyword-in">in</span> the buffer. For large datasets, this may lead to large memory footprint.
  warnings.warn<span class="token punctuation">(</span>*args, **kwargs<span class="token punctuation">)</span>  <span class="token comment"># noqa: B028</span>
<span class="token punctuation">[</span><span class="token number">2024</span>-10-24 <span class="token number">15</span>:06:11,202<span class="token punctuation">]</span><span class="token punctuation">[</span>__main__<span class="token punctuation">]</span><span class="token punctuation">[</span>INFO<span class="token punctuation">]</span> - cuda
devices: <span class="token number">1</span>
/home/michaelvolk/miniconda3/envs/torchcell/lib/python3.11/site-packages/lightning/fabric/plugins/environments/slurm.py:204: The <span class="token variable"><span class="token variable">`</span>srun<span class="token variable">`</span></span> <span class="token builtin class-name">command</span> is available on your system but is not used. HINT: If your intention is to run Lightning on SLURM, prepend your python <span class="token builtin class-name">command</span> with <span class="token variable"><span class="token variable">`</span>srun<span class="token variable">`</span></span> like so: srun python experiments/003-fit-int/scripts/cell_diffpool_dense. <span class="token punctuation">..</span>.
GPU available: True <span class="token punctuation">(</span>cuda<span class="token punctuation">)</span>, used: True
TPU available: False, using: <span class="token number">0</span> TPU cores
HPU available: False, using: <span class="token number">0</span> HPUs
/home/michaelvolk/miniconda3/envs/torchcell/lib/python3.11/site-packages/lightning/pytorch/loggers/wandb.py:396: There is a wandb run already <span class="token keyword keyword-in">in</span> progress and newly created instances of <span class="token variable"><span class="token variable">`</span>WandbLogger<span class="token variable">`</span></span> will reuse this run. If this is not desired, call <span class="token variable"><span class="token variable">`</span>wandb.finish<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token variable">`</span></span> before instantiating <span class="token variable"><span class="token variable">`</span>WandbLogger<span class="token variable">`</span></span><span class="token builtin class-name">.</span>
Setting up PerturbationSubsetDataModule<span class="token punctuation">..</span>.
Creating subset datasets<span class="token punctuation">..</span>.
Setup complete.
LOCAL_RANK: <span class="token number">0</span> - CUDA_VISIBLE_DEVICES: <span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span>
/home/michaelvolk/miniconda3/envs/torchcell/lib/python3.11/site-packages/lightning/pytorch/core/optimizer.py:316: The lr scheduler dict contains the key<span class="token punctuation">(</span>s<span class="token punctuation">)</span> <span class="token punctuation">[</span><span class="token string">'monitor'</span><span class="token punctuation">]</span>, but the keys will be ignored. You need to call <span class="token variable"><span class="token variable">`</span>lr_scheduler.step<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token variable">`</span></span> manually <span class="token keyword keyword-in">in</span> manual optimization.

  <span class="token operator">|</span> Name          <span class="token operator">|</span> Type              <span class="token operator">|</span> Params <span class="token operator">|</span> Mode 
------------------------------------------------------------
<span class="token number">0</span> <span class="token operator">|</span> model         <span class="token operator">|</span> DenseCellDiffPool <span class="token operator">|</span> <span class="token number">25.8</span> K <span class="token operator">|</span> train
<span class="token number">1</span> <span class="token operator">|</span> combined_loss <span class="token operator">|</span> CombinedLoss      <span class="token operator">|</span> <span class="token number">0</span>      <span class="token operator">|</span> train
<span class="token number">2</span> <span class="token operator">|</span> train_metrics <span class="token operator">|</span> ModuleDict        <span class="token operator">|</span> <span class="token number">0</span>      <span class="token operator">|</span> train
<span class="token number">3</span> <span class="token operator">|</span> val_metrics   <span class="token operator">|</span> ModuleDict        <span class="token operator">|</span> <span class="token number">0</span>      <span class="token operator">|</span> train
<span class="token number">4</span> <span class="token operator">|</span> test_metrics  <span class="token operator">|</span> ModuleDict        <span class="token operator">|</span> <span class="token number">0</span>      <span class="token operator">|</span> train
------------------------------------------------------------
<span class="token number">25.8</span> K    Trainable params
<span class="token number">0</span>         Non-trainable params
<span class="token number">25.8</span> K    Total params
<span class="token number">0.103</span>     Total estimated model params size <span class="token punctuation">(</span>MB<span class="token punctuation">)</span>
<span class="token number">219</span>       Modules <span class="token keyword keyword-in">in</span> train mode
<span class="token number">0</span>         Modules <span class="token keyword keyword-in">in</span> <span class="token builtin class-name">eval</span> mode
Sanity Checking DataLoader <span class="token number">0</span>:   <span class="token number">0</span>%<span class="token operator">|</span>                          <span class="token operator">|</span> <span class="token number">0</span>/2 <span class="token punctuation">[</span>00:0<span class="token operator"><span class="token file-descriptor important">0</span>&lt;</span>?, ?it/s<span class="token punctuation">]</span>/home/michaelvolk/miniconda3/envs/torchcell/lib/python3.11/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: The variance of predictions or target is close to zero. This can cause instability <span class="token keyword keyword-in">in</span> Pearson correlationcoefficient, leading to wrong results. Consider re-scaling the input <span class="token keyword keyword-if">if</span> possible or computing using alarger dtype <span class="token punctuation">(</span>currently using torch.float32<span class="token punctuation">)</span>.
  warnings.warn<span class="token punctuation">(</span>*args, **kwargs<span class="token punctuation">)</span>  <span class="token comment"># noqa: B028</span>
Epoch <span class="token number">0</span>:  <span class="token number">11</span>%<span class="token operator">|</span>█▊               <span class="token operator">|</span> <span class="token number">723</span>/6667 <span class="token punctuation">[</span><span class="token number">9</span>:07:2<span class="token operator"><span class="token file-descriptor important">6</span>&lt;</span><span class="token number">75</span>:00:39,  <span class="token number">0</span>.02it/s, <span class="token assign-left variable">v_num</span><span class="token operator">=</span>upxp<span class="token punctuation">]</span>
</code></pre><p>Projected total time after time stabilized - 84 hrs (0.02 it/s)</p>
<h3 id="20241025---a40---fast">2024.10.25 - A40 - Fast </h3>
<pre data-role="codeBlock" data-info="bash" class="language-bash bash"><code><span class="token number">2024</span>-10-24 <span class="token number">18</span>:37:01,534 - wandb.wandb_agent - INFO - Running runs: <span class="token punctuation">[</span><span class="token punctuation">]</span>
<span class="token number">2024</span>-10-24 <span class="token number">18</span>:37:02,077 - wandb.wandb_agent - INFO - Agent received command: run
<span class="token number">2024</span>-10-24 <span class="token number">18</span>:37:02,077 - wandb.wandb_agent - INFO - Agent starting run with config:
 cell_dataset: <span class="token punctuation">{</span><span class="token string">'graphs'</span><span class="token builtin class-name">:</span> <span class="token punctuation">[</span><span class="token string">'physical'</span>, <span class="token string">'regulatory'</span><span class="token punctuation">]</span>, <span class="token string">'node_embeddings'</span><span class="token builtin class-name">:</span> <span class="token punctuation">[</span><span class="token string">'codon_frequency'</span><span class="token punctuation">]</span><span class="token punctuation">}</span>
 data_module: <span class="token punctuation">{</span><span class="token string">'batch_size'</span><span class="token builtin class-name">:</span> <span class="token number">4</span>, <span class="token string">'is_perturbation_subset'</span><span class="token builtin class-name">:</span> True, <span class="token string">'num_workers'</span><span class="token builtin class-name">:</span> <span class="token number">4</span>, <span class="token string">'perturbation_subset_size'</span><span class="token builtin class-name">:</span> <span class="token number">50000</span>, <span class="token string">'pin_memory'</span><span class="token builtin class-name">:</span> True, <span class="token string">'prefetch'</span><span class="token builtin class-name">:</span> True<span class="token punctuation">}</span>
 model: <span class="token punctuation">{</span><span class="token string">'activation'</span><span class="token builtin class-name">:</span> <span class="token string">'relu'</span>, <span class="token string">'cluster_size_decay_factor'</span><span class="token builtin class-name">:</span> <span class="token number">6</span>, <span class="token string">'concat'</span><span class="token builtin class-name">:</span> False, <span class="token string">'dropout'</span><span class="token builtin class-name">:</span> <span class="token number">0.2</span>, <span class="token string">'embed_gat_hidden_channels'</span><span class="token builtin class-name">:</span> <span class="token number">4</span>, <span class="token string">'heads'</span><span class="token builtin class-name">:</span> <span class="token number">1</span>, <span class="token string">'norm'</span><span class="token builtin class-name">:</span> <span class="token string">'batch'</span>, <span class="token string">'num_embed_gat_layers'</span><span class="token builtin class-name">:</span> <span class="token number">2</span>, <span class="token string">'num_pool_gat_layers'</span><span class="token builtin class-name">:</span> <span class="token number">2</span>, <span class="token string">'num_pooling_layers'</span><span class="token builtin class-name">:</span> <span class="token number">5</span>, <span class="token string">'pool_gat_hidden_channels'</span><span class="token builtin class-name">:</span> <span class="token number">4</span>, <span class="token string">'target_dim'</span><span class="token builtin class-name">:</span> <span class="token number">2</span><span class="token punctuation">}</span>
 regression_task: <span class="token punctuation">{</span><span class="token string">'boxplot_every_n_epochs'</span><span class="token builtin class-name">:</span> <span class="token number">1</span>, <span class="token string">'clip_grad_norm'</span><span class="token builtin class-name">:</span> True, <span class="token string">'clip_grad_norm_max_norm'</span><span class="token builtin class-name">:</span> <span class="token number">0.1</span>, <span class="token string">'cluster_loss_weight'</span><span class="token builtin class-name">:</span> <span class="token number">0.1</span>, <span class="token string">'entropy_loss_weight'</span><span class="token builtin class-name">:</span> <span class="token number">0.1</span>, <span class="token string">'grad_accumulation_schedule'</span><span class="token builtin class-name">:</span> None, <span class="token string">'link_pred_loss_weight'</span><span class="token builtin class-name">:</span> <span class="token number">0.1</span>, <span class="token string">'loss_type'</span><span class="token builtin class-name">:</span> <span class="token string">'mse'</span>, <span class="token string">'lr_scheduler'</span><span class="token builtin class-name">:</span> <span class="token punctuation">{</span><span class="token string">'cooldown'</span><span class="token builtin class-name">:</span> <span class="token number">2</span>, <span class="token string">'eps'</span><span class="token builtin class-name">:</span> 1e-10, <span class="token string">'factor'</span><span class="token builtin class-name">:</span> <span class="token number">0.2</span>, <span class="token string">'min_lr'</span><span class="token builtin class-name">:</span> 1e-09, <span class="token string">'mode'</span><span class="token builtin class-name">:</span> <span class="token string">'min'</span>, <span class="token string">'patience'</span><span class="token builtin class-name">:</span> <span class="token number">3</span>, <span class="token string">'threshold'</span><span class="token builtin class-name">:</span> <span class="token number">0.0001</span>, <span class="token string">'threshold_mode'</span><span class="token builtin class-name">:</span> <span class="token string">'rel'</span>, <span class="token string">'type'</span><span class="token builtin class-name">:</span> <span class="token string">'ReduceLROnPlateau'</span><span class="token punctuation">}</span>, <span class="token string">'optimizer'</span><span class="token builtin class-name">:</span> <span class="token punctuation">{</span><span class="token string">'lr'</span><span class="token builtin class-name">:</span> <span class="token number">0.0001</span>, <span class="token string">'type'</span><span class="token builtin class-name">:</span> <span class="token string">'AdamW'</span>, <span class="token string">'weight_decay'</span><span class="token builtin class-name">:</span> <span class="token number">0.0001</span><span class="token punctuation">}</span><span class="token punctuation">}</span>
 trainer: <span class="token punctuation">{</span><span class="token string">'accelerator'</span><span class="token builtin class-name">:</span> <span class="token string">'gpu'</span>, <span class="token string">'devices'</span><span class="token builtin class-name">:</span> <span class="token string">'auto'</span>, <span class="token string">'max_epochs'</span><span class="token builtin class-name">:</span> <span class="token number">5</span>, <span class="token string">'strategy'</span><span class="token builtin class-name">:</span> <span class="token string">'auto'</span><span class="token punctuation">}</span>
<span class="token number">2024</span>-10-24 <span class="token number">18</span>:37:02,105 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python experiments/003-fit-int/scripts/cell_diffpool_dense.py
<span class="token number">2024</span>-10-24 <span class="token number">18</span>:37:07,117 - wandb.wandb_agent - INFO - Running runs: <span class="token punctuation">[</span><span class="token string">'xlv4olh3'</span><span class="token punctuation">]</span>
wandb: WARNING Ignored wandb.init<span class="token punctuation">(</span><span class="token punctuation">)</span> arg project when running a sweep.
wandb: Tracking run with wandb version <span class="token number">0.16</span>.0
wandb: W<span class="token operator">&amp;</span>B syncing is <span class="token builtin class-name">set</span> to <span class="token variable"><span class="token variable">`</span>offline<span class="token variable">`</span></span> <span class="token keyword keyword-in">in</span> this directory.  
wandb: Run <span class="token variable"><span class="token variable">`</span>wandb online<span class="token variable">`</span></span> or <span class="token builtin class-name">set</span> <span class="token assign-left variable">WANDB_MODE</span><span class="token operator">=</span>online to <span class="token builtin class-name">enable</span> cloud syncing.
Starting GatDiffPool 🌋
wandb_cfg <span class="token punctuation">{</span><span class="token string">'hydra_logging'</span><span class="token builtin class-name">:</span> <span class="token punctuation">{</span><span class="token string">'loggers'</span><span class="token builtin class-name">:</span> <span class="token punctuation">{</span><span class="token string">'logging_example'</span><span class="token builtin class-name">:</span> <span class="token punctuation">{</span><span class="token string">'level'</span><span class="token builtin class-name">:</span> <span class="token string">'INFO'</span><span class="token punctuation">}</span><span class="token punctuation">}</span><span class="token punctuation">}</span>, <span class="token string">'wandb'</span><span class="token builtin class-name">:</span> <span class="token punctuation">{</span><span class="token string">'project'</span><span class="token builtin class-name">:</span> <span class="token string">'torchcell_test_cell_diffpool_dense'</span>, <span class="token string">'tags'</span><span class="token builtin class-name">:</span> <span class="token punctuation">[</span><span class="token punctuation">]</span><span class="token punctuation">}</span>, <span class="token string">'cell_dataset'</span><span class="token builtin class-name">:</span> <span class="token punctuation">{</span><span class="token string">'graphs'</span><span class="token builtin class-name">:</span> <span class="token punctuation">[</span><span class="token string">'physical'</span>, <span class="token string">'regulatory'</span><span class="token punctuation">]</span>, <span class="token string">'node_embeddings'</span><span class="token builtin class-name">:</span> <span class="token punctuation">[</span><span class="token string">'codon_frequency'</span><span class="token punctuation">]</span><span class="token punctuation">}</span>, <span class="token string">'data_module'</span><span class="token builtin class-name">:</span> <span class="token punctuation">{</span><span class="token string">'is_perturbation_subset'</span><span class="token builtin class-name">:</span> True, <span class="token string">'perturbation_subset_size'</span><span class="token builtin class-name">:</span> <span class="token number">50000.0</span>, <span class="token string">'batch_size'</span><span class="token builtin class-name">:</span> <span class="token number">6</span>, <span class="token string">'num_workers'</span><span class="token builtin class-name">:</span> <span class="token number">6</span>, <span class="token string">'pin_memory'</span><span class="token builtin class-name">:</span> True, <span class="token string">'prefetch'</span><span class="token builtin class-name">:</span> True<span class="token punctuation">}</span>, <span class="token string">'trainer'</span><span class="token builtin class-name">:</span> <span class="token punctuation">{</span><span class="token string">'max_epochs'</span><span class="token builtin class-name">:</span> <span class="token number">2</span>, <span class="token string">'strategy'</span><span class="token builtin class-name">:</span> <span class="token string">'auto'</span>, <span class="token string">'accelerator'</span><span class="token builtin class-name">:</span> <span class="token string">'gpu'</span>, <span class="token string">'devices'</span><span class="token builtin class-name">:</span> <span class="token number">1</span><span class="token punctuation">}</span>, <span class="token string">'model'</span><span class="token builtin class-name">:</span> <span class="token punctuation">{</span><span class="token string">'pool_gat_hidden_channels'</span><span class="token builtin class-name">:</span> <span class="token number">16</span>, <span class="token string">'num_pool_gat_layers'</span><span class="token builtin class-name">:</span> <span class="token number">2</span>, <span class="token string">'embed_gat_hidden_channels'</span><span class="token builtin class-name">:</span> <span class="token number">16</span>, <span class="token string">'num_embed_gat_layers'</span><span class="token builtin class-name">:</span> <span class="token number">2</span>, <span class="token string">'num_pooling_layers'</span><span class="token builtin class-name">:</span> <span class="token number">5</span>, <span class="token string">'cluster_size_decay_factor'</span><span class="token builtin class-name">:</span> <span class="token number">5.0</span>, <span class="token string">'activation'</span><span class="token builtin class-name">:</span> <span class="token string">'relu'</span>, <span class="token string">'norm'</span><span class="token builtin class-name">:</span> <span class="token string">'batch'</span>, <span class="token string">'target_dim'</span><span class="token builtin class-name">:</span> <span class="token number">2</span>, <span class="token string">'heads'</span><span class="token builtin class-name">:</span> <span class="token number">1</span>, <span class="token string">'concat'</span><span class="token builtin class-name">:</span> False, <span class="token string">'dropout'</span><span class="token builtin class-name">:</span> <span class="token number">0.1</span><span class="token punctuation">}</span>, <span class="token string">'regression_task'</span><span class="token builtin class-name">:</span> <span class="token punctuation">{</span><span class="token string">'loss_type'</span><span class="token builtin class-name">:</span> <span class="token string">'mse'</span>, <span class="token string">'optimizer'</span><span class="token builtin class-name">:</span> <span class="token punctuation">{</span><span class="token string">'type'</span><span class="token builtin class-name">:</span> <span class="token string">'AdamW'</span>, <span class="token string">'lr'</span><span class="token builtin class-name">:</span> 1e-05, <span class="token string">'weight_decay'</span><span class="token builtin class-name">:</span> <span class="token number">0.0001</span><span class="token punctuation">}</span>, <span class="token string">'lr_scheduler'</span><span class="token builtin class-name">:</span> <span class="token punctuation">{</span><span class="token string">'type'</span><span class="token builtin class-name">:</span> <span class="token string">'ReduceLROnPlateau'</span>, <span class="token string">'mode'</span><span class="token builtin class-name">:</span> <span class="token string">'min'</span>, <span class="token string">'factor'</span><span class="token builtin class-name">:</span> <span class="token number">0.2</span>, <span class="token string">'patience'</span><span class="token builtin class-name">:</span> <span class="token number">3</span>, <span class="token string">'threshold'</span><span class="token builtin class-name">:</span> <span class="token number">0.0001</span>, <span class="token string">'threshold_mode'</span><span class="token builtin class-name">:</span> <span class="token string">'rel'</span>, <span class="token string">'cooldown'</span><span class="token builtin class-name">:</span> <span class="token number">2</span>, <span class="token string">'min_lr'</span><span class="token builtin class-name">:</span> 1e-09, <span class="token string">'eps'</span><span class="token builtin class-name">:</span> 1e-10<span class="token punctuation">}</span>, <span class="token string">'boxplot_every_n_epochs'</span><span class="token builtin class-name">:</span> <span class="token number">1</span>, <span class="token string">'clip_grad_norm'</span><span class="token builtin class-name">:</span> True, <span class="token string">'clip_grad_norm_max_norm'</span><span class="token builtin class-name">:</span> <span class="token number">1.0</span>, <span class="token string">'cluster_loss_weight'</span><span class="token builtin class-name">:</span> <span class="token number">1.0</span>, <span class="token string">'link_pred_loss_weight'</span><span class="token builtin class-name">:</span> <span class="token number">1.0</span>, <span class="token string">'entropy_loss_weight'</span><span class="token builtin class-name">:</span> <span class="token number">1.0</span>, <span class="token string">'grad_accumulation_schedule'</span><span class="token builtin class-name">:</span> None<span class="token punctuation">}</span><span class="token punctuation">}</span>
data/go/go.obo: fmt<span class="token punctuation">(</span><span class="token number">1.2</span><span class="token punctuation">)</span> rel<span class="token punctuation">(</span><span class="token number">2023</span>-07-27<span class="token punctuation">)</span> <span class="token number">46,356</span> Terms
<span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">=</span>
node.embeddings
<span class="token punctuation">{</span><span class="token string">'codon_frequency'</span><span class="token builtin class-name">:</span> CodonFrequencyDataset<span class="token punctuation">(</span><span class="token number">6607</span><span class="token punctuation">)</span><span class="token punctuation">}</span>
<span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">=</span>
<span class="token punctuation">[</span><span class="token number">2024</span>-10-24 <span class="token number">18</span>:38:56,501<span class="token punctuation">]</span><span class="token punctuation">[</span>torchcell.datamodules.cell<span class="token punctuation">]</span><span class="token punctuation">[</span>INFO<span class="token punctuation">]</span> - Loading index from /scratch/bbub/mjvolk3/torchcell/data/torchcell/experiments/003-fit-int/001-small-build/data_module_cache/index_seed_42.json
<span class="token punctuation">[</span><span class="token number">2024</span>-10-24 <span class="token number">18</span>:38:56,905<span class="token punctuation">]</span><span class="token punctuation">[</span>torchcell.datamodules.cell<span class="token punctuation">]</span><span class="token punctuation">[</span>INFO<span class="token punctuation">]</span> - Loading index details from /scratch/bbub/mjvolk3/torchcell/data/torchcell/experiments/003-fit-int/001-small-build/data_module_cache/index_details_seed_42.json
/scratch/bbub/miniconda3/envs/torchcell/lib/python3.11/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: Metric <span class="token variable"><span class="token variable">`</span>SpearmanCorrcoef<span class="token variable">`</span></span> will save all targets and predictions <span class="token keyword keyword-in">in</span> the buffer. For large datasets, this may lead to large memory footprint.
  warnings.warn<span class="token punctuation">(</span>*args, **kwargs<span class="token punctuation">)</span>  <span class="token comment"># noqa: B028</span>
Setting up PerturbationSubsetDataModule<span class="token punctuation">..</span>.
Creating subset datasets<span class="token punctuation">..</span>.
Setup complete.
Cluster sizes: <span class="token punctuation">[</span><span class="token number">1096</span>, <span class="token number">182</span>, <span class="token number">30</span>, <span class="token number">5</span>, <span class="token number">1</span><span class="token punctuation">]</span>
Cluster sizes: <span class="token punctuation">[</span><span class="token number">1096</span>, <span class="token number">182</span>, <span class="token number">30</span>, <span class="token number">5</span>, <span class="token number">1</span><span class="token punctuation">]</span>
Parameters per model: <span class="token number">12,906</span>
Expected total parameters: <span class="token number">25,842</span>
Actual total parameters: <span class="token number">25,842</span>
<span class="token punctuation">[</span><span class="token number">2024</span>-10-24 <span class="token number">18</span>:38:59,185<span class="token punctuation">]</span><span class="token punctuation">[</span>__main__<span class="token punctuation">]</span><span class="token punctuation">[</span>INFO<span class="token punctuation">]</span> - cuda
GPU available: True <span class="token punctuation">(</span>cuda<span class="token punctuation">)</span>, used: True
TPU available: False, using: <span class="token number">0</span> TPU cores
IPU available: False, using: <span class="token number">0</span> IPUs
HPU available: False, using: <span class="token number">0</span> HPUs
/scratch/bbub/miniconda3/envs/torchcell/lib/python3.11/site-packages/lightning/pytorch/loggers/wandb.py:389: There is a wandb run already <span class="token keyword keyword-in">in</span> progress and newly created instances of <span class="token variable"><span class="token variable">`</span>WandbLogger<span class="token variable">`</span></span> will reuse this run. If this is not desired, call <span class="token variable"><span class="token variable">`</span>wandb.finish<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token variable">`</span></span> before instantiating <span class="token variable"><span class="token variable">`</span>WandbLogger<span class="token variable">`</span></span><span class="token builtin class-name">.</span>
LOCAL_RANK: <span class="token number">0</span> - CUDA_VISIBLE_DEVICES: <span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span>
/scratch/bbub/miniconda3/envs/torchcell/lib/python3.11/site-packages/lightning/pytorch/core/optimizer.py:314: The lr scheduler dict contains the key<span class="token punctuation">(</span>s<span class="token punctuation">)</span> <span class="token punctuation">[</span><span class="token string">'monitor'</span><span class="token punctuation">]</span>, but the keys will be ignored. You need to call <span class="token variable"><span class="token variable">`</span>lr_scheduler.step<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token variable">`</span></span> manually <span class="token keyword keyword-in">in</span> manual optimization.

  <span class="token operator">|</span> Name          <span class="token operator">|</span> Type              <span class="token operator">|</span> Params
----------------------------------------------------
<span class="token number">0</span> <span class="token operator">|</span> model         <span class="token operator">|</span> DenseCellDiffPool <span class="token operator">|</span> <span class="token number">25.8</span> K
<span class="token number">1</span> <span class="token operator">|</span> combined_loss <span class="token operator">|</span> CombinedLoss      <span class="token operator">|</span> <span class="token number">0</span>     
<span class="token number">2</span> <span class="token operator">|</span> train_metrics <span class="token operator">|</span> ModuleDict        <span class="token operator">|</span> <span class="token number">0</span>     
<span class="token number">3</span> <span class="token operator">|</span> val_metrics   <span class="token operator">|</span> ModuleDict        <span class="token operator">|</span> <span class="token number">0</span>     
<span class="token number">4</span> <span class="token operator">|</span> test_metrics  <span class="token operator">|</span> ModuleDict        <span class="token operator">|</span> <span class="token number">0</span>     
----------------------------------------------------
<span class="token number">25.8</span> K    Trainable params
<span class="token number">0</span>         Non-trainable params
<span class="token number">25.8</span> K    Total params
<span class="token number">0.103</span>     Total estimated model params size <span class="token punctuation">(</span>MB<span class="token punctuation">)</span>
SLURM auto-requeueing enabled. Setting signal handlers.
devices: <span class="token number">1</span>
Setting up PerturbationSubsetDataModule<span class="token punctuation">..</span>.
Creating subset datasets<span class="token punctuation">..</span>.
Setup complete.

Sanity Checking: <span class="token operator">|</span>          <span class="token operator">|</span> <span class="token number">0</span>/? <span class="token punctuation">[</span>00:0<span class="token operator"><span class="token file-descriptor important">0</span>&lt;</span>?, ?it/s<span class="token punctuation">]</span>
Sanity Checking:   <span class="token number">0</span>%<span class="token operator">|</span>          <span class="token operator">|</span> <span class="token number">0</span>/2 <span class="token punctuation">[</span>00:0<span class="token operator"><span class="token file-descriptor important">0</span>&lt;</span>?, ?it/s<span class="token punctuation">]</span>
Sanity Checking DataLoader <span class="token number">0</span>:   <span class="token number">0</span>%<span class="token operator">|</span>          <span class="token operator">|</span> <span class="token number">0</span>/2 <span class="token punctuation">[</span>00:0<span class="token operator"><span class="token file-descriptor important">0</span>&lt;</span>?, ?it/s<span class="token punctuation">]</span>/scratch/bbub/miniconda3/envs/torchcell/lib/python3.11/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: The variance of predictions or target is close to zero. This can cause instability <span class="token keyword keyword-in">in</span> Pearson correlationcoefficient, leading to wrong results. Consider re-scaling the input <span class="token keyword keyword-if">if</span> possible or computing using alarger dtype <span class="token punctuation">(</span>currently using torch.float32<span class="token punctuation">)</span>.
  warnings.warn<span class="token punctuation">(</span>*args, **kwargs<span class="token punctuation">)</span>  <span class="token comment"># noqa: B028</span>

Sanity Checking DataLoader <span class="token number">0</span>:  <span class="token number">50</span>%<span class="token operator">|</span>█████     <span class="token operator">|</span> <span class="token number">1</span>/2 <span class="token punctuation">[</span>00:0<span class="token operator"><span class="token file-descriptor important">3</span>&lt;</span>00:03,  <span class="token number">0</span>.29it/s<span class="token punctuation">]</span>
Sanity Checking DataLoader <span class="token number">0</span>: <span class="token number">100</span>%<span class="token operator">|</span>██████████<span class="token operator">|</span> <span class="token number">2</span>/2 <span class="token punctuation">[</span>00:0<span class="token operator"><span class="token file-descriptor important">3</span>&lt;</span>00:00,  <span class="token number">0</span>.53it/s<span class="token punctuation">]</span>
                                                                           
Training: <span class="token operator">|</span>          <span class="token operator">|</span> <span class="token number">0</span>/? <span class="token punctuation">[</span>00:0<span class="token operator"><span class="token file-descriptor important">0</span>&lt;</span>?, ?it/s<span class="token punctuation">]</span>
Training:   <span class="token number">0</span>%<span class="token operator">|</span>          <span class="token operator">|</span> <span class="token number">0</span>/10001 <span class="token punctuation">[</span>00:0<span class="token operator"><span class="token file-descriptor important">0</span>&lt;</span>?, ?it/s<span class="token punctuation">]</span>
Epoch <span class="token number">0</span>:   <span class="token number">0</span>%<span class="token operator">|</span>          <span class="token operator">|</span> <span class="token number">0</span>/10001 <span class="token punctuation">[</span>00:0<span class="token operator"><span class="token file-descriptor important">0</span>&lt;</span>?, ?it/s<span class="token punctuation">]</span> 
Epoch <span class="token number">0</span>:   <span class="token number">0</span>%<span class="token operator">|</span>          <span class="token operator">|</span> <span class="token number">1</span>/10001 <span class="token punctuation">[</span>00:1<span class="token operator"><span class="token file-descriptor important">5</span>&lt;</span><span class="token number">41</span>:58:26,  <span class="token number">0</span>.07it/s<span class="token punctuation">]</span>
Epoch <span class="token number">0</span>:   <span class="token number">0</span>%<span class="token operator">|</span>          <span class="token operator">|</span> <span class="token number">1</span>/10001 <span class="token punctuation">[</span>00:1<span class="token operator"><span class="token file-descriptor important">5</span>&lt;</span><span class="token number">41</span>:58:38,  <span class="token number">0</span>.07it/s, <span class="token assign-left variable">v_num</span><span class="token operator">=</span>olh3<span class="token punctuation">]</span>
<span class="token operator">&lt;</span>----- DELETED <span class="token environment constant">LINES</span> FOR BREVITY ------<span class="token operator">&gt;</span>
Epoch <span class="token number">0</span>:  <span class="token number">27</span>%<span class="token operator">|</span>██▋       <span class="token operator">|</span> <span class="token number">2744</span>/10001 <span class="token punctuation">[</span><span class="token number">2</span>:16:0<span class="token operator"><span class="token file-descriptor important">5</span>&lt;</span><span class="token number">5</span>:59:55,  <span class="token number">0</span>.34it/s, <span class="token assign-left variable">v_num</span><span class="token operator">=</span>olh3<span class="token punctuation">]</span>
Epoch <span class="token number">0</span>:  <span class="token number">27</span>%<span class="token operator">|</span>██▋       <span class="token operator">|</span> <span class="token number">2744</span>/10001 <span class="token punctuation">[</span><span class="token number">2</span>:16:0<span class="token operator"><span class="token file-descriptor important">5</span>&lt;</span><span class="token number">5</span>:59:55,  <span class="token number">0</span>.34it/s, <span class="token assign-left variable">v_num</span><span class="token operator">=</span>olh3<span class="token punctuation">]</span>
Epoch <span class="token number">0</span>:  <span class="token number">27</span>%<span class="token operator">|</span>██▋       <span class="token operator">|</span> <span class="token number">2745</span>/10001 <span class="token punctuation">[</span><span class="token number">2</span>:16:1<span class="token operator"><span class="token file-descriptor important">0</span>&lt;</span><span class="token number">5</span>:59:56,  <span class="token number">0</span>.34it/s, <span class="token assign-left variable">v_num</span><span class="token operator">=</span>olh3<span class="token punctuation">]</span>
Epoch <span class="token number">0</span>:  <span class="token number">27</span>%<span class="token operator">|</span>██▋       <span class="token operator">|</span> <span class="token number">2745</span>/10001 <span class="token punctuation">[</span><span class="token number">2</span>:16:1<span class="token operator"><span class="token file-descriptor important">0</span>&lt;</span><span class="token number">5</span>:59:56,  <span class="token number">0</span>.34it/s, <span class="token assign-left variable">v_num</span><span class="token operator">=</span>olh3<span class="token punctuation">]</span>
Epoch <span class="token number">0</span>:  <span class="token number">27</span>%<span class="token operator">|</span>██▋       <span class="token operator">|</span> <span class="token number">2746</span>/10001 <span class="token punctuation">[</span><span class="token number">2</span>:16:1<span class="token operator"><span class="token file-descriptor important">5</span>&lt;</span><span class="token number">5</span>:59:58,  <span class="token number">0</span>.34it/s, <span class="token assign-left variable">v_num</span><span class="token operator">=</span>olh3<span class="token punctuation">]</span>
Epoch <span class="token number">0</span>:  <span class="token number">27</span>%<span class="token operator">|</span>██▋       <span class="token operator">|</span> <span class="token number">2746</span>/10001 <span class="token punctuation">[</span><span class="token number">2</span>:16:1<span class="token operator"><span class="token file-descriptor important">5</span>&lt;</span><span class="token number">5</span>:59:58,  <span class="token number">0</span>.34it/s, <span class="token assign-left variable">v_num</span><span class="token operator">=</span>olh3<span class="token punctuation">]</span>
Epoch <span class="token number">0</span>:  <span class="token number">27</span>%<span class="token operator">|</span>██▋       <span class="token operator">|</span> <span class="token number">2747</span>/10001 <span class="token punctuation">[</span><span class="token number">2</span>:16:2<span class="token operator"><span class="token file-descriptor important">0</span>&lt;</span><span class="token number">6</span>:00:01,  <span class="token number">0</span>.34it/s, <span class="token assign-left variable">v_num</span><span class="token operator">=</span>olh3<span class="token punctuation">]</span>
Epoch <span class="token number">0</span>:  <span class="token number">27</span>%<span class="token operator">|</span>██▋       <span class="token operator">|</span> <span class="token number">2747</span>/10001 <span class="token punctuation">[</span><span class="token number">2</span>:16:2<span class="token operator"><span class="token file-descriptor important">0</span>&lt;</span><span class="token number">6</span>:00:01,  <span class="token number">0</span>.34it/s, <span class="token assign-left variable">v_num</span><span class="token operator">=</span>olh3<span class="token punctuation">]</span>
</code></pre><p>Projected total time after time stabilized - 8 hrs (0.34 it/s)</p>
<h2 id="20241025---on-m1-mac">2024.10.25 - On M1 Mac </h2>
<pre data-role="codeBlock" data-info="bash" class="language-bash bash"><code>michaelvolk@M1-MV torchcell % conda activate torchcell                                                         <span class="token number">3</span>:18
<span class="token punctuation">(</span>torchcell<span class="token punctuation">)</span> michaelvolk@M1-MV torchcell %  wandb agent zhao-group/torchcell_003-fit-int_cell_diffpool_dense_5e4/e48up434                        
wandb: Starting wandb agent 🕵️
<span class="token number">2024</span>-10-25 03:18:13,461 - wandb.wandb_agent - INFO - Running runs: <span class="token punctuation">[</span><span class="token punctuation">]</span>
<span class="token number">2024</span>-10-25 03:18:14,251 - wandb.wandb_agent - INFO - Agent received command: run
<span class="token number">2024</span>-10-25 03:18:14,251 - wandb.wandb_agent - INFO - Agent starting run with config:
        cell_dataset: <span class="token punctuation">{</span><span class="token string">'graphs'</span><span class="token builtin class-name">:</span> <span class="token punctuation">[</span><span class="token string">'physical'</span>, <span class="token string">'regulatory'</span><span class="token punctuation">]</span>, <span class="token string">'node_embeddings'</span><span class="token builtin class-name">:</span> <span class="token punctuation">[</span><span class="token string">'codon_frequency'</span><span class="token punctuation">]</span><span class="token punctuation">}</span>
        data_module: <span class="token punctuation">{</span><span class="token string">'batch_size'</span><span class="token builtin class-name">:</span> <span class="token number">2</span>, <span class="token string">'is_perturbation_subset'</span><span class="token builtin class-name">:</span> True, <span class="token string">'num_workers'</span><span class="token builtin class-name">:</span> <span class="token number">2</span>, <span class="token string">'perturbation_subset_size'</span><span class="token builtin class-name">:</span> <span class="token number">50000</span>, <span class="token string">'pin_memory'</span><span class="token builtin class-name">:</span> True, <span class="token string">'prefetch'</span><span class="token builtin class-name">:</span> True<span class="token punctuation">}</span>
        model: <span class="token punctuation">{</span><span class="token string">'activation'</span><span class="token builtin class-name">:</span> <span class="token string">'relu'</span>, <span class="token string">'cluster_size_decay_factor'</span><span class="token builtin class-name">:</span> <span class="token number">6</span>, <span class="token string">'concat'</span><span class="token builtin class-name">:</span> False, <span class="token string">'dropout'</span><span class="token builtin class-name">:</span> <span class="token number">0.2</span>, <span class="token string">'embed_gat_hidden_channels'</span><span class="token builtin class-name">:</span> <span class="token number">4</span>, <span class="token string">'heads'</span><span class="token builtin class-name">:</span> <span class="token number">1</span>, <span class="token string">'norm'</span><span class="token builtin class-name">:</span> <span class="token string">'batch'</span>, <span class="token string">'num_embed_gat_layers'</span><span class="token builtin class-name">:</span> <span class="token number">2</span>, <span class="token string">'num_pool_gat_layers'</span><span class="token builtin class-name">:</span> <span class="token number">2</span>, <span class="token string">'num_pooling_layers'</span><span class="token builtin class-name">:</span> <span class="token number">5</span>, <span class="token string">'pool_gat_hidden_channels'</span><span class="token builtin class-name">:</span> <span class="token number">4</span>, <span class="token string">'target_dim'</span><span class="token builtin class-name">:</span> <span class="token number">2</span><span class="token punctuation">}</span>
        regression_task: <span class="token punctuation">{</span><span class="token string">'boxplot_every_n_epochs'</span><span class="token builtin class-name">:</span> <span class="token number">1</span>, <span class="token string">'clip_grad_norm'</span><span class="token builtin class-name">:</span> True, <span class="token string">'clip_grad_norm_max_norm'</span><span class="token builtin class-name">:</span> <span class="token number">0.1</span>, <span class="token string">'cluster_loss_weight'</span><span class="token builtin class-name">:</span> <span class="token number">1</span>, <span class="token string">'entropy_loss_weight'</span><span class="token builtin class-name">:</span> <span class="token number">0.1</span>, <span class="token string">'grad_accumulation_schedule'</span><span class="token builtin class-name">:</span> <span class="token punctuation">{</span><span class="token string">'0'</span><span class="token builtin class-name">:</span> <span class="token number">2</span>, <span class="token string">'4'</span><span class="token builtin class-name">:</span> <span class="token number">3</span>, <span class="token string">'8'</span><span class="token builtin class-name">:</span> <span class="token number">1</span><span class="token punctuation">}</span>, <span class="token string">'link_pred_loss_weight'</span><span class="token builtin class-name">:</span> <span class="token number">0.1</span>, <span class="token string">'loss_type'</span><span class="token builtin class-name">:</span> <span class="token string">'mse'</span>, <span class="token string">'lr_scheduler'</span><span class="token builtin class-name">:</span> <span class="token punctuation">{</span><span class="token string">'cooldown'</span><span class="token builtin class-name">:</span> <span class="token number">2</span>, <span class="token string">'eps'</span><span class="token builtin class-name">:</span> 1e-10, <span class="token string">'factor'</span><span class="token builtin class-name">:</span> <span class="token number">0.2</span>, <span class="token string">'min_lr'</span><span class="token builtin class-name">:</span> 1e-09, <span class="token string">'mode'</span><span class="token builtin class-name">:</span> <span class="token string">'min'</span>, <span class="token string">'patience'</span><span class="token builtin class-name">:</span> <span class="token number">3</span>, <span class="token string">'threshold'</span><span class="token builtin class-name">:</span> <span class="token number">0.0001</span>, <span class="token string">'threshold_mode'</span><span class="token builtin class-name">:</span> <span class="token string">'rel'</span>, <span class="token string">'type'</span><span class="token builtin class-name">:</span> <span class="token string">'ReduceLROnPlateau'</span><span class="token punctuation">}</span>, <span class="token string">'optimizer'</span><span class="token builtin class-name">:</span> <span class="token punctuation">{</span><span class="token string">'lr'</span><span class="token builtin class-name">:</span> <span class="token number">0.0001</span>, <span class="token string">'type'</span><span class="token builtin class-name">:</span> <span class="token string">'AdamW'</span>, <span class="token string">'weight_decay'</span><span class="token builtin class-name">:</span> <span class="token number">0.0001</span><span class="token punctuation">}</span><span class="token punctuation">}</span>
        trainer: <span class="token punctuation">{</span><span class="token string">'accelerator'</span><span class="token builtin class-name">:</span> <span class="token string">'gpu'</span>, <span class="token string">'devices'</span><span class="token builtin class-name">:</span> <span class="token string">'auto'</span>, <span class="token string">'max_epochs'</span><span class="token builtin class-name">:</span> <span class="token number">5</span>, <span class="token string">'strategy'</span><span class="token builtin class-name">:</span> <span class="token string">'auto'</span><span class="token punctuation">}</span>
<span class="token number">2024</span>-10-25 03:18:14,255 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python experiments/003-fit-int/scripts/cell_diffpool_dense.py
Starting GatDiffPool 🌋
wandb_cfg <span class="token punctuation">{</span><span class="token string">'hydra_logging'</span><span class="token builtin class-name">:</span> <span class="token punctuation">{</span><span class="token string">'loggers'</span><span class="token builtin class-name">:</span> <span class="token punctuation">{</span><span class="token string">'logging_example'</span><span class="token builtin class-name">:</span> <span class="token punctuation">{</span><span class="token string">'level'</span><span class="token builtin class-name">:</span> <span class="token string">'INFO'</span><span class="token punctuation">}</span><span class="token punctuation">}</span><span class="token punctuation">}</span>, <span class="token string">'wandb'</span><span class="token builtin class-name">:</span> <span class="token punctuation">{</span><span class="token string">'project'</span><span class="token builtin class-name">:</span> <span class="token string">'torchcell_test_cell_diffpool_dense'</span>, <span class="token string">'tags'</span><span class="token builtin class-name">:</span> <span class="token punctuation">[</span><span class="token punctuation">]</span><span class="token punctuation">}</span>, <span class="token string">'cell_dataset'</span><span class="token builtin class-name">:</span> <span class="token punctuation">{</span><span class="token string">'graphs'</span><span class="token builtin class-name">:</span> <span class="token punctuation">[</span><span class="token string">'physical'</span>, <span class="token string">'regulatory'</span><span class="token punctuation">]</span>, <span class="token string">'node_embeddings'</span><span class="token builtin class-name">:</span> <span class="token punctuation">[</span><span class="token string">'codon_frequency'</span><span class="token punctuation">]</span><span class="token punctuation">}</span>, <span class="token string">'data_module'</span><span class="token builtin class-name">:</span> <span class="token punctuation">{</span><span class="token string">'is_perturbation_subset'</span><span class="token builtin class-name">:</span> True, <span class="token string">'perturbation_subset_size'</span><span class="token builtin class-name">:</span> <span class="token number">50000.0</span>, <span class="token string">'num_workers'</span><span class="token builtin class-name">:</span> <span class="token number">10</span>, <span class="token string">'batch_size'</span><span class="token builtin class-name">:</span> <span class="token number">2</span>, <span class="token string">'pin_memory'</span><span class="token builtin class-name">:</span> True, <span class="token string">'prefetch'</span><span class="token builtin class-name">:</span> True<span class="token punctuation">}</span>, <span class="token string">'trainer'</span><span class="token builtin class-name">:</span> <span class="token punctuation">{</span><span class="token string">'max_epochs'</span><span class="token builtin class-name">:</span> <span class="token number">2</span>, <span class="token string">'strategy'</span><span class="token builtin class-name">:</span> <span class="token string">'auto'</span>, <span class="token string">'accelerator'</span><span class="token builtin class-name">:</span> <span class="token string">'cpu'</span>, <span class="token string">'devices'</span><span class="token builtin class-name">:</span> <span class="token string">'auto'</span><span class="token punctuation">}</span>, <span class="token string">'model'</span><span class="token builtin class-name">:</span> <span class="token punctuation">{</span><span class="token string">'pool_gat_hidden_channels'</span><span class="token builtin class-name">:</span> <span class="token number">16</span>, <span class="token string">'num_pool_gat_layers'</span><span class="token builtin class-name">:</span> <span class="token number">2</span>, <span class="token string">'embed_gat_hidden_channels'</span><span class="token builtin class-name">:</span> <span class="token number">16</span>, <span class="token string">'num_embed_gat_layers'</span><span class="token builtin class-name">:</span> <span class="token number">2</span>, <span class="token string">'num_pooling_layers'</span><span class="token builtin class-name">:</span> <span class="token number">5</span>, <span class="token string">'cluster_size_decay_factor'</span><span class="token builtin class-name">:</span> <span class="token number">5.0</span>, <span class="token string">'activation'</span><span class="token builtin class-name">:</span> <span class="token string">'relu'</span>, <span class="token string">'norm'</span><span class="token builtin class-name">:</span> <span class="token string">'batch'</span>, <span class="token string">'target_dim'</span><span class="token builtin class-name">:</span> <span class="token number">2</span>, <span class="token string">'heads'</span><span class="token builtin class-name">:</span> <span class="token number">1</span>, <span class="token string">'concat'</span><span class="token builtin class-name">:</span> False, <span class="token string">'dropout'</span><span class="token builtin class-name">:</span> <span class="token number">0.1</span><span class="token punctuation">}</span>, <span class="token string">'regression_task'</span><span class="token builtin class-name">:</span> <span class="token punctuation">{</span><span class="token string">'loss_type'</span><span class="token builtin class-name">:</span> <span class="token string">'mse'</span>, <span class="token string">'optimizer'</span><span class="token builtin class-name">:</span> <span class="token punctuation">{</span><span class="token string">'type'</span><span class="token builtin class-name">:</span> <span class="token string">'AdamW'</span>, <span class="token string">'lr'</span><span class="token builtin class-name">:</span> 1e-05, <span class="token string">'weight_decay'</span><span class="token builtin class-name">:</span> <span class="token number">0.0001</span><span class="token punctuation">}</span>, <span class="token string">'lr_scheduler'</span><span class="token builtin class-name">:</span> <span class="token punctuation">{</span><span class="token string">'type'</span><span class="token builtin class-name">:</span> <span class="token string">'ReduceLROnPlateau'</span>, <span class="token string">'mode'</span><span class="token builtin class-name">:</span> <span class="token string">'min'</span>, <span class="token string">'factor'</span><span class="token builtin class-name">:</span> <span class="token number">0.2</span>, <span class="token string">'patience'</span><span class="token builtin class-name">:</span> <span class="token number">3</span>, <span class="token string">'threshold'</span><span class="token builtin class-name">:</span> <span class="token number">0.0001</span>, <span class="token string">'threshold_mode'</span><span class="token builtin class-name">:</span> <span class="token string">'rel'</span>, <span class="token string">'cooldown'</span><span class="token builtin class-name">:</span> <span class="token number">2</span>, <span class="token string">'min_lr'</span><span class="token builtin class-name">:</span> 1e-09, <span class="token string">'eps'</span><span class="token builtin class-name">:</span> 1e-10<span class="token punctuation">}</span>, <span class="token string">'boxplot_every_n_epochs'</span><span class="token builtin class-name">:</span> <span class="token number">1</span>, <span class="token string">'clip_grad_norm'</span><span class="token builtin class-name">:</span> True, <span class="token string">'clip_grad_norm_max_norm'</span><span class="token builtin class-name">:</span> <span class="token number">1.0</span>, <span class="token string">'cluster_loss_weight'</span><span class="token builtin class-name">:</span> <span class="token number">1.0</span>, <span class="token string">'link_pred_loss_weight'</span><span class="token builtin class-name">:</span> <span class="token number">1.0</span>, <span class="token string">'entropy_loss_weight'</span><span class="token builtin class-name">:</span> <span class="token number">1.0</span>, <span class="token string">'grad_accumulation_schedule'</span><span class="token builtin class-name">:</span> None<span class="token punctuation">}</span><span class="token punctuation">}</span>
wandb: WARNING Ignored wandb.init<span class="token punctuation">(</span><span class="token punctuation">)</span> arg project when running a sweep.
<span class="token number">2024</span>-10-25 03:18:19,263 - wandb.wandb_agent - INFO - Running runs: <span class="token punctuation">[</span><span class="token string">'93v4tiz4'</span><span class="token punctuation">]</span>
wandb: Tracking run with wandb version <span class="token number">0.17</span>.7
wandb: W<span class="token operator">&amp;</span>B syncing is <span class="token builtin class-name">set</span> to <span class="token variable"><span class="token variable">`</span>offline<span class="token variable">`</span></span> <span class="token keyword keyword-in">in</span> this directory.  
wandb: Run <span class="token variable"><span class="token variable">`</span>wandb online<span class="token variable">`</span></span> or <span class="token builtin class-name">set</span> <span class="token assign-left variable">WANDB_MODE</span><span class="token operator">=</span>online to <span class="token builtin class-name">enable</span> cloud syncing.
data/go/go.obo: fmt<span class="token punctuation">(</span><span class="token number">1.2</span><span class="token punctuation">)</span> rel<span class="token punctuation">(</span><span class="token number">2024</span>-01-17<span class="token punctuation">)</span> <span class="token number">45,869</span> Terms
<span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">=</span>
node.embeddings
<span class="token punctuation">{</span><span class="token string">'codon_frequency'</span><span class="token builtin class-name">:</span> CodonFrequencyDataset<span class="token punctuation">(</span><span class="token number">6607</span><span class="token punctuation">)</span><span class="token punctuation">}</span>
<span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">=</span>
<span class="token punctuation">[</span><span class="token number">2024</span>-10-25 03:18:28,922<span class="token punctuation">]</span><span class="token punctuation">[</span>torchcell.datamodules.cell<span class="token punctuation">]</span><span class="token punctuation">[</span>INFO<span class="token punctuation">]</span> - Loading index from /Users/michaelvolk/Documents/projects/torchcell/data/torchcell/experiments/003-fit-int/001-small-build/data_module_cache/index_seed_42.json
<span class="token punctuation">[</span><span class="token number">2024</span>-10-25 03:18:29,110<span class="token punctuation">]</span><span class="token punctuation">[</span>torchcell.datamodules.cell<span class="token punctuation">]</span><span class="token punctuation">[</span>INFO<span class="token punctuation">]</span> - Loading index details from /Users/michaelvolk/Documents/projects/torchcell/data/torchcell/experiments/003-fit-int/001-small-build/data_module_cache/index_details_seed_42.json
Setting up PerturbationSubsetDataModule<span class="token punctuation">..</span>.
Creating subset datasets<span class="token punctuation">..</span>.
Setup complete.
<span class="token punctuation">[</span><span class="token number">2024</span>-10-25 03:18:30,204<span class="token punctuation">]</span><span class="token punctuation">[</span>__main__<span class="token punctuation">]</span><span class="token punctuation">[</span>INFO<span class="token punctuation">]</span> - cpu
Cluster sizes: <span class="token punctuation">[</span><span class="token number">1096</span>, <span class="token number">182</span>, <span class="token number">30</span>, <span class="token number">5</span>, <span class="token number">1</span><span class="token punctuation">]</span>
Cluster sizes: <span class="token punctuation">[</span><span class="token number">1096</span>, <span class="token number">182</span>, <span class="token number">30</span>, <span class="token number">5</span>, <span class="token number">1</span><span class="token punctuation">]</span>
Parameters per model: <span class="token number">12,906</span>
Expected total parameters: <span class="token number">25,842</span>
Actual total parameters: <span class="token number">25,842</span>
/Users/michaelvolk/opt/miniconda3/envs/torchcell/lib/python3.11/site-packages/lightning/pytorch/utilities/parsing.py:198: Attribute <span class="token string">'loss_func'</span> is an instance of <span class="token variable"><span class="token variable">`</span>nn.Module<span class="token variable">`</span></span> and is already saved during checkpointing. It is recommended to ignore them using <span class="token variable"><span class="token variable">`</span>self.save_hyperparameters<span class="token punctuation">(</span>ignore<span class="token operator">=</span><span class="token punctuation">[</span><span class="token string">'loss_func'</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token variable">`</span></span><span class="token builtin class-name">.</span>
/Users/michaelvolk/opt/miniconda3/envs/torchcell/lib/python3.11/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: Metric <span class="token variable"><span class="token variable">`</span>SpearmanCorrcoef<span class="token variable">`</span></span> will save all targets and predictions <span class="token keyword keyword-in">in</span> the buffer. For large datasets, this may lead to large memory footprint.
  warnings.warn<span class="token punctuation">(</span>*args, **kwargs<span class="token punctuation">)</span>  <span class="token comment"># noqa: B028</span>
devices: <span class="token number">1</span>
GPU available: True <span class="token punctuation">(</span>mps<span class="token punctuation">)</span>, used: True
TPU available: False, using: <span class="token number">0</span> TPU cores
IPU available: False, using: <span class="token number">0</span> IPUs
HPU available: False, using: <span class="token number">0</span> HPUs
/Users/michaelvolk/opt/miniconda3/envs/torchcell/lib/python3.11/site-packages/lightning/pytorch/loggers/wandb.py:389: There is a wandb run already <span class="token keyword keyword-in">in</span> progress and newly created instances of <span class="token variable"><span class="token variable">`</span>WandbLogger<span class="token variable">`</span></span> will reuse this run. If this is not desired, call <span class="token variable"><span class="token variable">`</span>wandb.finish<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token variable">`</span></span> before instantiating <span class="token variable"><span class="token variable">`</span>WandbLogger<span class="token variable">`</span></span><span class="token builtin class-name">.</span>
Setting up PerturbationSubsetDataModule<span class="token punctuation">..</span>.
Creating subset datasets<span class="token punctuation">..</span>.
Setup complete.
/Users/michaelvolk/opt/miniconda3/envs/torchcell/lib/python3.11/site-packages/lightning/pytorch/core/optimizer.py:314: The lr scheduler dict contains the key<span class="token punctuation">(</span>s<span class="token punctuation">)</span> <span class="token punctuation">[</span><span class="token string">'monitor'</span><span class="token punctuation">]</span>, but the keys will be ignored. You need to call <span class="token variable"><span class="token variable">`</span>lr_scheduler.step<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token variable">`</span></span> manually <span class="token keyword keyword-in">in</span> manual optimization.

  <span class="token operator">|</span> Name          <span class="token operator">|</span> Type              <span class="token operator">|</span> Params
----------------------------------------------------
<span class="token number">0</span> <span class="token operator">|</span> model         <span class="token operator">|</span> DenseCellDiffPool <span class="token operator">|</span> <span class="token number">25.8</span> K
<span class="token number">1</span> <span class="token operator">|</span> combined_loss <span class="token operator">|</span> CombinedLoss      <span class="token operator">|</span> <span class="token number">0</span>     
<span class="token number">2</span> <span class="token operator">|</span> train_metrics <span class="token operator">|</span> ModuleDict        <span class="token operator">|</span> <span class="token number">0</span>     
<span class="token number">3</span> <span class="token operator">|</span> val_metrics   <span class="token operator">|</span> ModuleDict        <span class="token operator">|</span> <span class="token number">0</span>     
<span class="token number">4</span> <span class="token operator">|</span> test_metrics  <span class="token operator">|</span> ModuleDict        <span class="token operator">|</span> <span class="token number">0</span>     
----------------------------------------------------
<span class="token number">25.8</span> K    Trainable params
<span class="token number">0</span>         Non-trainable params
<span class="token number">25.8</span> K    Total params
<span class="token number">0.103</span>     Total estimated model params size <span class="token punctuation">(</span>MB<span class="token punctuation">)</span>
Sanity Checking DataLoader <span class="token number">0</span>:   <span class="token number">0</span>%<span class="token operator">|</span>                                                           <span class="token operator">|</span> <span class="token number">0</span>/2 <span class="token punctuation">[</span>00:0<span class="token operator"><span class="token file-descriptor important">0</span>&lt;</span>?, ?it/s<span class="token punctuation">]</span>/Users/michaelvolk/opt/miniconda3/envs/torchcell/lib/python3.11/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: The variance of predictions or target is close to zero. This can cause instability <span class="token keyword keyword-in">in</span> Pearson correlationcoefficient, leading to wrong results. Consider re-scaling the input <span class="token keyword keyword-if">if</span> possible or computing using alarger dtype <span class="token punctuation">(</span>currently using torch.float32<span class="token punctuation">)</span>.
  warnings.warn<span class="token punctuation">(</span>*args, **kwargs<span class="token punctuation">)</span>  <span class="token comment"># noqa: B028</span>
Epoch <span class="token number">0</span>:   <span class="token number">1</span>%<span class="token operator">|</span>▋                                                  <span class="token operator">|</span> <span class="token number">256</span>/20001 <span class="token punctuation">[</span><span class="token number">26</span>:4<span class="token operator"><span class="token file-descriptor important">8</span>&lt;</span><span class="token number">34</span>:27:27,  <span class="token number">0</span>.16it/s, <span class="token assign-left variable">v_num</span><span class="token operator">=</span>tiz4<span class="token punctuation">]</span>
</code></pre><h3 id="rtx6000-ada-vs-a40---discussion">RTX6000 Ada vs A40 - Discussion </h3>
<p>We have a 10x speed difference on A40.</p>
<p>I thought maybe this was due to SLURM overhead on the workstation but I ran these without SLURM so that cannot be the issue. The SLURM times are 0.02 it/s.</p>
<p>Also the data from on the A40 is on Delta HDD without NVMe and our SSD on the workstation has NVMe. This makes the speed difference even more baffling.</p>
<p>We haven't done any CPU overclocking or any other adjustments in BIOS. Also we do not have access to the BIOS on Delta (A40 and Epyc cpu system).</p>

      </div>
      
      
    
    
    
    
    
    
  
    </body></html>