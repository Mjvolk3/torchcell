commit ca28679c478aea7e04c1fc27eea9b192ef79ac1d
Author: mjvolk3 <mjvolk3>
Date:   Tue Feb 13 13:51:21 2024 -0600

    source update - dump to docker community works -> enterprise

diff --git a/torchcell/adapters/kuzmin2018_adapter.py b/torchcell/adapters/kuzmin2018_adapter.py
--- a/torchcell/adapters/kuzmin2018_adapter.py
+++ b/torchcell/adapters/kuzmin2018_adapter.py
@@ -760,718 +665,611 @@
 class DmfKuzmin2018Adapter:
     def __init__(self, dataset: DmfKuzmin2018Dataset, num_workers: int):
         self.dataset = dataset
         self.num_workers = num_workers
 
-    def get_nodes(self):
+    def get_nodes(self) -> Generator[BioCypherNode, None, None]:
         methods = [
             self._get_experiment_reference_nodes,
             self._get_genome_nodes,
             self._get_experiment_nodes,
-            self._get_dataset_nodes,
             self._get_genotype_nodes,
+            self._get_dataset_nodes,
             self._get_environment_nodes,
             self._get_media_nodes,
             self._get_temperature_nodes,
             self._get_phenotype_nodes,
         ]
 
         with ProcessPoolExecutor(max_workers=self.num_workers) as executor:
             futures = [executor.submit(method) for method in methods]
-
             for future in as_completed(futures):
                 try:
                     node_generator = future.result()
                     for node in node_generator:
                         yield node
                 except Exception as exc:
                     logger.error(
                         f"Node generation method generated an exception: {exc}"
                     )
 
-    def _get_experiment_reference_nodes(self) -> None:
+    def _get_experiment_reference_nodes(self) -> list[BioCypherNode]:
         for i, data in tqdm(enumerate(self.dataset.experiment_reference_index)):
             nodes = []
-            experiment_ref_id = hashlib.md5(
+            experiment_ref_id = hashlib.sha256(
                 json.dumps(data.reference.model_dump()).encode("utf-8")
             ).hexdigest()
             node = BioCypherNode(
                 node_id=experiment_ref_id,
                 preferred_id=f"DmfKuzmin2018_reference_{i}",
                 node_label="experiment reference",
                 properties={
                     "dataset_index": i,
                     "serialized_data": json.dumps(data.reference.model_dump()),
                 },
             )
             nodes.append(node)
         return nodes
 
-    def _get_genome_nodes(self) -> None:
+    def _get_genome_nodes(self) -> list[BioCypherNode]:
         nodes = []
         seen_node_ids: Set[str] = set()
         for i, data in tqdm(enumerate(self.dataset.experiment_reference_index)):
-            genome_id = hashlib.md5(
+            genome_id = hashlib.sha256(
                 json.dumps(data.reference.reference_genome.model_dump()).encode("utf-8")
             ).hexdigest()
-
             if genome_id not in seen_node_ids:
                 seen_node_ids.add(genome_id)
                 node = BioCypherNode(
                     node_id=genome_id,
                     preferred_id=f"reference_genome_{i}",
                     node_label="genome",
                     properties={
                         "species": data.reference.reference_genome.species,
                         "strain": data.reference.reference_genome.strain,
                         "serialized_data": json.dumps(
                             data.reference.reference_genome.model_dump()
                         ),
                     },
                 )
                 nodes.append(node)
         return nodes
 
     def _get_experiment_nodes(self) -> None:
         nodes = []
         for i, data in tqdm(enumerate(self.dataset)):
-            experiment_id = hashlib.md5(
+            experiment_id = hashlib.sha256(
                 json.dumps(data["experiment"].model_dump()).encode("utf-8")
             ).hexdigest()
-
             node = BioCypherNode(
                 node_id=experiment_id,
                 preferred_id=f"DmfKuzmin2018_{i}",
                 node_label="experiment",
                 properties={
                     "dataset_index": i,
                     "serialized_data": json.dumps(data["experiment"].model_dump()),
                 },
             )
             nodes.append(node)
         return nodes
 
-    def _get_genotype_nodes(self) -> Generator[BioCypherNode, None, None]:
+    def _get_genotype_nodes(self) -> list[BioCypherNode]:
         nodes = []
-        seen_node_ids: Set[str] = set()
+        seen_node_ids = set()
         for i, data in tqdm(enumerate(self.dataset)):
-            for genotype in data["experiment"].genotype:
-                genotype_id = hashlib.md5(
-                    json.dumps(genotype.model_dump()).encode("utf-8")
-                ).hexdigest()
-
-                if genotype_id not in seen_node_ids:
-                    seen_node_ids.add(genotype_id)
-                    systematic_gene_name = genotype.perturbation.systematic_gene_name
-                    perturbed_gene_name = genotype.perturbation.perturbed_gene_name
-                    description = genotype.perturbation.description
-                    perturbation_type = genotype.perturbation.perturbation_type
-                    self._get_perturbation(genotype)
-
-                    node = BioCypherNode(
-                        node_id=genotype_id,
-                        preferred_id=f"genotype_{i}",
-                        node_label="genotype",
-                        properties={
-                            "systematic_gene_names": [systematic_gene_name],
-                            "perturbed_gene_names": [perturbed_gene_name],
-                            "is_deletion_genotype": isinstance(
-                                data["experiment"].genotype, Genotype
-                            ),
-                            "is_interference_genotype": isinstance(
-                                data["experiment"].genotype, Genotype
-                            ),
-                            "description": description,
-                            "perturbation_types": [perturbation_type],
-                            "serialized_data": json.dumps(genotype.model_dump()),
-                        },
-                    )
-                    nodes.append(node)
+            genotype = data["experiment"].genotype
+            genotype_id = hashlib.sha256(
+                json.dumps(genotype.model_dump()).encode("utf-8")
+            ).hexdigest()
+            if genotype_id not in seen_node_ids:
+                seen_node_ids.add(genotype_id)
+                node = BioCypherNode(
+                    node_id=genotype_id,
+                    preferred_id=f"genotype_{i}",
+                    node_label="genotype",
+                    properties={
+                        "systematic_gene_names": genotype.systematic_gene_names,
+                        "perturbed_gene_names": genotype.perturbed_gene_names,
+                        "perturbation_types": genotype.perturbation_types,
+                        "serialized_data": json.dumps(
+                            data["experiment"].genotype.model_dump()
+                        ),
+                    },
+                )
+                nodes.append(node)
         return nodes
 
     @staticmethod
-    def _get_perturbation(
-        genotype: Genotype,
-    ) -> Generator[BioCypherNode, None, None]:
+    def _get_perturbation(genotype: Genotype) -> Generator[BioCypherNode, None, None]:
         nodes = []
         if genotype.perturbation:
             i = 1
-            perturbation_id = hashlib.md5(
+            perturbation_id = hashlib.sha256(
                 json.dumps(genotype.perturbation.model_dump()).encode("utf-8")
             ).hexdigest()
 
             node = BioCypherNode(
                 node_id=perturbation_id,
                 preferred_id=f"perturbation_{i}",
                 node_label="perturbation",
                 properties={
                     "systematic_gene_name": [
                         genotype.perturbation.systematic_gene_name
                     ],
                     "perturbed_gene_name": [genotype.perturbation.perturbed_gene_name],
                     "description": genotype.perturbation.description,
                     "perturbation_type": genotype.perturbation.perturbation_type,
                     "strain_id": genotype.perturbation.strain_id,
                     "serialized_data": json.dumps(genotype.perturbation.model_dump()),
                 },
             )
             nodes.append(node)
         return nodes
 
-    def _get_environment_nodes(self) -> Generator[BioCypherNode, None, None]:
+    def _get_environment_nodes(self) -> list[BioCypherNode]:
         nodes = []
         seen_node_ids: Set[str] = set()
         for i, data in tqdm(enumerate(self.dataset)):
-            environment_id = hashlib.md5(
+            environment_id = hashlib.sha256(
                 json.dumps(data["experiment"].environment.model_dump()).encode("utf-8")
             ).hexdigest()
-
-            node_id = environment_id
-
-            if node_id not in seen_node_ids:
-                seen_node_ids.add(node_id)
+            if environment_id not in seen_node_ids:
+                seen_node_ids.add(environment_id)
                 media = json.dumps(data["experiment"].environment.media.model_dump())
-
                 node = BioCypherNode(
-                    node_id=node_id,
+                    node_id=environment_id,
                     preferred_id=f"environment_{i}",
                     node_label="environment",
                     properties={
                         "temperature": data["experiment"].environment.temperature.value,
                         "media": media,
                         "serialized_data": json.dumps(
                             data["experiment"].environment.model_dump()
                         ),
                     },
                 )
                 nodes.append(node)
-        for i, data in tqdm(enumerate(self.dataset)):
-            environment_id = hashlib.md5(
-                json.dumps(data["reference"].reference_environment.model_dump()).encode(
+
+        for i, data in enumerate(self.dataset.experiment_reference_index):
+            environment_id = hashlib.sha256(
+                json.dumps(data.reference.reference_environment.model_dump()).encode(
                     "utf-8"
                 )
             ).hexdigest()
-
-            node_id = environment_id
-
-            if node_id not in seen_node_ids:
-                seen_node_ids.add(node_id)
+            if environment_id not in seen_node_ids:
+                seen_node_ids.add(environment_id)
                 media = json.dumps(
-                    data["reference"].reference_environment.media.model_dump()
+                    data.reference.reference_environment.media.model_dump()
                 )
-
                 node = BioCypherNode(
-                    node_id=node_id,
+                    node_id=environment_id,
                     preferred_id=f"environment_{i}",
                     node_label="environment",
                     properties={
                         "temperature": data[
                             "reference"
                         ].reference_environment.temperature.value,
                         "media": media,
                         "serialized_data": json.dumps(
-                            data["reference"].reference_environment.model_dump()
+                            data.reference.reference_environment.model_dump()
                         ),
                     },
                 )
                 nodes.append(node)
         return nodes
 
     def _get_media_nodes(self) -> Generator[BioCypherNode, None, None]:
         nodes = []
         seen_node_ids: Set[str] = set()
         for i, data in tqdm(enumerate(self.dataset)):
-            media_id = hashlib.md5(
+            media_id = hashlib.sha256(
                 json.dumps(data["experiment"].environment.media.model_dump()).encode(
                     "utf-8"
                 )
             ).hexdigest()
-
             if media_id not in seen_node_ids:
                 seen_node_ids.add(media_id)
                 name = data["experiment"].environment.media.name
                 state = data["experiment"].environment.media.state
-
                 node = BioCypherNode(
                     node_id=media_id,
                     preferred_id=f"media_{media_id}",
                     node_label="media",
                     properties={
                         "name": name,
                         "state": state,
                         "serialized_data": json.dumps(
                             data["experiment"].environment.media.model_dump()
                         ),
                     },
                 )
                 nodes.append(node)
 
         for i, data in tqdm(enumerate(self.dataset)):
-            media_id = hashlib.md5(
+            media_id = hashlib.sha256(
                 json.dumps(
                     data["reference"].reference_environment.media.model_dump()
                 ).encode("utf-8")
             ).hexdigest()
-
             if media_id not in seen_node_ids:
                 seen_node_ids.add(media_id)
                 name = data["reference"].reference_environment.media.name
                 state = data["reference"].reference_environment.media.state
 
                 node = BioCypherNode(
                     node_id=media_id,
                     preferred_id=f"media_{media_id}",
                     node_label="media",
                     properties={
                         "name": name,
                         "state": state,
                         "serialized_data": json.dumps(
                             data["reference"].reference_environment.media.model_dump()
                         ),
                     },
                 )
                 nodes.append(node)
         return nodes
 
-    def _get_temperature_nodes(self) -> Generator[BioCypherNode, None, None]:
+    def _get_temperature_nodes(self) -> list[BioCypherNode]:
         nodes = []
         seen_node_ids: Set[str] = set()
         for i, data in tqdm(enumerate(self.dataset)):
-            temperature_id = hashlib.md5(
+            temperature_id = hashlib.sha256(
                 json.dumps(
                     data["experiment"].environment.temperature.model_dump()
                 ).encode("utf-8")
             ).hexdigest()
-
             if temperature_id not in seen_node_ids:
                 seen_node_ids.add(temperature_id)
-
                 node = BioCypherNode(
                     node_id=temperature_id,
                     preferred_id=f"temperature_{temperature_id}",
                     node_label="temperature",
                     properties={
                         "value": data["experiment"].environment.temperature.value,
                         "unit": data["experiment"].environment.temperature.unit,
                         "serialized_data": json.dumps(
                             data["experiment"].environment.temperature.model_dump()
                         ),
                     },
                 )
                 nodes.append(node)
 
-        for i, data in tqdm(enumerate(self.dataset)):
-            temperature_id = hashlib.md5(
+        for i, data in enumerate(self.dataset.experiment_reference_index):
+            temperature_id = hashlib.sha256(
                 json.dumps(
-                    data["reference"].reference_environment.temperature.model_dump()
+                    data.reference.reference_environment.temperature.model_dump()
                 ).encode("utf-8")
             ).hexdigest()
-
             if temperature_id not in seen_node_ids:
                 seen_node_ids.add(temperature_id)
-
                 node = BioCypherNode(
                     node_id=temperature_id,
                     preferred_id=f"temperature_{temperature_id}",
                     node_label="temperature",
                     properties={
-                        "value": data[
-                            "reference"
-                        ].reference_environment.temperature.value,
-                        "description": data[
-                            "reference"
-                        ].reference_environment.temperature.description,
+                        "value": data["experiment"].environment.temperature.value,
+                        "unit": data["experiment"].environment.temperature.unit,
                         "serialized_data": json.dumps(
-                            data[
-                                "reference"
-                            ].reference_environment.temperature.model_dump()
+                            data["experiment"].environment.temperature.model_dump()
                         ),
                     },
                 )
                 nodes.append(node)
         return nodes
 
-    def _get_phenotype_nodes(self) -> Generator[BioCypherNode, None, None]:
+    def _get_phenotype_nodes(self) -> list[BioCypherNode]:
         nodes = []
         seen_node_ids: Set[str] = set()
         for i, data in tqdm(enumerate(self.dataset)):
-            phenotype_id = hashlib.md5(
+            phenotype_id = hashlib.sha256(
                 json.dumps(data["experiment"].phenotype.model_dump()).encode("utf-8")
             ).hexdigest()
 
             if phenotype_id not in seen_node_ids:
                 seen_node_ids.add(phenotype_id)
                 graph_level = data["experiment"].phenotype.graph_level
                 label = data["experiment"].phenotype.label
                 label_error = data["experiment"].phenotype.label_error
                 fitness = data["experiment"].phenotype.fitness
                 fitness_std = data["experiment"].phenotype.fitness_std
 
                 node = BioCypherNode(
                     node_id=phenotype_id,
                     preferred_id=f"phenotype_{phenotype_id}",
                     node_label="phenotype",
                     properties={
                         "graph_level": graph_level,
                         "label": label,
                         "label_error": label_error,
                         "fitness": fitness,
                         "fitness_std": fitness_std,
                         "serialized_data": json.dumps(
                             data["experiment"].phenotype.model_dump()
                         ),
                     },
                 )
                 nodes.append(node)
-
-        # References
-        for i, data in tqdm(enumerate(self.dataset)):
-            # Get the phenotype ID associated with the experiment reference
-            phenotype_id = hashlib.md5(
-                json.dumps(data["reference"].reference_phenotype.model_dump()).encode(
-                    "utf-8"
-                )
-            ).hexdigest()
-
-            if phenotype_id not in seen_node_ids:
-                seen_node_ids.add(phenotype_id)
-                graph_level = data["reference"].reference_phenotype.graph_level
-                label = data["reference"].reference_phenotype.label
-                label_error = data["reference"].reference_phenotype.label_error
-                fitness = data["reference"].reference_phenotype.fitness
-                fitness_std = data["reference"].reference_phenotype.fitness_std
-
-                node = BioCypherNode(
-                    node_id=phenotype_id,
-                    preferred_id=f"phenotype_{phenotype_id}",
-                    node_label="phenotype",
-                    properties={
-                        "graph_level": graph_level,
-                        "label": label,
-                        "label_error": label_error,
-                        "fitness": fitness,
-                        "fitness_std": fitness_std,
-                        "serialized_data": json.dumps(
-                            data["reference"].reference_phenotype.model_dump()
-                        ),
-                    },
-                )
-                nodes.append(node)
         return nodes
 
-    def _get_dataset_nodes(self) -> None:
+    def _get_dataset_nodes(self) -> list[BioCypherNode]:
         nodes = [
             BioCypherNode(
                 node_id="DmfKuzmin2018",
                 preferred_id="DmfKuzmin2018",
                 node_label="dataset",
             )
         ]
         return nodes
 
-    def get_edges(self):
+    def get_edges(self) -> Generator[BioCypherEdge, None, None]:
         methods = [
             self._get_dataset_experiment_ref_edges,
             self._get_experiment_dataset_edges,
             self._get_experiment_ref_experiment_edges,
             self._get_genotype_experiment_edges,
             self._get_environment_experiment_edges,
             self._get_environment_experiment_ref_edges,
             self._get_phenotype_experiment_edges,
             self._get_phenotype_experiment_ref_edges,
             self._get_media_environment_edges,
             self._get_temperature_environment_edges,
             self._get_genome_edges,
         ]
 
         with ProcessPoolExecutor(max_workers=self.num_workers) as executor:
             futures = [executor.submit(method) for method in methods]
             for future in as_completed(futures):
                 try:
                     edge_generator = future.result()
                     for edge in edge_generator:
                         yield edge
                 except Exception as exc:
                     logger.error(
                         f"Edge generation method generated an exception: {exc}"
                     )
 
-    def _get_dataset_experiment_ref_edges(self):
+    def _get_dataset_experiment_ref_edges(self) -> list[BioCypherEdge]:
         edges = []
         for data in self.dataset.experiment_reference_index:
-            experiment_ref_id = hashlib.md5(
+            experiment_ref_id = hashlib.sha256(
                 json.dumps(data.reference.model_dump()).encode("utf-8")
             ).hexdigest()
             edge = BioCypherEdge(
                 source_id=experiment_ref_id,
                 target_id="DmfKuzmin2018",
                 relationship_label="experiment reference member of",
             )
             edges.append(edge)
         return edges
 
-    def _get_experiment_dataset_edges(self):
+    def _get_experiment_dataset_edges(self) -> list[BioCypherEdge]:
         # concept level
         edges = []
         for i, data in tqdm(enumerate(self.dataset)):
-            experiment_id = hashlib.md5(
+            experiment_id = hashlib.sha256(
                 json.dumps(data["experiment"].model_dump()).encode("utf-8")
             ).hexdigest()
             edge = BioCypherEdge(
                 source_id=experiment_id,
                 target_id="DmfKuzmin2018",
                 relationship_label="experiment member of",
             )
             edges.append(edge)
         return edges
 
-    def _get_experiment_ref_experiment_edges(self):
-        # instance level
+    def _get_experiment_ref_experiment_edges(self) -> list[BioCypherEdge]:
         edges = []
-        for data in tqdm(self.dataset.experiment_reference_index):
+        for data in self.dataset.experiment_reference_index:
             dataset_subset = self.dataset[torch.tensor(data.index)]
-            experiment_ref_id = hashlib.md5(
+            experiment_ref_id = hashlib.sha256(
                 json.dumps(data.reference.model_dump()).encode("utf-8")
             ).hexdigest()
             for i, data in enumerate(dataset_subset):
-                experiment_id = hashlib.md5(
+                experiment_id = hashlib.sha256(
                     json.dumps(data["experiment"].model_dump()).encode("utf-8")
                 ).hexdigest()
                 edge = BioCypherEdge(
                     source_id=experiment_ref_id,
                     target_id=experiment_id,
                     relationship_label="experiment reference of",
                 )
                 edges.append(edge)
         return edges
 
-    def _get_genotype_experiment_edges(self) -> Generator[BioCypherEdge, None, None]:
-        # CHECK if needed - don't think needed since exp ref index
-        # seen_genotype_experiment_pairs: Set[tuple] = set()
+    def _get_genotype_experiment_edges(self) -> list[BioCypherEdge]:
         edges = []
         for i, data in tqdm(enumerate(self.dataset)):
-            experiment_id = hashlib.md5(
+            experiment_id = hashlib.sha256(
                 json.dumps(data["experiment"].model_dump()).encode("utf-8")
             ).hexdigest()
-            for genotype in data["experiment"].genotype:
-                genotype_id = hashlib.md5(
-                    json.dumps(genotype.model_dump()).encode("utf-8")
-                ).hexdigest()
-
-                self._get_perturbation_genotype_edges(
-                    genotype=genotype, genotype_id=genotype_id
-                )
-
-                # CHECK if needed - don't think needed since exp ref index
-                # genotype_experiment_pair = (genotype_id, experiment_id)
-                # if genotype_experiment_pair not in seen_genotype_experiment_pairs:
-                #     seen_genotype_experiment_pairs.add(genotype_experiment_pair)
-
-                edge = BioCypherEdge(
-                    source_id=genotype_id,
-                    target_id=experiment_id,
-                    relationship_label="genotype member of",
-                )
-                edges.append(edge)
+            genotype_id = hashlib.sha256(
+                json.dumps(data["experiment"].genotype.model_dump()).encode("utf-8")
+            ).hexdigest()
+            self._get_perturbation_genotype_edges(
+                genotype=data["experiment"].genotype, genotype_id=genotype_id
+            )
+            edge = BioCypherEdge(
+                source_id=genotype_id,
+                target_id=experiment_id,
+                relationship_label="genotype member of",
+            )
+            edges.append(edge)
         return edges
 
     @staticmethod
     def _get_perturbation_genotype_edges(
         genotype: Genotype, genotype_id: str
-    ) -> Generator[BioCypherEdge, None, None]:
+    ) -> list[BioCypherEdge]:
         edges = []
-        if genotype.perturbation:
-            perturbation_id = hashlib.md5(
-                json.dumps(genotype.perturbation.model_dump()).encode("utf-8")
+        for perturbation in genotype.perturbations:
+            perturbation_id = hashlib.sha256(
+                json.dumps(perturbation.model_dump()).encode("utf-8")
             ).hexdigest()
-
             edge = BioCypherEdge(
                 source_id=perturbation_id,
                 target_id=genotype_id,
                 relationship_label="perturbation member of",
             )
             edges.append(edge)
         return edges
 
-    def _get_environment_experiment_edges(self) -> Generator[BioCypherEdge, None, None]:
+    def _get_environment_experiment_edges(self) -> list[BioCypherEdge]:
         edges = []
         seen_environment_experiment_pairs: Set[tuple] = set()
         # Linking environments to experiments
         for i, data in tqdm(enumerate(self.dataset)):
-            experiment_id = hashlib.md5(
+            experiment_id = hashlib.sha256(
                 json.dumps(data["experiment"].model_dump()).encode("utf-8")
             ).hexdigest()
-            environment_id = hashlib.md5(
+            environment_id = hashlib.sha256(
                 json.dumps(data["experiment"].environment.model_dump()).encode("utf-8")
             ).hexdigest()
 
             env_experiment_pair = (environment_id, experiment_id)
             if env_experiment_pair not in seen_environment_experiment_pairs:
                 seen_environment_experiment_pairs.add(env_experiment_pair)
                 edge = BioCypherEdge(
                     source_id=environment_id,
                     target_id=experiment_id,
                     relationship_label="environment member of",
                 )
                 edges.append(edge)
         return edges
 
-    def _get_environment_experiment_ref_edges(
-        self,
-    ) -> Generator[BioCypherEdge, None, None]:
+    def _get_environment_experiment_ref_edges(self) -> list[BioCypherEdge]:
         edges = []
         seen_environment_experiment_ref_pairs: Set[tuple] = set()
-        # Linking environments to experiment references
-        for i, data in tqdm(enumerate(self.dataset.experiment_reference_index)):
-            experiment_ref_id = hashlib.md5(
+        for i, data in enumerate(self.dataset.experiment_reference_index):
+            experiment_ref_id = hashlib.sha256(
                 json.dumps(data.reference.model_dump()).encode("utf-8")
             ).hexdigest()
-
-            environment_id = hashlib.md5(
+            environment_id = hashlib.sha256(
                 json.dumps(data.reference.reference_environment.model_dump()).encode(
                     "utf-8"
                 )
             ).hexdigest()
-
             env_experiment_ref_pair = (environment_id, experiment_ref_id)
             if env_experiment_ref_pair not in seen_environment_experiment_ref_pairs:
                 seen_environment_experiment_ref_pairs.add(env_experiment_ref_pair)
-
                 edge = BioCypherEdge(
                     source_id=environment_id,
                     target_id=experiment_ref_id,
                     relationship_label="environment member of",
                 )
                 edges.append(edge)
         return edges
 
-    def _get_phenotype_experiment_edges(self) -> Generator[BioCypherEdge, None, None]:
+    def _get_phenotype_experiment_edges(self) -> list[BioCypherEdge]:
         edges = []
         seen_phenotype_experiment_pairs: Set[tuple] = set()
-        # Linking phenotypes to experiments
         for i, data in tqdm(enumerate(self.dataset)):
-            experiment_id = hashlib.md5(
+            experiment_id = hashlib.sha256(
                 json.dumps(data["experiment"].model_dump()).encode("utf-8")
             ).hexdigest()
-            phenotype_id = hashlib.md5(
+            phenotype_id = hashlib.sha256(
                 json.dumps(data["experiment"].phenotype.model_dump()).encode("utf-8")
             ).hexdigest()
-
             phenotype_experiment_pair = (phenotype_id, experiment_id)
             if phenotype_experiment_pair not in seen_phenotype_experiment_pairs:
                 seen_phenotype_experiment_pairs.add(phenotype_experiment_pair)
-
                 edge = BioCypherEdge(
                     source_id=phenotype_id,
                     target_id=experiment_id,
                     relationship_label="phenotype member of",
                 )
                 edges.append(edge)
         return edges
 
-    def _get_phenotype_experiment_ref_edges(
-        self,
-    ) -> Generator[BioCypherEdge, None, None]:
+    def _get_phenotype_experiment_ref_edges(self) -> list[BioCypherEdge]:
         edges = []
         seen_phenotype_experiment_ref_pairs: Set[tuple] = set()
         for i, data in tqdm(enumerate(self.dataset.experiment_reference_index)):
-            experiment_ref_id = hashlib.md5(
+            experiment_ref_id = hashlib.sha256(
                 json.dumps(data.reference.model_dump()).encode("utf-8")
             ).hexdigest()
-
-            phenotype_id = hashlib.md5(
+            phenotype_id = hashlib.sha256(
                 json.dumps(data.reference.reference_phenotype.model_dump()).encode(
                     "utf-8"
                 )
             ).hexdigest()
-
             phenotype_experiment_ref_pair = (phenotype_id, experiment_ref_id)
             if phenotype_experiment_ref_pair not in seen_phenotype_experiment_ref_pairs:
                 seen_phenotype_experiment_ref_pairs.add(phenotype_experiment_ref_pair)
-
                 edge = BioCypherEdge(
                     source_id=phenotype_id,
                     target_id=experiment_ref_id,
                     relationship_label="phenotype member of",
                 )
                 edges.append(edge)
         return edges
 
-    def _get_media_environment_edges(self) -> Generator[BioCypherEdge, None, None]:
+    def _get_media_environment_edges(self) -> list[BioCypherEdge]:
         edges = []
         seen_media_environment_pairs: Set[tuple] = set()
         for i, data in tqdm(enumerate(self.dataset)):
-            environment_id = hashlib.md5(
+            environment_id = hashlib.sha256(
                 json.dumps(data["experiment"].environment.model_dump()).encode("utf-8")
             ).hexdigest()
-            media_id = hashlib.md5(
+            media_id = hashlib.sha256(
                 json.dumps(data["experiment"].environment.media.model_dump()).encode(
                     "utf-8"
                 )
             ).hexdigest()
-
             media_environment_pair = (media_id, environment_id)
             if media_environment_pair not in seen_media_environment_pairs:
                 seen_media_environment_pairs.add(media_environment_pair)
-
                 edge = BioCypherEdge(
                     source_id=media_id,
                     target_id=environment_id,
                     relationship_label="media member of",
                 )
                 edges.append(edge)
         return edges
 
-    def _get_temperature_environment_edges(
-        self,
-    ) -> Generator[BioCypherEdge, None, None]:
+    def _get_temperature_environment_edges(self) -> list[BioCypherEdge]:
         edges = []
         seen_temperature_environment_pairs: Set[tuple] = set()
         for i, data in tqdm(enumerate(self.dataset)):
-            environment_id = hashlib.md5(
+            environment_id = hashlib.sha256(
                 json.dumps(data["experiment"].environment.model_dump()).encode("utf-8")
             ).hexdigest()
-            temperature_id = hashlib.md5(
+            temperature_id = hashlib.sha256(
                 json.dumps(
                     data["experiment"].environment.temperature.model_dump()
                 ).encode("utf-8")
             ).hexdigest()
-
             temperature_environment_pair = (temperature_id, environment_id)
             if temperature_environment_pair not in seen_temperature_environment_pairs:
                 seen_temperature_environment_pairs.add(temperature_environment_pair)
 
                 edge = BioCypherEdge(
                     source_id=temperature_id,
                     target_id=environment_id,
                     relationship_label="temperature member of",
                 )
                 edges.append(edge)
         return edges
 
-    def _get_genome_edges(self) -> None:
+    def _get_genome_edges(self) -> list[BioCypherEdge]:
         edges = []
         seen_genome_experiment_ref_pairs: Set[tuple] = set()
         for i, data in tqdm(enumerate(self.dataset.experiment_reference_index)):
-            experiment_ref_id = hashlib.md5(
+            experiment_ref_id = hashlib.sha256(
                 json.dumps(data.reference.model_dump()).encode("utf-8")
             ).hexdigest()
-
-            genome_id = hashlib.md5(
-                json.dumps(data.reference.reference_genome.model_dump()).encode(
-                    "utf-8"
-                )
+            genome_id = hashlib.sha256(
+                json.dumps(data.reference.reference_genome.model_dump()).encode("utf-8")
             ).hexdigest()
-
             genome_experiment_ref_pair = (genome_id, experiment_ref_id)
             if genome_experiment_ref_pair not in seen_genome_experiment_ref_pairs:
                 seen_genome_experiment_ref_pairs.add(genome_experiment_ref_pair)
-
                 edge = BioCypherEdge(
                     source_id=genome_id,
                     target_id=experiment_ref_id,
                     relationship_label="genome member of",
                 )
                 edges.append(edge)
         return edges
 
 

commit af628a1168bd8c735fd1a78688ec5ecf6c153fe9
Author: mjvolk3 <mjvolk3>
Date:   Wed Jan 31 19:00:15 2024 -0600

    create_kg_small prototype for delta neo4j

diff --git a/torchcell/adapters/kuzmin2018_adapter.py b/torchcell/adapters/kuzmin2018_adapter.py
--- a/torchcell/adapters/kuzmin2018_adapter.py
+++ b/torchcell/adapters/kuzmin2018_adapter.py
@@ -762,718 +760,718 @@
 class DmfKuzmin2018Adapter:
     def __init__(self, dataset: DmfKuzmin2018Dataset, num_workers: int):
         self.dataset = dataset
         self.num_workers = num_workers
 
     def get_nodes(self):
         methods = [
             self._get_experiment_reference_nodes,
             self._get_genome_nodes,
             self._get_experiment_nodes,
             self._get_dataset_nodes,
             self._get_genotype_nodes,
             self._get_environment_nodes,
             self._get_media_nodes,
             self._get_temperature_nodes,
             self._get_phenotype_nodes,
         ]
 
         with ProcessPoolExecutor(max_workers=self.num_workers) as executor:
             futures = [executor.submit(method) for method in methods]
 
             for future in as_completed(futures):
                 try:
                     node_generator = future.result()
                     for node in node_generator:
                         yield node
                 except Exception as exc:
                     logger.error(
                         f"Node generation method generated an exception: {exc}"
                     )
 
     def _get_experiment_reference_nodes(self) -> None:
         for i, data in tqdm(enumerate(self.dataset.experiment_reference_index)):
             nodes = []
             experiment_ref_id = hashlib.md5(
                 json.dumps(data.reference.model_dump()).encode("utf-8")
             ).hexdigest()
             node = BioCypherNode(
                 node_id=experiment_ref_id,
                 preferred_id=f"DmfKuzmin2018_reference_{i}",
                 node_label="experiment reference",
                 properties={
                     "dataset_index": i,
                     "serialized_data": json.dumps(data.reference.model_dump()),
                 },
             )
             nodes.append(node)
         return nodes
 
     def _get_genome_nodes(self) -> None:
         nodes = []
         seen_node_ids: Set[str] = set()
         for i, data in tqdm(enumerate(self.dataset.experiment_reference_index)):
             genome_id = hashlib.md5(
                 json.dumps(data.reference.reference_genome.model_dump()).encode("utf-8")
             ).hexdigest()
 
             if genome_id not in seen_node_ids:
                 seen_node_ids.add(genome_id)
                 node = BioCypherNode(
                     node_id=genome_id,
                     preferred_id=f"reference_genome_{i}",
                     node_label="genome",
                     properties={
                         "species": data.reference.reference_genome.species,
                         "strain": data.reference.reference_genome.strain,
                         "serialized_data": json.dumps(
                             data.reference.reference_genome.model_dump()
                         ),
                     },
                 )
                 nodes.append(node)
         return nodes
 
     def _get_experiment_nodes(self) -> None:
         nodes = []
         for i, data in tqdm(enumerate(self.dataset)):
             experiment_id = hashlib.md5(
                 json.dumps(data["experiment"].model_dump()).encode("utf-8")
             ).hexdigest()
 
             node = BioCypherNode(
                 node_id=experiment_id,
                 preferred_id=f"DmfKuzmin2018_{i}",
                 node_label="experiment",
                 properties={
                     "dataset_index": i,
                     "serialized_data": json.dumps(data["experiment"].model_dump()),
                 },
             )
             nodes.append(node)
         return nodes
 
     def _get_genotype_nodes(self) -> Generator[BioCypherNode, None, None]:
         nodes = []
         seen_node_ids: Set[str] = set()
         for i, data in tqdm(enumerate(self.dataset)):
             for genotype in data["experiment"].genotype:
                 genotype_id = hashlib.md5(
                     json.dumps(genotype.model_dump()).encode("utf-8")
                 ).hexdigest()
 
                 if genotype_id not in seen_node_ids:
                     seen_node_ids.add(genotype_id)
                     systematic_gene_name = genotype.perturbation.systematic_gene_name
                     perturbed_gene_name = genotype.perturbation.perturbed_gene_name
                     description = genotype.perturbation.description
                     perturbation_type = genotype.perturbation.perturbation_type
                     self._get_perturbation(genotype)
 
                     node = BioCypherNode(
                         node_id=genotype_id,
                         preferred_id=f"genotype_{i}",
                         node_label="genotype",
                         properties={
                             "systematic_gene_names": [systematic_gene_name],
                             "perturbed_gene_names": [perturbed_gene_name],
                             "is_deletion_genotype": isinstance(
-                                data["experiment"].genotype, DeletionGenotype
+                                data["experiment"].genotype, Genotype
                             ),
                             "is_interference_genotype": isinstance(
-                                data["experiment"].genotype, InterferenceGenotype
+                                data["experiment"].genotype, Genotype
                             ),
                             "description": description,
                             "perturbation_types": [perturbation_type],
                             "serialized_data": json.dumps(genotype.model_dump()),
                         },
                     )
                     nodes.append(node)
         return nodes
 
     @staticmethod
     def _get_perturbation(
-        genotype: BaseGenotype,
+        genotype: Genotype,
     ) -> Generator[BioCypherNode, None, None]:
         nodes = []
         if genotype.perturbation:
             i = 1
             perturbation_id = hashlib.md5(
                 json.dumps(genotype.perturbation.model_dump()).encode("utf-8")
             ).hexdigest()
 
             node = BioCypherNode(
                 node_id=perturbation_id,
                 preferred_id=f"perturbation_{i}",
                 node_label="perturbation",
                 properties={
                     "systematic_gene_name": [
                         genotype.perturbation.systematic_gene_name
                     ],
                     "perturbed_gene_name": [genotype.perturbation.perturbed_gene_name],
                     "description": genotype.perturbation.description,
                     "perturbation_type": genotype.perturbation.perturbation_type,
                     "strain_id": genotype.perturbation.strain_id,
                     "serialized_data": json.dumps(genotype.perturbation.model_dump()),
                 },
             )
             nodes.append(node)
         return nodes
 
     def _get_environment_nodes(self) -> Generator[BioCypherNode, None, None]:
         nodes = []
         seen_node_ids: Set[str] = set()
         for i, data in tqdm(enumerate(self.dataset)):
             environment_id = hashlib.md5(
                 json.dumps(data["experiment"].environment.model_dump()).encode("utf-8")
             ).hexdigest()
 
             node_id = environment_id
 
             if node_id not in seen_node_ids:
                 seen_node_ids.add(node_id)
                 media = json.dumps(data["experiment"].environment.media.model_dump())
 
                 node = BioCypherNode(
                     node_id=node_id,
                     preferred_id=f"environment_{i}",
                     node_label="environment",
                     properties={
                         "temperature": data["experiment"].environment.temperature.value,
                         "media": media,
                         "serialized_data": json.dumps(
                             data["experiment"].environment.model_dump()
                         ),
                     },
                 )
                 nodes.append(node)
         for i, data in tqdm(enumerate(self.dataset)):
             environment_id = hashlib.md5(
                 json.dumps(data["reference"].reference_environment.model_dump()).encode(
                     "utf-8"
                 )
             ).hexdigest()
 
             node_id = environment_id
 
             if node_id not in seen_node_ids:
                 seen_node_ids.add(node_id)
                 media = json.dumps(
                     data["reference"].reference_environment.media.model_dump()
                 )
 
                 node = BioCypherNode(
                     node_id=node_id,
                     preferred_id=f"environment_{i}",
                     node_label="environment",
                     properties={
                         "temperature": data[
                             "reference"
                         ].reference_environment.temperature.value,
                         "media": media,
                         "serialized_data": json.dumps(
                             data["reference"].reference_environment.model_dump()
                         ),
                     },
                 )
                 nodes.append(node)
         return nodes
 
     def _get_media_nodes(self) -> Generator[BioCypherNode, None, None]:
         nodes = []
         seen_node_ids: Set[str] = set()
         for i, data in tqdm(enumerate(self.dataset)):
             media_id = hashlib.md5(
                 json.dumps(data["experiment"].environment.media.model_dump()).encode(
                     "utf-8"
                 )
             ).hexdigest()
 
             if media_id not in seen_node_ids:
                 seen_node_ids.add(media_id)
                 name = data["experiment"].environment.media.name
                 state = data["experiment"].environment.media.state
 
                 node = BioCypherNode(
                     node_id=media_id,
                     preferred_id=f"media_{media_id}",
                     node_label="media",
                     properties={
                         "name": name,
                         "state": state,
                         "serialized_data": json.dumps(
                             data["experiment"].environment.media.model_dump()
                         ),
                     },
                 )
                 nodes.append(node)
 
         for i, data in tqdm(enumerate(self.dataset)):
             media_id = hashlib.md5(
                 json.dumps(
                     data["reference"].reference_environment.media.model_dump()
                 ).encode("utf-8")
             ).hexdigest()
 
             if media_id not in seen_node_ids:
                 seen_node_ids.add(media_id)
                 name = data["reference"].reference_environment.media.name
                 state = data["reference"].reference_environment.media.state
 
                 node = BioCypherNode(
                     node_id=media_id,
                     preferred_id=f"media_{media_id}",
                     node_label="media",
                     properties={
                         "name": name,
                         "state": state,
                         "serialized_data": json.dumps(
                             data["reference"].reference_environment.media.model_dump()
                         ),
                     },
                 )
                 nodes.append(node)
         return nodes
 
     def _get_temperature_nodes(self) -> Generator[BioCypherNode, None, None]:
         nodes = []
         seen_node_ids: Set[str] = set()
         for i, data in tqdm(enumerate(self.dataset)):
             temperature_id = hashlib.md5(
                 json.dumps(
                     data["experiment"].environment.temperature.model_dump()
                 ).encode("utf-8")
             ).hexdigest()
 
             if temperature_id not in seen_node_ids:
                 seen_node_ids.add(temperature_id)
 
                 node = BioCypherNode(
                     node_id=temperature_id,
                     preferred_id=f"temperature_{temperature_id}",
                     node_label="temperature",
                     properties={
                         "value": data["experiment"].environment.temperature.value,
                         "unit": data["experiment"].environment.temperature.unit,
                         "serialized_data": json.dumps(
                             data["experiment"].environment.temperature.model_dump()
                         ),
                     },
                 )
                 nodes.append(node)
 
         for i, data in tqdm(enumerate(self.dataset)):
             temperature_id = hashlib.md5(
                 json.dumps(
                     data["reference"].reference_environment.temperature.model_dump()
                 ).encode("utf-8")
             ).hexdigest()
 
             if temperature_id not in seen_node_ids:
                 seen_node_ids.add(temperature_id)
 
                 node = BioCypherNode(
                     node_id=temperature_id,
                     preferred_id=f"temperature_{temperature_id}",
                     node_label="temperature",
                     properties={
                         "value": data[
                             "reference"
                         ].reference_environment.temperature.value,
                         "description": data[
                             "reference"
                         ].reference_environment.temperature.description,
                         "serialized_data": json.dumps(
                             data[
                                 "reference"
                             ].reference_environment.temperature.model_dump()
                         ),
                     },
                 )
                 nodes.append(node)
         return nodes
 
     def _get_phenotype_nodes(self) -> Generator[BioCypherNode, None, None]:
         nodes = []
         seen_node_ids: Set[str] = set()
         for i, data in tqdm(enumerate(self.dataset)):
             phenotype_id = hashlib.md5(
                 json.dumps(data["experiment"].phenotype.model_dump()).encode("utf-8")
             ).hexdigest()
 
             if phenotype_id not in seen_node_ids:
                 seen_node_ids.add(phenotype_id)
                 graph_level = data["experiment"].phenotype.graph_level
                 label = data["experiment"].phenotype.label
                 label_error = data["experiment"].phenotype.label_error
                 fitness = data["experiment"].phenotype.fitness
                 fitness_std = data["experiment"].phenotype.fitness_std
 
                 node = BioCypherNode(
                     node_id=phenotype_id,
                     preferred_id=f"phenotype_{phenotype_id}",
                     node_label="phenotype",
                     properties={
                         "graph_level": graph_level,
                         "label": label,
                         "label_error": label_error,
                         "fitness": fitness,
                         "fitness_std": fitness_std,
                         "serialized_data": json.dumps(
                             data["experiment"].phenotype.model_dump()
                         ),
                     },
                 )
                 nodes.append(node)
 
         # References
         for i, data in tqdm(enumerate(self.dataset)):
             # Get the phenotype ID associated with the experiment reference
             phenotype_id = hashlib.md5(
                 json.dumps(data["reference"].reference_phenotype.model_dump()).encode(
                     "utf-8"
                 )
             ).hexdigest()
 
             if phenotype_id not in seen_node_ids:
                 seen_node_ids.add(phenotype_id)
                 graph_level = data["reference"].reference_phenotype.graph_level
                 label = data["reference"].reference_phenotype.label
                 label_error = data["reference"].reference_phenotype.label_error
                 fitness = data["reference"].reference_phenotype.fitness
                 fitness_std = data["reference"].reference_phenotype.fitness_std
 
                 node = BioCypherNode(
                     node_id=phenotype_id,
                     preferred_id=f"phenotype_{phenotype_id}",
                     node_label="phenotype",
                     properties={
                         "graph_level": graph_level,
                         "label": label,
                         "label_error": label_error,
                         "fitness": fitness,
                         "fitness_std": fitness_std,
                         "serialized_data": json.dumps(
                             data["reference"].reference_phenotype.model_dump()
                         ),
                     },
                 )
                 nodes.append(node)
         return nodes
 
     def _get_dataset_nodes(self) -> None:
         nodes = [
             BioCypherNode(
                 node_id="DmfKuzmin2018",
                 preferred_id="DmfKuzmin2018",
                 node_label="dataset",
             )
         ]
         return nodes
 
     def get_edges(self):
         methods = [
             self._get_dataset_experiment_ref_edges,
             self._get_experiment_dataset_edges,
             self._get_experiment_ref_experiment_edges,
             self._get_genotype_experiment_edges,
             self._get_environment_experiment_edges,
             self._get_environment_experiment_ref_edges,
             self._get_phenotype_experiment_edges,
             self._get_phenotype_experiment_ref_edges,
             self._get_media_environment_edges,
             self._get_temperature_environment_edges,
             self._get_genome_edges,
         ]
 
         with ProcessPoolExecutor(max_workers=self.num_workers) as executor:
             futures = [executor.submit(method) for method in methods]
             for future in as_completed(futures):
                 try:
                     edge_generator = future.result()
                     for edge in edge_generator:
                         yield edge
                 except Exception as exc:
                     logger.error(
                         f"Edge generation method generated an exception: {exc}"
                     )
 
     def _get_dataset_experiment_ref_edges(self):
         edges = []
         for data in self.dataset.experiment_reference_index:
             experiment_ref_id = hashlib.md5(
                 json.dumps(data.reference.model_dump()).encode("utf-8")
             ).hexdigest()
             edge = BioCypherEdge(
                 source_id=experiment_ref_id,
                 target_id="DmfKuzmin2018",
                 relationship_label="experiment reference member of",
             )
             edges.append(edge)
         return edges
 
     def _get_experiment_dataset_edges(self):
         # concept level
         edges = []
         for i, data in tqdm(enumerate(self.dataset)):
             experiment_id = hashlib.md5(
                 json.dumps(data["experiment"].model_dump()).encode("utf-8")
             ).hexdigest()
             edge = BioCypherEdge(
                 source_id=experiment_id,
                 target_id="DmfKuzmin2018",
                 relationship_label="experiment member of",
             )
             edges.append(edge)
         return edges
 
     def _get_experiment_ref_experiment_edges(self):
         # instance level
         edges = []
         for data in tqdm(self.dataset.experiment_reference_index):
             dataset_subset = self.dataset[torch.tensor(data.index)]
             experiment_ref_id = hashlib.md5(
                 json.dumps(data.reference.model_dump()).encode("utf-8")
             ).hexdigest()
             for i, data in enumerate(dataset_subset):
                 experiment_id = hashlib.md5(
                     json.dumps(data["experiment"].model_dump()).encode("utf-8")
                 ).hexdigest()
                 edge = BioCypherEdge(
                     source_id=experiment_ref_id,
                     target_id=experiment_id,
                     relationship_label="experiment reference of",
                 )
                 edges.append(edge)
         return edges
 
     def _get_genotype_experiment_edges(self) -> Generator[BioCypherEdge, None, None]:
         # CHECK if needed - don't think needed since exp ref index
         # seen_genotype_experiment_pairs: Set[tuple] = set()
         edges = []
         for i, data in tqdm(enumerate(self.dataset)):
             experiment_id = hashlib.md5(
                 json.dumps(data["experiment"].model_dump()).encode("utf-8")
             ).hexdigest()
             for genotype in data["experiment"].genotype:
                 genotype_id = hashlib.md5(
                     json.dumps(genotype.model_dump()).encode("utf-8")
                 ).hexdigest()
 
                 self._get_perturbation_genotype_edges(
                     genotype=genotype, genotype_id=genotype_id
                 )
 
                 # CHECK if needed - don't think needed since exp ref index
                 # genotype_experiment_pair = (genotype_id, experiment_id)
                 # if genotype_experiment_pair not in seen_genotype_experiment_pairs:
                 #     seen_genotype_experiment_pairs.add(genotype_experiment_pair)
 
                 edge = BioCypherEdge(
                     source_id=genotype_id,
                     target_id=experiment_id,
                     relationship_label="genotype member of",
                 )
                 edges.append(edge)
         return edges
 
     @staticmethod
     def _get_perturbation_genotype_edges(
-        genotype: BaseGenotype, genotype_id: str
+        genotype: Genotype, genotype_id: str
     ) -> Generator[BioCypherEdge, None, None]:
         edges = []
         if genotype.perturbation:
             perturbation_id = hashlib.md5(
                 json.dumps(genotype.perturbation.model_dump()).encode("utf-8")
             ).hexdigest()
 
             edge = BioCypherEdge(
                 source_id=perturbation_id,
                 target_id=genotype_id,
                 relationship_label="perturbation member of",
             )
             edges.append(edge)
         return edges
 
     def _get_environment_experiment_edges(self) -> Generator[BioCypherEdge, None, None]:
         edges = []
         seen_environment_experiment_pairs: Set[tuple] = set()
         # Linking environments to experiments
         for i, data in tqdm(enumerate(self.dataset)):
             experiment_id = hashlib.md5(
                 json.dumps(data["experiment"].model_dump()).encode("utf-8")
             ).hexdigest()
             environment_id = hashlib.md5(
                 json.dumps(data["experiment"].environment.model_dump()).encode("utf-8")
             ).hexdigest()
 
             env_experiment_pair = (environment_id, experiment_id)
             if env_experiment_pair not in seen_environment_experiment_pairs:
                 seen_environment_experiment_pairs.add(env_experiment_pair)
                 edge = BioCypherEdge(
                     source_id=environment_id,
                     target_id=experiment_id,
                     relationship_label="environment member of",
                 )
                 edges.append(edge)
         return edges
 
     def _get_environment_experiment_ref_edges(
         self,
     ) -> Generator[BioCypherEdge, None, None]:
         edges = []
         seen_environment_experiment_ref_pairs: Set[tuple] = set()
         # Linking environments to experiment references
         for i, data in tqdm(enumerate(self.dataset.experiment_reference_index)):
             experiment_ref_id = hashlib.md5(
                 json.dumps(data.reference.model_dump()).encode("utf-8")
             ).hexdigest()
 
             environment_id = hashlib.md5(
                 json.dumps(data.reference.reference_environment.model_dump()).encode(
                     "utf-8"
                 )
             ).hexdigest()
 
             env_experiment_ref_pair = (environment_id, experiment_ref_id)
             if env_experiment_ref_pair not in seen_environment_experiment_ref_pairs:
                 seen_environment_experiment_ref_pairs.add(env_experiment_ref_pair)
 
                 edge = BioCypherEdge(
                     source_id=environment_id,
                     target_id=experiment_ref_id,
                     relationship_label="environment member of",
                 )
                 edges.append(edge)
         return edges
 
     def _get_phenotype_experiment_edges(self) -> Generator[BioCypherEdge, None, None]:
         edges = []
         seen_phenotype_experiment_pairs: Set[tuple] = set()
         # Linking phenotypes to experiments
         for i, data in tqdm(enumerate(self.dataset)):
             experiment_id = hashlib.md5(
                 json.dumps(data["experiment"].model_dump()).encode("utf-8")
             ).hexdigest()
             phenotype_id = hashlib.md5(
                 json.dumps(data["experiment"].phenotype.model_dump()).encode("utf-8")
             ).hexdigest()
 
             phenotype_experiment_pair = (phenotype_id, experiment_id)
             if phenotype_experiment_pair not in seen_phenotype_experiment_pairs:
                 seen_phenotype_experiment_pairs.add(phenotype_experiment_pair)
 
                 edge = BioCypherEdge(
                     source_id=phenotype_id,
                     target_id=experiment_id,
                     relationship_label="phenotype member of",
                 )
                 edges.append(edge)
         return edges
 
     def _get_phenotype_experiment_ref_edges(
         self,
     ) -> Generator[BioCypherEdge, None, None]:
         edges = []
         seen_phenotype_experiment_ref_pairs: Set[tuple] = set()
         for i, data in tqdm(enumerate(self.dataset.experiment_reference_index)):
             experiment_ref_id = hashlib.md5(
                 json.dumps(data.reference.model_dump()).encode("utf-8")
             ).hexdigest()
 
             phenotype_id = hashlib.md5(
                 json.dumps(data.reference.reference_phenotype.model_dump()).encode(
                     "utf-8"
                 )
             ).hexdigest()
 
             phenotype_experiment_ref_pair = (phenotype_id, experiment_ref_id)
             if phenotype_experiment_ref_pair not in seen_phenotype_experiment_ref_pairs:
                 seen_phenotype_experiment_ref_pairs.add(phenotype_experiment_ref_pair)
 
                 edge = BioCypherEdge(
                     source_id=phenotype_id,
                     target_id=experiment_ref_id,
                     relationship_label="phenotype member of",
                 )
                 edges.append(edge)
         return edges
 
     def _get_media_environment_edges(self) -> Generator[BioCypherEdge, None, None]:
         edges = []
         seen_media_environment_pairs: Set[tuple] = set()
         for i, data in tqdm(enumerate(self.dataset)):
             environment_id = hashlib.md5(
                 json.dumps(data["experiment"].environment.model_dump()).encode("utf-8")
             ).hexdigest()
             media_id = hashlib.md5(
                 json.dumps(data["experiment"].environment.media.model_dump()).encode(
                     "utf-8"
                 )
             ).hexdigest()
 
             media_environment_pair = (media_id, environment_id)
             if media_environment_pair not in seen_media_environment_pairs:
                 seen_media_environment_pairs.add(media_environment_pair)
 
                 edge = BioCypherEdge(
                     source_id=media_id,
                     target_id=environment_id,
                     relationship_label="media member of",
                 )
                 edges.append(edge)
         return edges
 
     def _get_temperature_environment_edges(
         self,
     ) -> Generator[BioCypherEdge, None, None]:
         edges = []
         seen_temperature_environment_pairs: Set[tuple] = set()
         for i, data in tqdm(enumerate(self.dataset)):
             environment_id = hashlib.md5(
                 json.dumps(data["experiment"].environment.model_dump()).encode("utf-8")
             ).hexdigest()
             temperature_id = hashlib.md5(
                 json.dumps(
                     data["experiment"].environment.temperature.model_dump()
                 ).encode("utf-8")
             ).hexdigest()
 
             temperature_environment_pair = (temperature_id, environment_id)
             if temperature_environment_pair not in seen_temperature_environment_pairs:
                 seen_temperature_environment_pairs.add(temperature_environment_pair)
 
                 edge = BioCypherEdge(
                     source_id=temperature_id,
                     target_id=environment_id,
                     relationship_label="temperature member of",
                 )
                 edges.append(edge)
         return edges
 
     def _get_genome_edges(self) -> None:
         edges = []
         seen_genome_experiment_ref_pairs: Set[tuple] = set()
         for i, data in tqdm(enumerate(self.dataset.experiment_reference_index)):
             experiment_ref_id = hashlib.md5(
                 json.dumps(data.reference.model_dump()).encode("utf-8")
             ).hexdigest()
 
             genome_id = hashlib.md5(
                 json.dumps(data.reference.reference_genome.model_dump()).encode(
                     "utf-8"
                 )
             ).hexdigest()
 
             genome_experiment_ref_pair = (genome_id, experiment_ref_id)
             if genome_experiment_ref_pair not in seen_genome_experiment_ref_pairs:
                 seen_genome_experiment_ref_pairs.add(genome_experiment_ref_pair)
 
                 edge = BioCypherEdge(
                     source_id=genome_id,
                     target_id=experiment_ref_id,
                     relationship_label="genome member of",
                 )
                 edges.append(edge)
         return edges
 
 

commit 429f78c3c8652fa332f0b02ac172546ad9ab5592
Author: mjvolk3 <mjvolk3>
Date:   Wed Jan 24 15:33:06 2024 -0600

    pypy3.10 env working for kuzmin smf db build

diff --git a/torchcell/adapters/kuzmin2018_adapter.py b/torchcell/adapters/kuzmin2018_adapter.py
--- a/torchcell/adapters/kuzmin2018_adapter.py
+++ b/torchcell/adapters/kuzmin2018_adapter.py
@@ -696,653 +762,718 @@
 class DmfKuzmin2018Adapter:
-    def __init__(self, dataset: DmfKuzmin2018Dataset):
+    def __init__(self, dataset: DmfKuzmin2018Dataset, num_workers: int):
         self.dataset = dataset
-
-    def get_nodes(self) -> None:
-        logger.info("Getting nodes.")
-        logger.info("Get experiment reference nodes.")
-        yield from self._get_experiment_reference_nodes()
-        logger.info("Get genome nodes.")
-        yield from self._get_genome_nodes()
-        logger.info("Get experiment nodes.")
-        yield from self._get_experiment_nodes()
-        logger.info("Get dataset nodes.")
-        yield from self._get_dataset_nodes()
-        logger.info("Get genotype nodes.")
-        logger.info("--- perturbation nodes.")
-        yield from self._get_genotype_nodes()
-        logger.info("Get environment nodes.")
-        yield from self._get_environment_nodes()
-        logger.info("Get media nodes.")
-        yield from self._get_media_nodes()
-        logger.info("Get temperature nodes.")
-        yield from self._get_temperature_nodes()
-        logger.info("Get phenotype nodes.")
-        yield from self._get_phenotype_nodes()
+        self.num_workers = num_workers
+
+    def get_nodes(self):
+        methods = [
+            self._get_experiment_reference_nodes,
+            self._get_genome_nodes,
+            self._get_experiment_nodes,
+            self._get_dataset_nodes,
+            self._get_genotype_nodes,
+            self._get_environment_nodes,
+            self._get_media_nodes,
+            self._get_temperature_nodes,
+            self._get_phenotype_nodes,
+        ]
+
+        with ProcessPoolExecutor(max_workers=self.num_workers) as executor:
+            futures = [executor.submit(method) for method in methods]
+
+            for future in as_completed(futures):
+                try:
+                    node_generator = future.result()
+                    for node in node_generator:
+                        yield node
+                except Exception as exc:
+                    logger.error(
+                        f"Node generation method generated an exception: {exc}"
+                    )
 
     def _get_experiment_reference_nodes(self) -> None:
         for i, data in tqdm(enumerate(self.dataset.experiment_reference_index)):
+            nodes = []
             experiment_ref_id = hashlib.md5(
                 json.dumps(data.reference.model_dump()).encode("utf-8")
             ).hexdigest()
-            yield BioCypherNode(
+            node = BioCypherNode(
                 node_id=experiment_ref_id,
-                preferred_id=f"CostanzoSmf2016_reference_{i}",
+                preferred_id=f"DmfKuzmin2018_reference_{i}",
                 node_label="experiment reference",
                 properties={
                     "dataset_index": i,
                     "serialized_data": json.dumps(data.reference.model_dump()),
                 },
             )
+            nodes.append(node)
+        return nodes
 
     def _get_genome_nodes(self) -> None:
+        nodes = []
         seen_node_ids: Set[str] = set()
-
         for i, data in tqdm(enumerate(self.dataset.experiment_reference_index)):
             genome_id = hashlib.md5(
                 json.dumps(data.reference.reference_genome.model_dump()).encode("utf-8")
             ).hexdigest()
 
             if genome_id not in seen_node_ids:
                 seen_node_ids.add(genome_id)
-                yield BioCypherNode(
+                node = BioCypherNode(
                     node_id=genome_id,
                     preferred_id=f"reference_genome_{i}",
                     node_label="genome",
                     properties={
                         "species": data.reference.reference_genome.species,
                         "strain": data.reference.reference_genome.strain,
                         "serialized_data": json.dumps(
                             data.reference.reference_genome.model_dump()
                         ),
                     },
                 )
+                nodes.append(node)
+        return nodes
 
     def _get_experiment_nodes(self) -> None:
+        nodes = []
         for i, data in tqdm(enumerate(self.dataset)):
             experiment_id = hashlib.md5(
                 json.dumps(data["experiment"].model_dump()).encode("utf-8")
             ).hexdigest()
 
-            yield BioCypherNode(
+            node = BioCypherNode(
                 node_id=experiment_id,
-                preferred_id=f"CostanzoSmf2016_{i}",
+                preferred_id=f"DmfKuzmin2018_{i}",
                 node_label="experiment",
                 properties={
                     "dataset_index": i,
                     "serialized_data": json.dumps(data["experiment"].model_dump()),
                 },
             )
-            
+            nodes.append(node)
+        return nodes
+
     def _get_genotype_nodes(self) -> Generator[BioCypherNode, None, None]:
+        nodes = []
         seen_node_ids: Set[str] = set()
         for i, data in tqdm(enumerate(self.dataset)):
             for genotype in data["experiment"].genotype:
                 genotype_id = hashlib.md5(
                     json.dumps(genotype.model_dump()).encode("utf-8")
                 ).hexdigest()
 
                 if genotype_id not in seen_node_ids:
                     seen_node_ids.add(genotype_id)
                     systematic_gene_name = genotype.perturbation.systematic_gene_name
                     perturbed_gene_name = genotype.perturbation.perturbed_gene_name
                     description = genotype.perturbation.description
                     perturbation_type = genotype.perturbation.perturbation_type
                     self._get_perturbation(genotype)
 
-                    yield BioCypherNode(
+                    node = BioCypherNode(
                         node_id=genotype_id,
                         preferred_id=f"genotype_{i}",
                         node_label="genotype",
                         properties={
                             "systematic_gene_names": [systematic_gene_name],
                             "perturbed_gene_names": [perturbed_gene_name],
                             "is_deletion_genotype": isinstance(
                                 data["experiment"].genotype, DeletionGenotype
                             ),
                             "is_interference_genotype": isinstance(
                                 data["experiment"].genotype, InterferenceGenotype
                             ),
                             "description": description,
                             "perturbation_types": [perturbation_type],
                             "serialized_data": json.dumps(genotype.model_dump()),
                         },
                     )
+                    nodes.append(node)
+        return nodes
 
     @staticmethod
     def _get_perturbation(
         genotype: BaseGenotype,
     ) -> Generator[BioCypherNode, None, None]:
+        nodes = []
         if genotype.perturbation:
             i = 1
             perturbation_id = hashlib.md5(
                 json.dumps(genotype.perturbation.model_dump()).encode("utf-8")
             ).hexdigest()
 
-            yield BioCypherNode(
+            node = BioCypherNode(
                 node_id=perturbation_id,
                 preferred_id=f"perturbation_{i}",
                 node_label="perturbation",
                 properties={
                     "systematic_gene_name": [
                         genotype.perturbation.systematic_gene_name
                     ],
                     "perturbed_gene_name": [genotype.perturbation.perturbed_gene_name],
                     "description": genotype.perturbation.description,
                     "perturbation_type": genotype.perturbation.perturbation_type,
                     "strain_id": genotype.perturbation.strain_id,
                     "serialized_data": json.dumps(genotype.perturbation.model_dump()),
                 },
             )
+            nodes.append(node)
+        return nodes
 
     def _get_environment_nodes(self) -> Generator[BioCypherNode, None, None]:
+        nodes = []
         seen_node_ids: Set[str] = set()
         for i, data in tqdm(enumerate(self.dataset)):
             environment_id = hashlib.md5(
                 json.dumps(data["experiment"].environment.model_dump()).encode("utf-8")
             ).hexdigest()
 
             node_id = environment_id
 
             if node_id not in seen_node_ids:
                 seen_node_ids.add(node_id)
                 media = json.dumps(data["experiment"].environment.media.model_dump())
 
-                yield BioCypherNode(
+                node = BioCypherNode(
                     node_id=node_id,
                     preferred_id=f"environment_{i}",
                     node_label="environment",
                     properties={
                         "temperature": data["experiment"].environment.temperature.value,
                         "media": media,
                         "serialized_data": json.dumps(
                             data["experiment"].environment.model_dump()
                         ),
                     },
                 )
+                nodes.append(node)
         for i, data in tqdm(enumerate(self.dataset)):
             environment_id = hashlib.md5(
                 json.dumps(data["reference"].reference_environment.model_dump()).encode(
                     "utf-8"
                 )
             ).hexdigest()
 
             node_id = environment_id
 
             if node_id not in seen_node_ids:
                 seen_node_ids.add(node_id)
                 media = json.dumps(
                     data["reference"].reference_environment.media.model_dump()
                 )
 
-                yield BioCypherNode(
+                node = BioCypherNode(
                     node_id=node_id,
                     preferred_id=f"environment_{i}",
                     node_label="environment",
                     properties={
                         "temperature": data[
                             "reference"
                         ].reference_environment.temperature.value,
                         "media": media,
                         "serialized_data": json.dumps(
                             data["reference"].reference_environment.model_dump()
                         ),
                     },
                 )
+                nodes.append(node)
+        return nodes
 
     def _get_media_nodes(self) -> Generator[BioCypherNode, None, None]:
+        nodes = []
         seen_node_ids: Set[str] = set()
         for i, data in tqdm(enumerate(self.dataset)):
             media_id = hashlib.md5(
                 json.dumps(data["experiment"].environment.media.model_dump()).encode(
                     "utf-8"
                 )
             ).hexdigest()
 
             if media_id not in seen_node_ids:
                 seen_node_ids.add(media_id)
                 name = data["experiment"].environment.media.name
                 state = data["experiment"].environment.media.state
 
-                yield BioCypherNode(
+                node = BioCypherNode(
                     node_id=media_id,
                     preferred_id=f"media_{media_id}",
                     node_label="media",
                     properties={
                         "name": name,
                         "state": state,
                         "serialized_data": json.dumps(
                             data["experiment"].environment.media.model_dump()
                         ),
                     },
                 )
+                nodes.append(node)
+
         for i, data in tqdm(enumerate(self.dataset)):
             media_id = hashlib.md5(
                 json.dumps(
                     data["reference"].reference_environment.media.model_dump()
                 ).encode("utf-8")
             ).hexdigest()
 
             if media_id not in seen_node_ids:
                 seen_node_ids.add(media_id)
                 name = data["reference"].reference_environment.media.name
                 state = data["reference"].reference_environment.media.state
 
-                yield BioCypherNode(
+                node = BioCypherNode(
                     node_id=media_id,
                     preferred_id=f"media_{media_id}",
                     node_label="media",
                     properties={
                         "name": name,
                         "state": state,
                         "serialized_data": json.dumps(
                             data["reference"].reference_environment.media.model_dump()
                         ),
                     },
                 )
+                nodes.append(node)
+        return nodes
 
     def _get_temperature_nodes(self) -> Generator[BioCypherNode, None, None]:
+        nodes = []
         seen_node_ids: Set[str] = set()
         for i, data in tqdm(enumerate(self.dataset)):
             temperature_id = hashlib.md5(
                 json.dumps(
                     data["experiment"].environment.temperature.model_dump()
                 ).encode("utf-8")
             ).hexdigest()
 
             if temperature_id not in seen_node_ids:
                 seen_node_ids.add(temperature_id)
 
-                yield BioCypherNode(
+                node = BioCypherNode(
                     node_id=temperature_id,
                     preferred_id=f"temperature_{temperature_id}",
                     node_label="temperature",
                     properties={
                         "value": data["experiment"].environment.temperature.value,
                         "unit": data["experiment"].environment.temperature.unit,
                         "serialized_data": json.dumps(
                             data["experiment"].environment.temperature.model_dump()
                         ),
                     },
                 )
+                nodes.append(node)
 
         for i, data in tqdm(enumerate(self.dataset)):
             temperature_id = hashlib.md5(
                 json.dumps(
                     data["reference"].reference_environment.temperature.model_dump()
                 ).encode("utf-8")
             ).hexdigest()
 
             if temperature_id not in seen_node_ids:
                 seen_node_ids.add(temperature_id)
 
-                yield BioCypherNode(
+                node = BioCypherNode(
                     node_id=temperature_id,
                     preferred_id=f"temperature_{temperature_id}",
                     node_label="temperature",
                     properties={
                         "value": data[
                             "reference"
                         ].reference_environment.temperature.value,
                         "description": data[
                             "reference"
                         ].reference_environment.temperature.description,
                         "serialized_data": json.dumps(
                             data[
                                 "reference"
                             ].reference_environment.temperature.model_dump()
                         ),
                     },
                 )
+                nodes.append(node)
+        return nodes
 
     def _get_phenotype_nodes(self) -> Generator[BioCypherNode, None, None]:
+        nodes = []
         seen_node_ids: Set[str] = set()
         for i, data in tqdm(enumerate(self.dataset)):
             phenotype_id = hashlib.md5(
                 json.dumps(data["experiment"].phenotype.model_dump()).encode("utf-8")
             ).hexdigest()
 
             if phenotype_id not in seen_node_ids:
                 seen_node_ids.add(phenotype_id)
                 graph_level = data["experiment"].phenotype.graph_level
                 label = data["experiment"].phenotype.label
                 label_error = data["experiment"].phenotype.label_error
                 fitness = data["experiment"].phenotype.fitness
                 fitness_std = data["experiment"].phenotype.fitness_std
 
-                yield BioCypherNode(
+                node = BioCypherNode(
                     node_id=phenotype_id,
                     preferred_id=f"phenotype_{phenotype_id}",
                     node_label="phenotype",
                     properties={
                         "graph_level": graph_level,
                         "label": label,
                         "label_error": label_error,
                         "fitness": fitness,
                         "fitness_std": fitness_std,
                         "serialized_data": json.dumps(
                             data["experiment"].phenotype.model_dump()
                         ),
                     },
                 )
+                nodes.append(node)
 
         # References
         for i, data in tqdm(enumerate(self.dataset)):
             # Get the phenotype ID associated with the experiment reference
             phenotype_id = hashlib.md5(
                 json.dumps(data["reference"].reference_phenotype.model_dump()).encode(
                     "utf-8"
                 )
             ).hexdigest()
 
             if phenotype_id not in seen_node_ids:
                 seen_node_ids.add(phenotype_id)
                 graph_level = data["reference"].reference_phenotype.graph_level
                 label = data["reference"].reference_phenotype.label
                 label_error = data["reference"].reference_phenotype.label_error
                 fitness = data["reference"].reference_phenotype.fitness
                 fitness_std = data["reference"].reference_phenotype.fitness_std
 
-                yield BioCypherNode(
+                node = BioCypherNode(
                     node_id=phenotype_id,
                     preferred_id=f"phenotype_{phenotype_id}",
                     node_label="phenotype",
                     properties={
                         "graph_level": graph_level,
                         "label": label,
                         "label_error": label_error,
                         "fitness": fitness,
                         "fitness_std": fitness_std,
                         "serialized_data": json.dumps(
                             data["reference"].reference_phenotype.model_dump()
                         ),
                     },
                 )
+                nodes.append(node)
+        return nodes
 
     def _get_dataset_nodes(self) -> None:
-        yield BioCypherNode(
-            node_id="CostanzoSmf2016",
-            preferred_id="CostanzoSmf2016",
-            node_label="dataset",
-        )
-
-    def get_edges(self) -> None:
-        logger.info("Generating edges.")
-        logger.info("Get dataset experiment reference edges.")
-        yield from self._get_dataset_experiment_ref_edges()
-        logger.info("Get experiment dataset edges.")
-        yield from self._get_experiment_dataset_edges()
-        logger.info("Get experiment reference experiment edges.")
-        yield from self._get_experiment_ref_experiment_edges()
-        logger.info("Get genotype experiment edges.")
-        logger.info("--- perturbation genotype edges.")
-        yield from self._get_genotype_experiment_edges()
-        logger.info("Get environment experiment edges.")
-        yield from self._get_environment_experiment_edges()
-        logger.info("Get environment experiment reference edges.")
-        yield from self._get_environment_experiment_ref_edges()
-        logger.info("Get phenotype experiment edges.")
-        yield from self._get_phenotype_experiment_edges()
-        logger.info("Get phenotype experiment reference edges.")
-        yield from self._get_phenotype_experiment_ref_edges()
-        logger.info("Get media environment edges.")
-        yield from self._get_media_environment_edges()
-        logger.info("Get temperature environment edges.")
-        yield from self._get_temperature_environment_edges()
-        logger.info("Get genome experiment reference edges.")
-        yield from self._get_genome_edges()
+        nodes = [
+            BioCypherNode(
+                node_id="DmfKuzmin2018",
+                preferred_id="DmfKuzmin2018",
+                node_label="dataset",
+            )
+        ]
+        return nodes
+
+    def get_edges(self):
+        methods = [
+            self._get_dataset_experiment_ref_edges,
+            self._get_experiment_dataset_edges,
+            self._get_experiment_ref_experiment_edges,
+            self._get_genotype_experiment_edges,
+            self._get_environment_experiment_edges,
+            self._get_environment_experiment_ref_edges,
+            self._get_phenotype_experiment_edges,
+            self._get_phenotype_experiment_ref_edges,
+            self._get_media_environment_edges,
+            self._get_temperature_environment_edges,
+            self._get_genome_edges,
+        ]
+
+        with ProcessPoolExecutor(max_workers=self.num_workers) as executor:
+            futures = [executor.submit(method) for method in methods]
+            for future in as_completed(futures):
+                try:
+                    edge_generator = future.result()
+                    for edge in edge_generator:
+                        yield edge
+                except Exception as exc:
+                    logger.error(
+                        f"Edge generation method generated an exception: {exc}"
+                    )
 
     def _get_dataset_experiment_ref_edges(self):
-        # concept level
-        for data in tqdm(self.dataset):
+        edges = []
+        for data in self.dataset.experiment_reference_index:
             experiment_ref_id = hashlib.md5(
-                json.dumps(data["experiment"].model_dump()).encode("utf-8")
+                json.dumps(data.reference.model_dump()).encode("utf-8")
             ).hexdigest()
-            yield BioCypherEdge(
+            edge = BioCypherEdge(
                 source_id=experiment_ref_id,
-                target_id="CostanzoSmf2016",
+                target_id="DmfKuzmin2018",
                 relationship_label="experiment reference member of",
             )
+            edges.append(edge)
+        return edges
 
     def _get_experiment_dataset_edges(self):
         # concept level
+        edges = []
         for i, data in tqdm(enumerate(self.dataset)):
             experiment_id = hashlib.md5(
                 json.dumps(data["experiment"].model_dump()).encode("utf-8")
             ).hexdigest()
-            yield BioCypherEdge(
+            edge = BioCypherEdge(
                 source_id=experiment_id,
-                target_id="CostanzoSmf2016",
+                target_id="DmfKuzmin2018",
                 relationship_label="experiment member of",
             )
+            edges.append(edge)
+        return edges
 
     def _get_experiment_ref_experiment_edges(self):
         # instance level
-        print()
+        edges = []
         for data in tqdm(self.dataset.experiment_reference_index):
             dataset_subset = self.dataset[torch.tensor(data.index)]
             experiment_ref_id = hashlib.md5(
                 json.dumps(data.reference.model_dump()).encode("utf-8")
             ).hexdigest()
             for i, data in enumerate(dataset_subset):
                 experiment_id = hashlib.md5(
                     json.dumps(data["experiment"].model_dump()).encode("utf-8")
                 ).hexdigest()
-                yield BioCypherEdge(
+                edge = BioCypherEdge(
                     source_id=experiment_ref_id,
                     target_id=experiment_id,
                     relationship_label="experiment reference of",
                 )
+                edges.append(edge)
+        return edges
 
     def _get_genotype_experiment_edges(self) -> Generator[BioCypherEdge, None, None]:
         # CHECK if needed - don't think needed since exp ref index
         # seen_genotype_experiment_pairs: Set[tuple] = set()
+        edges = []
         for i, data in tqdm(enumerate(self.dataset)):
             experiment_id = hashlib.md5(
                 json.dumps(data["experiment"].model_dump()).encode("utf-8")
             ).hexdigest()
             for genotype in data["experiment"].genotype:
                 genotype_id = hashlib.md5(
                     json.dumps(genotype.model_dump()).encode("utf-8")
                 ).hexdigest()
 
                 self._get_perturbation_genotype_edges(
                     genotype=genotype, genotype_id=genotype_id
                 )
 
                 # CHECK if needed - don't think needed since exp ref index
                 # genotype_experiment_pair = (genotype_id, experiment_id)
                 # if genotype_experiment_pair not in seen_genotype_experiment_pairs:
                 #     seen_genotype_experiment_pairs.add(genotype_experiment_pair)
 
-                yield BioCypherEdge(
+                edge = BioCypherEdge(
                     source_id=genotype_id,
                     target_id=experiment_id,
                     relationship_label="genotype member of",
                 )
+                edges.append(edge)
+        return edges
 
     @staticmethod
     def _get_perturbation_genotype_edges(
         genotype: BaseGenotype, genotype_id: str
     ) -> Generator[BioCypherEdge, None, None]:
+        edges = []
         if genotype.perturbation:
             perturbation_id = hashlib.md5(
                 json.dumps(genotype.perturbation.model_dump()).encode("utf-8")
             ).hexdigest()
 
-            yield BioCypherEdge(
+            edge = BioCypherEdge(
                 source_id=perturbation_id,
                 target_id=genotype_id,
                 relationship_label="perturbation member of",
             )
+            edges.append(edge)
+        return edges
 
     def _get_environment_experiment_edges(self) -> Generator[BioCypherEdge, None, None]:
+        edges = []
         seen_environment_experiment_pairs: Set[tuple] = set()
-
         # Linking environments to experiments
         for i, data in tqdm(enumerate(self.dataset)):
             experiment_id = hashlib.md5(
                 json.dumps(data["experiment"].model_dump()).encode("utf-8")
             ).hexdigest()
             environment_id = hashlib.md5(
                 json.dumps(data["experiment"].environment.model_dump()).encode("utf-8")
             ).hexdigest()
 
             env_experiment_pair = (environment_id, experiment_id)
             if env_experiment_pair not in seen_environment_experiment_pairs:
                 seen_environment_experiment_pairs.add(env_experiment_pair)
-
-                yield BioCypherEdge(
+                edge = BioCypherEdge(
                     source_id=environment_id,
                     target_id=experiment_id,
                     relationship_label="environment member of",
                 )
+                edges.append(edge)
+        return edges
 
     def _get_environment_experiment_ref_edges(
         self,
     ) -> Generator[BioCypherEdge, None, None]:
+        edges = []
         seen_environment_experiment_ref_pairs: Set[tuple] = set()
-
         # Linking environments to experiment references
         for i, data in tqdm(enumerate(self.dataset.experiment_reference_index)):
             experiment_ref_id = hashlib.md5(
                 json.dumps(data.reference.model_dump()).encode("utf-8")
             ).hexdigest()
 
             environment_id = hashlib.md5(
                 json.dumps(data.reference.reference_environment.model_dump()).encode(
                     "utf-8"
                 )
             ).hexdigest()
 
             env_experiment_ref_pair = (environment_id, experiment_ref_id)
             if env_experiment_ref_pair not in seen_environment_experiment_ref_pairs:
                 seen_environment_experiment_ref_pairs.add(env_experiment_ref_pair)
 
-                yield BioCypherEdge(
+                edge = BioCypherEdge(
                     source_id=environment_id,
                     target_id=experiment_ref_id,
                     relationship_label="environment member of",
                 )
+                edges.append(edge)
+        return edges
 
     def _get_phenotype_experiment_edges(self) -> Generator[BioCypherEdge, None, None]:
+        edges = []
         seen_phenotype_experiment_pairs: Set[tuple] = set()
-
         # Linking phenotypes to experiments
         for i, data in tqdm(enumerate(self.dataset)):
             experiment_id = hashlib.md5(
                 json.dumps(data["experiment"].model_dump()).encode("utf-8")
             ).hexdigest()
             phenotype_id = hashlib.md5(
                 json.dumps(data["experiment"].phenotype.model_dump()).encode("utf-8")
             ).hexdigest()
 
             phenotype_experiment_pair = (phenotype_id, experiment_id)
             if phenotype_experiment_pair not in seen_phenotype_experiment_pairs:
                 seen_phenotype_experiment_pairs.add(phenotype_experiment_pair)
 
-                yield BioCypherEdge(
+                edge = BioCypherEdge(
                     source_id=phenotype_id,
                     target_id=experiment_id,
                     relationship_label="phenotype member of",
                 )
+                edges.append(edge)
+        return edges
 
     def _get_phenotype_experiment_ref_edges(
         self,
     ) -> Generator[BioCypherEdge, None, None]:
+        edges = []
         seen_phenotype_experiment_ref_pairs: Set[tuple] = set()
-
-        # Linking phenotypes to experiment references
-        for i, data in tqdm(enumerate(self.dataset)):
+        for i, data in tqdm(enumerate(self.dataset.experiment_reference_index)):
             experiment_ref_id = hashlib.md5(
-                json.dumps(data["experiment"].model_dump()).encode("utf-8")
+                json.dumps(data.reference.model_dump()).encode("utf-8")
             ).hexdigest()
 
-            # Get the phenotype ID associated with the experiment reference
             phenotype_id = hashlib.md5(
-                json.dumps(data["reference"].reference_phenotype.model_dump()).encode(
+                json.dumps(data.reference.reference_phenotype.model_dump()).encode(
                     "utf-8"
                 )
             ).hexdigest()
 
             phenotype_experiment_ref_pair = (phenotype_id, experiment_ref_id)
             if phenotype_experiment_ref_pair not in seen_phenotype_experiment_ref_pairs:
                 seen_phenotype_experiment_ref_pairs.add(phenotype_experiment_ref_pair)
 
-                yield BioCypherEdge(
+                edge = BioCypherEdge(
                     source_id=phenotype_id,
                     target_id=experiment_ref_id,
                     relationship_label="phenotype member of",
                 )
+                edges.append(edge)
+        return edges
 
     def _get_media_environment_edges(self) -> Generator[BioCypherEdge, None, None]:
+        edges = []
         seen_media_environment_pairs: Set[tuple] = set()
-
         for i, data in tqdm(enumerate(self.dataset)):
             environment_id = hashlib.md5(
                 json.dumps(data["experiment"].environment.model_dump()).encode("utf-8")
             ).hexdigest()
             media_id = hashlib.md5(
                 json.dumps(data["experiment"].environment.media.model_dump()).encode(
                     "utf-8"
                 )
             ).hexdigest()
 
             media_environment_pair = (media_id, environment_id)
             if media_environment_pair not in seen_media_environment_pairs:
                 seen_media_environment_pairs.add(media_environment_pair)
 
-                yield BioCypherEdge(
+                edge = BioCypherEdge(
                     source_id=media_id,
                     target_id=environment_id,
                     relationship_label="media member of",
                 )
+                edges.append(edge)
+        return edges
 
     def _get_temperature_environment_edges(
         self,
     ) -> Generator[BioCypherEdge, None, None]:
+        edges = []
         seen_temperature_environment_pairs: Set[tuple] = set()
-
         for i, data in tqdm(enumerate(self.dataset)):
             environment_id = hashlib.md5(
                 json.dumps(data["experiment"].environment.model_dump()).encode("utf-8")
             ).hexdigest()
             temperature_id = hashlib.md5(
                 json.dumps(
                     data["experiment"].environment.temperature.model_dump()
                 ).encode("utf-8")
             ).hexdigest()
 
             temperature_environment_pair = (temperature_id, environment_id)
             if temperature_environment_pair not in seen_temperature_environment_pairs:
                 seen_temperature_environment_pairs.add(temperature_environment_pair)
 
-                yield BioCypherEdge(
+                edge = BioCypherEdge(
                     source_id=temperature_id,
                     target_id=environment_id,
                     relationship_label="temperature member of",
                 )
+                edges.append(edge)
+        return edges
 
     def _get_genome_edges(self) -> None:
+        edges = []
         seen_genome_experiment_ref_pairs: Set[tuple] = set()
-
-        for i, data in tqdm(enumerate(self.dataset)):
+        for i, data in tqdm(enumerate(self.dataset.experiment_reference_index)):
             experiment_ref_id = hashlib.md5(
-                json.dumps(data["experiment"].model_dump()).encode("utf-8")
+                json.dumps(data.reference.model_dump()).encode("utf-8")
             ).hexdigest()
 
             genome_id = hashlib.md5(
-                json.dumps(data["reference"].reference_genome.model_dump()).encode(
+                json.dumps(data.reference.reference_genome.model_dump()).encode(
                     "utf-8"
                 )
             ).hexdigest()
 
             genome_experiment_ref_pair = (genome_id, experiment_ref_id)
             if genome_experiment_ref_pair not in seen_genome_experiment_ref_pairs:
                 seen_genome_experiment_ref_pairs.add(genome_experiment_ref_pair)
 
-                yield BioCypherEdge(
+                edge = BioCypherEdge(
                     source_id=genome_id,
                     target_id=experiment_ref_id,
                     relationship_label="genome member of",
                 )
+                edges.append(edge)
+        return edges
+
 

commit 3aea9fad09c8c6186e1e48a0c194a501285c9be6
Author: mjvolk3 <mjvolk3>
Date:   Fri Jan 19 08:04:34 2024 -0600

    nan to None in SmfKuzmin2018

diff --git a/torchcell/adapters/kuzmin2018_adapter.py b/torchcell/adapters/kuzmin2018_adapter.py
--- a/torchcell/adapters/kuzmin2018_adapter.py
+++ b/torchcell/adapters/kuzmin2018_adapter.py
@@ -696,685 +696,653 @@
 class DmfKuzmin2018Adapter:
-    def __init__(self, dataset: SmfKuzmin2018Dataset):
+    def __init__(self, dataset: DmfKuzmin2018Dataset):
         self.dataset = dataset
 
     def get_nodes(self) -> None:
         logger.info("Getting nodes.")
         logger.info("Get experiment reference nodes.")
         yield from self._get_experiment_reference_nodes()
         logger.info("Get genome nodes.")
         yield from self._get_genome_nodes()
         logger.info("Get experiment nodes.")
         yield from self._get_experiment_nodes()
         logger.info("Get dataset nodes.")
         yield from self._get_dataset_nodes()
         logger.info("Get genotype nodes.")
         logger.info("--- perturbation nodes.")
         yield from self._get_genotype_nodes()
         logger.info("Get environment nodes.")
         yield from self._get_environment_nodes()
         logger.info("Get media nodes.")
         yield from self._get_media_nodes()
         logger.info("Get temperature nodes.")
         yield from self._get_temperature_nodes()
         logger.info("Get phenotype nodes.")
         yield from self._get_phenotype_nodes()
 
     def _get_experiment_reference_nodes(self) -> None:
-        for i, data in enumerate(self.dataset.experiment_reference_index):
+        for i, data in tqdm(enumerate(self.dataset.experiment_reference_index)):
             experiment_ref_id = hashlib.md5(
                 json.dumps(data.reference.model_dump()).encode("utf-8")
             ).hexdigest()
             yield BioCypherNode(
                 node_id=experiment_ref_id,
                 preferred_id=f"CostanzoSmf2016_reference_{i}",
                 node_label="experiment reference",
                 properties={
                     "dataset_index": i,
                     "serialized_data": json.dumps(data.reference.model_dump()),
                 },
             )
 
     def _get_genome_nodes(self) -> None:
         seen_node_ids: Set[str] = set()
 
-        for i, data in enumerate(self.dataset.experiment_reference_index):
+        for i, data in tqdm(enumerate(self.dataset.experiment_reference_index)):
             genome_id = hashlib.md5(
                 json.dumps(data.reference.reference_genome.model_dump()).encode("utf-8")
             ).hexdigest()
 
             if genome_id not in seen_node_ids:
                 seen_node_ids.add(genome_id)
                 yield BioCypherNode(
                     node_id=genome_id,
                     preferred_id=f"reference_genome_{i}",
                     node_label="genome",
                     properties={
                         "species": data.reference.reference_genome.species,
                         "strain": data.reference.reference_genome.strain,
                         "serialized_data": json.dumps(
                             data.reference.reference_genome.model_dump()
                         ),
                     },
                 )
 
-    # def _get_experiment_nodes(self) -> None:
-    #     seen_node_ids: Set[str] = set()
-
-    #     for i, data in enumerate(self.dataset):
-    #         experiment_id = hashlib.md5(
-    #             json.dumps(data["experiment"].model_dump()).encode("utf-8")
-    #         ).hexdigest()
-
-    #         if experiment_id not in seen_node_ids:
-    #             seen_node_ids.add(experiment_id)
-    #             yield BioCypherNode(
-    #                 node_id=experiment_id,
-    #                 preferred_id=f"CostanzoSmf2016_{i}",
-    #                 node_label="experiment",
-    #                 properties={
-    #                     "dataset_index": i,
-    #                     "serialized_data": json.dumps(data["experiment"].model_dump()),
-    #                 },
-    #             )
-    #         else:
-    #             # print self.dataset of the two matching dataset[i]['experiment']
-
     def _get_experiment_nodes(self) -> None:
-        seen_node_ids: Dict[str, int] = {}
-
-        for i, data in enumerate(self.dataset):
+        for i, data in tqdm(enumerate(self.dataset)):
             experiment_id = hashlib.md5(
                 json.dumps(data["experiment"].model_dump()).encode("utf-8")
             ).hexdigest()
 
-            if experiment_id not in seen_node_ids:
-                seen_node_ids[experiment_id] = i
-                yield BioCypherNode(
-                    node_id=experiment_id,
-                    preferred_id=f"CostanzoSmf2016_{i}",
-                    node_label="experiment",
-                    properties={
-                        "dataset_index": i,
-                        "serialized_data": json.dumps(data["experiment"].model_dump()),
-                    },
-                )
-            else:
-                first_seen_index = seen_node_ids[experiment_id]
-                print(f"Duplicate experiment_id found at indices {first_seen_index} and {i}")
-                print("First occurrence:", self.dataset[first_seen_index]['experiment'])
-                print("Current occurrence:", self.dataset[i]['experiment'])
-                print()
-
+            yield BioCypherNode(
+                node_id=experiment_id,
+                preferred_id=f"CostanzoSmf2016_{i}",
+                node_label="experiment",
+                properties={
+                    "dataset_index": i,
+                    "serialized_data": json.dumps(data["experiment"].model_dump()),
+                },
+            )
+            
     def _get_genotype_nodes(self) -> Generator[BioCypherNode, None, None]:
         seen_node_ids: Set[str] = set()
-        for i, data in enumerate(self.dataset):
+        for i, data in tqdm(enumerate(self.dataset)):
             for genotype in data["experiment"].genotype:
                 genotype_id = hashlib.md5(
                     json.dumps(genotype.model_dump()).encode("utf-8")
                 ).hexdigest()
 
                 if genotype_id not in seen_node_ids:
                     seen_node_ids.add(genotype_id)
                     systematic_gene_name = genotype.perturbation.systematic_gene_name
                     perturbed_gene_name = genotype.perturbation.perturbed_gene_name
                     description = genotype.perturbation.description
                     perturbation_type = genotype.perturbation.perturbation_type
                     self._get_perturbation(genotype)
 
                     yield BioCypherNode(
                         node_id=genotype_id,
                         preferred_id=f"genotype_{i}",
                         node_label="genotype",
                         properties={
                             "systematic_gene_names": [systematic_gene_name],
                             "perturbed_gene_names": [perturbed_gene_name],
                             "is_deletion_genotype": isinstance(
                                 data["experiment"].genotype, DeletionGenotype
                             ),
                             "is_interference_genotype": isinstance(
                                 data["experiment"].genotype, InterferenceGenotype
                             ),
                             "description": description,
                             "perturbation_types": [perturbation_type],
                             "serialized_data": json.dumps(genotype.model_dump()),
                         },
                     )
 
     @staticmethod
     def _get_perturbation(
         genotype: BaseGenotype,
     ) -> Generator[BioCypherNode, None, None]:
         if genotype.perturbation:
             i = 1
             perturbation_id = hashlib.md5(
                 json.dumps(genotype.perturbation.model_dump()).encode("utf-8")
             ).hexdigest()
 
             yield BioCypherNode(
                 node_id=perturbation_id,
                 preferred_id=f"perturbation_{i}",
                 node_label="perturbation",
                 properties={
                     "systematic_gene_name": [
                         genotype.perturbation.systematic_gene_name
                     ],
                     "perturbed_gene_name": [genotype.perturbation.perturbed_gene_name],
                     "description": genotype.perturbation.description,
                     "perturbation_type": genotype.perturbation.perturbation_type,
                     "strain_id": genotype.perturbation.strain_id,
                     "serialized_data": json.dumps(genotype.perturbation.model_dump()),
                 },
             )
 
     def _get_environment_nodes(self) -> Generator[BioCypherNode, None, None]:
         seen_node_ids: Set[str] = set()
-        for i, data in enumerate(self.dataset):
+        for i, data in tqdm(enumerate(self.dataset)):
             environment_id = hashlib.md5(
                 json.dumps(data["experiment"].environment.model_dump()).encode("utf-8")
             ).hexdigest()
 
             node_id = environment_id
 
             if node_id not in seen_node_ids:
                 seen_node_ids.add(node_id)
                 media = json.dumps(data["experiment"].environment.media.model_dump())
 
                 yield BioCypherNode(
                     node_id=node_id,
                     preferred_id=f"environment_{i}",
                     node_label="environment",
                     properties={
                         "temperature": data["experiment"].environment.temperature.value,
                         "media": media,
                         "serialized_data": json.dumps(
                             data["experiment"].environment.model_dump()
                         ),
                     },
                 )
-        for i, data in enumerate(self.dataset):
+        for i, data in tqdm(enumerate(self.dataset)):
             environment_id = hashlib.md5(
                 json.dumps(data["reference"].reference_environment.model_dump()).encode(
                     "utf-8"
                 )
             ).hexdigest()
 
             node_id = environment_id
 
             if node_id not in seen_node_ids:
                 seen_node_ids.add(node_id)
                 media = json.dumps(
                     data["reference"].reference_environment.media.model_dump()
                 )
 
                 yield BioCypherNode(
                     node_id=node_id,
                     preferred_id=f"environment_{i}",
                     node_label="environment",
                     properties={
                         "temperature": data[
                             "reference"
                         ].reference_environment.temperature.value,
                         "media": media,
                         "serialized_data": json.dumps(
                             data["reference"].reference_environment.model_dump()
                         ),
                     },
                 )
 
     def _get_media_nodes(self) -> Generator[BioCypherNode, None, None]:
         seen_node_ids: Set[str] = set()
-        for i, data in enumerate(self.dataset):
+        for i, data in tqdm(enumerate(self.dataset)):
             media_id = hashlib.md5(
                 json.dumps(data["experiment"].environment.media.model_dump()).encode(
                     "utf-8"
                 )
             ).hexdigest()
 
             if media_id not in seen_node_ids:
                 seen_node_ids.add(media_id)
                 name = data["experiment"].environment.media.name
                 state = data["experiment"].environment.media.state
 
                 yield BioCypherNode(
                     node_id=media_id,
                     preferred_id=f"media_{media_id}",
                     node_label="media",
                     properties={
                         "name": name,
                         "state": state,
                         "serialized_data": json.dumps(
                             data["experiment"].environment.media.model_dump()
                         ),
                     },
                 )
-        for i, data in enumerate(self.dataset):
+        for i, data in tqdm(enumerate(self.dataset)):
             media_id = hashlib.md5(
                 json.dumps(
                     data["reference"].reference_environment.media.model_dump()
                 ).encode("utf-8")
             ).hexdigest()
 
             if media_id not in seen_node_ids:
                 seen_node_ids.add(media_id)
                 name = data["reference"].reference_environment.media.name
                 state = data["reference"].reference_environment.media.state
 
                 yield BioCypherNode(
                     node_id=media_id,
                     preferred_id=f"media_{media_id}",
                     node_label="media",
                     properties={
                         "name": name,
                         "state": state,
                         "serialized_data": json.dumps(
                             data["reference"].reference_environment.media.model_dump()
                         ),
                     },
                 )
 
     def _get_temperature_nodes(self) -> Generator[BioCypherNode, None, None]:
         seen_node_ids: Set[str] = set()
-        for i, data in enumerate(self.dataset):
+        for i, data in tqdm(enumerate(self.dataset)):
             temperature_id = hashlib.md5(
                 json.dumps(
                     data["experiment"].environment.temperature.model_dump()
                 ).encode("utf-8")
             ).hexdigest()
 
             if temperature_id not in seen_node_ids:
                 seen_node_ids.add(temperature_id)
 
                 yield BioCypherNode(
                     node_id=temperature_id,
                     preferred_id=f"temperature_{temperature_id}",
                     node_label="temperature",
                     properties={
                         "value": data["experiment"].environment.temperature.value,
                         "unit": data["experiment"].environment.temperature.unit,
                         "serialized_data": json.dumps(
                             data["experiment"].environment.temperature.model_dump()
                         ),
                     },
                 )
 
-        for i, data in enumerate(self.dataset):
+        for i, data in tqdm(enumerate(self.dataset)):
             temperature_id = hashlib.md5(
                 json.dumps(
                     data["reference"].reference_environment.temperature.model_dump()
                 ).encode("utf-8")
             ).hexdigest()
 
             if temperature_id not in seen_node_ids:
                 seen_node_ids.add(temperature_id)
 
                 yield BioCypherNode(
                     node_id=temperature_id,
                     preferred_id=f"temperature_{temperature_id}",
                     node_label="temperature",
                     properties={
                         "value": data[
                             "reference"
                         ].reference_environment.temperature.value,
                         "description": data[
                             "reference"
                         ].reference_environment.temperature.description,
                         "serialized_data": json.dumps(
                             data[
                                 "reference"
                             ].reference_environment.temperature.model_dump()
                         ),
                     },
                 )
 
     def _get_phenotype_nodes(self) -> Generator[BioCypherNode, None, None]:
         seen_node_ids: Set[str] = set()
-        for i, data in enumerate(self.dataset):
+        for i, data in tqdm(enumerate(self.dataset)):
             phenotype_id = hashlib.md5(
                 json.dumps(data["experiment"].phenotype.model_dump()).encode("utf-8")
             ).hexdigest()
 
             if phenotype_id not in seen_node_ids:
                 seen_node_ids.add(phenotype_id)
                 graph_level = data["experiment"].phenotype.graph_level
                 label = data["experiment"].phenotype.label
                 label_error = data["experiment"].phenotype.label_error
                 fitness = data["experiment"].phenotype.fitness
                 fitness_std = data["experiment"].phenotype.fitness_std
 
                 yield BioCypherNode(
                     node_id=phenotype_id,
                     preferred_id=f"phenotype_{phenotype_id}",
                     node_label="phenotype",
                     properties={
                         "graph_level": graph_level,
                         "label": label,
                         "label_error": label_error,
                         "fitness": fitness,
                         "fitness_std": fitness_std,
                         "serialized_data": json.dumps(
                             data["experiment"].phenotype.model_dump()
                         ),
                     },
                 )
 
         # References
-        for i, data in enumerate(self.dataset):
+        for i, data in tqdm(enumerate(self.dataset)):
             # Get the phenotype ID associated with the experiment reference
             phenotype_id = hashlib.md5(
                 json.dumps(data["reference"].reference_phenotype.model_dump()).encode(
                     "utf-8"
                 )
             ).hexdigest()
 
             if phenotype_id not in seen_node_ids:
                 seen_node_ids.add(phenotype_id)
                 graph_level = data["reference"].reference_phenotype.graph_level
                 label = data["reference"].reference_phenotype.label
                 label_error = data["reference"].reference_phenotype.label_error
                 fitness = data["reference"].reference_phenotype.fitness
                 fitness_std = data["reference"].reference_phenotype.fitness_std
 
                 yield BioCypherNode(
                     node_id=phenotype_id,
                     preferred_id=f"phenotype_{phenotype_id}",
                     node_label="phenotype",
                     properties={
                         "graph_level": graph_level,
                         "label": label,
                         "label_error": label_error,
                         "fitness": fitness,
                         "fitness_std": fitness_std,
                         "serialized_data": json.dumps(
                             data["reference"].reference_phenotype.model_dump()
                         ),
                     },
                 )
 
     def _get_dataset_nodes(self) -> None:
         yield BioCypherNode(
             node_id="CostanzoSmf2016",
             preferred_id="CostanzoSmf2016",
             node_label="dataset",
         )
 
     def get_edges(self) -> None:
         logger.info("Generating edges.")
         logger.info("Get dataset experiment reference edges.")
         yield from self._get_dataset_experiment_ref_edges()
         logger.info("Get experiment dataset edges.")
         yield from self._get_experiment_dataset_edges()
         logger.info("Get experiment reference experiment edges.")
         yield from self._get_experiment_ref_experiment_edges()
         logger.info("Get genotype experiment edges.")
         logger.info("--- perturbation genotype edges.")
         yield from self._get_genotype_experiment_edges()
         logger.info("Get environment experiment edges.")
         yield from self._get_environment_experiment_edges()
         logger.info("Get environment experiment reference edges.")
         yield from self._get_environment_experiment_ref_edges()
         logger.info("Get phenotype experiment edges.")
         yield from self._get_phenotype_experiment_edges()
         logger.info("Get phenotype experiment reference edges.")
         yield from self._get_phenotype_experiment_ref_edges()
         logger.info("Get media environment edges.")
         yield from self._get_media_environment_edges()
         logger.info("Get temperature environment edges.")
         yield from self._get_temperature_environment_edges()
         logger.info("Get genome experiment reference edges.")
         yield from self._get_genome_edges()
 
     def _get_dataset_experiment_ref_edges(self):
         # concept level
-        for data in self.dataset:
+        for data in tqdm(self.dataset):
             experiment_ref_id = hashlib.md5(
                 json.dumps(data["experiment"].model_dump()).encode("utf-8")
             ).hexdigest()
             yield BioCypherEdge(
                 source_id=experiment_ref_id,
                 target_id="CostanzoSmf2016",
                 relationship_label="experiment reference member of",
             )
 
     def _get_experiment_dataset_edges(self):
         # concept level
-        for i, data in enumerate(self.dataset):
+        for i, data in tqdm(enumerate(self.dataset)):
             experiment_id = hashlib.md5(
                 json.dumps(data["experiment"].model_dump()).encode("utf-8")
             ).hexdigest()
             yield BioCypherEdge(
                 source_id=experiment_id,
                 target_id="CostanzoSmf2016",
                 relationship_label="experiment member of",
             )
 
     def _get_experiment_ref_experiment_edges(self):
         # instance level
         print()
-        for data in self.dataset.experiment_reference_index:
+        for data in tqdm(self.dataset.experiment_reference_index):
             dataset_subset = self.dataset[torch.tensor(data.index)]
             experiment_ref_id = hashlib.md5(
                 json.dumps(data.reference.model_dump()).encode("utf-8")
             ).hexdigest()
             for i, data in enumerate(dataset_subset):
                 experiment_id = hashlib.md5(
                     json.dumps(data["experiment"].model_dump()).encode("utf-8")
                 ).hexdigest()
                 yield BioCypherEdge(
                     source_id=experiment_ref_id,
                     target_id=experiment_id,
                     relationship_label="experiment reference of",
                 )
 
     def _get_genotype_experiment_edges(self) -> Generator[BioCypherEdge, None, None]:
         # CHECK if needed - don't think needed since exp ref index
         # seen_genotype_experiment_pairs: Set[tuple] = set()
-        for i, data in enumerate(self.dataset):
+        for i, data in tqdm(enumerate(self.dataset)):
             experiment_id = hashlib.md5(
                 json.dumps(data["experiment"].model_dump()).encode("utf-8")
             ).hexdigest()
             for genotype in data["experiment"].genotype:
                 genotype_id = hashlib.md5(
                     json.dumps(genotype.model_dump()).encode("utf-8")
                 ).hexdigest()
 
                 self._get_perturbation_genotype_edges(
                     genotype=genotype, genotype_id=genotype_id
                 )
 
                 # CHECK if needed - don't think needed since exp ref index
                 # genotype_experiment_pair = (genotype_id, experiment_id)
                 # if genotype_experiment_pair not in seen_genotype_experiment_pairs:
                 #     seen_genotype_experiment_pairs.add(genotype_experiment_pair)
 
                 yield BioCypherEdge(
                     source_id=genotype_id,
                     target_id=experiment_id,
                     relationship_label="genotype member of",
                 )
 
     @staticmethod
     def _get_perturbation_genotype_edges(
         genotype: BaseGenotype, genotype_id: str
     ) -> Generator[BioCypherEdge, None, None]:
         if genotype.perturbation:
             perturbation_id = hashlib.md5(
                 json.dumps(genotype.perturbation.model_dump()).encode("utf-8")
             ).hexdigest()
 
             yield BioCypherEdge(
                 source_id=perturbation_id,
                 target_id=genotype_id,
                 relationship_label="perturbation member of",
             )
 
     def _get_environment_experiment_edges(self) -> Generator[BioCypherEdge, None, None]:
         seen_environment_experiment_pairs: Set[tuple] = set()
 
         # Linking environments to experiments
-        for i, data in enumerate(self.dataset):
+        for i, data in tqdm(enumerate(self.dataset)):
             experiment_id = hashlib.md5(
                 json.dumps(data["experiment"].model_dump()).encode("utf-8")
             ).hexdigest()
             environment_id = hashlib.md5(
                 json.dumps(data["experiment"].environment.model_dump()).encode("utf-8")
             ).hexdigest()
 
             env_experiment_pair = (environment_id, experiment_id)
             if env_experiment_pair not in seen_environment_experiment_pairs:
                 seen_environment_experiment_pairs.add(env_experiment_pair)
 
                 yield BioCypherEdge(
                     source_id=environment_id,
                     target_id=experiment_id,
                     relationship_label="environment member of",
                 )
 
     def _get_environment_experiment_ref_edges(
         self,
     ) -> Generator[BioCypherEdge, None, None]:
         seen_environment_experiment_ref_pairs: Set[tuple] = set()
 
         # Linking environments to experiment references
-        for i, data in enumerate(self.dataset.experiment_reference_index):
+        for i, data in tqdm(enumerate(self.dataset.experiment_reference_index)):
             experiment_ref_id = hashlib.md5(
                 json.dumps(data.reference.model_dump()).encode("utf-8")
             ).hexdigest()
 
             environment_id = hashlib.md5(
                 json.dumps(data.reference.reference_environment.model_dump()).encode(
                     "utf-8"
                 )
             ).hexdigest()
 
             env_experiment_ref_pair = (environment_id, experiment_ref_id)
             if env_experiment_ref_pair not in seen_environment_experiment_ref_pairs:
                 seen_environment_experiment_ref_pairs.add(env_experiment_ref_pair)
 
                 yield BioCypherEdge(
                     source_id=environment_id,
                     target_id=experiment_ref_id,
                     relationship_label="environment member of",
                 )
 
     def _get_phenotype_experiment_edges(self) -> Generator[BioCypherEdge, None, None]:
         seen_phenotype_experiment_pairs: Set[tuple] = set()
 
         # Linking phenotypes to experiments
-        for i, data in enumerate(self.dataset):
+        for i, data in tqdm(enumerate(self.dataset)):
             experiment_id = hashlib.md5(
                 json.dumps(data["experiment"].model_dump()).encode("utf-8")
             ).hexdigest()
             phenotype_id = hashlib.md5(
                 json.dumps(data["experiment"].phenotype.model_dump()).encode("utf-8")
             ).hexdigest()
 
             phenotype_experiment_pair = (phenotype_id, experiment_id)
             if phenotype_experiment_pair not in seen_phenotype_experiment_pairs:
                 seen_phenotype_experiment_pairs.add(phenotype_experiment_pair)
 
                 yield BioCypherEdge(
                     source_id=phenotype_id,
                     target_id=experiment_id,
                     relationship_label="phenotype member of",
                 )
 
     def _get_phenotype_experiment_ref_edges(
         self,
     ) -> Generator[BioCypherEdge, None, None]:
         seen_phenotype_experiment_ref_pairs: Set[tuple] = set()
 
         # Linking phenotypes to experiment references
-        for i, data in enumerate(self.dataset):
+        for i, data in tqdm(enumerate(self.dataset)):
             experiment_ref_id = hashlib.md5(
                 json.dumps(data["experiment"].model_dump()).encode("utf-8")
             ).hexdigest()
 
             # Get the phenotype ID associated with the experiment reference
             phenotype_id = hashlib.md5(
                 json.dumps(data["reference"].reference_phenotype.model_dump()).encode(
                     "utf-8"
                 )
             ).hexdigest()
 
             phenotype_experiment_ref_pair = (phenotype_id, experiment_ref_id)
             if phenotype_experiment_ref_pair not in seen_phenotype_experiment_ref_pairs:
                 seen_phenotype_experiment_ref_pairs.add(phenotype_experiment_ref_pair)
 
                 yield BioCypherEdge(
                     source_id=phenotype_id,
                     target_id=experiment_ref_id,
                     relationship_label="phenotype member of",
                 )
 
     def _get_media_environment_edges(self) -> Generator[BioCypherEdge, None, None]:
         seen_media_environment_pairs: Set[tuple] = set()
 
-        for i, data in enumerate(self.dataset):
+        for i, data in tqdm(enumerate(self.dataset)):
             environment_id = hashlib.md5(
                 json.dumps(data["experiment"].environment.model_dump()).encode("utf-8")
             ).hexdigest()
             media_id = hashlib.md5(
                 json.dumps(data["experiment"].environment.media.model_dump()).encode(
                     "utf-8"
                 )
             ).hexdigest()
 
             media_environment_pair = (media_id, environment_id)
             if media_environment_pair not in seen_media_environment_pairs:
                 seen_media_environment_pairs.add(media_environment_pair)
 
                 yield BioCypherEdge(
                     source_id=media_id,
                     target_id=environment_id,
                     relationship_label="media member of",
                 )
 
     def _get_temperature_environment_edges(
         self,
     ) -> Generator[BioCypherEdge, None, None]:
         seen_temperature_environment_pairs: Set[tuple] = set()
 
-        for i, data in enumerate(self.dataset):
+        for i, data in tqdm(enumerate(self.dataset)):
             environment_id = hashlib.md5(
                 json.dumps(data["experiment"].environment.model_dump()).encode("utf-8")
             ).hexdigest()
             temperature_id = hashlib.md5(
                 json.dumps(
                     data["experiment"].environment.temperature.model_dump()
                 ).encode("utf-8")
             ).hexdigest()
 
             temperature_environment_pair = (temperature_id, environment_id)
             if temperature_environment_pair not in seen_temperature_environment_pairs:
                 seen_temperature_environment_pairs.add(temperature_environment_pair)
 
                 yield BioCypherEdge(
                     source_id=temperature_id,
                     target_id=environment_id,
                     relationship_label="temperature member of",
                 )
 
     def _get_genome_edges(self) -> None:
         seen_genome_experiment_ref_pairs: Set[tuple] = set()
 
-        for i, data in enumerate(self.dataset):
+        for i, data in tqdm(enumerate(self.dataset)):
             experiment_ref_id = hashlib.md5(
                 json.dumps(data["experiment"].model_dump()).encode("utf-8")
             ).hexdigest()
 
             genome_id = hashlib.md5(
                 json.dumps(data["reference"].reference_genome.model_dump()).encode(
                     "utf-8"
                 )
             ).hexdigest()
 
             genome_experiment_ref_pair = (genome_id, experiment_ref_id)
             if genome_experiment_ref_pair not in seen_genome_experiment_ref_pairs:
                 seen_genome_experiment_ref_pairs.add(genome_experiment_ref_pair)
 
                 yield BioCypherEdge(
                     source_id=genome_id,
                     target_id=experiment_ref_id,
                     relationship_label="genome member of",
                 )
 

commit c1eefc0f382a1058ee2b067e579d34f33b256b63
Author: mjvolk3 <mjvolk3>
Date:   Thu Jan 18 01:48:34 2024 -0600

    DmfKuzmin2018Adapter works

diff --git a/torchcell/adapters/kuzmin2018_adapter.py b/torchcell/adapters/kuzmin2018_adapter.py
--- /dev/null
+++ b/torchcell/adapters/kuzmin2018_adapter.py
@@ -0,0 +696,685 @@
+class DmfKuzmin2018Adapter:
+    def __init__(self, dataset: SmfKuzmin2018Dataset):
+        self.dataset = dataset
+
+    def get_nodes(self) -> None:
+        logger.info("Getting nodes.")
+        logger.info("Get experiment reference nodes.")
+        yield from self._get_experiment_reference_nodes()
+        logger.info("Get genome nodes.")
+        yield from self._get_genome_nodes()
+        logger.info("Get experiment nodes.")
+        yield from self._get_experiment_nodes()
+        logger.info("Get dataset nodes.")
+        yield from self._get_dataset_nodes()
+        logger.info("Get genotype nodes.")
+        logger.info("--- perturbation nodes.")
+        yield from self._get_genotype_nodes()
+        logger.info("Get environment nodes.")
+        yield from self._get_environment_nodes()
+        logger.info("Get media nodes.")
+        yield from self._get_media_nodes()
+        logger.info("Get temperature nodes.")
+        yield from self._get_temperature_nodes()
+        logger.info("Get phenotype nodes.")
+        yield from self._get_phenotype_nodes()
+
+    def _get_experiment_reference_nodes(self) -> None:
+        for i, data in enumerate(self.dataset.experiment_reference_index):
+            experiment_ref_id = hashlib.md5(
+                json.dumps(data.reference.model_dump()).encode("utf-8")
+            ).hexdigest()
+            yield BioCypherNode(
+                node_id=experiment_ref_id,
+                preferred_id=f"CostanzoSmf2016_reference_{i}",
+                node_label="experiment reference",
+                properties={
+                    "dataset_index": i,
+                    "serialized_data": json.dumps(data.reference.model_dump()),
+                },
+            )
+
+    def _get_genome_nodes(self) -> None:
+        seen_node_ids: Set[str] = set()
+
+        for i, data in enumerate(self.dataset.experiment_reference_index):
+            genome_id = hashlib.md5(
+                json.dumps(data.reference.reference_genome.model_dump()).encode("utf-8")
+            ).hexdigest()
+
+            if genome_id not in seen_node_ids:
+                seen_node_ids.add(genome_id)
+                yield BioCypherNode(
+                    node_id=genome_id,
+                    preferred_id=f"reference_genome_{i}",
+                    node_label="genome",
+                    properties={
+                        "species": data.reference.reference_genome.species,
+                        "strain": data.reference.reference_genome.strain,
+                        "serialized_data": json.dumps(
+                            data.reference.reference_genome.model_dump()
+                        ),
+                    },
+                )
+
+    # def _get_experiment_nodes(self) -> None:
+    #     seen_node_ids: Set[str] = set()
+
+    #     for i, data in enumerate(self.dataset):
+    #         experiment_id = hashlib.md5(
+    #             json.dumps(data["experiment"].model_dump()).encode("utf-8")
+    #         ).hexdigest()
+
+    #         if experiment_id not in seen_node_ids:
+    #             seen_node_ids.add(experiment_id)
+    #             yield BioCypherNode(
+    #                 node_id=experiment_id,
+    #                 preferred_id=f"CostanzoSmf2016_{i}",
+    #                 node_label="experiment",
+    #                 properties={
+    #                     "dataset_index": i,
+    #                     "serialized_data": json.dumps(data["experiment"].model_dump()),
+    #                 },
+    #             )
+    #         else:
+    #             # print self.dataset of the two matching dataset[i]['experiment']
+
+    def _get_experiment_nodes(self) -> None:
+        seen_node_ids: Dict[str, int] = {}
+
+        for i, data in enumerate(self.dataset):
+            experiment_id = hashlib.md5(
+                json.dumps(data["experiment"].model_dump()).encode("utf-8")
+            ).hexdigest()
+
+            if experiment_id not in seen_node_ids:
+                seen_node_ids[experiment_id] = i
+                yield BioCypherNode(
+                    node_id=experiment_id,
+                    preferred_id=f"CostanzoSmf2016_{i}",
+                    node_label="experiment",
+                    properties={
+                        "dataset_index": i,
+                        "serialized_data": json.dumps(data["experiment"].model_dump()),
+                    },
+                )
+            else:
+                first_seen_index = seen_node_ids[experiment_id]
+                print(f"Duplicate experiment_id found at indices {first_seen_index} and {i}")
+                print("First occurrence:", self.dataset[first_seen_index]['experiment'])
+                print("Current occurrence:", self.dataset[i]['experiment'])
+                print()
+
+    def _get_genotype_nodes(self) -> Generator[BioCypherNode, None, None]:
+        seen_node_ids: Set[str] = set()
+        for i, data in enumerate(self.dataset):
+            for genotype in data["experiment"].genotype:
+                genotype_id = hashlib.md5(
+                    json.dumps(genotype.model_dump()).encode("utf-8")
+                ).hexdigest()
+
+                if genotype_id not in seen_node_ids:
+                    seen_node_ids.add(genotype_id)
+                    systematic_gene_name = genotype.perturbation.systematic_gene_name
+                    perturbed_gene_name = genotype.perturbation.perturbed_gene_name
+                    description = genotype.perturbation.description
+                    perturbation_type = genotype.perturbation.perturbation_type
+                    self._get_perturbation(genotype)
+
+                    yield BioCypherNode(
+                        node_id=genotype_id,
+                        preferred_id=f"genotype_{i}",
+                        node_label="genotype",
+                        properties={
+                            "systematic_gene_names": [systematic_gene_name],
+                            "perturbed_gene_names": [perturbed_gene_name],
+                            "is_deletion_genotype": isinstance(
+                                data["experiment"].genotype, DeletionGenotype
+                            ),
+                            "is_interference_genotype": isinstance(
+                                data["experiment"].genotype, InterferenceGenotype
+                            ),
+                            "description": description,
+                            "perturbation_types": [perturbation_type],
+                            "serialized_data": json.dumps(genotype.model_dump()),
+                        },
+                    )
+
+    @staticmethod
+    def _get_perturbation(
+        genotype: BaseGenotype,
+    ) -> Generator[BioCypherNode, None, None]:
+        if genotype.perturbation:
+            i = 1
+            perturbation_id = hashlib.md5(
+                json.dumps(genotype.perturbation.model_dump()).encode("utf-8")
+            ).hexdigest()
+
+            yield BioCypherNode(
+                node_id=perturbation_id,
+                preferred_id=f"perturbation_{i}",
+                node_label="perturbation",
+                properties={
+                    "systematic_gene_name": [
+                        genotype.perturbation.systematic_gene_name
+                    ],
+                    "perturbed_gene_name": [genotype.perturbation.perturbed_gene_name],
+                    "description": genotype.perturbation.description,
+                    "perturbation_type": genotype.perturbation.perturbation_type,
+                    "strain_id": genotype.perturbation.strain_id,
+                    "serialized_data": json.dumps(genotype.perturbation.model_dump()),
+                },
+            )
+
+    def _get_environment_nodes(self) -> Generator[BioCypherNode, None, None]:
+        seen_node_ids: Set[str] = set()
+        for i, data in enumerate(self.dataset):
+            environment_id = hashlib.md5(
+                json.dumps(data["experiment"].environment.model_dump()).encode("utf-8")
+            ).hexdigest()
+
+            node_id = environment_id
+
+            if node_id not in seen_node_ids:
+                seen_node_ids.add(node_id)
+                media = json.dumps(data["experiment"].environment.media.model_dump())
+
+                yield BioCypherNode(
+                    node_id=node_id,
+                    preferred_id=f"environment_{i}",
+                    node_label="environment",
+                    properties={
+                        "temperature": data["experiment"].environment.temperature.value,
+                        "media": media,
+                        "serialized_data": json.dumps(
+                            data["experiment"].environment.model_dump()
+                        ),
+                    },
+                )
+        for i, data in enumerate(self.dataset):
+            environment_id = hashlib.md5(
+                json.dumps(data["reference"].reference_environment.model_dump()).encode(
+                    "utf-8"
+                )
+            ).hexdigest()
+
+            node_id = environment_id
+
+            if node_id not in seen_node_ids:
+                seen_node_ids.add(node_id)
+                media = json.dumps(
+                    data["reference"].reference_environment.media.model_dump()
+                )
+
+                yield BioCypherNode(
+                    node_id=node_id,
+                    preferred_id=f"environment_{i}",
+                    node_label="environment",
+                    properties={
+                        "temperature": data[
+                            "reference"
+                        ].reference_environment.temperature.value,
+                        "media": media,
+                        "serialized_data": json.dumps(
+                            data["reference"].reference_environment.model_dump()
+                        ),
+                    },
+                )
+
+    def _get_media_nodes(self) -> Generator[BioCypherNode, None, None]:
+        seen_node_ids: Set[str] = set()
+        for i, data in enumerate(self.dataset):
+            media_id = hashlib.md5(
+                json.dumps(data["experiment"].environment.media.model_dump()).encode(
+                    "utf-8"
+                )
+            ).hexdigest()
+
+            if media_id not in seen_node_ids:
+                seen_node_ids.add(media_id)
+                name = data["experiment"].environment.media.name
+                state = data["experiment"].environment.media.state
+
+                yield BioCypherNode(
+                    node_id=media_id,
+                    preferred_id=f"media_{media_id}",
+                    node_label="media",
+                    properties={
+                        "name": name,
+                        "state": state,
+                        "serialized_data": json.dumps(
+                            data["experiment"].environment.media.model_dump()
+                        ),
+                    },
+                )
+        for i, data in enumerate(self.dataset):
+            media_id = hashlib.md5(
+                json.dumps(
+                    data["reference"].reference_environment.media.model_dump()
+                ).encode("utf-8")
+            ).hexdigest()
+
+            if media_id not in seen_node_ids:
+                seen_node_ids.add(media_id)
+                name = data["reference"].reference_environment.media.name
+                state = data["reference"].reference_environment.media.state
+
+                yield BioCypherNode(
+                    node_id=media_id,
+                    preferred_id=f"media_{media_id}",
+                    node_label="media",
+                    properties={
+                        "name": name,
+                        "state": state,
+                        "serialized_data": json.dumps(
+                            data["reference"].reference_environment.media.model_dump()
+                        ),
+                    },
+                )
+
+    def _get_temperature_nodes(self) -> Generator[BioCypherNode, None, None]:
+        seen_node_ids: Set[str] = set()
+        for i, data in enumerate(self.dataset):
+            temperature_id = hashlib.md5(
+                json.dumps(
+                    data["experiment"].environment.temperature.model_dump()
+                ).encode("utf-8")
+            ).hexdigest()
+
+            if temperature_id not in seen_node_ids:
+                seen_node_ids.add(temperature_id)
+
+                yield BioCypherNode(
+                    node_id=temperature_id,
+                    preferred_id=f"temperature_{temperature_id}",
+                    node_label="temperature",
+                    properties={
+                        "value": data["experiment"].environment.temperature.value,
+                        "unit": data["experiment"].environment.temperature.unit,
+                        "serialized_data": json.dumps(
+                            data["experiment"].environment.temperature.model_dump()
+                        ),
+                    },
+                )
+
+        for i, data in enumerate(self.dataset):
+            temperature_id = hashlib.md5(
+                json.dumps(
+                    data["reference"].reference_environment.temperature.model_dump()
+                ).encode("utf-8")
+            ).hexdigest()
+
+            if temperature_id not in seen_node_ids:
+                seen_node_ids.add(temperature_id)
+
+                yield BioCypherNode(
+                    node_id=temperature_id,
+                    preferred_id=f"temperature_{temperature_id}",
+                    node_label="temperature",
+                    properties={
+                        "value": data[
+                            "reference"
+                        ].reference_environment.temperature.value,
+                        "description": data[
+                            "reference"
+                        ].reference_environment.temperature.description,
+                        "serialized_data": json.dumps(
+                            data[
+                                "reference"
+                            ].reference_environment.temperature.model_dump()
+                        ),
+                    },
+                )
+
+    def _get_phenotype_nodes(self) -> Generator[BioCypherNode, None, None]:
+        seen_node_ids: Set[str] = set()
+        for i, data in enumerate(self.dataset):
+            phenotype_id = hashlib.md5(
+                json.dumps(data["experiment"].phenotype.model_dump()).encode("utf-8")
+            ).hexdigest()
+
+            if phenotype_id not in seen_node_ids:
+                seen_node_ids.add(phenotype_id)
+                graph_level = data["experiment"].phenotype.graph_level
+                label = data["experiment"].phenotype.label
+                label_error = data["experiment"].phenotype.label_error
+                fitness = data["experiment"].phenotype.fitness
+                fitness_std = data["experiment"].phenotype.fitness_std
+
+                yield BioCypherNode(
+                    node_id=phenotype_id,
+                    preferred_id=f"phenotype_{phenotype_id}",
+                    node_label="phenotype",
+                    properties={
+                        "graph_level": graph_level,
+                        "label": label,
+                        "label_error": label_error,
+                        "fitness": fitness,
+                        "fitness_std": fitness_std,
+                        "serialized_data": json.dumps(
+                            data["experiment"].phenotype.model_dump()
+                        ),
+                    },
+                )
+
+        # References
+        for i, data in enumerate(self.dataset):
+            # Get the phenotype ID associated with the experiment reference
+            phenotype_id = hashlib.md5(
+                json.dumps(data["reference"].reference_phenotype.model_dump()).encode(
+                    "utf-8"
+                )
+            ).hexdigest()
+
+            if phenotype_id not in seen_node_ids:
+                seen_node_ids.add(phenotype_id)
+                graph_level = data["reference"].reference_phenotype.graph_level
+                label = data["reference"].reference_phenotype.label
+                label_error = data["reference"].reference_phenotype.label_error
+                fitness = data["reference"].reference_phenotype.fitness
+                fitness_std = data["reference"].reference_phenotype.fitness_std
+
+                yield BioCypherNode(
+                    node_id=phenotype_id,
+                    preferred_id=f"phenotype_{phenotype_id}",
+                    node_label="phenotype",
+                    properties={
+                        "graph_level": graph_level,
+                        "label": label,
+                        "label_error": label_error,
+                        "fitness": fitness,
+                        "fitness_std": fitness_std,
+                        "serialized_data": json.dumps(
+                            data["reference"].reference_phenotype.model_dump()
+                        ),
+                    },
+                )
+
+    def _get_dataset_nodes(self) -> None:
+        yield BioCypherNode(
+            node_id="CostanzoSmf2016",
+            preferred_id="CostanzoSmf2016",
+            node_label="dataset",
+        )
+
+    def get_edges(self) -> None:
+        logger.info("Generating edges.")
+        logger.info("Get dataset experiment reference edges.")
+        yield from self._get_dataset_experiment_ref_edges()
+        logger.info("Get experiment dataset edges.")
+        yield from self._get_experiment_dataset_edges()
+        logger.info("Get experiment reference experiment edges.")
+        yield from self._get_experiment_ref_experiment_edges()
+        logger.info("Get genotype experiment edges.")
+        logger.info("--- perturbation genotype edges.")
+        yield from self._get_genotype_experiment_edges()
+        logger.info("Get environment experiment edges.")
+        yield from self._get_environment_experiment_edges()
+        logger.info("Get environment experiment reference edges.")
+        yield from self._get_environment_experiment_ref_edges()
+        logger.info("Get phenotype experiment edges.")
+        yield from self._get_phenotype_experiment_edges()
+        logger.info("Get phenotype experiment reference edges.")
+        yield from self._get_phenotype_experiment_ref_edges()
+        logger.info("Get media environment edges.")
+        yield from self._get_media_environment_edges()
+        logger.info("Get temperature environment edges.")
+        yield from self._get_temperature_environment_edges()
+        logger.info("Get genome experiment reference edges.")
+        yield from self._get_genome_edges()
+
+    def _get_dataset_experiment_ref_edges(self):
+        # concept level
+        for data in self.dataset:
+            experiment_ref_id = hashlib.md5(
+                json.dumps(data["experiment"].model_dump()).encode("utf-8")
+            ).hexdigest()
+            yield BioCypherEdge(
+                source_id=experiment_ref_id,
+                target_id="CostanzoSmf2016",
+                relationship_label="experiment reference member of",
+            )
+
+    def _get_experiment_dataset_edges(self):
+        # concept level
+        for i, data in enumerate(self.dataset):
+            experiment_id = hashlib.md5(
+                json.dumps(data["experiment"].model_dump()).encode("utf-8")
+            ).hexdigest()
+            yield BioCypherEdge(
+                source_id=experiment_id,
+                target_id="CostanzoSmf2016",
+                relationship_label="experiment member of",
+            )
+
+    def _get_experiment_ref_experiment_edges(self):
+        # instance level
+        print()
+        for data in self.dataset.experiment_reference_index:
+            dataset_subset = self.dataset[torch.tensor(data.index)]
+            experiment_ref_id = hashlib.md5(
+                json.dumps(data.reference.model_dump()).encode("utf-8")
+            ).hexdigest()
+            for i, data in enumerate(dataset_subset):
+                experiment_id = hashlib.md5(
+                    json.dumps(data["experiment"].model_dump()).encode("utf-8")
+                ).hexdigest()
+                yield BioCypherEdge(
+                    source_id=experiment_ref_id,
+                    target_id=experiment_id,
+                    relationship_label="experiment reference of",
+                )
+
+    def _get_genotype_experiment_edges(self) -> Generator[BioCypherEdge, None, None]:
+        # CHECK if needed - don't think needed since exp ref index
+        # seen_genotype_experiment_pairs: Set[tuple] = set()
+        for i, data in enumerate(self.dataset):
+            experiment_id = hashlib.md5(
+                json.dumps(data["experiment"].model_dump()).encode("utf-8")
+            ).hexdigest()
+            for genotype in data["experiment"].genotype:
+                genotype_id = hashlib.md5(
+                    json.dumps(genotype.model_dump()).encode("utf-8")
+                ).hexdigest()
+
+                self._get_perturbation_genotype_edges(
+                    genotype=genotype, genotype_id=genotype_id
+                )
+
+                # CHECK if needed - don't think needed since exp ref index
+                # genotype_experiment_pair = (genotype_id, experiment_id)
+                # if genotype_experiment_pair not in seen_genotype_experiment_pairs:
+                #     seen_genotype_experiment_pairs.add(genotype_experiment_pair)
+
+                yield BioCypherEdge(
+                    source_id=genotype_id,
+                    target_id=experiment_id,
+                    relationship_label="genotype member of",
+                )
+
+    @staticmethod
+    def _get_perturbation_genotype_edges(
+        genotype: BaseGenotype, genotype_id: str
+    ) -> Generator[BioCypherEdge, None, None]:
+        if genotype.perturbation:
+            perturbation_id = hashlib.md5(
+                json.dumps(genotype.perturbation.model_dump()).encode("utf-8")
+            ).hexdigest()
+
+            yield BioCypherEdge(
+                source_id=perturbation_id,
+                target_id=genotype_id,
+                relationship_label="perturbation member of",
+            )
+
+    def _get_environment_experiment_edges(self) -> Generator[BioCypherEdge, None, None]:
+        seen_environment_experiment_pairs: Set[tuple] = set()
+
+        # Linking environments to experiments
+        for i, data in enumerate(self.dataset):
+            experiment_id = hashlib.md5(
+                json.dumps(data["experiment"].model_dump()).encode("utf-8")
+            ).hexdigest()
+            environment_id = hashlib.md5(
+                json.dumps(data["experiment"].environment.model_dump()).encode("utf-8")
+            ).hexdigest()
+
+            env_experiment_pair = (environment_id, experiment_id)
+            if env_experiment_pair not in seen_environment_experiment_pairs:
+                seen_environment_experiment_pairs.add(env_experiment_pair)
+
+                yield BioCypherEdge(
+                    source_id=environment_id,
+                    target_id=experiment_id,
+                    relationship_label="environment member of",
+                )
+
+    def _get_environment_experiment_ref_edges(
+        self,
+    ) -> Generator[BioCypherEdge, None, None]:
+        seen_environment_experiment_ref_pairs: Set[tuple] = set()
+
+        # Linking environments to experiment references
+        for i, data in enumerate(self.dataset.experiment_reference_index):
+            experiment_ref_id = hashlib.md5(
+                json.dumps(data.reference.model_dump()).encode("utf-8")
+            ).hexdigest()
+
+            environment_id = hashlib.md5(
+                json.dumps(data.reference.reference_environment.model_dump()).encode(
+                    "utf-8"
+                )
+            ).hexdigest()
+
+            env_experiment_ref_pair = (environment_id, experiment_ref_id)
+            if env_experiment_ref_pair not in seen_environment_experiment_ref_pairs:
+                seen_environment_experiment_ref_pairs.add(env_experiment_ref_pair)
+
+                yield BioCypherEdge(
+                    source_id=environment_id,
+                    target_id=experiment_ref_id,
+                    relationship_label="environment member of",
+                )
+
+    def _get_phenotype_experiment_edges(self) -> Generator[BioCypherEdge, None, None]:
+        seen_phenotype_experiment_pairs: Set[tuple] = set()
+
+        # Linking phenotypes to experiments
+        for i, data in enumerate(self.dataset):
+            experiment_id = hashlib.md5(
+                json.dumps(data["experiment"].model_dump()).encode("utf-8")
+            ).hexdigest()
+            phenotype_id = hashlib.md5(
+                json.dumps(data["experiment"].phenotype.model_dump()).encode("utf-8")
+            ).hexdigest()
+
+            phenotype_experiment_pair = (phenotype_id, experiment_id)
+            if phenotype_experiment_pair not in seen_phenotype_experiment_pairs:
+                seen_phenotype_experiment_pairs.add(phenotype_experiment_pair)
+
+                yield BioCypherEdge(
+                    source_id=phenotype_id,
+                    target_id=experiment_id,
+                    relationship_label="phenotype member of",
+                )
+
+    def _get_phenotype_experiment_ref_edges(
+        self,
+    ) -> Generator[BioCypherEdge, None, None]:
+        seen_phenotype_experiment_ref_pairs: Set[tuple] = set()
+
+        # Linking phenotypes to experiment references
+        for i, data in enumerate(self.dataset):
+            experiment_ref_id = hashlib.md5(
+                json.dumps(data["experiment"].model_dump()).encode("utf-8")
+            ).hexdigest()
+
+            # Get the phenotype ID associated with the experiment reference
+            phenotype_id = hashlib.md5(
+                json.dumps(data["reference"].reference_phenotype.model_dump()).encode(
+                    "utf-8"
+                )
+            ).hexdigest()
+
+            phenotype_experiment_ref_pair = (phenotype_id, experiment_ref_id)
+            if phenotype_experiment_ref_pair not in seen_phenotype_experiment_ref_pairs:
+                seen_phenotype_experiment_ref_pairs.add(phenotype_experiment_ref_pair)
+
+                yield BioCypherEdge(
+                    source_id=phenotype_id,
+                    target_id=experiment_ref_id,
+                    relationship_label="phenotype member of",
+                )
+
+    def _get_media_environment_edges(self) -> Generator[BioCypherEdge, None, None]:
+        seen_media_environment_pairs: Set[tuple] = set()
+
+        for i, data in enumerate(self.dataset):
+            environment_id = hashlib.md5(
+                json.dumps(data["experiment"].environment.model_dump()).encode("utf-8")
+            ).hexdigest()
+            media_id = hashlib.md5(
+                json.dumps(data["experiment"].environment.media.model_dump()).encode(
+                    "utf-8"
+                )
+            ).hexdigest()
+
+            media_environment_pair = (media_id, environment_id)
+            if media_environment_pair not in seen_media_environment_pairs:
+                seen_media_environment_pairs.add(media_environment_pair)
+
+                yield BioCypherEdge(
+                    source_id=media_id,
+                    target_id=environment_id,
+                    relationship_label="media member of",
+                )
+
+    def _get_temperature_environment_edges(
+        self,
+    ) -> Generator[BioCypherEdge, None, None]:
+        seen_temperature_environment_pairs: Set[tuple] = set()
+
+        for i, data in enumerate(self.dataset):
+            environment_id = hashlib.md5(
+                json.dumps(data["experiment"].environment.model_dump()).encode("utf-8")
+            ).hexdigest()
+            temperature_id = hashlib.md5(
+                json.dumps(
+                    data["experiment"].environment.temperature.model_dump()
+                ).encode("utf-8")
+            ).hexdigest()
+
+            temperature_environment_pair = (temperature_id, environment_id)
+            if temperature_environment_pair not in seen_temperature_environment_pairs:
+                seen_temperature_environment_pairs.add(temperature_environment_pair)
+
+                yield BioCypherEdge(
+                    source_id=temperature_id,
+                    target_id=environment_id,
+                    relationship_label="temperature member of",
+                )
+
+    def _get_genome_edges(self) -> None:
+        seen_genome_experiment_ref_pairs: Set[tuple] = set()
+
+        for i, data in enumerate(self.dataset):
+            experiment_ref_id = hashlib.md5(
+                json.dumps(data["experiment"].model_dump()).encode("utf-8")
+            ).hexdigest()
+
+            genome_id = hashlib.md5(
+                json.dumps(data["reference"].reference_genome.model_dump()).encode(
+                    "utf-8"
+                )
+            ).hexdigest()
+
+            genome_experiment_ref_pair = (genome_id, experiment_ref_id)
+            if genome_experiment_ref_pair not in seen_genome_experiment_ref_pairs:
+                seen_genome_experiment_ref_pairs.add(genome_experiment_ref_pair)
+
+                yield BioCypherEdge(
+                    source_id=genome_id,
+                    target_id=experiment_ref_id,
+                    relationship_label="genome member of",
+                )
+
