defaults:
  - default
  - _self_ # append to end for overriding duplicate configs in default

wandb:
  mode: offline # disabled, offline, online
  project: torchcell_test
  tags: []

cell_dataset:
  graphs: null #[physical], [regulatory], [physical, regulatory], []
  node_embeddings: [esm2_t33_650M_UR50D_all] #one_hot_gene, codon_frequency, fudt_downstream, fudt_upstream, prot_T5_all, prot_T5_no_dubious, nt_window_5979, nt_window_5979_max, nt_window_three_prime_5979, nt_window_five_prime_5979, nt_window_three_prime_300, nt_window_five_prime_1003, esm2_t33_650M_UR50D_all, esm2_t33_650M_UR50D_no_dubious, esm2_t33_650M_UR50D_no_dubious_uncharacterized, esm2_t33_650M_UR50D_no_uncharacterized, normalized_chr_2_mean_pathways_4, normalized_chr_2_sum_pathways_4,

  max_size: 1e2

data_module:
  batch_size: 16 #32
  num_workers: 10
  pin_memory: true

trainer:
  max_epochs: 2
  strategy: auto # ddp, auto

models:
  graph:
    in_channels: null # This will be set based on the input_dim
    hidden_channels: 128
    out_channels: 32
    num_node_layers: 3
    num_set_layers: 3
    norm: batch
    activation: gelu
    skip_node: true
    skip_set: true
  pred_head:
    layer_dims: [1]

regression_task:
  target: fitness # fitness
  boxplot_every_n_epochs: 1
  learning_rate: 1e-2 #1e-3
  weight_decay: 1e-5
  loss: mse
  clip_grad_norm: true
  clip_grad_norm_max_norm: 10
