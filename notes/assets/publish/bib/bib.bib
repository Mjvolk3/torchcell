@article{ashyraliyevSystemsBiologyParameter2009,
  title = {Systems Biology: Parameter Estimation for Biochemical Models},
  shorttitle = {Systems Biology},
  author = {Ashyraliyev, Maksat and Fomekong-Nanfack, Yves and Kaandorp, Jaap A. and Blom, Joke G.},
  date = {2009},
  journaltitle = {The FEBS Journal},
  volume = {276},
  number = {4},
  pages = {886--902},
  issn = {1742-4658},
  doi = {10.1111/j.1742-4658.2008.06844.x},
  url = {https://onlinelibrary.wiley.com/doi/abs/10.1111/j.1742-4658.2008.06844.x},
  urldate = {2022-09-07},
  abstract = {Mathematical models of biological processes have various applications: to assist in understanding the functioning of a system, to simulate experiments before actually performing them, to study situations that cannot be dealt with experimentally, etc. Some parameters in the model can be directly obtained from experiments or from the literature. Others have to be inferred by comparing model results to experiments. In this minireview, we discuss the identifiability of models, both intrinsic to the model and taking into account the available data. Furthermore, we give an overview of the most frequently used approaches to search the parameter space.},
  langid = {english},
  keywords = {📌,🦌📚,a-prioiri-and-a-posteriori-identifiability,local-and-global-optimization,ODE.Parameter-Estimation,Parameter\_Estimation,parameter-estimation},
  annotation = {224 citations (Crossref) [2022-09-07]},
  file = {/Users/michaelvolk/Zotero/storage/JWUU2H5Y/Ashyraliyev et al_2009_Systems biology.pdf;/Users/michaelvolk/Zotero/storage/B3RUC9JP/j.1742-4658.2008.06844.html}
}

@book{asterParameterEstimationInverse2018,
  title = {Parameter {{Estimation}} and {{Inverse Problems}}},
  author = {Aster, Richard C. and Borchers, Brian and Thurber, Clifford H.},
  date = {2018-10-16},
  eprint = {VuRyDwAAQBAJ},
  eprinttype = {googlebooks},
  publisher = {{Elsevier}},
  abstract = {Parameter Estimation and Inverse Problems, Third Edition, is structured around a course at New Mexico Tech and is designed to be accessible to typical graduate students in the physical sciences who do not have an extensive mathematical background. The book is complemented by a companion website that includes MATLAB codes that correspond to examples that are illustrated with simple, easy to follow problems that illuminate the details of particular numerical methods. Updates to the new edition include more discussions of Laplacian smoothing, an expansion of basis function exercises, the addition of stochastic descent, an improved presentation of Fourier methods and exercises, and more. Features examples that are illustrated with simple, easy to follow problems that illuminate the details of a particular numerical method Includes an online instructor’s guide that helps professors teach and customize exercises and select homework problems Covers updated information on adjoint methods that are presented in an accessible manner},
  isbn = {978-0-12-813423-8},
  langid = {english},
  pagetotal = {406},
  keywords = {Earth-Sciences.Geology,Physics.Geophysics,Technology-Engineering.Petroleum},
  file = {/Users/michaelvolk/Zotero/storage/X2YHCP9Z/2018 - Parameter estimation and inverse problems.pdf}
}

@inproceedings{balandatBoTorchFrameworkEfficient2020,
  title = {{{BoTorch}}: {{A Framework}} for {{Efficient Monte-Carlo Bayesian Optimization}}},
  shorttitle = {{{BoTorch}}},
  booktitle = {Advances in {{Neural Information Processing Systems}}},
  author = {Balandat, Maximilian and Karrer, Brian and Jiang, Daniel and Daulton, Samuel and Letham, Ben and Wilson, Andrew G and Bakshy, Eytan},
  date = {2020},
  volume = {33},
  pages = {21524--21538},
  publisher = {{Curran Associates, Inc.}},
  url = {https://proceedings.neurips.cc/paper/2020/hash/f5b1b89d98b7286673128a5fb112cb9a-Abstract.html},
  urldate = {2023-04-27},
  abstract = {Bayesian optimization provides sample-efficient global optimization for a broad range of applications, including automatic machine learning, engineering, physics, and experimental design. We introduce BoTorch, a modern programming framework for Bayesian optimization that combines Monte-Carlo (MC) acquisition functions, a novel sample average approximation optimization approach, auto-differentiation, and variance reduction techniques. BoTorch's modular design facilitates flexible specification and optimization of probabilistic models written in PyTorch, simplifying implementation of new acquisition functions. Our approach is backed by novel theoretical convergence results and made practical by a distinctive algorithmic foundation that leverages fast predictive distributions, hardware acceleration, and deterministic optimization. We also propose a novel "one-shot" formulation of the Knowledge Gradient, enabled by a combination of our theoretical and software contributions. In experiments, we demonstrate the improved sample efficiency of BoTorch relative to other popular libraries.},
  file = {/Users/michaelvolk/Zotero/storage/RM6DKNRI/Balandat et al_2020_BoTorch.pdf}
}

@article{bradleyTwoStageApproachParameter2021,
  title = {Two-{{Stage Approach}} to {{Parameter Estimation}} of {{Differential Equations Using Neural ODEs}}},
  author = {Bradley, William and Boukouvala, Fani},
  date = {2021-11-17},
  journaltitle = {Industrial \& Engineering Chemistry Research},
  shortjournal = {Ind. Eng. Chem. Res.},
  volume = {60},
  number = {45},
  pages = {16330--16344},
  issn = {0888-5885, 1520-5045},
  doi = {10.1021/acs.iecr.1c00552},
  url = {https://pubs.acs.org/doi/10.1021/acs.iecr.1c00552},
  urldate = {2022-09-07},
  abstract = {Modeling physiochemical relationships using dynamic data is a common task in fields throughout science and engineering. A common step in developing generalizable, mechanistic models is to fit unmeasured parameters to measured data. However, fitting differential equation-based models can be computation-intensive and uncertain due to the presence of nonlinearity, noise, and sparsity in the data, which in turn causes convergence to local minima and divergence issues. This work proposes a merger of machine learning (ML) and mechanistic approaches by employing ML models as a means to fit nonlinear mechanistic ordinary differential equations (ODEs). Using a two-stage indirect approach, neural ODEs are used to estimate state derivatives, which are then used to estimate the parameters of a more interpretable mechanistic ODE model. In addition to its computational efficiency, the proposed method demonstrates the ability of neural ODEs to better estimate derivative information than interpolating methods based on algebraic data-driven models. Most notably, the proposed method is shown to yield accurate predictions even when little information is known about the parameters of the ODEs. The proposed parameter estimation approach is believed to be most advantageous when the ODE to be fit is strongly nonlinear with respect to its unknown parameters.},
  langid = {english},
  keywords = {📌,🦌📚,Parameter\_Estimation,Parameter\_Estimation.Machine-Learning},
  annotation = {4 citations (Crossref) [2022-09-07]},
  file = {/Users/michaelvolk/Zotero/storage/5CGA8CZR/Bradley_Boukouvala_2021_Two-Stage Approach to Parameter Estimation of Differential Equations Using.pdf;/Users/michaelvolk/Zotero/storage/T634MSR3/acs.iecr.html}
}

@article{chenTeasingOutMissing2023,
  title = {Teasing out Missing Reactions in Genome-Scale Metabolic Networks through Hypergraph Learning},
  author = {Chen, Can and Liao, Chen and Liu, Yang-Yu},
  date = {2023-04-25},
  journaltitle = {Nature Communications},
  shortjournal = {Nat Commun},
  volume = {14},
  number = {1},
  pages = {2375},
  publisher = {{Nature Publishing Group}},
  issn = {2041-1723},
  doi = {10.1038/s41467-023-38110-7},
  url = {https://www.nature.com/articles/s41467-023-38110-7},
  urldate = {2023-04-27},
  abstract = {GEnome-scale Metabolic models (GEMs) are powerful tools to predict cellular metabolism and physiological states in living organisms. However, due to our imperfect knowledge of metabolic processes, even highly curated GEMs have knowledge gaps (e.g., missing reactions). Existing gap-filling methods typically require phenotypic data as input to tease out missing reactions. We still lack a computational method for rapid and accurate gap-filling of metabolic networks before experimental data is available. Here we present a deep learning-based method — CHEbyshev Spectral HyperlInk pREdictor (CHESHIRE) — to predict missing reactions in GEMs purely from metabolic network topology. We demonstrate that CHESHIRE outperforms other topology-based methods in predicting artificially removed reactions over 926 high- and intermediate-quality GEMs. Furthermore, CHESHIRE is able to improve the phenotypic predictions of 49 draft GEMs for fermentation products and amino acids secretions. Both types of validation suggest that CHESHIRE is a powerful tool for GEM curation to reveal unknown links between reactions and observed metabolic phenotypes.},
  issue = {1},
  langid = {english},
  keywords = {Applied-microbiology,Biochemical-reaction-networks,Machine-learning,Metabolic-engineering},
  annotation = {0 citations (Semantic Scholar/DOI) [2023-04-27]},
  file = {/Users/michaelvolk/Zotero/storage/6SIUHU59/Chen et al_2023_Teasing out missing reactions in genome-scale metabolic networks through.pdf}
}

@article{chouRecentDevelopmentsParameter2009,
  title = {Recent Developments in Parameter Estimation and Structure Identification of Biochemical and Genomic Systems},
  author = {Chou, I-Chun and Voit, Eberhard O.},
  date = {2009-06-01},
  journaltitle = {Mathematical Biosciences},
  shortjournal = {Mathematical Biosciences},
  volume = {219},
  number = {2},
  pages = {57--83},
  issn = {0025-5564},
  doi = {10.1016/j.mbs.2009.03.002},
  url = {https://www.sciencedirect.com/science/article/pii/S0025556409000583},
  urldate = {2022-09-07},
  abstract = {The organization, regulation and dynamical responses of biological systems are in many cases too complex to allow intuitive predictions and require the support of mathematical modeling for quantitative assessments and a reliable understanding of system functioning. All steps of constructing mathematical models for biological systems are challenging, but arguably the most difficult task among them is the estimation of model parameters and the identification of the structure and regulation of the underlying biological networks. Recent advancements in modern high-throughput techniques have been allowing the generation of time series data that characterize the dynamics of genomic, proteomic, metabolic, and physiological responses and enable us, at least in principle, to tackle estimation and identification tasks using ‘top-down’ or ‘inverse’ approaches. While the rewards of a successful inverse estimation or identification are great, the process of extracting structural and regulatory information is technically difficult. The challenges can generally be categorized into four areas, namely, issues related to the data, the model, the mathematical structure of the system, and the optimization and support algorithms. Many recent articles have addressed inverse problems within the modeling framework of Biochemical Systems Theory (BST). BST was chosen for these tasks because of its unique structural flexibility and the fact that the structure and regulation of a biological system are mapped essentially one-to-one onto the parameters of the describing model. The proposed methods mainly focused on various optimization algorithms, but also on support techniques, including methods for circumventing the time consuming numerical integration of systems of differential equations, smoothing overly noisy data, estimating slopes of time series, reducing the complexity of the inference task, and constraining the parameter search space. Other methods targeted issues of data preprocessing, detection and amelioration of model redundancy, and model-free or model-based structure identification. The total number of proposed methods and their applications has by now exceeded one hundred, which makes it difficult for the newcomer, as well as the expert, to gain a comprehensive overview of available algorithmic options and limitations. To facilitate the entry into the field of inverse modeling within BST and related modeling areas, the article presented here reviews the field and proposes an operational ‘work-flow’ that guides the user through the estimation process, identifies possibly problematic steps, and suggests corresponding solutions based on the specific characteristics of the various available algorithms. The article concludes with a discussion of the present state of the art and with a description of open questions.},
  langid = {english},
  keywords = {📌,🦌📚,Inverse-modeling,Network-identification,Parameter\_Estimation,Parameterestimation},
  annotation = {291 citations (Crossref) [2022-09-07]},
  file = {/Users/michaelvolk/Zotero/storage/LF9ETTKT/Chou_Voit_2009_Recent developments in parameter estimation and structure identification of.pdf;/Users/michaelvolk/Zotero/storage/V84H8HLT/S0025556409000583.html}
}

@online{doerschTutorialVariationalAutoencoders2021,
  title = {Tutorial on {{Variational Autoencoders}}},
  author = {Doersch, Carl},
  date = {2021-01-03},
  eprint = {1606.05908},
  eprinttype = {arxiv},
  eprintclass = {cs, stat},
  url = {http://arxiv.org/abs/1606.05908},
  urldate = {2023-05-10},
  abstract = {In just three years, Variational Autoencoders (VAEs) have emerged as one of the most popular approaches to unsupervised learning of complicated distributions. VAEs are appealing because they are built on top of standard function approximators (neural networks), and can be trained with stochastic gradient descent. VAEs have already shown promise in generating many kinds of complicated data, including handwritten digits, faces, house numbers, CIFAR images, physical models of scenes, segmentation, and predicting the future from static images. This tutorial introduces the intuitions behind VAEs, explains the mathematics behind them, and describes some empirical behavior. No prior knowledge of variational Bayesian methods is assumed.},
  pubstate = {preprint},
  keywords = {Computer-Science.Machine-Learning,Statistics.Machine-Learning},
  annotation = {1207 citations (Semantic Scholar/arXiv) [2023-05-10]},
  file = {/Users/michaelvolk/Zotero/storage/29HHCLP2/Doersch - 2021 - Tutorial on Variational Autoencoders.pdf;/Users/michaelvolk/Zotero/storage/DVDWFYED/1606.html}
}

@article{ferrellSystemsBiology2009,
  title = {Q\&{{A}}: {{Systems}} Biology},
  shorttitle = {Q\&{{A}}},
  author = {Ferrell, James E.},
  date = {2009-01-26},
  journaltitle = {Journal of Biology},
  shortjournal = {Journal of Biology},
  volume = {8},
  number = {1},
  pages = {2},
  issn = {1475-4924},
  doi = {10.1186/jbiol107},
  url = {https://doi.org/10.1186/jbiol107},
  urldate = {2022-09-07},
  keywords = {🦌✅,Complex-Biological-System,Emergent-Property,Parameter\_Estimation,Planetary-Motion,System-Biology,Toggle-Switch},
  annotation = {22 citations (Crossref) [2022-09-07]},
  file = {/Users/michaelvolk/Zotero/storage/AD6GR8JL/Ferrell_2009_Q&A.pdf;/Users/michaelvolk/Zotero/storage/66Z7VBQX/jbiol107.html}
}

@article{figueredoInvestigatingMathematicalModels2013,
  title = {Investigating Mathematical Models of Immuno-Interactions with Early-Stage Cancer under an Agent-Based Modelling Perspective},
  author = {Figueredo, Grazziela P. and Siebers, Peer-Olaf and Aickelin, Uwe},
  date = {2013-04-17},
  journaltitle = {BMC Bioinformatics},
  shortjournal = {BMC Bioinformatics},
  volume = {14},
  number = {6},
  pages = {S6},
  issn = {1471-2105},
  doi = {10.1186/1471-2105-14-S6-S6},
  url = {https://doi.org/10.1186/1471-2105-14-S6-S6},
  urldate = {2023-03-02},
  abstract = {Many advances in research regarding immuno-interactions with cancer were developed with the help of ordinary differential equation (ODE) models. These models, however, are not effectively capable of representing problems involving individual localisation, memory and emerging properties, which are common characteristics of cells and molecules of the immune system. Agent-based modelling and simulation is an alternative paradigm to ODE models that overcomes these limitations. In this paper we investigate the potential contribution of agent-based modelling and simulation when compared to ODE modelling and simulation. We seek answers to the following questions: Is it possible to obtain an equivalent agent-based model from the ODE formulation? Do the outcomes differ? Are there any benefits of using one method compared to the other? To answer these questions, we have considered three case studies using established mathematical models of immune interactions with early-stage cancer. These case studies were re-conceptualised under an agent-based perspective and the simulation results were then compared with those from the ODE models. Our results show that it is possible to obtain equivalent agent-based models (i.e. implementing the same mechanisms); the simulation output of both types of models however might differ depending on the attributes of the system to be modelled. In some cases, additional insight from using agent-based modelling was obtained. Overall, we can confirm that agent-based modelling is a useful addition to the tool set of immunologists, as it has extra features that allow for simulations with characteristics that are closer to the biological phenomena.},
  keywords = {Effector-Cell,Ordinary-Differential-Equation,Proactive-Behaviour,Tumour-Cell-Population,Unify-Modelling-Language},
  file = {/Users/michaelvolk/Zotero/storage/NTRPVZDR/Figueredo et al_2013_Investigating mathematical models of immuno-interactions with early-stage.pdf}
}

@article{frohlichAMICIHighperformanceSensitivity2021,
  title = {{{AMICI}}: High-Performance Sensitivity Analysis for Large Ordinary Differential Equation Models},
  shorttitle = {{{AMICI}}},
  author = {Fröhlich, Fabian and Weindl, Daniel and Schälte, Yannik and Pathirana, Dilan and Paszkowski, Łukasz and Lines, Glenn Terje and Stapor, Paul and Hasenauer, Jan},
  date = {2021-10-15},
  journaltitle = {Bioinformatics},
  shortjournal = {Bioinformatics},
  volume = {37},
  number = {20},
  pages = {3676--3677},
  issn = {1367-4803},
  doi = {10.1093/bioinformatics/btab227},
  url = {https://doi.org/10.1093/bioinformatics/btab227},
  urldate = {2022-09-07},
  abstract = {Ordinary differential equation models facilitate the understanding of cellular signal transduction and other biological processes. However, for large and comprehensive models, the computational cost of simulating or calibrating can be limiting. AMICI is a modular toolbox implemented in C++/Python/MATLAB that provides efficient simulation and sensitivity analysis routines tailored for scalable, gradient-based parameter estimation and uncertainty quantification.AMICI is published under the permissive BSD-3-Clause license with source code publicly available on https://github.com/AMICI-dev/AMICI. Citeable releases are archived on Zenodo.Supplementary data are available at Bioinformatics online.},
  keywords = {📌,🦌📚,Parameter\_Estimation,Parameter\_Estimation.benchmarking},
  annotation = {16 citations (Crossref) [2022-09-07]},
  file = {/Users/michaelvolk/Zotero/storage/8GPAIDIH/Fröhlich et al_2021_AMICI.pdf;/Users/michaelvolk/Zotero/storage/PUBKHWKZ/6209017.html}
}

@article{frohlichScalableParameterEstimation2017,
  title = {Scalable {{Parameter Estimation}} for {{Genome-Scale Biochemical Reaction Networks}}},
  author = {Fröhlich, Fabian and Kaltenbacher, Barbara and Theis, Fabian J. and Hasenauer, Jan},
  date = {2017-01-23},
  journaltitle = {PLOS Computational Biology},
  shortjournal = {PLOS Computational Biology},
  volume = {13},
  number = {1},
  pages = {e1005331},
  publisher = {{Public Library of Science}},
  issn = {1553-7358},
  doi = {10.1371/journal.pcbi.1005331},
  url = {https://journals.plos.org/ploscompbiol/article?id=10.1371/journal.pcbi.1005331},
  urldate = {2022-04-01},
  abstract = {Mechanistic mathematical modeling of biochemical reaction networks using ordinary differential equation (ODE) models has improved our understanding of small- and medium-scale biological processes. While the same should in principle hold for large- and genome-scale processes, the computational methods for the analysis of ODE models which describe hundreds or thousands of biochemical species and reactions are missing so far. While individual simulations are feasible, the inference of the model parameters from experimental data is computationally too intensive. In this manuscript, we evaluate adjoint sensitivity analysis for parameter estimation in large scale biochemical reaction networks. We present the approach for time-discrete measurement and compare it to state-of-the-art methods used in systems and computational biology. Our comparison reveals a significantly improved computational efficiency and a superior scalability of adjoint sensitivity analysis. The computational complexity is effectively independent of the number of parameters, enabling the analysis of large- and genome-scale models. Our study of a comprehensive kinetic model of ErbB signaling shows that parameter estimation using adjoint sensitivity analysis requires a fraction of the computation time of established methods. The proposed method will facilitate mechanistic modeling of genome-scale cellular processes, as required in the age of omics.},
  langid = {english},
  keywords = {Algorithms,Biochemical-simulations,Differential-equations,Genome-analysis,Genomics,Mathematical-models,Network-analysis,Optimization},
  file = {/Users/michaelvolk/Zotero/storage/PEPGDB7X/Fröhlich et al_2017_Scalable Parameter Estimation for Genome-Scale Biochemical Reaction Networks.pdf}
}

@article{gabbardBayesianParameterEstimation2022a,
  title = {Bayesian Parameter Estimation Using Conditional Variational Autoencoders for Gravitational-Wave Astronomy},
  author = {Gabbard, Hunter and Messenger, Chris and Heng, Ik Siong and Tonolini, Francesco and Murray-Smith, Roderick},
  date = {2022-01},
  journaltitle = {Nature Physics},
  shortjournal = {Nat. Phys.},
  volume = {18},
  number = {1},
  pages = {112--117},
  publisher = {{Nature Publishing Group}},
  issn = {1745-2481},
  doi = {10.1038/s41567-021-01425-7},
  url = {https://www.nature.com/articles/s41567-021-01425-7},
  urldate = {2023-05-10},
  abstract = {With the improving sensitivity of the global network of gravitational-wave detectors, we expect to observe hundreds of transient gravitational-wave events per year. The current methods used to estimate their source parameters employ optimally sensitive but computationally costly Bayesian inference approaches, where typical analyses have taken between 6\,h and 6\,d. For binary neutron star and neutron star–black hole systems prompt counterpart electromagnetic signatures are expected on timescales between 1\,s and 1\,min. However, the current fastest method for alerting electromagnetic follow-up observers can provide estimates in of the order of 1\,min on a limited range of key source parameters. Here, we show that a conditional variational autoencoder pretrained on binary black hole signals can return Bayesian posterior probability estimates. The training procedure need only be performed once for a given prior parameter space and the resulting trained machine can then generate samples describing the posterior distribution around six orders of magnitude faster than existing techniques.},
  issue = {1},
  langid = {english},
  keywords = {🦌✅,Computational-astrophysics,General-relativity-and-gravity},
  annotation = {0 citations (Semantic Scholar/DOI) [2023-05-10]},
  file = {/Users/michaelvolk/Zotero/storage/8SPTBC2A/Gabbard et al. - 2022 - Bayesian parameter estimation using conditional va.pdf}
}

@article{glontBioModelsExpandingHorizons2018,
  title = {{{BioModels}}: Expanding Horizons to Include More Modelling Approaches and Formats},
  shorttitle = {{{BioModels}}},
  author = {Glont, Mihai and Nguyen, Tung~V~N and Graesslin, Martin and Hälke, Robert and Ali, Raza and Schramm, Jochen and Wimalaratne, Sarala M and Kothamachu, Varun B and Rodriguez, Nicolas and Swat, Maciej J and Eils, Jurgen and Eils, Roland and Laibe, Camille and Malik-Sheriff, Rahuman S and Chelliah, Vijayalakshmi and Le~Novère, Nicolas and Hermjakob, Henning},
  date = {2018-01-04},
  journaltitle = {Nucleic Acids Research},
  shortjournal = {Nucleic Acids Research},
  volume = {46},
  number = {D1},
  pages = {D1248-D1253},
  issn = {0305-1048},
  doi = {10.1093/nar/gkx1023},
  url = {https://doi.org/10.1093/nar/gkx1023},
  urldate = {2023-04-06},
  abstract = {BioModels serves as a central repository of mathematical models representing biological processes. It offers a platform to make mathematical models easily shareable across the systems modelling community, thereby supporting model reuse. To facilitate hosting a broader range of model formats derived from diverse modelling approaches and tools, a new infrastructure for BioModels has been developed that is available at http://www.ebi.ac.uk/biomodels. This new system allows submitting and sharing of a wide range of models with improved support for formats other than SBML. It also offers a version-control backed environment in which authors and curators can work collaboratively to curate models. This article summarises the features available in the current system and discusses the potential benefit they offer to the users over the previous system. In summary, the new portal broadens the scope of models accepted in BioModels and supports collaborative model curation which is crucial for model reproducibility and sharing.},
  annotation = {68 citations (Semantic Scholar/DOI) [2023-04-06]},
  file = {/Users/michaelvolk/Zotero/storage/EZCH69TE/Glont et al_2018_BioModels.pdf}
}

@inproceedings{guoAcceleratingLargeScaleInference2020,
  title = {Accelerating {{Large-Scale Inference}} with {{Anisotropic Vector Quantization}}},
  booktitle = {Proceedings of the 37th {{International Conference}} on {{Machine Learning}}},
  author = {Guo, Ruiqi and Sun, Philip and Lindgren, Erik and Geng, Quan and Simcha, David and Chern, Felix and Kumar, Sanjiv},
  date = {2020-11-21},
  pages = {3887--3896},
  publisher = {{PMLR}},
  issn = {2640-3498},
  url = {https://proceedings.mlr.press/v119/guo20h.html},
  urldate = {2023-06-16},
  abstract = {Quantization based techniques are the current state-of-the-art for scaling maximum inner product search to massive databases. Traditional approaches to quantization aim to minimize the reconstruction error of the database points. Based on the observation that for a given query, the database points that have the largest inner products are more relevant, we develop a family of anisotropic quantization loss functions. Under natural statistical assumptions, we show that quantization with these loss functions leads to a new variant of vector quantization that more greatly penalizes the parallel component of a datapoint’s residual relative to its orthogonal component. The proposed approach, whose implementation is open-source, achieves state-of-the-art results on the public benchmarks available at ann-benchmarks.com.},
  eventtitle = {International {{Conference}} on {{Machine Learning}}},
  langid = {english},
  file = {/Users/michaelvolk/Zotero/storage/83D9WADB/Guo et al. - 2020 - Accelerating Large-Scale Inference with Anisotropi.pdf;/Users/michaelvolk/Zotero/storage/RNQ9TWGF/Guo et al_2020_Accelerating Large-Scale Inference with Anisotropic Vector Quantization.pdf}
}

@article{hamiltonGraphRepresentationLearning,
  title = {Graph {{Representation Learning}}},
  author = {Hamilton, William L},
  pages = {141},
  abstract = {Graph-structured data is ubiquitous throughout the natural and social sciences, from telecommunication networks to quantum chemistry. Building relational inductive biases into deep learning architectures is crucial if we want systems that can learn, reason, and generalize from this kind of data. Recent years have seen a surge in research on graph representation learning, including techniques for deep graph embeddings, generalizations of convolutional neural networks to graph-structured data, and neural message-passing approaches inspired by belief propagation. These advances in graph representation learning have led to new state-of-the-art results in numerous domains, including chemical synthesis, 3D-vision, recommender systems, question answering, and social network analysis.},
  langid = {english},
  keywords = {🦌📚},
  file = {/Users/michaelvolk/Zotero/storage/KVKXCAK5/Hamilton_Graph Representation Learning.pdf}
}

@article{hassBenchmarkProblemsDynamic2019,
  title = {Benchmark Problems for Dynamic Modeling of Intracellular Processes},
  author = {Hass, Helge and Loos, Carolin and Raimúndez-Álvarez, Elba and Timmer, Jens and Hasenauer, Jan and Kreutz, Clemens},
  date = {2019-09-01},
  journaltitle = {Bioinformatics},
  shortjournal = {Bioinformatics},
  volume = {35},
  number = {17},
  pages = {3073--3082},
  issn = {1367-4803},
  doi = {10.1093/bioinformatics/btz020},
  url = {https://doi.org/10.1093/bioinformatics/btz020},
  urldate = {2023-04-10},
  abstract = {Dynamic models are used in systems biology to study and understand cellular processes like gene regulation or signal transduction. Frequently, ordinary differential equation (ODE) models are used to model the time and dose dependency of the abundances of molecular compounds as well as interactions and translocations. A multitude of computational approaches, e.g. for parameter estimation or uncertainty analysis have been developed within recent years. However, many of these approaches lack proper testing in application settings because a comprehensive set of benchmark problems is yet missing.We present a collection of 20 benchmark problems in order to evaluate new and existing methodologies, where an ODE model with corresponding experimental data is referred to as problem. In addition to the equations of the dynamical system, the benchmark collection provides observation functions as well as assumptions about measurement noise distributions and parameters. The presented benchmark models comprise problems of different size, complexity and numerical demands. Important characteristics of the models and methodological requirements are summarized, estimated parameters are provided, and some example studies were performed for illustrating the capabilities of the presented benchmark collection.The models are provided in several standardized formats, including an easy-to-use human readable form and machine-readable SBML files. The data is provided as Excel sheets. All files are available at https://github.com/Benchmarking-Initiative/Benchmark-Models, including step-by-step explanations and MATLAB code to process and simulate the models.Supplementary data are available at Bioinformatics online.},
  file = {/Users/michaelvolk/Zotero/storage/TJ6LVB6U/Hass et al_2019_Benchmark problems for dynamic modeling of intracellular processes.pdf}
}

@inproceedings{ioffeBatchNormalizationAccelerating2015,
  title = {Batch {{Normalization}}: {{Accelerating Deep Network Training}} by {{Reducing Internal Covariate Shift}}},
  shorttitle = {Batch {{Normalization}}},
  booktitle = {Proceedings of the 32nd {{International Conference}} on {{Machine Learning}}},
  author = {Ioffe, Sergey and Szegedy, Christian},
  date = {2015-06-01},
  pages = {448--456},
  publisher = {{PMLR}},
  issn = {1938-7228},
  url = {https://proceedings.mlr.press/v37/ioffe15.html},
  urldate = {2023-07-03},
  abstract = {Training Deep Neural Networks is complicated by the fact that the distribution of each layer’s inputs changes during training, as the parameters of the previous layers change. This slows down the training by requiring lower learning rates and careful parameter initialization, and makes it notoriously hard to train models with saturating nonlinearities. We refer to this phenomenon as internal covariate shift, and address the problem by normalizing layer inputs. Our method draws its strength from making normalization a part of the model architecture and performing the normalization for each training mini-batch. Batch Normalization allows us to use much higher learning rates and be less careful about initialization, and in some cases eliminates the need for Dropout. Applied to a stateof-the-art image classification model, Batch Normalization achieves the same accuracy with 14 times fewer training steps, and beats the original model by a significant margin. Using an ensemble of batch-normalized networks, we improve upon the best published result on ImageNet classification: reaching 4.82\% top-5 test error, exceeding the accuracy of human raters.},
  eventtitle = {International {{Conference}} on {{Machine Learning}}},
  langid = {english},
  file = {/Users/michaelvolk/Zotero/storage/44QFK5C4/Ioffe_Szegedy_2015_Batch Normalization.pdf}
}

@article{jiaoFeedbackRegulationStem2018,
  title = {Feedback Regulation in a Stem Cell Model with Acute Myeloid Leukaemia},
  author = {Jiao, Jianfeng and Luo, Min and Wang, Ruiqi},
  date = {2018-04-24},
  journaltitle = {BMC Systems Biology},
  shortjournal = {BMC Systems Biology},
  volume = {12},
  number = {4},
  pages = {43},
  issn = {1752-0509},
  doi = {10.1186/s12918-018-0561-2},
  url = {https://doi.org/10.1186/s12918-018-0561-2},
  urldate = {2023-03-02},
  abstract = {The haematopoietic lineages with leukaemia lineages are considered in this paper. In particular, we mainly consider that haematopoietic lineages are tightly controlled by negative feedback inhibition of end-product. Actually, leukemia has been found 100 years ago. Up to now, the exact mechanism is still unknown, and many factors are thought to be associated with the pathogenesis of leukemia. Nevertheless, it is very necessary to continue the profound study of the pathogenesis of leukemia. Here, we propose a new mathematical model which include some negative feedback inhibition from the terminally differentiated cells of haematopoietic lineages to the haematopoietic stem cells and haematopoietic progenitor cells in order to describe the regulatory mechanisms mentioned above by a set of ordinary differential equations. Afterwards, we carried out detailed dynamical bifurcation analysis of the model, and obtained some meaningful results.},
  keywords = {acute-myeloid-leukaemia,feedback-regulation,haematopoietic-stem-cells,Hill-function,mathematical-model},
  annotation = {5 citations (Semantic Scholar/DOI) [2023-03-02]},
  file = {/Users/michaelvolk/Zotero/storage/PP692FJC/Jiao et al_2018_Feedback regulation in a stem cell model with acute myeloid leukaemia.pdf}
}

@article{jiStiffPINNPhysicsInformedNeural2021,
  title = {Stiff-{{PINN}}: {{Physics-Informed Neural Network}} for {{Stiff Chemical Kinetics}}},
  shorttitle = {Stiff-{{PINN}}},
  author = {Ji, Weiqi and Qiu, Weilun and Shi, Zhiyu and Pan, Shaowu and Deng, Sili},
  date = {2021-09-16},
  journaltitle = {The Journal of Physical Chemistry A},
  shortjournal = {J. Phys. Chem. A},
  volume = {125},
  number = {36},
  pages = {8098--8106},
  publisher = {{American Chemical Society}},
  issn = {1089-5639},
  doi = {10.1021/acs.jpca.1c05102},
  url = {https://doi.org/10.1021/acs.jpca.1c05102},
  urldate = {2022-09-13},
  abstract = {The recently developed physics-informed neural network (PINN) has achieved success in many science and engineering disciplines by encoding physics laws into the loss functions of the neural network such that the network not only conforms to the measurements and initial and boundary conditions but also satisfies the governing equations. This work first investigates the performance of the PINN in solving stiff chemical kinetic problems with governing equations of stiff ordinary differential equations (ODEs). The results elucidate the challenges of utilizing the PINN in stiff ODE systems. Consequently, we employ quasi-steady-state assumption (QSSA) to reduce the stiffness of the ODE systems, and the PINN then can be successfully applied to the converted non-/mild-stiff systems. Therefore, the results suggest that stiffness could be the major reason for the failure of the regular PINN in the studied stiff chemical kinetic systems. The developed stiff-PINN approach that utilizes QSSA to enable the PINN to solve stiff chemical kinetics shall open the possibility of applying the PINN to various reaction-diffusion systems involving stiff dynamics.},
  keywords = {🦌📚,Parameter\_Estimation},
  file = {/Users/michaelvolk/Zotero/storage/WGCQL3XU/Ji et al_2021_Stiff-PINN.pdf;/Users/michaelvolk/Zotero/storage/JW5VEQWF/acs.jpca.html}
}

@article{khodayariGenomescaleEscherichiaColi2016,
  title = {A Genome-Scale {{Escherichia}} Coli Kinetic Metabolic Model k-Ecoli457 Satisfying Flux Data for Multiple Mutant Strains},
  author = {Khodayari, Ali and Maranas, Costas D.},
  date = {2016-12-20},
  journaltitle = {Nature Communications},
  shortjournal = {Nat Commun},
  volume = {7},
  number = {1},
  pages = {13806},
  publisher = {{Nature Publishing Group}},
  issn = {2041-1723},
  doi = {10.1038/ncomms13806},
  url = {https://www.nature.com/articles/ncomms13806},
  urldate = {2023-06-13},
  abstract = {Kinetic models of metabolism at a genome scale that faithfully recapitulate the effect of multiple genetic interventions would be transformative in our ability to reliably design novel overproducing microbial strains. Here, we introduce k-ecoli457, a genome-scale kinetic model of Escherichia coli metabolism that satisfies fluxomic data for wild-type and 25 mutant strains under different substrates and growth conditions. The k-ecoli457 model contains 457 model reactions, 337 metabolites and 295 substrate-level regulatory interactions. Parameterization is carried out using a genetic algorithm by simultaneously imposing all available fluxomic data (about 30 measured fluxes per mutant). The Pearson correlation coefficient between experimental data and predicted product yields for 320 engineered strains spanning 24 product metabolites is 0.84. This is substantially higher than that using flux balance analysis, minimization of metabolic adjustment or maximization of product yield exhibiting systematic errors with correlation coefficients of, respectively, 0.18, 0.37 and 0.47 (k-ecoli457 is available for download at http://www.maranasgroup.com).},
  issue = {1},
  langid = {english},
  keywords = {Bacteria,Computer modelling,Metabolic engineering},
  annotation = {175 citations (Semantic Scholar/DOI) [2023-06-13]},
  file = {/Users/michaelvolk/Zotero/storage/XLT5HKLP/Khodayari and Maranas - 2016 - A genome-scale Escherichia coli kinetic metabolic .pdf}
}

@article{kingmaIntroductionVariationalAutoencoders2019,
  title = {An {{Introduction}} to {{Variational Autoencoders}}},
  author = {Kingma, Diederik P. and Welling, Max},
  date = {2019},
  journaltitle = {Foundations and Trends® in Machine Learning},
  shortjournal = {FNT in Machine Learning},
  volume = {12},
  number = {4},
  eprint = {1906.02691},
  eprinttype = {arxiv},
  eprintclass = {cs, stat},
  pages = {307--392},
  issn = {1935-8237, 1935-8245},
  doi = {10.1561/2200000056},
  url = {http://arxiv.org/abs/1906.02691},
  urldate = {2023-05-10},
  abstract = {Variational autoencoders provide a principled framework for learning deep latent-variable models and corresponding inference models. In this work, we provide an introduction to variational autoencoders and some important extensions.},
  keywords = {Computer-Science.Machine-Learning,Statistics.Machine-Learning},
  annotation = {1068 citations (Semantic Scholar/arXiv) [2023-05-10] 1068 citations (Semantic Scholar/DOI) [2023-05-10]},
  file = {/Users/michaelvolk/Zotero/storage/E8PP9YCJ/Kingma and Welling - 2019 - An Introduction to Variational Autoencoders.pdf;/Users/michaelvolk/Zotero/storage/KKLVYEWJ/1906.html}
}

@article{kraanKineticsCortisolMetabolism1992,
  title = {Kinetics of Cortisol Metabolism and Excretion. {{A}} Hypothetic Model Based on the Cumulative Urinary Radioactivity in Eight Multiple Pituitary Deficient Patients},
  author = {Kraan, G. P. B. and Drayer, N. M. and family=Bruin, given=R., prefix=de, useprefix=true},
  date = {1992-04-01},
  journaltitle = {The Journal of Steroid Biochemistry and Molecular Biology},
  shortjournal = {The Journal of Steroid Biochemistry and Molecular Biology},
  volume = {42},
  number = {2},
  pages = {169--177},
  issn = {0960-0760},
  doi = {10.1016/0960-0760(92)90025-E},
  url = {https://www.sciencedirect.com/science/article/pii/096007609290025E},
  urldate = {2023-03-02},
  abstract = {A new model is proposed to study the kinetics of [3H]cortisol metabolism by using urinary data only. The model consists of 5 pools, in which changes of the fractions of dose are given by a system of 5 ordinary differential equations. After i.v. administration of [3H]cortisol to 8 multiple pituitary deficient (MPD) patients (group I) the urines from each patient were collected in 9–15 portions during the following 3 days. From the urinary data the rate constants of cortisol metabolism were calculated. A published set of urinary data from patients with a normal cortisol metabolism (group II) was used for comparison. The overall half-life of the label in the circulation was 30 min for both groups; the half-life of the label excretion by both groups was 6 h and the time of maximal activity in the main metabolizing pool was 1.8 h in group I and 1.5 h in group II. The 20\% of normal cortisol production rate (CPR) in the 8 MPD patients amounted to 7.2 ± 1.9 μmol/(m2∗d). Therefore, the low CPR but normal rate constants, i.e. a normal metabolic clearance rate of cortisol, in the MPD patients suggest a sensitive adjustment of the cortisol response in the target organs.},
  langid = {english},
  annotation = {6 citations (Semantic Scholar/DOI) [2023-03-02]},
  file = {/Users/michaelvolk/Zotero/storage/3EK5CTF6/Kraan et al_1992_Kinetics of cortisol metabolism and excretion.pdf}
}

@article{kramerNonlinearPrincipalComponent1991,
  title = {Nonlinear Principal Component Analysis Using Autoassociative Neural Networks},
  author = {Kramer, Mark A.},
  date = {1991},
  journaltitle = {AIChE Journal},
  volume = {37},
  number = {2},
  pages = {233--243},
  issn = {1547-5905},
  doi = {10.1002/aic.690370209},
  url = {https://onlinelibrary.wiley.com/doi/abs/10.1002/aic.690370209},
  urldate = {2023-05-11},
  abstract = {Nonlinear principal component analysis is a novel technique for multivariate data analysis, similar to the well-known method of principal component analysis. NLPCA, like PCA, is used to identify and remove correlations among problem variables as an aid to dimensionality reduction, visualization, and exploratory data analysis. While PCA identifies only linear correlations between variables, NLPCA uncovers both linear and nonlinear correlations, without restriction on the character of the nonlinearities present in the data. NLPCA operates by training a feedforward neural network to perform the identity mapping, where the network inputs are reproduced at the output layer. The network contains an internal “bottleneck” layer (containing fewer nodes than input or output layers), which forces the network to develop a compact representation of the input data, and two additional hidden layers. The NLPCA method is demonstrated using time-dependent, simulated batch reaction data. Results show that NLPCA successfully reduces dimensionality and produces a feature space map resembling the actual distribution of the underlying system parameters.},
  langid = {english},
  annotation = {2514 citations (Semantic Scholar/DOI) [2023-05-10]},
  file = {/Users/michaelvolk/Zotero/storage/U996HAPU/Kramer - 1991 - Nonlinear principal component analysis using autoa.pdf;/Users/michaelvolk/Zotero/storage/N6GL2P63/aic.html}
}

@online{kruseBenchmarkingInvertibleArchitectures2021,
  title = {Benchmarking {{Invertible Architectures}} on {{Inverse Problems}}},
  author = {Kruse, Jakob and Ardizzone, Lynton and Rother, Carsten and Köthe, Ullrich},
  date = {2021-06-22},
  eprint = {2101.10763},
  eprinttype = {arxiv},
  eprintclass = {cs},
  url = {http://arxiv.org/abs/2101.10763},
  urldate = {2023-05-10},
  abstract = {Recent work demonstrated that flow-based invertible neural networks are promising tools for solving ambiguous inverse problems. Following up on this, we investigate how ten invertible architectures and related models fare on two intuitive, low-dimensional benchmark problems, obtaining the best results with coupling layers and simple autoencoders. We hope that our initial efforts inspire other researchers to evaluate their invertible architectures in the same setting and put forth additional benchmarks, so our evaluation may eventually grow into an official community challenge.},
  pubstate = {preprint},
  keywords = {Computer-Science.Machine-Learning},
  annotation = {27 citations (Semantic Scholar/arXiv) [2023-05-10]},
  file = {/Users/michaelvolk/Zotero/storage/B3URM3P6/Kruse et al. - 2021 - Benchmarking Invertible Architectures on Inverse P.pdf;/Users/michaelvolk/Zotero/storage/Z2S79A5B/2101.html}
}

@article{liepeFrameworkParameterEstimation2014,
  title = {A Framework for Parameter Estimation and Model Selection from Experimental Data in Systems Biology Using Approximate {{Bayesian}} Computation},
  author = {Liepe, Juliane and Kirk, Paul and Filippi, Sarah and Toni, Tina and Barnes, Chris P. and Stumpf, Michael P. H.},
  date = {2014-02},
  journaltitle = {Nature Protocols},
  shortjournal = {Nat Protoc},
  volume = {9},
  number = {2},
  pages = {439--456},
  publisher = {{Nature Publishing Group}},
  issn = {1750-2799},
  doi = {10.1038/nprot.2014.025},
  url = {https://www.nature.com/articles/nprot.2014.025},
  urldate = {2022-09-07},
  abstract = {As modeling becomes a more widespread practice in the life sciences and biomedical sciences, researchers need reliable tools to calibrate models against ever more complex and detailed data. Here we present an approximate Bayesian computation (ABC) framework and software environment, ABC-SysBio, which is a Python package that runs on Linux and Mac OS X systems and that enables parameter estimation and model selection in the Bayesian formalism by using sequential Monte Carlo (SMC) approaches. We outline the underlying rationale, discuss the computational and practical issues and provide detailed guidance as to how the important tasks of parameter inference and model selection can be performed in practice. Unlike other available packages, ABC-SysBio is highly suited for investigating, in particular, the challenging problem of fitting stochastic models to data. In order to demonstrate the use of ABC-SysBio, in this protocol we postulate the existence of an imaginary reaction network composed of seven interrelated biological reactions (involving a specific mRNA, the protein it encodes and a post-translationally modified version of the protein), a network that is defined by two files containing 'observed' data that we provide as supplementary information. In the first part of the PROCEDURE, ABC-SysBio is used to infer the parameters of this system, whereas in the second part we use ABC-SysBio's relevant functionality to discriminate between two different reaction network models, one of them being the 'true' one. Although computationally expensive, the additional insights gained in the Bayesian formalism more than make up for this cost, especially in complex problems.},
  issue = {2},
  langid = {english},
  keywords = {📌,🦌📚,Bayesian-inference,Bioinformatics,Computational-models,Parameter\_Estimation,Software},
  annotation = {148 citations (Crossref) [2022-09-07]},
  file = {/Users/michaelvolk/Zotero/storage/SLF6WKAF/Liepe et al_2014_A framework for parameter estimation and model selection from experimental data.pdf;/Users/michaelvolk/Zotero/storage/9AXVHJZJ/nprot.2014.html}
}

@online{liHyperbandNovelBanditBased2018,
  title = {Hyperband: {{A Novel Bandit-Based Approach}} to {{Hyperparameter Optimization}}},
  shorttitle = {Hyperband},
  author = {Li, Lisha and Jamieson, Kevin and DeSalvo, Giulia and Rostamizadeh, Afshin and Talwalkar, Ameet},
  date = {2018-06-18},
  eprint = {1603.06560},
  eprinttype = {arxiv},
  eprintclass = {cs, stat},
  doi = {10.48550/arXiv.1603.06560},
  url = {http://arxiv.org/abs/1603.06560},
  urldate = {2023-04-20},
  abstract = {Performance of machine learning algorithms depends critically on identifying a good set of hyperparameters. While recent approaches use Bayesian optimization to adaptively select configurations, we focus on speeding up random search through adaptive resource allocation and early-stopping. We formulate hyperparameter optimization as a pure-exploration non-stochastic infinite-armed bandit problem where a predefined resource like iterations, data samples, or features is allocated to randomly sampled configurations. We introduce a novel algorithm, Hyperband, for this framework and analyze its theoretical properties, providing several desirable guarantees. Furthermore, we compare Hyperband with popular Bayesian optimization methods on a suite of hyperparameter optimization problems. We observe that Hyperband can provide over an order-of-magnitude speedup over our competitor set on a variety of deep-learning and kernel-based learning problems.},
  pubstate = {preprint},
  keywords = {Computer-Science-Machine-Learning,Statistics-Machine-Learning},
  annotation = {1460 citations (Semantic Scholar/arXiv) [2023-04-19]},
  file = {/Users/michaelvolk/Zotero/storage/DKEEKK8M/Li et al_2018_Hyperband.pdf;/Users/michaelvolk/Zotero/storage/SLAEDGM7/1603.html}
}

@online{liUnderstandingDisharmonyDropout2018,
  title = {Understanding the {{Disharmony}} between {{Dropout}} and {{Batch Normalization}} by {{Variance Shift}}},
  author = {Li, Xiang and Chen, Shuo and Hu, Xiaolin and Yang, Jian},
  date = {2018-01-16},
  eprint = {1801.05134},
  eprinttype = {arxiv},
  eprintclass = {cs, stat},
  doi = {10.48550/arXiv.1801.05134},
  url = {http://arxiv.org/abs/1801.05134},
  urldate = {2023-07-03},
  abstract = {This paper first answers the question "why do the two most powerful techniques Dropout and Batch Normalization (BN) often lead to a worse performance when they are combined together?" in both theoretical and statistical aspects. Theoretically, we find that Dropout would shift the variance of a specific neural unit when we transfer the state of that network from train to test. However, BN would maintain its statistical variance, which is accumulated from the entire learning procedure, in the test phase. The inconsistency of that variance (we name this scheme as "variance shift") causes the unstable numerical behavior in inference that leads to more erroneous predictions finally, when applying Dropout before BN. Thorough experiments on DenseNet, ResNet, ResNeXt and Wide ResNet confirm our findings. According to the uncovered mechanism, we next explore several strategies that modifies Dropout and try to overcome the limitations of their combination by avoiding the variance shift risks.},
  pubstate = {preprint},
  keywords = {Computer Science - Machine Learning,Statistics - Machine Learning},
  annotation = {245 citations (Semantic Scholar/arXiv) [2023-07-03]},
  file = {/Users/michaelvolk/Zotero/storage/QGKWFSPL/Li et al_2018_Understanding the Disharmony between Dropout and Batch Normalization by.pdf;/Users/michaelvolk/Zotero/storage/S2DFJ5LR/1801.html}
}

@article{malik-sheriffBioModels15Years2020,
  title = {{{BioModels}}—15 Years of Sharing Computational Models in Life Science},
  author = {Malik-Sheriff, Rahuman S and Glont, Mihai and Nguyen, Tung V N and Tiwari, Krishna and Roberts, Matthew G and Xavier, Ashley and Vu, Manh T and Men, Jinghao and Maire, Matthieu and Kananathan, Sarubini and Fairbanks, Emma L and Meyer, Johannes P and Arankalle, Chinmay and Varusai, Thawfeek M and Knight-Schrijver, Vincent and Li, Lu and Dueñas-Roca, Corina and Dass, Gaurhari and Keating, Sarah M and Park, Young M and Buso, Nicola and Rodriguez, Nicolas and Hucka, Michael and Hermjakob, Henning},
  date = {2020-01-08},
  journaltitle = {Nucleic Acids Research},
  shortjournal = {Nucleic Acids Research},
  volume = {48},
  number = {D1},
  pages = {D407-D415},
  issn = {0305-1048},
  doi = {10.1093/nar/gkz1055},
  url = {https://doi.org/10.1093/nar/gkz1055},
  urldate = {2023-04-06},
  abstract = {Computational modelling has become increasingly common in life science research. To provide a platform to support universal sharing, easy accessibility and model reproducibility, BioModels (https://www.ebi.ac.uk/biomodels/), a repository for mathematical models, was established in 2005. The current BioModels platform allows submission of models encoded in diverse modelling formats, including SBML, CellML, PharmML, COMBINE archive, MATLAB, Mathematica, R, Python or C++. The models submitted to BioModels are curated to verify the computational representation of the biological process and the reproducibility of the simulation results in the reference publication. The curation also involves encoding models in standard formats and annotation with controlled vocabularies following MIRIAM (minimal information required in the annotation of biochemical models)~guidelines. BioModels now accepts large-scale submission of auto-generated computational models. With gradual growth in content over 15 years, BioModels currently hosts about 2000 models from the published literature. With about 800 curated models, BioModels has become the world’s largest repository of curated models and emerged as the third most used data resource after PubMed and Google Scholar among the scientists who use modelling in their research. Thus, BioModels benefits modellers by providing access to reliable and semantically enriched curated models in standard formats that are easy to share, reproduce and reuse.},
  annotation = {160 citations (Semantic Scholar/DOI) [2023-04-06]},
  file = {/Users/michaelvolk/Zotero/storage/J3JC8JTD/Malik-Sheriff et al_2020_BioModels—15 years of sharing computational models in life science.pdf}
}

@article{nazabalHandlingIncompleteHeterogeneous2020,
  title = {Handling Incomplete Heterogeneous Data Using {{VAEs}}},
  author = {Nazábal, Alfredo and Olmos, Pablo M. and Ghahramani, Zoubin and Valera, Isabel},
  date = {2020-11-01},
  journaltitle = {Pattern Recognition},
  shortjournal = {Pattern Recognition},
  volume = {107},
  pages = {107501},
  issn = {0031-3203},
  doi = {10.1016/j.patcog.2020.107501},
  url = {https://www.sciencedirect.com/science/article/pii/S0031320320303046},
  urldate = {2023-05-10},
  abstract = {Variational autoencoders (VAEs), as well as other generative models, have been shown to be efficient and accurate for capturing the latent structure of vast amounts of complex high-dimensional data. However, existing VAEs can still not directly handle data that are heterogenous (mixed continuous and discrete) or incomplete (with missing data at random), which is indeed common in real-world applications. In this paper, we propose a general framework to design VAEs suitable for fitting incomplete heterogenous data. The proposed HI-VAE includes likelihood models for real-valued, positive real valued, interval, categorical, ordinal and count data, and allows accurate estimation (and potentially imputation) of missing data. Furthermore, HI-VAE presents competitive predictive performance in supervised tasks, outperforming supervised models when trained on incomplete data.},
  langid = {english},
  keywords = {Generative-models,Incomplete-heterogenous-data,Variational-autoencoders},
  file = {/Users/michaelvolk/Zotero/storage/4ZXKC8XR/Nazábal et al. - 2020 - Handling incomplete heterogeneous data using VAEs.pdf;/Users/michaelvolk/Zotero/storage/LSNW35PX/S0031320320303046.html}
}

@article{raueLessonsLearnedQuantitative2013,
  title = {Lessons {{Learned}} from {{Quantitative Dynamical Modeling}} in {{Systems Biology}}},
  author = {Raue, Andreas and Schilling, Marcel and Bachmann, Julie and Matteson, Andrew and Schelke, Max and Kaschek, Daniel and Hug, Sabine and Kreutz, Clemens and Harms, Brian D. and Theis, Fabian J. and Klingmüller, Ursula and Timmer, Jens},
  date = {2013-09-30},
  journaltitle = {PLOS ONE},
  shortjournal = {PLOS ONE},
  volume = {8},
  number = {9},
  pages = {e74335},
  publisher = {{Public Library of Science}},
  issn = {1932-6203},
  doi = {10.1371/journal.pone.0074335},
  url = {https://journals.plos.org/plosone/article?id=10.1371/journal.pone.0074335},
  urldate = {2022-09-07},
  abstract = {Due to the high complexity of biological data it is difficult to disentangle cellular processes relying only on intuitive interpretation of measurements. A Systems Biology approach that combines quantitative experimental data with dynamic mathematical modeling promises to yield deeper insights into these processes. Nevertheless, with growing complexity and increasing amount of quantitative experimental data, building realistic and reliable mathematical models can become a challenging task: the quality of experimental data has to be assessed objectively, unknown model parameters need to be estimated from the experimental data, and numerical calculations need to be precise and efficient. Here, we discuss, compare and characterize the performance of computational methods throughout the process of quantitative dynamic modeling using two previously established examples, for which quantitative, dose- and time-resolved experimental data are available. In particular, we present an approach that allows to determine the quality of experimental data in an efficient, objective and automated manner. Using this approach data generated by different measurement techniques and even in single replicates can be reliably used for mathematical modeling. For the estimation of unknown model parameters, the performance of different optimization algorithms was compared systematically. Our results show that deterministic derivative-based optimization employing the sensitivity equations in combination with a multi-start strategy based on latin hypercube sampling outperforms the other methods by orders of magnitude in accuracy and speed. Finally, we investigated transformations that yield a more efficient parameterization of the model and therefore lead to a further enhancement in optimization performance. We provide a freely available open source software package that implements the algorithms and examples compared here.},
  langid = {english},
  keywords = {📌,🦌¾📖,Algorithms,Evolutionary-algorithms,Evolutionary-genetics,Immunoblotting,Mathematical-models,Membrane-receptor-signaling,Optimization,Parameter\_Estimation,STAT-proteins},
  annotation = {211 citations (Crossref) [2022-09-07]},
  file = {/Users/michaelvolk/Zotero/storage/ZJNA7FG7/Raue et al_2013_Lessons Learned from Quantitative Dynamical Modeling in Systems Biology.pdf;/Users/michaelvolk/Zotero/storage/E2MRTBYP/article.html}
}

@article{schmiesterEfficientParameterizationLargescale2020,
  title = {Efficient Parameterization of Large-Scale Dynamic Models Based on Relative Measurements},
  author = {Schmiester, Leonard and Schälte, Yannik and Fröhlich, Fabian and Hasenauer, Jan and Weindl, Daniel},
  date = {2020-01-15},
  journaltitle = {Bioinformatics},
  shortjournal = {Bioinformatics},
  volume = {36},
  number = {2},
  pages = {594--602},
  issn = {1367-4803},
  doi = {10.1093/bioinformatics/btz581},
  url = {https://doi.org/10.1093/bioinformatics/btz581},
  urldate = {2023-06-13},
  abstract = {Mechanistic models of biochemical reaction networks facilitate the quantitative understanding of biological processes and the integration of heterogeneous datasets. However, some biological processes require the consideration of comprehensive reaction networks and therefore large-scale models. Parameter estimation for such models poses great challenges, in particular when the data are on a relative scale.Here, we propose a novel hierarchical approach combining (i) the efficient analytic evaluation of optimal scaling, offset and error model parameters with (ii) the scalable evaluation of objective function gradients using adjoint sensitivity analysis. We evaluate the properties of the methods by parameterizing a pan-cancer ordinary differential equation model (\&gt;1000 state variables, \&gt;4000 parameters) using relative protein, phosphoprotein and viability measurements. The hierarchical formulation improves optimizer performance considerably. Furthermore, we show that this approach allows estimating error model parameters with negligible computational overhead when no experimental estimates are available, providing an unbiased way to weight heterogeneous data. Overall, our hierarchical formulation is applicable to a wide range of models, and allows for the efficient parameterization of large-scale models based on heterogeneous relative measurements.Supplementary code and data are available online at http://doi.org/10.5281/zenodo.3254429 and http://doi.org/10.5281/zenodo.3254441.Supplementary data are available at Bioinformatics online.},
  file = {/Users/michaelvolk/Zotero/storage/7TPQPPKR/Schmiester et al. - 2020 - Efficient parameterization of large-scale dynamic .pdf;/Users/michaelvolk/Zotero/storage/R97NPWGV/5538985.html}
}

@article{schmiesterPEtabInteroperableSpecification2021,
  title = {{{PEtab}}—{{Interoperable}} Specification of Parameter Estimation Problems in Systems Biology},
  author = {Schmiester, Leonard and Schälte, Yannik and Bergmann, Frank T. and Camba, Tacio and Dudkin, Erika and Egert, Janine and Fröhlich, Fabian and Fuhrmann, Lara and Hauber, Adrian L. and Kemmer, Svenja and Lakrisenko, Polina and Loos, Carolin and Merkt, Simon and Müller, Wolfgang and Pathirana, Dilan and Raimúndez, Elba and Refisch, Lukas and Rosenblatt, Marcus and Stapor, Paul L. and Städter, Philipp and Wang, Dantong and Wieland, Franz-Georg and Banga, Julio R. and Timmer, Jens and Villaverde, Alejandro F. and Sahle, Sven and Kreutz, Clemens and Hasenauer, Jan and Weindl, Daniel},
  date = {2021-01-26},
  journaltitle = {PLOS Computational Biology},
  shortjournal = {PLOS Computational Biology},
  volume = {17},
  number = {1},
  pages = {e1008646},
  publisher = {{Public Library of Science}},
  issn = {1553-7358},
  doi = {10.1371/journal.pcbi.1008646},
  url = {https://journals.plos.org/ploscompbiol/article?id=10.1371/journal.pcbi.1008646},
  urldate = {2022-08-25},
  abstract = {Reproducibility and reusability of the results of data-based modeling studies are essential. Yet, there has been—so far—no broadly supported format for the specification of parameter estimation problems in systems biology. Here, we introduce PEtab, a format which facilitates the specification of parameter estimation problems using Systems Biology Markup Language (SBML) models and a set of tab-separated value files describing the observation model and experimental data as well as parameters to be estimated. We already implemented PEtab support into eight well-established model simulation and parameter estimation toolboxes with hundreds of users in total. We provide a Python library for validation and modification of a PEtab problem and currently 20 example parameter estimation problems based on recent studies.},
  langid = {english},
  keywords = {✅,🦌,Algorithms,Language,Libraries,Optimization,Simulation-and-modeling,Software-tools,System-stability,Systems-biology},
  file = {/Users/michaelvolk/Zotero/storage/2QW56KZM/Schmiester et al. - 2021 - PEtab—Interoperable specification of parameter est.pdf;/Users/michaelvolk/Zotero/storage/M2QRKRZG/Schmiester et al. - 2021 - PEtab—Interoperable specification of parameter est.pdf}
}

@article{schuetzCombinatorialOptimizationPhysicsinspired2022,
  title = {Combinatorial Optimization with Physics-Inspired Graph Neural Networks},
  author = {Schuetz, Martin J. A. and Brubaker, J. Kyle and Katzgraber, Helmut G.},
  date = {2022-04},
  journaltitle = {Nature Machine Intelligence},
  shortjournal = {Nat Mach Intell},
  volume = {4},
  number = {4},
  pages = {367--377},
  publisher = {{Nature Publishing Group}},
  issn = {2522-5839},
  doi = {10.1038/s42256-022-00468-6},
  url = {https://www.nature.com/articles/s42256-022-00468-6},
  urldate = {2022-06-03},
  abstract = {Combinatorial optimization problems are pervasive across science and industry. Modern deep learning tools are poised to solve these problems at unprecedented scales, but a unifying framework that incorporates insights from statistical physics is still outstanding. Here we demonstrate how graph neural networks can be used to solve combinatorial optimization problems. Our approach is broadly applicable to canonical NP-hard problems in the form of quadratic unconstrained binary optimization problems, such as maximum cut, minimum vertex cover, maximum independent set, as well as Ising spin glasses and higher-order generalizations thereof in the form of polynomial unconstrained binary optimization problems. We apply a relaxation strategy to the problem Hamiltonian to generate a differentiable loss function with which we train the graph neural network and apply a simple projection to integer variables once the unsupervised training process has completed. We showcase our approach with numerical results for the canonical maximum cut and maximum independent set problems. We find that the graph neural network optimizer performs on par or outperforms existing solvers, with the ability to scale beyond the state of the art to problems with millions of variables.},
  issue = {4},
  langid = {english},
  keywords = {☁️,📚,🦌,Computer science,Operational research,Quantum information,Statistical physics},
  annotation = {39 citations (Semantic Scholar/DOI) [2023-05-27]},
  file = {/Users/michaelvolk/Zotero/storage/FHT8VB2Y/Schuetz et al_2022_Combinatorial optimization with physics-inspired graph neural networks.pdf;/Users/michaelvolk/Zotero/storage/RSTIKMIQ/s42256-022-00468-6.html}
}

@article{sinkoeOptimalExperimentalDesign2017,
  title = {Optimal {{Experimental Design}} for {{Parameter Estimation}} of an {{IL-6 Signaling Model}}},
  author = {Sinkoe, Andrew and Hahn, Juergen},
  date = {2017-09},
  journaltitle = {Processes},
  volume = {5},
  number = {3},
  pages = {49},
  publisher = {{Multidisciplinary Digital Publishing Institute}},
  issn = {2227-9717},
  doi = {10.3390/pr5030049},
  url = {https://www.mdpi.com/2227-9717/5/3/49},
  urldate = {2023-04-12},
  abstract = {IL-6 signaling plays an important role in inflammatory processes in the body. While a number of models for IL-6 signaling are available, the parameters associated with these models vary from case to case as they are non-trivial to determine. In this study, optimal experimental design is utilized to reduce the parameter uncertainty of an IL-6 signaling model consisting of ordinary differential equations, thereby increasing the accuracy of the estimated parameter values and, potentially, the model itself. The D-optimality criterion, operating on the Fisher information matrix and, separately, on a sensitivity matrix computed from the Morris method, was used as the objective function for the optimal experimental design problem. Optimal input functions for model parameter estimation were identified by solving the optimal experimental design problem, and the resulting input functions were shown to significantly decrease parameter uncertainty in simulated experiments. Interestingly, the determined optimal input functions took on the shape of PRBS signals even though there were no restrictions on their nature. Future work should corroborate these findings by applying the determined optimal experimental design on a real experiment.},
  issue = {3},
  langid = {english},
  keywords = {D-optimality-criterion,Fisher-information-matrix,IL-6-signaling,optimal-experimental-design,parameter-estimation,piecewise-constant-functions,sensitivity-analysis},
  annotation = {16 citations (Semantic Scholar/DOI) [2023-04-12]},
  file = {/Users/michaelvolk/Zotero/storage/5D698RRY/Sinkoe_Hahn_2017_Optimal Experimental Design for Parameter Estimation of an IL-6 Signaling Model.pdf}
}

@article{smallboneLargeScaleMetabolicModels2013,
  title = {Large-{{Scale Metabolic Models}}: {{From Reconstruction}} to {{Differential Equations}}},
  shorttitle = {Large-{{Scale Metabolic Models}}},
  author = {Smallbone, Kieran and Mendes, Pedro},
  date = {2013-08},
  journaltitle = {Industrial Biotechnology},
  volume = {9},
  number = {4},
  pages = {179--184},
  publisher = {{Mary Ann Liebert, Inc., publishers}},
  issn = {1550-9087},
  doi = {10.1089/ind.2013.0003},
  url = {https://www.liebertpub.com/doi/10.1089/ind.2013.0003},
  urldate = {2023-03-29},
  abstract = {Genome-scale kinetic models of metabolism are important for rational design of the metabolic engineering required for industrial biotechnology applications. They allow one to predict the alterations needed to optimize the flux or yield of the compounds of interest, while keeping the other functions of the host organism to a minimal, but essential, level. We define a pipeline for the generation of genome-scale kinetic models from reconstruction data. To build such a model, inputs of all concentrations, fluxes, rate laws, and kinetic parameters are required. However, we propose typical estimates for these numbers when experimental data are not available. While little data are required to produce the model, the pipeline ensures consistency with any known flux or concentration data, or any kinetic constants. We apply the method to create genome-scale models of Escherichia coli and Saccharomyces cerevisiae. We go on to show how these may be used to expand a detailed model of yeast glycolysis to the genome level.},
  annotation = {61 citations (Semantic Scholar/DOI) [2023-03-29]},
  file = {/Users/michaelvolk/Zotero/storage/CEJ9FPTB/Smallbone_Mendes_2013_Large-Scale Metabolic Models.pdf}
}

@inproceedings{sohnLearningStructuredOutput2015,
  title = {Learning {{Structured Output Representation}} Using {{Deep Conditional Generative Models}}},
  booktitle = {Advances in {{Neural Information Processing Systems}}},
  author = {Sohn, Kihyuk and Lee, Honglak and Yan, Xinchen},
  date = {2015},
  volume = {28},
  publisher = {{Curran Associates, Inc.}},
  url = {https://proceedings.neurips.cc/paper/2015/hash/8d55a249e6baa5c06772297520da2051-Abstract.html},
  urldate = {2023-05-10},
  abstract = {Supervised deep learning has been successfully applied for many recognition problems in machine learning and computer vision. Although it can approximate a complex many-to-one function very well when large number of training data is provided, the lack of probabilistic inference of the current supervised deep learning methods makes it difficult to model a complex structured output representations. In this work, we develop a scalable deep conditional generative model for structured output variables using Gaussian latent variables. The model is trained efficiently in the framework of stochastic gradient variational Bayes, and allows a fast prediction using stochastic feed-forward inference. In addition, we provide novel strategies to build a robust structured prediction algorithms, such as recurrent prediction network architecture, input noise-injection and multi-scale prediction training methods. In experiments, we demonstrate the effectiveness of our proposed algorithm in comparison to the deterministic deep neural network counterparts in generating diverse but realistic output representations using stochastic inference. Furthermore, the proposed schemes in training methods and architecture design were complimentary, which leads to achieve strong pixel-level object segmentation and semantic labeling performance on Caltech-UCSD Birds 200 and the subset of Labeled Faces in the Wild dataset.},
  file = {/Users/michaelvolk/Zotero/storage/VC46GSIB/Sohn et al. - 2015 - Learning Structured Output Representation using De.pdf}
}

@article{srinivasanConstructingKineticModels2015,
  title = {Constructing Kinetic Models of Metabolism at Genome-Scales: {{A}} Review},
  shorttitle = {Constructing Kinetic Models of Metabolism at Genome-Scales},
  author = {Srinivasan, Shyam and Cluett, William R. and Mahadevan, Radhakrishnan},
  date = {2015},
  journaltitle = {Biotechnology Journal},
  volume = {10},
  number = {9},
  pages = {1345--1359},
  issn = {1860-7314},
  doi = {10.1002/biot.201400522},
  url = {https://onlinelibrary.wiley.com/doi/abs/10.1002/biot.201400522},
  urldate = {2022-09-07},
  abstract = {Constraint-based modeling of biological networks (metabolism, transcription and signal transduction), although used successfully in many applications, suffer from specific limitations such as the lack of representation of metabolite concentrations and enzymatic regulation, which are necessary for a complete physiologically relevant model. Kinetic models conversely overcome these shortcomings and enable dynamic analysis of biological systems for enhanced in silico hypothesis generation. Nonetheless, kinetic models also have limitations for modeling at genome-scales chiefly due to: (i) model non-linearity; (ii) computational tractability; (iii) parameter identifiability; (iv) estimability; and (v) uncertainty. In order to support further development of kinetic models as viable alternatives to constraint-based models, this review presents a brief description of the existing obstacles towards building genome-scale kinetic models. Specific kinetic modeling frameworks capable of overcoming these obstacles are covered in this review. The tractability and physiological feasibility of these models are discussed with the objective of using available in vivo experimental observations to define the model parameter space. Among the different methods discussed, Monte Carlo kinetic models of metabolism stand out as potentially tractable methods to model genome scale networks while also addressing in vivo parameter uncertainty.},
  langid = {english},
  keywords = {📌,🦌📚,Approximate-kinetic-models,Constraint-based-models,Genome-scale-kinetic-models,In-silico-modeling,Monte-Carlo-kinetic-models,Parameter\_Estimation,Parameter\_Estimation.motivation},
  annotation = {58 citations (Crossref) [2022-09-07]},
  file = {/Users/michaelvolk/Zotero/storage/L3AZVDEX/Srinivasan et al_2015_Constructing kinetic models of metabolism at genome-scales.pdf;/Users/michaelvolk/Zotero/storage/KGCPM7NA/biot.html}
}

@article{stadterBenchmarkingNumericalIntegration2021,
  title = {Benchmarking of Numerical Integration Methods for {{ODE}} Models of Biological Systems},
  author = {Städter, Philipp and Schälte, Yannik and Schmiester, Leonard and Hasenauer, Jan and Stapor, Paul L.},
  date = {2021-12},
  journaltitle = {Scientific Reports},
  shortjournal = {Sci Rep},
  volume = {11},
  number = {1},
  pages = {2696},
  issn = {2045-2322},
  doi = {10.1038/s41598-021-82196-2},
  url = {http://www.nature.com/articles/s41598-021-82196-2},
  urldate = {2022-04-11},
  abstract = {Abstract             Ordinary differential equation (ODE) models are a key tool to understand complex mechanisms in systems biology. These models are studied using various approaches, including stability and bifurcation analysis, but most frequently by numerical simulations. The number of required simulations is often large, e.g., when unknown parameters need to be inferred. This renders efficient and reliable numerical integration methods essential. However, these methods depend on various hyperparameters, which strongly impact the ODE solution. Despite this, and although hundreds of published ODE models are freely available in public databases, a thorough study that quantifies the impact of hyperparameters on the ODE solver in terms of accuracy and computation time is still missing. In this manuscript, we investigate which choices of algorithms and hyperparameters are generally favorable when dealing with ODE models arising from biological processes. To ensure a representative evaluation, we considered 142 published models. Our study provides evidence that most ODEs in computational biology are stiff, and we give guidelines for the choice of algorithms and hyperparameters. We anticipate that our results will help researchers in systems biology to choose appropriate numerical methods when dealing with ODE models.},
  langid = {english},
  annotation = {20 citations (Semantic Scholar/DOI) [2023-04-13]},
  file = {/Users/michaelvolk/Zotero/storage/XVXXL79P/Städter et al_2021_Benchmarking of numerical integration methods for ODE models of biological.pdf}
}

@article{staporMinibatchOptimizationEnables2022,
  title = {Mini-Batch Optimization Enables Training of {{ODE}} Models on Large-Scale Datasets},
  author = {Stapor, Paul and Schmiester, Leonard and Wierling, Christoph and Merkt, Simon and Pathirana, Dilan and Lange, Bodo M. H. and Weindl, Daniel and Hasenauer, Jan},
  date = {2022-01-10},
  journaltitle = {Nature Communications},
  shortjournal = {Nat Commun},
  volume = {13},
  number = {1},
  pages = {34},
  publisher = {{Nature Publishing Group}},
  issn = {2041-1723},
  doi = {10.1038/s41467-021-27374-6},
  url = {https://www.nature.com/articles/s41467-021-27374-6},
  urldate = {2023-06-13},
  abstract = {Quantitative dynamic models are widely used to study cellular signal processing. A critical step in modelling is the estimation of unknown model parameters from experimental data. As model sizes and datasets are steadily growing, established parameter optimization approaches for mechanistic models become computationally extremely challenging. Mini-batch optimization methods, as employed in deep learning, have better scaling properties. In this work, we adapt, apply, and benchmark mini-batch optimization for ordinary differential equation (ODE) models, thereby establishing a direct link between dynamic modelling and machine learning. On our main application example, a large-scale model of cancer signaling, we benchmark mini-batch optimization against established methods, achieving better optimization results and reducing computation by more than an order of magnitude. We expect that our work will serve as a first step towards mini-batch optimization tailored to ODE models and enable modelling of even larger and more complex systems than what is currently possible.},
  issue = {1},
  langid = {english},
  keywords = {Cellular signalling networks,Computer modelling,Differential equations,Machine learning,Software},
  annotation = {1 citations (Semantic Scholar/DOI) [2023-06-13]},
  file = {/Users/michaelvolk/Zotero/storage/AA4ZHYZR/SI-Stapor et al. - 2022 - Mini-batch optimization enables training of ODE mo.pdf;/Users/michaelvolk/Zotero/storage/BSLJ7YG5/Stapor et al. - 2022 - Mini-batch optimization enables training of ODE mo.pdf}
}

@article{staporPESTOParameterEStimation2018,
  title = {{{PESTO}}: {{Parameter EStimation TOolbox}}},
  shorttitle = {{{PESTO}}},
  author = {Stapor, Paul and Weindl, Daniel and Ballnus, Benjamin and Hug, Sabine and Loos, Carolin and Fiedler, Anna and Krause, Sabrina and Hroß, Sabrina and Fröhlich, Fabian and Hasenauer, Jan},
  date = {2018-02-15},
  journaltitle = {Bioinformatics},
  shortjournal = {Bioinformatics},
  volume = {34},
  number = {4},
  pages = {705--707},
  issn = {1367-4803},
  doi = {10.1093/bioinformatics/btx676},
  url = {https://doi.org/10.1093/bioinformatics/btx676},
  urldate = {2022-09-07},
  abstract = {PESTO is a widely applicable and highly customizable toolbox for parameter estimation in MathWorks MATLAB. It offers scalable algorithms for optimization, uncertainty and identifiability analysis, which work in a very generic manner, treating the objective function as a black box. Hence, PESTO can be used for any parameter estimation problem, for which the user can provide a deterministic objective function in MATLAB.PESTO is a MATLAB toolbox, freely available under the BSD license. The source code, along with extensive documentation and example code, can be downloaded from https://github.com/ICB-DCM/PESTO/.Supplementary data are available at Bioinformatics online.},
  keywords = {📌,🦌📚,Parameter\_Estimation},
  annotation = {62 citations (Crossref) [2022-09-07]},
  file = {/Users/michaelvolk/Zotero/storage/7HNXSYA2/Stapor et al_2018_PESTO.pdf;/Users/michaelvolk/Zotero/storage/6AJSPP3M/4562504.html}
}

@article{tiwariReproducibilitySystemsBiology2021,
  title = {Reproducibility in Systems Biology Modelling},
  author = {Tiwari, Krishna and Kananathan, Sarubini and Roberts, Matthew G and Meyer, Johannes P and Sharif Shohan, Mohammad Umer and Xavier, Ashley and Maire, Matthieu and Zyoud, Ahmad and Men, Jinghao and Ng, Szeyi and Nguyen, Tung V N and Glont, Mihai and Hermjakob, Henning and Malik-Sheriff, Rahuman S},
  date = {2021-02},
  journaltitle = {Molecular Systems Biology},
  volume = {17},
  number = {2},
  pages = {e9982},
  publisher = {{John Wiley \& Sons, Ltd}},
  issn = {1744-4292},
  doi = {10.15252/msb.20209982},
  url = {https://www.embopress.org/doi/full/10.15252/msb.20209982},
  urldate = {2023-01-19},
  abstract = {Reproducibility of scientific results is a key element of science and credibility. The lack of reproducibility across many scientific fields has emerged as an important concern. In this piece, we assess mathematical model reproducibility and propose a scorecard for improving reproducibility in this field.},
  file = {/Users/michaelvolk/Zotero/storage/FLDAWWMW/Tiwari et al_2021_Reproducibility in systems biology modelling.pdf}
}

@article{villaverdeBenchmarkingOptimizationMethods2019a,
  title = {Benchmarking Optimization Methods for Parameter Estimation in Large Kinetic Models},
  author = {Villaverde, Alejandro F and Fröhlich, Fabian and Weindl, Daniel and Hasenauer, Jan and Banga, Julio R},
  editor = {Stegle, Oliver},
  date = {2019-03-01},
  journaltitle = {Bioinformatics},
  volume = {35},
  number = {5},
  pages = {830--838},
  issn = {1367-4803, 1460-2059},
  doi = {10.1093/bioinformatics/bty736},
  url = {https://academic.oup.com/bioinformatics/article/35/5/830/5078478},
  urldate = {2022-04-19},
  abstract = {Motivation: Kinetic models contain unknown parameters that are estimated by optimizing the fit to experimental data. This task can be computationally challenging due to the presence of local optima and ill-conditioning. While a variety of optimization methods have been suggested to surmount these issues, it is difficult to choose the best one for a given problem a priori. A systematic comparison of parameter estimation methods for problems with tens to hundreds of optimization variables is currently missing, and smaller studies provided contradictory findings. Results: We use a collection of benchmarks to evaluate the performance of two families of optimization methods: (i) multi-starts of deterministic local searches and (ii) stochastic global optimization metaheuristics; the latter may be combined with deterministic local searches, leading to hybrid methods. A fair comparison is ensured through a collaborative evaluation and a consideration of multiple performance metrics. We discuss possible evaluation criteria to assess the trade-off between computational efficiency and robustness. Our results show that, thanks to recent advances in the calculation of parametric sensitivities, a multi-start of gradient-based local methods is often a successful strategy, but a better performance can be obtained with a hybrid metaheuristic. The best performer combines a global scatter search metaheuristic with an interior point local method, provided with gradients estimated with adjoint-based sensitivities. We provide an implementation of this method to render it available to the scientific community.},
  langid = {english},
  annotation = {91 citations (Semantic Scholar/DOI) [2023-04-13]},
  file = {/Users/michaelvolk/Zotero/storage/2RL45JLK/Villaverde et al_2019_Benchmarking optimization methods for parameter estimation in large kinetic.pdf}
}

@article{villaverdeBioPreDynbenchSuiteBenchmark2015,
  title = {{{BioPreDyn-bench}}: A Suite of Benchmark Problems for Dynamic Modelling in Systems Biology},
  shorttitle = {{{BioPreDyn-bench}}},
  author = {Villaverde, Alejandro F. and Henriques, David and Smallbone, Kieran and Bongard, Sophia and Schmid, Joachim and Cicin-Sain, Damjan and Crombach, Anton and Saez-Rodriguez, Julio and Mauch, Klaus and Balsa-Canto, Eva and Mendes, Pedro and Jaeger, Johannes and Banga, Julio R.},
  date = {2015-02-20},
  journaltitle = {BMC Systems Biology},
  shortjournal = {BMC Systems Biology},
  volume = {9},
  number = {1},
  pages = {8},
  issn = {1752-0509},
  doi = {10.1186/s12918-015-0144-4},
  url = {https://doi.org/10.1186/s12918-015-0144-4},
  urldate = {2023-03-26},
  abstract = {Dynamic modelling is one of the cornerstones of systems biology. Many research efforts are currently being invested in the development and exploitation of large-scale kinetic models. The associated problems of parameter estimation (model calibration) and optimal experimental design are particularly challenging. The community has already developed many methods and software packages which aim to facilitate these tasks. However, there is a lack of suitable benchmark problems which allow a fair and systematic evaluation and comparison of these contributions.},
  keywords = {Benchmarks,development,Dynamic-modelling,Large-scale,Metabolism,Model-calibration,Optimization,Parameter-estimation,Signal-transduction,Transcription},
  annotation = {67 citations (Semantic Scholar/DOI) [2023-03-26]},
  file = {/Users/michaelvolk/Zotero/storage/T5RISKM5/Villaverde et al_2015_BioPreDyn-bench.pdf;/Users/michaelvolk/Zotero/storage/E2S6VGRC/s12918-015-0144-4.html}
}

@article{villaverdeProtocolDynamicModel2022,
  title = {A Protocol for Dynamic Model Calibration},
  author = {Villaverde, Alejandro F and Pathirana, Dilan and Fröhlich, Fabian and Hasenauer, Jan and Banga, Julio R},
  date = {2022-01-01},
  journaltitle = {Briefings in Bioinformatics},
  shortjournal = {Briefings in Bioinformatics},
  volume = {23},
  number = {1},
  pages = {bbab387},
  issn = {1477-4054},
  doi = {10.1093/bib/bbab387},
  url = {https://doi.org/10.1093/bib/bbab387},
  urldate = {2022-08-25},
  abstract = {Ordinary differential equation models are nowadays widely used for the mechanistic description of biological processes and their temporal evolution. These models typically have many unknown and nonmeasurable parameters, which have to be determined by fitting the model to experimental data. In order to perform this task, known as parameter estimation or model calibration, the modeller faces challenges such as poor parameter identifiability, lack of sufficiently informative experimental data and the existence of local minima in the objective function landscape. These issues tend to worsen with larger model sizes, increasing the computational complexity and the number of unknown parameters. An incorrectly calibrated model is problematic because it may result in inaccurate predictions and misleading conclusions. For nonexpert users, there are a large number of potential pitfalls. Here, we provide a protocol that guides the user through all the steps involved in the calibration of dynamic models. We illustrate the methodology with two models and provide all the code required to reproduce the results and perform the same analysis on new models. Our protocol provides practitioners and researchers in biological modelling with a one-stop guide that is at the same time compact and sufficiently comprehensive to cover all aspects of the problem.},
  keywords = {✅,🦌},
  file = {/Users/michaelvolk/Zotero/storage/F3GCJHDJ/Villaverde et al_2022_A protocol for dynamic model calibration.pdf}
}

@article{villaverdeProtocolDynamicModel2022a,
  title = {A Protocol for Dynamic Model Calibration},
  author = {Villaverde, Alejandro F and Pathirana, Dilan and Fröhlich, Fabian and Hasenauer, Jan and Banga, Julio R},
  date = {2022-01-01},
  journaltitle = {Briefings in Bioinformatics},
  shortjournal = {Briefings in Bioinformatics},
  volume = {23},
  number = {1},
  pages = {bbab387},
  issn = {1477-4054},
  doi = {10.1093/bib/bbab387},
  url = {https://doi.org/10.1093/bib/bbab387},
  urldate = {2023-06-13},
  abstract = {Ordinary differential equation models are nowadays widely used for the mechanistic description of biological processes and their temporal evolution. These models typically have many unknown and nonmeasurable parameters, which have to be determined by fitting the model to experimental data. In order to perform this task, known as parameter estimation or model calibration, the modeller faces challenges such as poor parameter identifiability, lack of sufficiently informative experimental data and the existence of local minima in the objective function landscape. These issues tend to worsen with larger model sizes, increasing the computational complexity and the number of unknown parameters. An incorrectly calibrated model is problematic because it may result in inaccurate predictions and misleading conclusions. For nonexpert users, there are a large number of potential pitfalls. Here, we provide a protocol that guides the user through all the steps involved in the calibration of dynamic models. We illustrate the methodology with two models and provide all the code required to reproduce the results and perform the same analysis on new models. Our protocol provides practitioners and researchers in biological modelling with a one-stop guide that is at the same time compact and sufficiently comprehensive to cover all aspects of the problem.},
  annotation = {18 citations (Semantic Scholar/DOI) [2023-06-13]},
  file = {/Users/michaelvolk/Zotero/storage/6B944NIU/Villaverde et al. - 2022 - A protocol for dynamic model calibration.pdf;/Users/michaelvolk/Zotero/storage/CV58492I/6383562.html}
}

@article{wangPredictingMetabolomicProfiles2023,
  title = {Predicting Metabolomic Profiles from Microbial Composition through Neural Ordinary Differential Equations},
  author = {Wang, Tong and Wang, Xu-Wen and Lee-Sarwar, Kathleen A. and Litonjua, Augusto A. and Weiss, Scott T. and Sun, Yizhou and Maslov, Sergei and Liu, Yang-Yu},
  date = {2023-03},
  journaltitle = {Nature Machine Intelligence},
  shortjournal = {Nat Mach Intell},
  volume = {5},
  number = {3},
  pages = {284--293},
  publisher = {{Nature Publishing Group}},
  issn = {2522-5839},
  doi = {10.1038/s42256-023-00627-3},
  url = {https://www.nature.com/articles/s42256-023-00627-3},
  urldate = {2023-04-27},
  abstract = {Characterizing the metabolic profile of a microbial community is crucial for understanding its biological function and its impact on the host or environment. Metabolomics experiments directly measuring these profiles are difficult and expensive, whereas sequencing methods quantifying the species composition of microbial communities are well developed and relatively cost-effective. Computational methods that are capable of predicting metabolomic profiles from microbial compositions can save considerable efforts needed for metabolomic profiling experimentally. Yet, despite existing efforts, we still lack a computational method with high prediction power, general applicability and great interpretability. Here we develop a method called metabolomic profile predictor using neural ordinary differential equations (mNODE), based on a state-of-the-art family of deep neural network models. We show compelling evidence that mNODE outperforms existing methods in predicting the metabolomic profiles of human microbiomes and several environmental microbiomes. Moreover, in the case of human gut microbiomes, mNODE can naturally incorporate dietary information to further enhance the prediction of metabolomic profiles. Furthermore, susceptibility analysis of mNODE enables us to reveal microbe–metabolite interactions, which can be validated using both synthetic and real data. The results demonstrate that mNODE is a powerful tool to investigate the microbiome–diet–metabolome relationship, facilitating future research on precision nutrition.},
  issue = {3},
  langid = {english},
  keywords = {Machine-learning,Microbial-ecology,Microbiome},
  annotation = {1 citations (Semantic Scholar/DOI) [2023-04-27]},
  file = {/Users/michaelvolk/Zotero/storage/G6ZYD4C2/Wang et al_2023_Predicting metabolomic profiles from microbial composition through neural.pdf}
}

@online{wuLearningAcceleratePartial2022,
  title = {Learning to {{Accelerate Partial Differential Equations}} via {{Latent Global Evolution}}},
  author = {Wu, Tailin and Maruyama, Takashi and Leskovec, Jure},
  date = {2022-10-11},
  eprint = {2206.07681},
  eprinttype = {arxiv},
  eprintclass = {physics},
  doi = {10.48550/arXiv.2206.07681},
  url = {http://arxiv.org/abs/2206.07681},
  urldate = {2023-04-24},
  abstract = {Simulating the time evolution of Partial Differential Equations (PDEs) of large-scale systems is crucial in many scientific and engineering domains such as fluid dynamics, weather forecasting and their inverse optimization problems. However, both classical solvers and recent deep learning-based surrogate models are typically extremely computationally intensive, because of their local evolution: they need to update the state of each discretized cell at each time step during inference. Here we develop Latent Evolution of PDEs (LE-PDE), a simple, fast and scalable method to accelerate the simulation and inverse optimization of PDEs. LE-PDE learns a compact, global representation of the system and efficiently evolves it fully in the latent space with learned latent evolution models. LE-PDE achieves speed-up by having a much smaller latent dimension to update during long rollout as compared to updating in the input space. We introduce new learning objectives to effectively learn such latent dynamics to ensure long-term stability. We further introduce techniques for speeding-up inverse optimization of boundary conditions for PDEs via backpropagation through time in latent space, and an annealing technique to address the non-differentiability and sparse interaction of boundary conditions. We test our method in a 1D benchmark of nonlinear PDEs, 2D Navier-Stokes flows into turbulent phase and an inverse optimization of boundary conditions in 2D Navier-Stokes flow. Compared to state-of-the-art deep learning-based surrogate models and other strong baselines, we demonstrate up to 128x reduction in the dimensions to update, and up to 15x improvement in speed, while achieving competitive accuracy.},
  pubstate = {preprint},
  keywords = {Computer-Science-Machine-Learning,Physics-Computational-Physics}
}

@article{xuSBMLDiagramsPythonPackage2023,
  title = {{{SBMLDiagrams}}: A Python Package to Process and Visualize {{SBML}} Layout and Render},
  shorttitle = {{{SBMLDiagrams}}},
  author = {Xu, Jin and Jiang, Jessie and Sauro, Herbert M},
  date = {2023-01-01},
  journaltitle = {Bioinformatics},
  shortjournal = {Bioinformatics},
  volume = {39},
  number = {1},
  pages = {btac730},
  issn = {1367-4811},
  doi = {10.1093/bioinformatics/btac730},
  url = {https://doi.org/10.1093/bioinformatics/btac730},
  urldate = {2023-04-16},
  abstract = {The systems biology markup language (SBML) is an extensible standard format for exchanging biochemical models. One of the extensions for SBML is the SBML Layout and Render package. This allows modelers to describe a biochemical model as a pathway diagram. However, up to now, there has been little support to help users easily add and retrieve such information from SBML. In this application note, we describe a new Python package called SBMLDiagrams. This package allows a user to add a layout and render information or retrieve it using a straightforward Python API. The package uses skia-python to support the rendering of the diagrams, allowing export to commons formats such as PNG or PDF.SBMLDiagrams is publicly available and licensed under the liberal MIT open-source license. The package is available for all major platforms. The source code has been deposited at GitHub (github.com/sys-bio/SBMLDiagrams). Users can install the package using the standard pip installation mechanism: pip install SBMLDiagrams.Supplementary data are available at Bioinformatics online.},
  annotation = {0 citations (Semantic Scholar/DOI) [2023-04-16]},
  file = {/Users/michaelvolk/Zotero/storage/RAGIDM5H/Xu et al_2023_SBMLDiagrams.pdf;/Users/michaelvolk/Zotero/storage/YNFUCGQ7/6825309.html}
}

@article{yangLearnedProteinEmbeddings2018,
  title = {Learned Protein Embeddings for Machine Learning},
  author = {Yang, Kevin K and Wu, Zachary and Bedbrook, Claire N and Arnold, Frances H},
  date = {2018-08-01},
  journaltitle = {Bioinformatics},
  shortjournal = {Bioinformatics},
  volume = {34},
  number = {15},
  pages = {2642--2648},
  issn = {1367-4803},
  doi = {10.1093/bioinformatics/bty178},
  url = {https://doi.org/10.1093/bioinformatics/bty178},
  urldate = {2023-04-27},
  abstract = {Machine-learning models trained on protein sequences and their measured functions can infer biological properties of unseen sequences without requiring an understanding of the underlying physical or biological mechanisms. Such models enable the prediction and discovery of sequences with optimal properties. Machine-learning models generally require that their inputs be vectors, and the conversion from a protein sequence to a vector representation affects the model’s ability to learn. We propose to learn embedded representations of protein sequences that take advantage of the vast quantity of unmeasured protein sequence data available. These embeddings are low-dimensional and can greatly simplify downstream modeling.The predictive power of Gaussian process models trained using embeddings is comparable to those trained on existing representations, which suggests that embeddings enable accurate predictions despite having orders of magnitude fewer dimensions. Moreover, embeddings are simpler to obtain because they do not require alignments, structural data, or selection of informative amino-acid properties. Visualizing the embedding vectors shows meaningful relationships between the embedded proteins are captured.The embedding vectors and code to reproduce the results are available at https://github.com/fhalab/embeddings\_reproduction/.Supplementary data are available at Bioinformatics online.},
  annotation = {190 citations (Semantic Scholar/DOI) [2023-04-27]},
  file = {/Users/michaelvolk/Zotero/storage/UUR3R9ZQ/Yang et al_2018_Learned protein embeddings for machine learning.pdf;/Users/michaelvolk/Zotero/storage/SR6PBWIQ/4951834.html}
}

@online{zhaoLearningDiscourselevelDiversity2017,
  title = {Learning {{Discourse-level Diversity}} for {{Neural Dialog Models}} Using {{Conditional Variational Autoencoders}}},
  author = {Zhao, Tiancheng and Zhao, Ran and Eskenazi, Maxine},
  date = {2017-10-21},
  eprint = {1703.10960},
  eprinttype = {arxiv},
  eprintclass = {cs},
  doi = {10.48550/arXiv.1703.10960},
  url = {http://arxiv.org/abs/1703.10960},
  urldate = {2023-03-25},
  abstract = {While recent neural encoder-decoder models have shown great promise in modeling open-domain conversations, they often generate dull and generic responses. Unlike past work that has focused on diversifying the output of the decoder at word-level to alleviate this problem, we present a novel framework based on conditional variational autoencoders that captures the discourse-level diversity in the encoder. Our model uses latent variables to learn a distribution over potential conversational intents and generates diverse responses using only greedy decoders. We have further developed a novel variant that is integrated with linguistic prior knowledge for better performance. Finally, the training procedure is improved by introducing a bag-of-word loss. Our proposed models have been validated to generate significantly more diverse responses than baseline approaches and exhibit competence in discourse-level decision-making.},
  pubstate = {preprint},
  keywords = {Computer-Science-Artificial-Intelligence,Computer-Science-Computation-and-Language},
  annotation = {608 citations (Semantic Scholar/arXiv) [2023-03-24]},
  file = {/Users/michaelvolk/Zotero/storage/D7FIENAS/Zhao et al_2017_Learning Discourse-level Diversity for Neural Dialog Models using Conditional.pdf;/Users/michaelvolk/Zotero/storage/MNVT6NGW/1703.html}
}

@article{zhongPIVAEPhysicsInformedVariational2023,
  title = {{{PI-VAE}}: {{Physics-Informed Variational Auto-Encoder}} for Stochastic Differential Equations},
  shorttitle = {{{PI-VAE}}},
  author = {Zhong, Weiheng and Meidani, Hadi},
  date = {2023-01-01},
  journaltitle = {Computer Methods in Applied Mechanics and Engineering},
  shortjournal = {Computer Methods in Applied Mechanics and Engineering},
  volume = {403},
  pages = {115664},
  issn = {0045-7825},
  doi = {10.1016/j.cma.2022.115664},
  url = {https://www.sciencedirect.com/science/article/pii/S0045782522006193},
  urldate = {2023-05-10},
  abstract = {We propose a new class of physics-informed neural networks, called the Physics-Informed Variational Auto-Encoder (PI-VAE), to solve stochastic differential equations (SDEs) or inverse problems involving SDEs. In these problems the governing equations are known but only a limited number of measurements of system parameters are available. PI-VAE consists of a variational autoencoder (VAE), which generates samples of system variables and parameters. This generative model is integrated with the governing equations. In this integration, the derivatives of VAE outputs are readily calculated using automatic differentiation, and used in the physics-based loss term. In this work, the loss function is chosen to be the Maximum Mean Discrepancy (MMD) for improved performance, and neural network parameters are updated iteratively using the stochastic gradient descent algorithm. We first test the proposed method on approximating stochastic processes. Then we study three types of problems related to SDEs: forward and inverse problems together with mixed problems where system parameters and solutions are simultaneously calculated. The satisfactory accuracy and efficiency of the proposed method are numerically demonstrated in comparison with physics-informed Wasserstein generative adversarial network (PI-WGAN).},
  langid = {english},
  keywords = {Physics-informed-deep-learning,Stochastic-differential-equations,Variational-autoencoders},
  annotation = {6 citations (Semantic Scholar/DOI) [2023-05-10]},
  file = {/Users/michaelvolk/Zotero/storage/84Y3WY2Z/Zhong and Meidani - 2023 - PI-VAE Physics-Informed Variational Auto-Encoder .pdf;/Users/michaelvolk/Zotero/storage/W8UC5GUI/S0045782522006193.html}
}

@article{zhouMixtureDiscrepancyQuasirandom2013a,
  title = {Mixture Discrepancy for Quasi-Random Point Sets},
  author = {Zhou, Yong-Dao and Fang, Kai-Tai and Ning, Jian-Hui},
  date = {2013-06-01},
  journaltitle = {Journal of Complexity},
  shortjournal = {Journal of Complexity},
  volume = {29},
  number = {3},
  pages = {283--301},
  issn = {0885-064X},
  doi = {10.1016/j.jco.2012.11.006},
  url = {https://www.sciencedirect.com/science/article/pii/S0885064X12001057},
  urldate = {2023-06-16},
  abstract = {There are various discrepancies that are measures of uniformity for a set of points on the unit hypercube. The discrepancies have played an important role in quasi-Monte Carlo methods. Each discrepancy has its own characteristic and some weakness. In this paper we point out some unreasonable phenomena associated with the commonly used discrepancies in the literature such as the Lp-star discrepancy, the center L2-discrepancy (CD) and the wrap-around L2-discrepancy (WD). Then, a new discrepancy, called the mixture discrepancy (MD), is proposed. As shown in this paper, the mixture discrepancy is more reasonable than CD and WD for measuring the uniformity from different aspects such as the intuitive view, the uniformity of subdimension projection, the curse of dimensionality and the geometric property of the kernel function. Moreover, the relationships between MD and other design criteria such as the balance pattern and generalized wordlength pattern are also given.},
  langid = {english},
  keywords = {Centered -discrepancy,Curse of dimensionality,Generalized wordlength pattern,Mixture discrepancy,Quasi-Monte Carlo methods,Uniform design},
  annotation = {86 citations (Semantic Scholar/DOI) [2023-06-16]},
  file = {/Users/michaelvolk/Zotero/storage/J8CAKLPI/Zhou et al_2013_Mixture discrepancy for quasi-random point sets.pdf;/Users/michaelvolk/Zotero/storage/PHICSZJC/S0885064X12001057.html}
}
