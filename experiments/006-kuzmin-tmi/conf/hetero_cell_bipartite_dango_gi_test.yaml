defaults:
  - default
  - _self_

wandb:
  # FLAG
  project: torchcell_006-kuzmin-tmi_hetero_cell_bipartite_dango_gi
  tags: ["1844414_test"]

cell_dataset:
  graphs:
    [
      physical,
      regulatory,
      tflink,
      string12_0_neighborhood,
      string12_0_fusion,
      string12_0_cooccurence,
      string12_0_coexpression,
      string12_0_experimental,
      string12_0_database,
    ]

  node_embeddings:
    - learnable
  learnable_embedding_input_channels: 96
  incidence_graphs: [metabolism_bipartite]

# Transform configuration moved out of regression_task
transforms:
  use_transforms: true
  forward_transform:
    normalization:
      gene_interaction:
        strategy: "standard" # Options: standard, minmax, robust

profiler:
  is_pytorch: true

data_module:
  is_perturbation_subset: false
  perturbation_subset_size: 1000
  batch_size: 8
  num_workers: 2
  pin_memory: false
  prefetch: false
  prefetch_factor: 4

trainer:
  max_epochs: 1000
  strategy: "auto"
  num_nodes: 1
  accelerator: gpu
  devices: 1
  overfit_batches: 0

# ------ Placeholders for hydra optuna
heads: 12
norms: "layer"
# ------
model:
  checkpoint_path: "/home/a-m/mjvolk3/scratch/torchcell/models/checkpoints/compute-5-7-1844414_e2095633aaa70752868739b24bbbd79e5ff805eccf8b90b66062f0e088a1ef7a/1ulxj500-best-epoch=23-val/gene_interaction/MSE=0.0034.ckpt"
  gene_num: 6607
  reaction_num: 7122
  metabolite_num: 2806
  hidden_channels: 96
  num_layers: 2
  norm: ${norms}
  activation: "relu"
  dropout: 0.0
  gene_encoder_config:
    heads: ${heads}
    concat: true
    bias: true
    add_self_loops: false
    share_weights: false
  gpr_conv_config:
    heads: ${heads} 
    concat: true
    add_self_loops: false
  metabolism_config:
    is_stoich_gated: true
    use_attention: true
    heads: ${heads}
    concat: true
  prediction_head_config:
    hidden_channels: 96
    head_num_layers: 4
    dropout: 0.0
    activation: "relu"
    head_norm: ${norms}
  local_predictor_config:
    num_attention_layers: 2
    num_heads: 4
    combination_method: "concat"
regression_task:
  loss: icloss
  is_weighted_phenotype_loss: false
  lambda_dist: 1
  lambda_supcr: 0.01
  optimizer:
    type: "AdamW"
    lr: 0.0001
    weight_decay: 0.000001
  lr_scheduler:
    type: "ReduceLROnPlateau"
    mode: "min"
    factor: 0.2
    patience: 3
    cooldown: 4
    min_lr: 1e-9
    eps: 1e-10
    threshold: 0.0001
    threshold_mode: "rel"
  clip_grad_norm: true
  clip_grad_norm_max_norm: 10
  grad_accumulation_schedule: null
  plot_sample_ceiling: 100000
  plot_every_n_epochs: 2
