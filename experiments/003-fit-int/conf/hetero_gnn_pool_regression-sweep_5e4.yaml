program: experiments/003-fit-int/scripts/hetero_gnn_pool_regression.py
project: torchcell_003-fit-int_hetero_gnn_pool_5e4_regression
method: grid

parameters:
  cell_dataset:
    parameters:
      graphs:
        values: [[physical, regulatory]]
      node_embeddings:
        values:
          - [codon_frequency]
          - [learnable_embedding]
        # - [one_hot_gene]
        # - [calm]
        # - [fudt_downstream]
        # - [fudt_upstream]
        # - [prot_T5_all]
        # - [prot_T5_no_dubious]
        # - [nt_window_5979]
        # - [nt_window_three_prime_300]
        # - [nt_window_five_prime_1003]
        # - [esm2_t33_650M_UR50D_all]
        # - [esm2_t33_650M_UR50D_no_dubious]
        # - [normalized_chrom_pathways]
        # - [random_1000]
        # - [random_100]
        # - [random_10]
        # - [random_1]

      learnable_embedding_input_channels:
        values: [64]
      graph_processor:
        values: [subgraph_representation]

  transforms:
    parameters:
      norm:
        values: [true]
      norm_strategy:
        values: ["minmax"]
      bin:
        values: [false]
      bin_strategy:
        values: ["equal_frequency"]
      num_bins:
        values: [32]
      store_continuous:
        values: [true]
      label_type:
        values: [soft]

  profiler:
    parameters:
      is_pytorch:
        values: [true]

  data_module:
    parameters:
      is_perturbation_subset:
        values: [true]
      perturbation_subset_size:
        values: [5e4]
      batch_size:
        values: [16]
      num_workers:
        values: [8]
      pin_memory:
        values: [true]
      prefetch:
        values: [true]

  trainer:
    parameters:
      max_epochs:
        values: [100]
      strategy:
        values: [auto]
      accelerator:
        values: [gpu]
      devices:
        values: [auto]

  model:
    parameters:
      hidden_channels:
        values: [64]
      num_layers:
        values: [2]
      conv_type:
        values: ["GCN"]
      pooling:
        values: ["sum"]
      activation:
        values: ["gelu"]
      norm:
        values: ["batch", "layer"]
      num_tasks:
        values: [2]
      dropout:
        values: [0.2]

      head_num_layers:
        values: [10]
      head_hidden_channels:
        values: [32]
      head_dropout:
        values: [0.2]
      head_activation:
        values: ["gelu"]
      head_residual:
        values: [true]
      head_norm:
        values: ["batch"]

      gcn_bias:
        values: [true]
      gcn_add_self_loops:
        values: [false]
      gcn_normalize:
        values: [false]
      gcn_is_skip_connection:
        values: [true]

      gat_heads:
        values: [10]
      gat_concat:
        values: [false]
      gat_bias:
        values: [true]
      gat_add_self_loops:
        values: [false]
      gat_share_weights:
        values: [false]
      gat_is_skip_connection:
        values: [true]

      transformer_heads:
        values: [4]
      transformer_concat:
        values: [true]
      transformer_beta:
        values: [true]
      transformer_bias:
        values: [true]
      transformer_root_weight:
        values: [true]
      transformer_add_self_loops:
        values: [false]
      transformer_edge_dim:
        values: [null]

      gin_train_eps:
        values: [true]
      gin_hidden_multiplier:
        values: [2.0]
      gin_add_self_loops:
        values: [true]
      gin_is_skip_connection:
        values: [true]
      gin_num_mlp_layers:
        values: [3]
      gin_is_mlp_skip_connection:
        values: [true]

  regression_task:
    parameters:
      is_weighted_phenotype_loss:
        values: [true]
      loss_type:
        values: ["logcosh"]
      quantile_config:
        parameters:
          spacing:
            values: [0.1] #[0.1, 0.03125] 
      dist_loss_config:
        parameters:
          num_bins:
            values: [100]
          bandwidth:
            values: [0.1, 0.5]
          eps:
            values: [1e-7]
      optimizer:
        parameters:
          type:
            values: ["AdamW"]
          lr:
            values: [1e-3, 1e-5]
          weight_decay:
            values: [1e-9]
      lr_scheduler:
      
        parameters:
          type:
            values: ["ReduceLROnPlateau"]
          mode:
            values: ["min"]
          factor:
            values: [0.2]
          patience:
            values: [3]
          threshold:
            values: [1e-4]
          threshold_mode:
            values: ["rel"]
          cooldown:
            values: [2]
          min_lr:
            values: [1e-9]
          eps:
            values: [1e-10]
      boxplot_every_n_epochs:
        values: [1]
      clip_grad_norm:
        values: [true]
      clip_grad_norm_max_norm:
        values: [10.0]
      grad_accumulation_schedule:
        values: [null]

command:
  - ${env}
  - python
  - ${program}
