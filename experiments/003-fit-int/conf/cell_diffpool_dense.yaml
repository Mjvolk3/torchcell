defaults:
  - default
  - _self_

wandb:
  # mode: offline # disabled, offline, online
  project: torchcell_test_cell_diffpool_dense
  tags: []

cell_dataset:
  graphs: [physical, regulatory] # [physical], [regulatory], [physical, regulatory], []
  node_embeddings: [codon_frequency]
  # [one_hot_gene], [codon_frequency], [calm], [fudt_downstream], [fudt_upstream], [prot_T5_all], [prot_T5_no_dubious], [nt_window_5979], [nt_window_three_prime_300], [nt_window_five_prime_1003], [esm2_t33_650M_UR50D_all], [esm2_t33_650M_UR50D_no_dubious], [normalized_chrom_pathways], [random_1000], [random_100], [random_10], [random_1]

data_module:
  is_perturbation_subset: true
  perturbation_subset_size: 5e4 #7e3
  num_workers: 10
  batch_size: 2 # ok: 4; oom: 8, 12
  pin_memory: true
  prefetch: false

trainer:
  max_epochs: 2
  strategy: auto # ddp, auto
  accelerator: gpu
  devices: auto # auto or int

model:
  pool_gat_hidden_channels: 16
  num_pool_gat_layers: 2
  embed_gat_hidden_channels: 16
  num_embed_gat_layers: 2
  num_pooling_layers: 5
  cluster_size_decay_factor: 5.0
  activation: relu
  norm: layer
  target_dim: 2
  heads: 1
  concat: false
  dropout: 0.1

regression_task:
  loss_type: "mse"
  optimizer:
    type: "AdamW"
    lr: 1e-5
    weight_decay: 1e-4
  lr_scheduler:
    type: "ReduceLROnPlateau"
    mode: "min"
    factor: 0.2
    patience: 3
    threshold: 1e-4
    threshold_mode: "rel"
    cooldown: 2
    min_lr: 1e-9
    eps: 1e-10
  boxplot_every_n_epochs: 1
  clip_grad_norm: true
  clip_grad_norm_max_norm: 1.0
  cluster_loss_weight: 1.0 #1.0
  link_pred_loss_weight: 1.0 # 1.0
  entropy_loss_weight: 1.0 # 1.0
  grad_accumulation_schedule:
    0: 12
  
  # grad_accumulation_schedule: null
