@article{aguade-gorgorioOncospaceHumanCancers2023,
  title = {An Oncospace for Human Cancers},
  author = {Aguadé-Gorgorió, Guim and Costa, José and Solé, Ricard},
  date = {2023},
  journaltitle = {BioEssays},
  volume = {45},
  number = {5},
  pages = {2200215},
  issn = {1521-1878},
  doi = {10.1002/bies.202200215},
  url = {https://onlinelibrary.wiley.com/doi/abs/10.1002/bies.202200215},
  urldate = {2024-07-04},
  abstract = {Human cancers comprise an heterogeneous array of diseases with different progression patterns and responses to therapy. However, they all develop within a host context that constrains their natural history. Since it occurs across the diversity of organisms, one can conjecture that there is order in the cancer multiverse. Is there a way to capture the broad range of tumor types within a space of the possible? Here we define the oncospace, a coordinate system that integrates the ecological, evolutionary and developmental components of cancer complexity. The spatial position of a tumor results from its departure from the healthy tissue along these three axes, and progression trajectories inform about the components driving malignancy across cancer subtypes. We postulate that the oncospace topology encodes new information regarding tumorigenic pathways, subtype prognosis, and therapeutic opportunities: treatment design could benefit from considering how to nudge tumors toward empty evolutionary dead ends in the oncospace.},
  langid = {english},
  keywords = {cancer morphospace,developmental abnormalities,genome instability,microenvironmental complexity},
  annotation = {2 citations (Semantic Scholar/DOI) [2024-07-04]},
  file = {/Users/michaelvolk/Zotero/storage/5UC77LYS/Aguadé-Gorgorió et al. - 2023 - An oncospace for human cancers.pdf;/Users/michaelvolk/Zotero/storage/IUAWREUR/bies.html}
}

@online{akanshaOverSquashingGraphNeural2024,
  title = {Over-{{Squashing}} in {{Graph Neural Networks}}: {{A Comprehensive}} Survey},
  shorttitle = {Over-{{Squashing}} in {{Graph Neural Networks}}},
  author = {Akansha, Singh},
  date = {2024-04-29},
  eprint = {2308.15568},
  eprinttype = {arXiv},
  eprintclass = {cs},
  doi = {10.48550/arXiv.2308.15568},
  url = {http://arxiv.org/abs/2308.15568},
  urldate = {2025-02-27},
  abstract = {Graph Neural Networks (GNNs) revolutionize machine learning for graph-structured data, effectively capturing complex relationships. They disseminate information through interconnected nodes, but long-range interactions face challenges known as "over-squashing". This survey delves into the challenge of over-squashing in Graph Neural Networks (GNNs), where long-range information dissemination is hindered, impacting tasks reliant on intricate long-distance interactions. It comprehensively explores the causes, consequences, and mitigation strategies for over-squashing. Various methodologies are reviewed, including graph rewiring, novel normalization, spectral analysis, and curvature-based strategies, with a focus on their trade-offs and effectiveness. The survey also discusses the interplay between over-squashing and other GNN limitations, such as over-smoothing, and provides a taxonomy of models designed to address these issues in node and graph-level tasks. Benchmark datasets for performance evaluation are also detailed, making this survey a valuable resource for researchers and practitioners in the GNN field.},
  pubstate = {prepublished},
  keywords = {Computer Science - Artificial Intelligence,Computer Science - Machine Learning},
  annotation = {6 citations (Semantic Scholar/arXiv) [2025-02-27]\\
6 citations (Semantic Scholar/DOI) [2025-02-27]},
  file = {/Users/michaelvolk/Zotero/storage/Y2JIX6XV/Akansha_2024_Over-Squashing in Graph Neural Networks.pdf;/Users/michaelvolk/Zotero/storage/UACHUXDE/2308.html}
}

@article{alamMetabolicBackgroundGlobal2016a,
  title = {The Metabolic Background Is a Global Player in {{Saccharomyces}} Gene Expression Epistasis},
  author = {Alam, Mohammad Tauqeer and Zelezniak, Aleksej and Mülleder, Michael and Shliaha, Pavel and Schwarz, Roland and Capuano, Floriana and Vowinckel, Jakob and Radmaneshfar, Elahe and Krüger, Antje and Calvani, Enrica and Michel, Steve and Börno, Stefan and Christen, Stefan and Patil, Kiran Raosaheb and Timmermann, Bernd and Lilley, Kathryn S. and Ralser, Markus},
  date = {2016-02-01},
  journaltitle = {Nature Microbiology},
  shortjournal = {Nat Microbiol},
  volume = {1},
  number = {3},
  pages = {1--10},
  publisher = {Nature Publishing Group},
  issn = {2058-5276},
  doi = {10.1038/nmicrobiol.2015.30},
  url = {https://www.nature.com/articles/nmicrobiol201530},
  urldate = {2023-11-02},
  abstract = {The regulation of gene expression in response to nutrient availability is fundamental to the genotype–phenotype relationship. The metabolic–genetic make-up of the cell, as reflected in auxotrophy, is hence likely to be a determinant of gene expression. Here, we address the importance of the metabolic–genetic background by monitoring transcriptome, proteome and metabolome in a repertoire of 16 Saccharomyces cerevisiae laboratory backgrounds, combinatorially perturbed in histidine, leucine, methionine and uracil biosynthesis. The metabolic background affected up to 85\% of the coding genome. Suggesting widespread confounding, these transcriptional changes show, on average, 83\% overlap between unrelated auxotrophs and 35\% with previously published transcriptomes generated for non-metabolic gene knockouts. Background-dependent gene expression correlated with metabolic flux and acted, predominantly through masking or suppression, on 88\% of transcriptional interactions epistatically. As a consequence, the deletion of the same metabolic gene in a different background could provoke an entirely different transcriptional response. Propagating to the proteome and scaling up at the metabolome, metabolic background dependencies reveal the prevalence of metabolism-dependent epistasis at all regulatory levels. Urging a fundamental change of the prevailing laboratory practice of using auxotrophs and nutrient supplemented media, these results reveal epistatic intertwining of metabolism with gene expression on the genomic scale.},
  issue = {3},
  langid = {english},
  keywords = {Fungal physiology,Fungal systems biology,Microbial genetics,Systems analysis},
  annotation = {73 citations (Semantic Scholar/DOI) [2023-11-02]},
  file = {/Users/michaelvolk/Zotero/storage/DB77A9UJ/Alam et al_2016_The metabolic background is a global player in Saccharomyces gene expression.pdf}
}

@article{alamSelfinhibitoryNatureMetabolic2017,
  title = {The Self-Inhibitory Nature of Metabolic Networks and Its Alleviation through Compartmentalization},
  author = {Alam, Mohammad Tauqeer and Olin-Sandoval, Viridiana and Stincone, Anna and Keller, Markus A. and Zelezniak, Aleksej and Luisi, Ben F. and Ralser, Markus},
  date = {2017},
  journaltitle = {Nature communications},
  volume = {8},
  number = {1},
  pages = {16018},
  publisher = {Nature Publishing Group UK London},
  url = {https://www.nature.com/articles/ncomms16018},
  urldate = {2023-11-02},
  file = {/Users/michaelvolk/Zotero/storage/G928U2IY/ncomms16018.html}
}

@article{alcantarHighthroughputSyntheticBiology2024,
  title = {A High-Throughput Synthetic Biology Approach for Studying Combinatorial Chromatin-Based Transcriptional Regulation},
  author = {Alcantar, Miguel A. and English, Max A. and Valeri, Jacqueline A. and Collins, James J.},
  date = {2024-06-20},
  journaltitle = {Molecular Cell},
  shortjournal = {Molecular Cell},
  volume = {84},
  number = {12},
  eprint = {38906116},
  eprinttype = {pmid},
  pages = {2382-2396.e9},
  publisher = {Elsevier},
  issn = {1097-2765},
  doi = {10.1016/j.molcel.2024.05.025},
  url = {https://www.cell.com/molecular-cell/abstract/S1097-2765(24)00448-9},
  urldate = {2024-06-24},
  langid = {english},
  keywords = {chromatin,high-throughput screening,machine learning,transcriptional regulation,yeast},
  annotation = {0 citations (Semantic Scholar/DOI) [2024-06-23]}
}

@online{alchihabiOvercomingClassImbalance2024,
  title = {Overcoming {{Class Imbalance}}: {{Unified GNN Learning}} with {{Structural}} and {{Semantic Connectivity Representations}}},
  shorttitle = {Overcoming {{Class Imbalance}}},
  author = {Alchihabi, Abdullah and Yan, Hao and Guo, Yuhong},
  date = {2024-12-30},
  eprint = {2412.20656},
  eprinttype = {arXiv},
  eprintclass = {cs},
  doi = {10.48550/arXiv.2412.20656},
  url = {http://arxiv.org/abs/2412.20656},
  urldate = {2025-04-24},
  abstract = {Class imbalance is pervasive in real-world graph datasets, where the majority of annotated nodes belong to a small set of classes (majority classes), leaving many other classes (minority classes) with only a handful of labeled nodes. Graph Neural Networks (GNNs) suffer from significant performance degradation in the presence of class imbalance, exhibiting bias towards majority classes and struggling to generalize effectively on minority classes. This limitation stems, in part, from the message passing process, leading GNNs to overfit to the limited neighborhood of annotated nodes from minority classes and impeding the propagation of discriminative information throughout the entire graph. In this paper, we introduce a novel Unified Graph Neural Network Learning (Uni-GNN) framework to tackle class-imbalanced node classification. The proposed framework seamlessly integrates both structural and semantic connectivity representations through semantic and structural node encoders. By combining these connectivity types, Uni-GNN extends the propagation of node embeddings beyond immediate neighbors, encompassing non-adjacent structural nodes and semantically similar nodes, enabling efficient diffusion of discriminative information throughout the graph. Moreover, to harness the potential of unlabeled nodes within the graph, we employ a balanced pseudo-label generation mechanism that augments the pool of available labeled nodes from minority classes in the training set. Experimental results underscore the superior performance of our proposed Uni-GNN framework compared to state-of-the-art class-imbalanced graph learning baselines across multiple benchmark datasets.},
  pubstate = {prepublished},
  keywords = {Computer Science - Artificial Intelligence,Computer Science - Machine Learning},
  annotation = {0 citations (Semantic Scholar/arXiv) [2025-04-23]\\
0 citations (Semantic Scholar/DOI) [2025-04-23]},
  file = {/Users/michaelvolk/Zotero/storage/JN3HPJ4I/Alchihabi et al_2024_Overcoming Class Imbalance.pdf;/Users/michaelvolk/Zotero/storage/B4DDEHZM/2412.html}
}

@article{allouDisruptionRegulatoryDomains2023,
  title = {Disruption of Regulatory Domains and Novel Transcripts as Disease-Causing Mechanisms},
  author = {Allou, Lila and Mundlos, Stefan},
  date = {2023},
  journaltitle = {BioEssays},
  volume = {45},
  number = {10},
  pages = {2300010},
  issn = {1521-1878},
  doi = {10.1002/bies.202300010},
  url = {https://onlinelibrary.wiley.com/doi/abs/10.1002/bies.202300010},
  urldate = {2024-07-04},
  abstract = {Deletions, duplications, insertions, inversions, and translocations, collectively called structural variations (SVs), affect more base pairs of the genome than any other sequence variant. The recent technological advancements in genome sequencing have enabled the discovery of tens of thousands of SVs per human genome. These SVs primarily affect non-coding DNA sequences, but the difficulties in interpreting their impact limit our understanding of human disease etiology. The functional annotation of non-coding DNA sequences and methodologies to characterize their three-dimensional (3D) organization in the nucleus have greatly expanded our understanding of the basic mechanisms underlying gene regulation, thereby improving the interpretation of SVs for their pathogenic impact. Here, we discuss the various mechanisms by which SVs can result in altered gene regulation and how these mechanisms can result in rare genetic disorders. Beyond changing gene expression, SVs can produce novel gene-intergenic fusion transcripts at the SV breakpoints.},
  langid = {english},
  keywords = {3D genome organization,enhancer-promoter communication,gene-intergenic fusion transcript,structural variation,topologically associated domain},
  annotation = {3 citations (Semantic Scholar/DOI) [2024-07-04]},
  file = {/Users/michaelvolk/Zotero/storage/4WYY97SU/Allou and Mundlos - 2023 - Disruption of regulatory domains and novel transcr.pdf;/Users/michaelvolk/Zotero/storage/6HSS568A/bies.html}
}

@article{almamunIdentityFunctionLarge2012,
  title = {Identity and {{Function}} of a {{Large Gene Network Underlying Mutagenic Repair}} of {{DNA Breaks}}},
  author = {Al Mamun, Abu Amar M. and Lombardo, Mary-Jane and Shee, Chandan and Lisewski, Andreas M. and Gonzalez, Caleb and Lin, Dongxu and Nehring, Ralf B. and Saint-Ruf, Claude and Gibson, Janet L. and Frisch, Ryan L. and Lichtarge, Olivier and Hastings, P. J. and Rosenberg, Susan M.},
  date = {2012-12-07},
  journaltitle = {Science},
  volume = {338},
  number = {6112},
  pages = {1344--1348},
  publisher = {American Association for the Advancement of Science},
  doi = {10.1126/science.1226683},
  url = {https://www.science.org/doi/full/10.1126/science.1226683},
  urldate = {2023-07-27},
  abstract = {Mechanisms of DNA repair and mutagenesis are defined on the basis of relatively few proteins acting on DNA, yet the identities and functions of all proteins required are unknown. Here, we identify the network that underlies mutagenic repair of DNA breaks in stressed Escherichia coli and define functions for much of it. Using a comprehensive screen, we identified a network of ≥93 genes that function in mutation. Most operate upstream of activation of three required stress responses (RpoS, RpoE, and SOS, key network hubs), apparently sensing stress. The results reveal how a network integrates mutagenic repair into the biology of the cell, show specific pathways of environmental sensing, demonstrate the centrality of stress responses, and imply that these responses are attractive as potential drug targets for blocking the evolution of pathogens.},
  annotation = {186 citations (Semantic Scholar/DOI) [2023-07-27]},
  file = {/Users/michaelvolk/Zotero/storage/SY9BDDY9/Al Mamun et al_2012_Identity and Function of a Large Gene Network Underlying Mutagenic Repair of.pdf}
}

@article{altmanEditorialBuildingSuccessful2004,
  title = {Editorial: {{Building}} Successful Biological Databases},
  shorttitle = {Editorial},
  author = {Altman, Russ B.},
  date = {2004-03-01},
  journaltitle = {Briefings in Bioinformatics},
  shortjournal = {Briefings in Bioinformatics},
  volume = {5},
  number = {1},
  pages = {4--5},
  issn = {1467-5463},
  doi = {10.1093/bib/5.1.4},
  url = {https://doi.org/10.1093/bib/5.1.4},
  urldate = {2023-11-23},
  annotation = {28 citations (Semantic Scholar/DOI) [2023-11-23]},
  file = {/Users/michaelvolk/Zotero/storage/Q9PK4GA4/Altman_2004_Editorial.pdf;/Users/michaelvolk/Zotero/storage/CH9R5VMC/430456.html}
}

@article{andrewsDesignPatternsBiological2024,
  title = {Design Patterns of Biological Cells},
  author = {Andrews, Steven S. and Wiley, H. Steven and Sauro, Herbert M.},
  date = {2024},
  journaltitle = {BioEssays},
  volume = {46},
  number = {3},
  pages = {2300188},
  issn = {1521-1878},
  doi = {10.1002/bies.202300188},
  url = {https://onlinelibrary.wiley.com/doi/abs/10.1002/bies.202300188},
  urldate = {2024-07-04},
  abstract = {Design patterns are generalized solutions to frequently recurring problems. They were initially developed by architects and computer scientists to create a higher level of abstraction for their designs. Here, we extend these concepts to cell biology to lend a new perspective on the evolved designs of cells' underlying reaction networks. We present a catalog of 21 design patterns divided into three categories: creational patterns describe processes that build the cell, structural patterns describe the layouts of reaction networks, and behavioral patterns describe reaction network function. Applying this pattern language to the E. coli central metabolic reaction network, the yeast pheromone response signaling network, and other examples lends new insights into these systems.},
  langid = {english},
  keywords = {✅🦌,cell biology modeling,cell signaling,metabolism,systems biology},
  annotation = {1 citations (Semantic Scholar/DOI) [2024-07-04]},
  file = {/Users/michaelvolk/Zotero/storage/MI6MAC9X/Andrews et al. - 2024 - Design patterns of biological cells.pdf;/Users/michaelvolk/Zotero/storage/INMUA7SH/bies.html}
}

@article{angelerBiologicalSystemsSymphonies2023,
  title = {Biological Systems — “{{Symphonies}} of {{Life}}”: {{Reviving Friedrich Cramer}}'s General Resonance Theory},
  shorttitle = {Biological Systems — “{{Symphonies}} of {{Life}}”},
  author = {Angeler, David G.},
  date = {2023},
  journaltitle = {BioEssays},
  volume = {45},
  number = {11},
  pages = {2300113},
  issn = {1521-1878},
  doi = {10.1002/bies.202300113},
  url = {https://onlinelibrary.wiley.com/doi/abs/10.1002/bies.202300113},
  urldate = {2024-07-04},
  abstract = {Understanding biological systems in terms of scientific materialism has arguably reached a frontier, leaving fundamental questions about their complexity unanswered. In 1998, Friedrich Cramer proposed a general resonance theory as a way forward. His theory builds on the extension of the quantum physical duality of matter and wave to the macroscopic world. According to Cramer’ theory, agents constituting biological systems oscillate, akin to musical soundwaves, at specific eigenfrequencies. Biological system dynamics can be described as “Symphonies of Life” emerging from the resonance (and dissonance) of eigenfrequencies within the interacting collective. His theory has potential for studying biological problems of increasing complexity in a fast-changing Anthropocene from a new and transdisciplinary angle. Despite data becoming increasingly available for analyses, Cramer's theory remains ignored and therefore untested a quarter century after its publication. This paper discusses how the theory can move to quantitative assessments and application. Cramer's general resonance theory deserves revival.},
  langid = {english},
  keywords = {Anthropocene,biological systems,complex adaptive systems,emergent properties,quantum biology,resilience,resonance theory},
  annotation = {0 citations (Semantic Scholar/DOI) [2024-07-04]},
  file = {/Users/michaelvolk/Zotero/storage/T676Y5PQ/bies.html}
}

@article{antelmiSurveyHypergraphRepresentation2023,
  title = {A {{Survey}} on {{Hypergraph Representation Learning}}},
  author = {Antelmi, Alessia and Cordasco, Gennaro and Polato, Mirko and Scarano, Vittorio and Spagnuolo, Carmine and Yang, Dingqi},
  date = {2023-08-26},
  journaltitle = {ACM Comput. Surv.},
  volume = {56},
  number = {1},
  pages = {24:1--24:38},
  issn = {0360-0300},
  doi = {10.1145/3605776},
  url = {https://dl.acm.org/doi/10.1145/3605776},
  urldate = {2025-02-14},
  abstract = {Hypergraphs have attracted increasing attention in recent years thanks to their flexibility in naturally modeling a broad range of systems where high-order relationships exist among their interacting parts. This survey reviews the newly born hypergraph representation learning problem, whose goal is to learn a function to project objects—most commonly nodes—of an input hyper-network into a latent space such that both the structural and relational properties of the network can be encoded and preserved. We provide a thorough overview of existing literature and offer a new taxonomy of hypergraph embedding methods by identifying three main families of techniques, i.e., spectral, proximity-preserving, and (deep) neural networks. For each family, we describe its characteristics and our insights in a single yet flexible framework and then discuss the peculiarities of individual methods, as well as their pros and cons. We then review the main tasks, datasets, and settings in which hypergraph embeddings are typically used. We finally identify and discuss open challenges that would inspire further research in this field.},
  annotation = {79 citations (Semantic Scholar/DOI) [2025-02-14]},
  file = {/Users/michaelvolk/Zotero/storage/6NA8LDFL/Antelmi et al. - 2023 - A Survey on Hypergraph Representation Learning.pdf}
}

@article{asimSurveyOntologyLearning2018,
  title = {A Survey of Ontology Learning Techniques and Applications},
  author = {Asim, Muhammad Nabeel and Wasim, Muhammad and Khan, Muhammad Usman Ghani and Mahmood, Waqar and Abbasi, Hafiza Mahnoor},
  date = {2018-01-01},
  journaltitle = {Database},
  shortjournal = {Database},
  volume = {2018},
  pages = {bay101},
  issn = {1758-0463},
  doi = {10.1093/database/bay101},
  url = {https://doi.org/10.1093/database/bay101},
  urldate = {2024-03-11},
  abstract = {Ontologies have gained a lot of popularity and recognition in the semantic web because of their extensive use in Internet-based applications. Ontologies are often considered a fine source of semantics and interoperability in all artificially smart systems. Exponential increase in unstructured data on the web has made automated acquisition of ontology from unstructured text a most prominent research area. Several methodologies exploiting numerous techniques of various fields (machine learning, text mining, knowledge representation and reasoning, information retrieval and natural language processing) are being proposed to bring some level of automation in the process of ontology acquisition from unstructured text. This paper describes the process of ontology learning and further classification of ontology learning techniques into three classes (linguistics, statistical and logical) and discusses many algorithms under each category. This paper also explores ontology evaluation techniques by highlighting their pros and cons. Moreover, it describes the scope and use of ontology learning in several industries. Finally, the paper discusses challenges of ontology learning along with their corresponding future directions.},
  annotation = {141 citations (Semantic Scholar/DOI) [2024-03-11]},
  file = {/Users/michaelvolk/Zotero/storage/X8RCIJSS/Asim et al_2018_A survey of ontology learning techniques and applications.pdf;/Users/michaelvolk/Zotero/storage/2TMINWQX/5116160.html}
}

@article{avsecEffectiveGeneExpression2021,
  title = {Effective Gene Expression Prediction from Sequence by Integrating Long-Range Interactions},
  author = {Avsec, Žiga and Agarwal, Vikram and Visentin, Daniel and Ledsam, Joseph R. and Grabska-Barwinska, Agnieszka and Taylor, Kyle R. and Assael, Yannis and Jumper, John and Kohli, Pushmeet and Kelley, David R.},
  date = {2021-10},
  journaltitle = {Nature Methods},
  shortjournal = {Nat Methods},
  volume = {18},
  number = {10},
  pages = {1196--1203},
  publisher = {Nature Publishing Group},
  issn = {1548-7105},
  doi = {10.1038/s41592-021-01252-x},
  url = {https://www.nature.com/articles/s41592-021-01252-x},
  urldate = {2022-06-21},
  abstract = {How noncoding DNA determines gene expression in different cell types is a major unsolved problem, and critical downstream applications in human genetics depend on improved solutions. Here, we report substantially improved gene expression prediction accuracy from DNA sequences through the use of a deep learning architecture, called Enformer, that is able to integrate information from long-range interactions (up to 100\,kb away) in the genome. This improvement yielded more accurate variant effect predictions on gene expression for both natural genetic variants and saturation mutagenesis measured by massively parallel reporter assays. Furthermore, Enformer learned to predict enhancer–promoter interactions directly from the DNA sequence competitively with methods that take direct experimental data as input. We expect that these advances will enable more effective fine-mapping of human disease associations and provide a framework to interpret cis-regulatory evolution.},
  issue = {10},
  langid = {english},
  keywords = {🦌📚,Gene expression,Machine learning,Software,Transcriptomics},
  file = {/Users/michaelvolk/Zotero/storage/3YDXQZLV/Avsec et al_2021_Effective gene expression prediction from sequence by integrating long-range.pdf;/Users/michaelvolk/Zotero/storage/Z432U2YK/s41592-021-01252-x (1).pdf;/Users/michaelvolk/Zotero/storage/39Z32XL8/s41592-021-01252-x.html}
}

@article{ayadiOntologyPopulationDeep2019,
  title = {Ontology Population with Deep Learning-Based {{NLP}}: A Case Study on the {{Biomolecular Network Ontology}}},
  shorttitle = {Ontology Population with Deep Learning-Based {{NLP}}},
  author = {Ayadi, Ali and Samet, Ahmed and family=Beuvron, given=François de Bertrand, prefix=de, useprefix=true and Zanni-Merk, Cecilia},
  date = {2019-01-01},
  journaltitle = {Procedia Computer Science},
  shortjournal = {Procedia Computer Science},
  series = {Knowledge-{{Based}} and {{Intelligent Information}} \& {{Engineering Systems}}: {{Proceedings}} of the 23rd {{International Conference KES2019}}},
  volume = {159},
  pages = {572--581},
  issn = {1877-0509},
  doi = {10.1016/j.procs.2019.09.212},
  url = {https://www.sciencedirect.com/science/article/pii/S1877050919313961},
  urldate = {2023-11-30},
  abstract = {As a scientific discipline, systems biology aims to build models of biological systems and processes through the computer analysis of a large amount of experimental data describing the behaviour of whole cells. It is within this context that we already developed the Biomolecular Network Ontology especially for the semantic understanding of the behaviour of complex biomolecular networks and their transittability. However, the challenge now is how to automatically populate it from a variety of biological documents. To this end, the target of this paper is to propose a new approach to automatically populate the Biomolecular Network Ontology and take advantage of the vast amount of biological knowledge expressed in heterogeneous unstructured data about complex biomolecular networks. Indeed, we have recently observed the emergence of deep learning techniques that provide significant and rapid progress in several domains, particularly in the process of deriving high-quality information from text. Despite its significant progress in recent years, deep learning is still not commonly used to populate ontologies. In this paper, we present a deep learning-based NLP ontology population system to populate the Biomolecular Network Ontology. Its originality is to jointly exploit deep learning and natural language processing techniques to identify, extract and classify new instances referring to the BNO ontology’s concepts from textual data. The preliminary results highlight the efficiency of our proposal for ontology population.},
  keywords = {Biomolecular Network Ontology,Deep learning,Knowledge acquisition,Natural language processing,Ontology population},
  annotation = {26 citations (Semantic Scholar/DOI) [2023-11-29]},
  file = {/Users/michaelvolk/Zotero/storage/6Q6L9SKB/Ayadi et al_2019_Ontology population with deep learning-based NLP.pdf;/Users/michaelvolk/Zotero/storage/ISDARHKF/S1877050919313961.html}
}

@article{babaConstructionEscherichiaColi2006,
  title = {Construction of {{Escherichia}} Coli {{K-12}} in-Frame, Single-Gene Knockout Mutants: The {{Keio}} Collection},
  shorttitle = {Construction of {{Escherichia}} Coli {{K-12}} in-Frame, Single-Gene Knockout Mutants},
  author = {Baba, Tomoya and Ara, Takeshi and Hasegawa, Miki and Takai, Yuki and Okumura, Yoshiko and Baba, Miki and Datsenko, Kirill A and Tomita, Masaru and Wanner, Barry L and Mori, Hirotada},
  date = {2006-01},
  journaltitle = {Molecular Systems Biology},
  volume = {2},
  number = {1},
  pages = {2006.0008},
  publisher = {John Wiley \& Sons, Ltd},
  issn = {1744-4292},
  doi = {10.1038/msb4100050},
  url = {https://www.embopress.org/doi/full/10.1038/msb4100050},
  urldate = {2023-11-30},
  abstract = {We have systematically made a set of precisely defined, single-gene deletions of all nonessential genes in Escherichia coli K-12. Open-reading frame coding regions were replaced with a kanamycin cassette flanked by FLP recognition target sites by using a one-step method for inactivation of chromosomal genes and primers designed to create in-frame deletions upon excision of the resistance cassette. Of 4288 genes targeted, mutants were obtained for 3985. To alleviate problems encountered in high-throughput studies, two independent mutants were saved for every deleted gene. These mutants?the ?Keio collection??provide a new resource not only for systematic analyses of unknown gene functions and gene regulatory networks but also for genome-wide testing of mutational effects in a common strain background, E. coli K-12 BW25113. We were unable to disrupt 303 genes, including 37 of unknown function, which are candidates for essential genes. Distribution is being handled via GenoBase (http://ecoli.aist-nara.ac.jp/).},
  annotation = {7161 citations (Semantic Scholar/DOI) [2023-11-29]},
  file = {/Users/michaelvolk/Zotero/storage/RHZJPFVG/Baba et al_2006_Construction of Escherichia coli K-12 in-frame, single-gene knockout mutants.pdf}
}

@online{baekAccurateLearningGraph2021a,
  title = {Accurate {{Learning}} of {{Graph Representations}} with {{Graph Multiset Pooling}}},
  author = {Baek, Jinheon and Kang, Minki and Hwang, Sung Ju},
  date = {2021-06-28},
  eprint = {2102.11533},
  eprinttype = {arXiv},
  eprintclass = {cs},
  url = {http://arxiv.org/abs/2102.11533},
  urldate = {2024-06-21},
  abstract = {Graph neural networks have been widely used on modeling graph data, achieving impressive results on node classification and link prediction tasks. Yet, obtaining an accurate representation for a graph further requires a pooling function that maps a set of node representations into a compact form. A simple sum or average over all node representations considers all node features equally without consideration of their task relevance, and any structural dependencies among them. Recently proposed hierarchical graph pooling methods, on the other hand, may yield the same representation for two different graphs that are distinguished by the Weisfeiler-Lehman test, as they suboptimally preserve information from the node features. To tackle these limitations of existing graph pooling methods, we first formulate the graph pooling problem as a multiset encoding problem with auxiliary information about the graph structure, and propose a Graph Multiset Transformer (GMT) which is a multi-head attention based global pooling layer that captures the interaction between nodes according to their structural dependencies. We show that GMT satisfies both injectiveness and permutation invariance, such that it is at most as powerful as the Weisfeiler-Lehman graph isomorphism test. Moreover, our methods can be easily extended to the previous node clustering approaches for hierarchical graph pooling. Our experimental results show that GMT significantly outperforms state-of-the-art graph pooling methods on graph classification benchmarks with high memory and time efficiency, and obtains even larger performance gain on graph reconstruction and generation tasks.},
  langid = {english},
  pubstate = {prepublished},
  keywords = {Computer Science - Machine Learning},
  annotation = {123 citations (Semantic Scholar/arXiv) [2024-06-20]},
  file = {/Users/michaelvolk/Zotero/storage/29HGI9HZ/Baek et al. - 2021 - Accurate Learning of Graph Representations with Gr.pdf}
}

@online{baiHypergraphConvolutionHypergraph2020,
  title = {Hypergraph {{Convolution}} and {{Hypergraph Attention}}},
  author = {Bai, Song and Zhang, Feihu and Torr, Philip H. S.},
  date = {2020-10-10},
  eprint = {1901.08150},
  eprinttype = {arXiv},
  eprintclass = {cs, stat},
  doi = {10.48550/arXiv.1901.08150},
  url = {http://arxiv.org/abs/1901.08150},
  urldate = {2023-04-04},
  abstract = {Recently, graph neural networks have attracted great attention and achieved prominent performance in various research fields. Most of those algorithms have assumed pairwise relationships of objects of interest. However, in many real applications, the relationships between objects are in higher-order, beyond a pairwise formulation. To efficiently learn deep embeddings on the high-order graph-structured data, we introduce two end-to-end trainable operators to the family of graph neural networks, i.e., hypergraph convolution and hypergraph attention. Whilst hypergraph convolution defines the basic formulation of performing convolution on a hypergraph, hypergraph attention further enhances the capacity of representation learning by leveraging an attention module. With the two operators, a graph neural network is readily extended to a more flexible model and applied to diverse applications where non-pairwise relationships are observed. Extensive experimental results with semi-supervised node classification demonstrate the effectiveness of hypergraph convolution and hypergraph attention.},
  pubstate = {prepublished},
  keywords = {Computer Science - Computer Vision and Pattern Recognition,Computer Science - Machine Learning,Statistics - Machine Learning},
  annotation = {214 citations (Semantic Scholar/arXiv) [2023-04-04]},
  file = {/Users/michaelvolk/Zotero/storage/W9HUNVXT/Bai et al_2020_Hypergraph Convolution and Hypergraph Attention.pdf;/Users/michaelvolk/Zotero/storage/BT5RQ3PX/1901.html}
}

@inproceedings{balestrieroBirthSelfSupervised2024,
  title = {The {{Birth}} of {{Self Supervised Learning}}: {{A Supervised Theory}}},
  shorttitle = {The {{Birth}} of {{Self Supervised Learning}}},
  author = {Balestriero, Randall and LeCun, Yann},
  date = {2024-12-02},
  url = {https://openreview.net/forum?id=NhYAjAAdQT&referrer=%5Bthe%20profile%20of%20Yann%20LeCun%5D(%2Fprofile%3Fid%3D~Yann_LeCun1)},
  urldate = {2025-04-24},
  abstract = {Self Supervised Learning (SSL) produces versatile representations from unlabeled datasets, while supervised learning produces overly specialized representations from labeled datasets. While this has been \{\textbackslash em empirically observed\} many times, it remains to be \{\textbackslash em theoretically explained\}. To that end, we bring forward a \{\textbackslash em supervised theory of SSL\}: we prove that (i) the training objective of supervised and self supervised learning are identical, but (ii) they use different labeling of the data. While supervised learning operates on \{\textbackslash em explicitly given\} task labels, SSL operates on \{\textbackslash em implicitly defined\} labels that maximize the worst-case downstream task performance. As such, the observed benefit of SSL for downstream task generalization stems from the labels being used as targets, rather than its loss function. In other words, both SSL and supervised learning can be made specialized or versatile solely by varying the training labels. Our proofs and findings only rely on minimal assumptions thus providing numerous practical insights. For example, we demonstrate how different constraints put on the supervised learning classifier head and label imbalance equate to different SSL objectives such as VICReg, opening new doors to actively modify them based on a priori knowledge on the data distribution.},
  eventtitle = {{{NeurIPS}} 2024 {{Workshop}}: {{Self-Supervised Learning}} - {{Theory}} and {{Practice}}},
  langid = {english},
  file = {/Users/michaelvolk/Zotero/storage/ICPB9HKR/Balestriero_LeCun_2024_The Birth of Self Supervised Learning.pdf}
}

@online{balestrieroCharacterizingLargeLanguage2024,
  title = {Characterizing {{Large Language Model Geometry Helps Solve Toxicity Detection}} and {{Generation}}},
  author = {Balestriero, Randall and Cosentino, Romain and Shekkizhar, Sarath},
  date = {2024-07-11},
  eprint = {2312.01648},
  eprinttype = {arXiv},
  eprintclass = {cs},
  doi = {10.48550/arXiv.2312.01648},
  url = {http://arxiv.org/abs/2312.01648},
  urldate = {2025-03-01},
  abstract = {Large Language Models (LLMs) drive current AI breakthroughs despite very little being known about their internal representations. In this work, we propose to shed the light on LLMs inner mechanisms through the lens of geometry. In particular, we develop in closed form \$(i)\$ the intrinsic dimension in which the Multi-Head Attention embeddings are constrained to exist and \$(ii)\$ the partition and per-region affine mappings of the feedforward (MLP) network of LLMs' layers. Our theoretical findings further enable the design of novel principled solutions applicable to state-of-the-art LLMs. First, we show that, through our geometric understanding, we can bypass LLMs' RLHF protection by controlling the embedding's intrinsic dimension through informed prompt manipulation. Second, we derive interpretable geometrical features that can be extracted from any (pre-trained) LLM, providing a rich abstract representation of their inputs. We observe that these features are sufficient to help solve toxicity detection, and even allow the identification of various types of toxicity. Our results demonstrate how, even in large-scale regimes, exact theoretical results can answer practical questions in LLMs. Code: https://github.com/RandallBalestriero/SplineLLM},
  pubstate = {prepublished},
  keywords = {Computer Science - Artificial Intelligence,Computer Science - Computation and Language,Computer Science - Machine Learning},
  annotation = {1 citations (Semantic Scholar/arXiv) [2025-03-01]\\
11 citations (Semantic Scholar/DOI) [2025-03-01]},
  file = {/Users/michaelvolk/Zotero/storage/Y8PGZBIV/Balestriero et al_2024_Characterizing Large Language Model Geometry Helps Solve Toxicity Detection and.pdf;/Users/michaelvolk/Zotero/storage/HGE3SYB7/2312.html}
}

@online{bambergerBundleNeuralNetworks2024,
  title = {Bundle {{Neural Networks}} for Message Diffusion on Graphs},
  author = {Bamberger, Jacob and Barbero, Federico and Dong, Xiaowen and Bronstein, Michael},
  date = {2024-05-24},
  eprint = {2405.15540},
  eprinttype = {arXiv},
  eprintclass = {cs},
  doi = {10.48550/arXiv.2405.15540},
  url = {http://arxiv.org/abs/2405.15540},
  urldate = {2025-02-27},
  abstract = {The dominant paradigm for learning on graph-structured data is message passing. Despite being a strong inductive bias, the local message passing mechanism suffers from pathological issues such as over-smoothing, over-squashing, and limited node-level expressivity. To address these limitations we propose Bundle Neural Networks (BuNN), a new type of GNN that operates via message diffusion over flat vector bundles - structures analogous to connections on Riemannian manifolds that augment the graph by assigning to each node a vector space and an orthogonal map. A BuNN layer evolves the features according to a diffusion-type partial differential equation. When discretized, BuNNs are a special case of Sheaf Neural Networks (SNNs), a recently proposed MPNN capable of mitigating over-smoothing. The continuous nature of message diffusion enables BuNNs to operate on larger scales of the graph and, therefore, to mitigate over-squashing. Finally, we prove that BuNN can approximate any feature transformation over nodes on any (potentially infinite) family of graphs given injective positional encodings, resulting in universal node-level expressivity. We support our theory via synthetic experiments and showcase the strong empirical performance of BuNNs over a range of real-world tasks, achieving state-of-the-art results on several standard benchmarks in transductive and inductive settings.},
  pubstate = {prepublished},
  keywords = {Computer Science - Machine Learning},
  annotation = {0 citations (Semantic Scholar/arXiv) [2025-02-27]\\
0 citations (Semantic Scholar/DOI) [2025-02-27]},
  file = {/Users/michaelvolk/Zotero/storage/2PH2CMBV/Bamberger et al_2024_Bundle Neural Networks for message diffusion on graphs.pdf;/Users/michaelvolk/Zotero/storage/VM4MCRPC/2405.html}
}

@inproceedings{banerjeeOversquashingGNNsLens2022,
  title = {Oversquashing in {{GNNs}} through the Lens of Information Contraction and Graph Expansion},
  booktitle = {2022 58th {{Annual Allerton Conference}} on {{Communication}}, {{Control}}, and {{Computing}} ({{Allerton}})},
  author = {Banerjee, Pradeep Kr. and Karhadkar, Kedar and Wang, Yu Guang and Alon, Uri and Montúfar, Guido},
  date = {2022-09},
  pages = {1--8},
  doi = {10.1109/Allerton49937.2022.9929363},
  url = {https://ieeexplore.ieee.org/abstract/document/9929363?casa_token=iG6FOIh2EsIAAAAA:wudceV_kNaQlHHEgeF0zPZ4_h2XcxcjOuDCNC-V1198g9axkYCbJk-EpDRVQvVVFh595fl9ByA},
  urldate = {2025-02-27},
  abstract = {The quality of signal propagation in message-passing graph neural networks (GNNs) strongly influences their expressivity as has been observed in recent works. In particular, for prediction tasks relying on long-range interactions, recursive aggregation of node features can lead to an undesired phenomenon called “oversquashing”. We present a framework for analyzing oversquashing based on information contraction. Our analysis is guided by a model of reliable computation due to von Neumann that lends a new insight into oversquashing as signal quenching in noisy computation graphs. Building on this, we propose a graph rewiring algorithm aimed at alleviating oversquashing. Our algorithm employs a random local edge flip primitive motivated by an expander graph construction. We compare the spectral expansion properties of our algorithm with that of an existing curvature-based non-local rewiring strategy. Synthetic experiments show that while our algorithm in general has a slower rate of expansion, it is overall computationally cheaper, preserves the node degrees exactly and never disconnects the graph.},
  eventtitle = {2022 58th {{Annual Allerton Conference}} on {{Communication}}, {{Control}}, and {{Computing}} ({{Allerton}})},
  keywords = {Analytical models,Benchmark testing,Buildings,Computational modeling,Graph theory,Noise measurement,Resistance},
  annotation = {43 citations (Semantic Scholar/DOI) [2025-02-27]},
  file = {/Users/michaelvolk/Zotero/storage/CEWBGMIC/Banerjee et al_2022_Oversquashing in GNNs through the lens of information contraction and graph.pdf}
}

@article{barberoTransformersNeedGlasses2025,
  title = {Transformers Need Glasses! Information over-Squashing in Language Tasks},
  author = {Barbero, Federico and Banino, Andrea and Kapturowski, Steven and Kumaran, Dharshan and Madeira Araújo, João and Vitvitskyi, Oleksandr and Pascanu, Razvan and Veličković, Petar},
  date = {2025},
  journaltitle = {Advances in Neural Information Processing Systems},
  volume = {37},
  pages = {98111--98142},
  url = {https://proceedings.neurips.cc/paper_files/paper/2024/hash/b1d35561c4a4a0e0b6012b2af531e149-Abstract-Conference.html},
  urldate = {2025-03-01},
  file = {/Users/michaelvolk/Zotero/storage/KMIR8XXW/Barbero et al_2025_Transformers need glasses.pdf}
}

@article{bardOntologiesBiologyDesign2004,
  title = {Ontologies in Biology: Design, Applications and Future Challenges},
  shorttitle = {Ontologies in Biology},
  author = {Bard, Jonathan B. L. and Rhee, Seung Y.},
  date = {2004-03},
  journaltitle = {Nature Reviews Genetics},
  shortjournal = {Nat Rev Genet},
  volume = {5},
  number = {3},
  pages = {213--222},
  publisher = {Nature Publishing Group},
  issn = {1471-0064},
  doi = {10.1038/nrg1295},
  url = {https://www.nature.com/articles/nrg1295},
  urldate = {2023-11-23},
  abstract = {Bio-ontologies provide a means of formalizing biological knowledge — for example, about genes, anatomy and phenotypes — in complex hierarchies that are composed of terms and rules.Most bio-ontologies are stored at http://obo.sourceforge.netand are accepted by the community as authoritative.All bio-ontologies assign a unique identifier (ID) for each term and these allow the archiving, storing and accessing of data in databases.Ontology IDs provide a means of querying between databases (a function known as 'interoperability').Complicated knowledge (such as that describing mutant phenotypes) can most easily be handled by composite annotations to multiple ontologies (anatomy, cell biology, pathology, traits, and so on).The review concludes by discussing some of the problems that the field is now facing.},
  issue = {3},
  langid = {english},
  keywords = {Agriculture,Animal Genetics and Genomics,Biomedicine,Cancer Research,Gene Function,general,Human Genetics},
  annotation = {349 citations (Semantic Scholar/DOI) [2023-11-23]},
  file = {/Users/michaelvolk/Zotero/storage/PCFMGNFH/Bard_Rhee_2004_Ontologies in biology.pdf}
}

@article{baryshnikovaQuantitativeAnalysisFitness2010,
  title = {Quantitative Analysis of Fitness and Genetic Interactions in Yeast on a Genome Scale},
  author = {Baryshnikova, Anastasia and Costanzo, Michael and Kim, Yungil and Ding, Huiming and Koh, Judice and Toufighi, Kiana and Youn, Ji-Young and Ou, Jiongwen and San Luis, Bryan-Joseph and Bandyopadhyay, Sunayan and Hibbs, Matthew and Hess, David and Gingras, Anne-Claude and Bader, Gary D and Troyanskaya, Olga G and Brown, Grant W and Andrews, Brenda and Boone, Charles and Myers, Chad L},
  date = {2010-12},
  journaltitle = {Nature Methods},
  shortjournal = {Nat Methods},
  volume = {7},
  number = {12},
  pages = {1017--1024},
  issn = {1548-7091, 1548-7105},
  doi = {10.1038/nmeth.1534},
  url = {http://www.nature.com/articles/nmeth.1534},
  urldate = {2022-02-08},
  langid = {english},
  keywords = {✅,🦌},
  annotation = {330 citations (Semantic Scholar/DOI) [2022-11-26]\\
265 citations (Crossref) [2022-04-15]},
  file = {/Users/michaelvolk/Zotero/storage/3678PIMB/Baryshnikova et al. - 2010 - Quantitative analysis of fitness and genetic inter.pdf;/Users/michaelvolk/Zotero/storage/AWUCVWQ9/SI - Baryshnikova et al. - 2010 - Quantitative analysis of fitness and genetic inter.pdf}
}

@article{bauerCausalityTranscriptionGenome2022,
  title = {Causality in Transcription and Genome Folding: {{Insights}} from {{X}} Inactivation},
  shorttitle = {Causality in Transcription and Genome Folding},
  author = {Bauer, Moritz and Payer, Bernhard and Filion, Guillaume J.},
  date = {2022},
  journaltitle = {BioEssays},
  volume = {44},
  number = {10},
  pages = {2200105},
  issn = {1521-1878},
  doi = {10.1002/bies.202200105},
  url = {https://onlinelibrary.wiley.com/doi/abs/10.1002/bies.202200105},
  urldate = {2024-07-04},
  abstract = {The spatial organization of genomes is becoming increasingly understood. In mammals, where it is most investigated, this organization ties in with transcription, so an important research objective is to understand whether gene activity is a cause or a consequence of genome folding in space. In this regard, the phenomena of X-chromosome inactivation and reactivation open a unique window of investigation because of the singularities of the inactive X chromosome. Here we focus on the cause–consequence nexus between genome conformation and transcription and explain how recent results about the structural changes associated with inactivation and reactivation of the X chromosome shed light on this problem.},
  langid = {english},
  keywords = {chromatin,genome organization,transcription,X-inactivation,X-reactivation},
  annotation = {2 citations (Semantic Scholar/DOI) [2024-07-04]},
  file = {/Users/michaelvolk/Zotero/storage/2ZA38N5P/Bauer et al. - 2022 - Causality in transcription and genome folding Ins.pdf;/Users/michaelvolk/Zotero/storage/IWL8PJZF/bies.html}
}

@article{baysoyTechnologicalLandscapeApplications2023a,
  title = {The Technological Landscape and Applications of Single-Cell Multi-Omics},
  author = {Baysoy, Alev and Bai, Zhiliang and Satija, Rahul and Fan, Rong},
  date = {2023-10},
  journaltitle = {Nature Reviews Molecular Cell Biology},
  shortjournal = {Nat Rev Mol Cell Biol},
  volume = {24},
  number = {10},
  pages = {695--713},
  publisher = {Nature Publishing Group},
  issn = {1471-0080},
  doi = {10.1038/s41580-023-00615-w},
  url = {https://www.nature.com/articles/s41580-023-00615-w},
  urldate = {2025-02-27},
  abstract = {Single-cell multi-omics technologies and methods characterize cell states and activities by simultaneously integrating various single-modality omics methods that profile the transcriptome, genome, epigenome, epitranscriptome, proteome, metabolome and other (emerging) omics. Collectively, these methods are revolutionizing molecular cell biology research. In this comprehensive Review, we discuss established multi-omics technologies as well as cutting-edge and state-of-the-art methods in the field. We discuss how multi-omics technologies have been adapted and improved over the past decade using a framework characterized by optimization of throughput and resolution, modality integration, uniqueness and accuracy, and we also discuss multi-omics limitations. We highlight the impact that single-cell multi-omics technologies have had in cell lineage tracing, tissue-specific and cell-specific atlas production, tumour immunology and cancer genetics, and in mapping of cellular spatial information in fundamental and translational research. Finally, we discuss bioinformatics tools that have been developed to link different omics modalities and elucidate functionality through the use of better mathematical modelling and computational methods.},
  langid = {english},
  keywords = {Next-generation sequencing,Protein–protein interaction networks,Transcriptomics},
  annotation = {316 citations (Semantic Scholar/DOI) [2025-02-27]},
  file = {/Users/michaelvolk/Zotero/storage/7Q5DJVX9/Baysoy et al_2023_The technological landscape and applications of single-cell multi-omics.pdf}
}

@article{benesBooleanNetworkSketches2023,
  title = {Boolean Network Sketches: A Unifying Framework for Logical Model Inference},
  shorttitle = {Boolean Network Sketches},
  author = {Beneš, Nikola and Brim, Luboš and Huvar, Ondřej and Pastva, Samuel and Šafránek, David},
  date = {2023-04-01},
  journaltitle = {Bioinformatics},
  shortjournal = {Bioinformatics},
  volume = {39},
  number = {4},
  pages = {btad158},
  issn = {1367-4811},
  doi = {10.1093/bioinformatics/btad158},
  url = {https://doi.org/10.1093/bioinformatics/btad158},
  urldate = {2023-05-12},
  abstract = {The problem of model inference is of fundamental importance to systems biology. Logical models (e.g. Boolean networks; BNs) represent a computationally attractive approach capable of handling large biological networks. The models are typically inferred from experimental data. However, even with a substantial amount of experimental data supported by some prior knowledge, existing inference methods often focus on a small sample of admissible candidate models only.We propose Boolean network sketches as a new formal instrument for the inference of Boolean networks. A sketch integrates (typically partial) knowledge about the network’s topology and the update logic (obtained through, e.g. a biological knowledge base or a literature search), as well as further assumptions about the properties of the network’s transitions (e.g. the form of its attractor landscape), and additional restrictions on the model dynamics given by the measured experimental data. Our new BNs inference algorithm starts with an ‘initial’ sketch, which is extended by adding restrictions representing experimental data to a ‘data-informed’ sketch and subsequently computes all BNs consistent with the data-informed sketch. Our algorithm is based on a symbolic representation and coloured model-checking. Our approach is unique in its ability to cover a broad spectrum of knowledge and efficiently produce a compact representation of all inferred BNs. We evaluate the method on a non-trivial collection of real-world and simulated data.All software and data are freely available as a reproducible artefact at https://doi.org/10.5281/zenodo.7688740.},
  annotation = {0 citations (Semantic Scholar/DOI) [2023-05-11]},
  file = {/Users/michaelvolk/Zotero/storage/5URPJUEI/Beneš et al. - 2023 - Boolean network sketches a unifying framework for.pdf;/Users/michaelvolk/Zotero/storage/2XA28NQ8/7099622.html}
}

@article{berahmandSpectralClusteringProteinprotein2021,
  title = {Spectral Clustering on Protein-Protein Interaction Networks via Constructing Affinity Matrix Using Attributed Graph Embedding},
  author = {Berahmand, Kamal and Nasiri, Elahe and Pir mohammadiani, Rojiar and Li, Yuefeng},
  date = {2021-11-01},
  journaltitle = {Computers in Biology and Medicine},
  shortjournal = {Computers in Biology and Medicine},
  volume = {138},
  pages = {104933},
  issn = {0010-4825},
  doi = {10.1016/j.compbiomed.2021.104933},
  url = {https://www.sciencedirect.com/science/article/pii/S0010482521007277},
  urldate = {2023-10-17},
  abstract = {The identification of protein complexes in protein-protein interaction networks is the most fundamental and essential problem for revealing the underlying mechanism of biological processes. However, most existing protein complexes identification methods only consider a network's topology structures, and in doing so, these methods miss the advantage of using nodes' feature information. In protein-protein interaction, both topological structure and node features are essential ingredients for protein complexes. The spectral clustering method utilizes the eigenvalues of the affinity matrix of the data to map to a low-dimensional space. It has attracted much attention in recent years as one of the most efficient algorithms in the subcategory of dimensionality reduction. In this paper, a new version of spectral clustering, named text-associated DeepWalk-Spectral Clustering (TADW-SC), is proposed for attributed networks in which the identified protein complexes have structural cohesiveness and attribute homogeneity. Since the performance of spectral clustering heavily depends on the effectiveness of the affinity matrix, our proposed method will use the text-associated DeepWalk (TADW) to calculate the embedding vectors of proteins. In the following, the affinity matrix will be computed by utilizing the cosine similarity between the two low dimensional vectors, which will be considerable to improve the accuracy of the affinity matrix. Experimental results show that our method performs unexpectedly well in comparison to existing state-of-the-art methods in both real protein network datasets and synthetic networks.},
  keywords = {Affinity matrix,Graph embedding,Protein complexes identification,Protein-protein interaction network,Spectral clustering},
  annotation = {66 citations (Semantic Scholar/DOI) [2023-10-16]},
  file = {/Users/michaelvolk/Zotero/storage/VGEAUZJ4/S0010482521007277.html}
}

@article{berahmandSpectralClusteringProteinprotein2021a,
  title = {Spectral Clustering on Protein-Protein Interaction Networks via Constructing Affinity Matrix Using Attributed Graph Embedding},
  author = {Berahmand, Kamal and Nasiri, Elahe and Pir Mohammadiani, Rojiar and Li, Yuefeng},
  date = {2021-11},
  journaltitle = {Computers in Biology and Medicine},
  shortjournal = {Computers in Biology and Medicine},
  volume = {138},
  pages = {104933},
  issn = {00104825},
  doi = {10.1016/j.compbiomed.2021.104933},
  url = {https://linkinghub.elsevier.com/retrieve/pii/S0010482521007277},
  urldate = {2023-10-17},
  abstract = {The identification of protein complexes in protein-protein interaction networks is the most fundamental and essential problem for revealing the underlying mechanism of biological processes. However, most existing protein complexes identification methods only consider a network’s topology structures, and in doing so, these methods miss the advantage of using nodes’ feature information. In protein-protein interaction, both topological structure and node features are essential ingredients for protein complexes. The spectral clustering method utilizes the eigenvalues of the affinity matrix of the data to map to a low-dimensional space. It has attracted much attention in recent years as one of the most efficient algorithms in the subcategory of dimensionality reduction. In this paper, a new version of spectral clustering, named text-associated DeepWalk-Spectral Clustering (TADWSC), is proposed for attributed networks in which the identified protein complexes have structural cohesiveness and attribute homogeneity. Since the performance of spectral clustering heavily depends on the effectiveness of the affinity matrix, our proposed method will use the text-associated DeepWalk (TADW) to calculate the embedding vectors of proteins. In the following, the affinity matrix will be computed by utilizing the cosine similarity between the two low dimensional vectors, which will be considerable to improve the accuracy of the affinity matrix. Experimental results show that our method performs unexpectedly well in comparison to existing state-of-the-art methods in both real protein network datasets and synthetic networks.},
  langid = {english},
  annotation = {66 citations (Semantic Scholar/DOI) [2023-10-16]},
  file = {/Users/michaelvolk/Zotero/storage/GFIIII8N/Berahmand et al. - 2021 - Spectral clustering on protein-protein interaction.pdf}
}

@incollection{bernalChapterSimilarityChemical2015,
  title = {Chapter 2 - {{Similarity}} in {{Chemical Reaction Networks}}: {{Categories}}, {{Concepts}} and {{Closures}}},
  shorttitle = {Chapter 2 - {{Similarity}} in {{Chemical Reaction Networks}}},
  booktitle = {Advances in {{Mathematical Chemistry}} and {{Applications}}},
  author = {Bernal, Andrés and Llanos, Eugenio and Leal, Wilmer and Restrepo, Guillermo},
  editor = {Basak, Subhash C. and Restrepo, Guillermo and Villaveces, José L.},
  date = {2015-01-01},
  pages = {24--54},
  publisher = {Bentham Science Publishers},
  doi = {10.1016/B978-1-68108-053-6.50002-8},
  url = {https://www.sciencedirect.com/science/article/pii/B9781681080536500028},
  urldate = {2024-07-07},
  abstract = {Similarity studies are important for chemistry and their applications range from the periodic table to the screening of large databases in the searching for new drugs. In this later case, it is assumed that similarity in molecular structure is related to similarity in reactivity. However, we state that structural formulas can be regarded as abstract representations emerging from the analysis of large amounts of data upon chemical reactivity. Hence, chemical formulas such as organic functions are not direct pictures of the atomic constitution of matter, but signs used to represent similarity in the reactivity of a class of substances. Therefore, reactivity, rather than molecular structure, becomes the fundamental feature of chemical substances. As reactivity is important, chemical identity is given by the relations substances establish with each other, giving place to a network of chemical reactions. We explore similarity in the network rather than in molecular structure. By characterising each substance in terms of the related ones, we show how Category Theory helps in this description. Afterwards, we study the similarity among substances using topological spaces, which leads us to concepts such as closure and neighbourhood, which formalise the intuition of things lying somewhere near around. The second focus of the chapter is the exploration of the potential of closure operators, and of topological closures in particular, as more general descriptors of chemical similarity. As we introduce the formalism, we develop a worked example, concerning the analysis of similarity among chemical elements regarding their ability to combine into binary compounds. The results show that several of the trends of chemical elements are found through the current approach.},
  isbn = {978-1-68108-053-6},
  keywords = {Binary compounds,category theory,chemical classification,chemical networks,closure,closure operators,directed hypergraphs,formal concept analysis,graph theory,network theory,order theory,periodic table,reaction networks,similarity,topology},
  file = {/Users/michaelvolk/Zotero/storage/LSYJUSLB/Bernal et al_2015_Chapter 2 - Similarity in Chemical Reaction Networks.pdf}
}

@online{bianchiExpressivePowerPooling2023,
  title = {The Expressive Power of Pooling in {{Graph Neural Networks}}},
  author = {Bianchi, Filippo Maria and Lachi, Veronica},
  date = {2023-10-12},
  eprint = {2304.01575},
  eprinttype = {arXiv},
  eprintclass = {cs},
  doi = {10.48550/arXiv.2304.01575},
  url = {http://arxiv.org/abs/2304.01575},
  urldate = {2024-09-04},
  abstract = {In Graph Neural Networks (GNNs), hierarchical pooling operators generate local summaries of the data by coarsening the graph structure and the vertex features. While considerable attention has been devoted to analyzing the expressive power of message-passing (MP) layers in GNNs, a study on how graph pooling affects the expressiveness of a GNN is still lacking. Additionally, despite the recent advances in the design of pooling operators, there is not a principled criterion to compare them. In this work, we derive sufficient conditions for a pooling operator to fully preserve the expressive power of the MP layers before it. These conditions serve as a universal and theoretically grounded criterion for choosing among existing pooling operators or designing new ones. Based on our theoretical findings, we analyze several existing pooling operators and identify those that fail to satisfy the expressiveness conditions. Finally, we introduce an experimental setup to verify empirically the expressive power of a GNN equipped with pooling layers, in terms of its capability to perform a graph isomorphism test.},
  pubstate = {prepublished},
  keywords = {Computer Science - Machine Learning},
  annotation = {18 citations (Semantic Scholar/arXiv) [2024-09-04]\\
18 citations (Semantic Scholar/DOI) [2024-09-04]},
  file = {/Users/michaelvolk/Zotero/storage/JFSG2ZEM/Bianchi_Lachi_2023_The expressive power of pooling in Graph Neural Networks.pdf;/Users/michaelvolk/Zotero/storage/24A5DT4M/2304.html}
}

@online{bianchiExpressivePowerPooling2023a,
  title = {The Expressive Power of Pooling in {{Graph Neural Networks}}},
  author = {Bianchi, Filippo Maria and Lachi, Veronica},
  date = {2023-10-12},
  eprint = {2304.01575},
  eprinttype = {arXiv},
  eprintclass = {cs},
  doi = {10.48550/arXiv.2304.01575},
  url = {http://arxiv.org/abs/2304.01575},
  urldate = {2025-02-27},
  abstract = {In Graph Neural Networks (GNNs), hierarchical pooling operators generate local summaries of the data by coarsening the graph structure and the vertex features. While considerable attention has been devoted to analyzing the expressive power of message-passing (MP) layers in GNNs, a study on how graph pooling affects the expressiveness of a GNN is still lacking. Additionally, despite the recent advances in the design of pooling operators, there is not a principled criterion to compare them. In this work, we derive sufficient conditions for a pooling operator to fully preserve the expressive power of the MP layers before it. These conditions serve as a universal and theoretically grounded criterion for choosing among existing pooling operators or designing new ones. Based on our theoretical findings, we analyze several existing pooling operators and identify those that fail to satisfy the expressiveness conditions. Finally, we introduce an experimental setup to verify empirically the expressive power of a GNN equipped with pooling layers, in terms of its capability to perform a graph isomorphism test.},
  pubstate = {prepublished},
  keywords = {Computer Science - Machine Learning},
  annotation = {23 citations (Semantic Scholar/arXiv) [2025-02-27]\\
23 citations (Semantic Scholar/DOI) [2025-02-27]},
  file = {/Users/michaelvolk/Zotero/storage/CC6ZJXTX/Bianchi_Lachi_2023_The expressive power of pooling in Graph Neural Networks.pdf;/Users/michaelvolk/Zotero/storage/LQ7VLP4G/2304.html}
}

@inproceedings{bianchiSpectralClusteringGraph2020a,
  title = {Spectral {{Clustering}} with {{Graph Neural Networks}} for {{Graph Pooling}}},
  booktitle = {Proceedings of the 37th {{International Conference}} on {{Machine Learning}}},
  author = {Bianchi, Filippo Maria and Grattarola, Daniele and Alippi, Cesare},
  date = {2020-11-21},
  pages = {874--883},
  publisher = {PMLR},
  issn = {2640-3498},
  url = {https://proceedings.mlr.press/v119/bianchi20a.html},
  urldate = {2024-03-11},
  abstract = {Spectral clustering (SC) is a popular clustering technique to find strongly connected communities on a graph. SC can be used in Graph Neural Networks (GNNs) to implement pooling operations that aggregate nodes belonging to the same cluster. However, the eigendecomposition of the Laplacian is expensive and, since clustering results are graph-specific, pooling methods based on SC must perform a new optimization for each new sample. In this paper, we propose a graph clustering approach that addresses these limitations of SC. We formulate a continuous relaxation of the normalized minCUT problem and train a GNN to compute cluster assignments that minimize this objective. Our GNN-based implementation is differentiable, does not require to compute the spectral decomposition, and learns a clustering function that can be quickly evaluated on out-of-sample graphs. From the proposed clustering method, we design a graph pooling operator that overcomes some important limitations of state-of-the-art graph pooling techniques and achieves the best performance in several supervised and unsupervised tasks.},
  eventtitle = {International {{Conference}} on {{Machine Learning}}},
  langid = {english},
  file = {/Users/michaelvolk/Zotero/storage/DDYWTKSV/Bianchi et al. - 2020 - Spectral Clustering with Graph Neural Networks for.pdf;/Users/michaelvolk/Zotero/storage/TIYDH4Y2/Bianchi et al_2020_Spectral Clustering with Graph Neural Networks for Graph Pooling.pdf}
}

@article{biConstructionMultiscaleGenomeScale2022,
  title = {Construction of {{Multiscale Genome-Scale Metabolic Models}}: {{Frameworks}} and {{Challenges}}},
  shorttitle = {Construction of {{Multiscale Genome-Scale Metabolic Models}}},
  author = {Bi, Xinyu and Liu, Yanfeng and Li, Jianghua and Du, Guocheng and Lv, Xueqin and Liu, Long},
  date = {2022-05},
  journaltitle = {Biomolecules},
  volume = {12},
  number = {5},
  pages = {721},
  publisher = {Multidisciplinary Digital Publishing Institute},
  issn = {2218-273X},
  doi = {10.3390/biom12050721},
  url = {https://www.mdpi.com/2218-273X/12/5/721},
  urldate = {2023-07-25},
  abstract = {Genome-scale metabolic models (GEMs) are effective tools for metabolic engineering and have been widely used to guide cell metabolic regulation. However, the single gene–protein-reaction data type in GEMs limits the understanding of biological complexity. As a result, multiscale models that add constraints or integrate omics data based on GEMs have been developed to more accurately predict phenotype from genotype. This review summarized the recent advances in the development of multiscale GEMs, including multiconstraint, multiomic, and whole-cell models, and outlined machine learning applications in GEM construction. This review focused on the frameworks, toolkits, and algorithms for constructing multiscale GEMs. The challenges and perspectives of multiscale GEM development are also discussed.},
  issue = {5},
  langid = {english},
  keywords = {machine learning,multiconstraint models,multiomics models,multiscale genome-scale metabolic models,whole-cell models},
  annotation = {3 citations (Semantic Scholar/DOI) [2023-07-25]},
  file = {/Users/michaelvolk/Zotero/storage/GZ7EBFVG/Bi et al_2022_Construction of Multiscale Genome-Scale Metabolic Models.pdf}
}

@article{boemEpistemicMisalignmentsMicrobiome2024,
  title = {Epistemic Misalignments in Microbiome Research},
  author = {Boem, Federico and Suárez, Javier},
  date = {2024},
  journaltitle = {BioEssays},
  volume = {46},
  number = {4},
  pages = {2300220},
  issn = {1521-1878},
  doi = {10.1002/bies.202300220},
  url = {https://onlinelibrary.wiley.com/doi/abs/10.1002/bies.202300220},
  urldate = {2024-07-04},
  abstract = {We argue that microbiome research should be more reflective on the methods that it relies on to build its datasets due to the danger of facing a methodological problem which we call “epistemic misalignment.” An epistemic misalignment occurs when the method used to answer specific scientific questions does not track justified answers, due to the material constraints imposed by the very method. For example, relying on 16S rRNA to answer questions about the function of the microbiome generates epistemic misalignments, due to the different temporal scales that 16S rRNA provides information about and the temporal scales that are required to know about the functionality of some microorganisms. We show how some of these exist in contemporary microbiome science and urge microbiome scientists to take some measures to avoid them, as they may question the credibility of the field as a whole.},
  langid = {english},
  keywords = {microbiome,misalignment,scientific methodology},
  annotation = {0 citations (Semantic Scholar/DOI) [2024-07-04]},
  file = {/Users/michaelvolk/Zotero/storage/JXLUPQUY/Boem and Suárez - 2024 - Epistemic misalignments in microbiome research.pdf;/Users/michaelvolk/Zotero/storage/2X9B6GJB/bies.html}
}

@online{bordeScalableMessagePassing2024,
  title = {Scalable {{Message Passing Neural Networks}}: {{No Need}} for {{Attention}} in {{Large Graph Representation Learning}}},
  shorttitle = {Scalable {{Message Passing Neural Networks}}},
  author = {Borde, Haitz Sáez de Ocáriz and Lukoianov, Artem and Kratsios, Anastasis and Bronstein, Michael and Dong, Xiaowen},
  date = {2024-10-29},
  eprint = {2411.00835},
  eprinttype = {arXiv},
  eprintclass = {cs},
  doi = {10.48550/arXiv.2411.00835},
  url = {http://arxiv.org/abs/2411.00835},
  urldate = {2025-02-27},
  abstract = {We propose Scalable Message Passing Neural Networks (SMPNNs) and demonstrate that, by integrating standard convolutional message passing into a Pre-Layer Normalization Transformer-style block instead of attention, we can produce high-performing deep message-passing-based Graph Neural Networks (GNNs). This modification yields results competitive with the state-of-the-art in large graph transductive learning, particularly outperforming the best Graph Transformers in the literature, without requiring the otherwise computationally and memory-expensive attention mechanism. Our architecture not only scales to large graphs but also makes it possible to construct deep message-passing networks, unlike simple GNNs, which have traditionally been constrained to shallow architectures due to oversmoothing. Moreover, we provide a new theoretical analysis of oversmoothing based on universal approximation which we use to motivate SMPNNs. We show that in the context of graph convolutions, residual connections are necessary for maintaining the universal approximation properties of downstream learners and that removing them can lead to a loss of universality.},
  pubstate = {prepublished},
  keywords = {Computer Science - Machine Learning},
  annotation = {0 citations (Semantic Scholar/arXiv) [2025-02-27]\\
0 citations (Semantic Scholar/DOI) [2025-02-27]},
  file = {/Users/michaelvolk/Zotero/storage/STCXCR39/Borde et al_2024_Scalable Message Passing Neural Networks.pdf;/Users/michaelvolk/Zotero/storage/53Z3ED9U/2411.html}
}

@article{bordeScalableMessagePassing2024a,
  title = {Scalable {{Message Passing Neural Networks}}: {{No Need}} for {{Attention}} in {{Large Graph Representation Learning}}},
  shorttitle = {Scalable {{Message Passing Neural Networks}}},
  author = {Borde, Haitz Sáez de Ocáriz and Lukoianov, Artem and Kratsios, Anastasis and Bronstein, Michael M. and Dong, Xiaowen},
  date = {2024-10-04},
  url = {https://openreview.net/forum?id=TCgcEQjaUQ},
  urldate = {2025-02-27},
  abstract = {We propose Scalable Message Passing Neural Networks (SMPNNs) and demonstrate that, by integrating standard convolutional message passing into a Pre-Layer Normalization Transformer-style block instead of attention, we can produce high-performing deep message-passing-based Graph Neural Networks (GNNs). This modification yields state-of-the-art results in large graph transductive learning, outperforming the best Graph Transformers in the literature without requiring the otherwise computationally and memory-expensive attention. Our architecture not only scales to large graphs but also makes it possible to construct deep message-passing networks, unlike simple GNNs, which have traditionally been constrained to shallow architectures due to oversmoothing. Moreover, we provide a new theoretical analysis of oversmoothing based on universal approximation which we use to motivate SMPNNs.},
  langid = {english},
  file = {/Users/michaelvolk/Zotero/storage/EJMCYQJF/Borde et al_2024_Scalable Message Passing Neural Networks.pdf}
}

@article{bouyssetProLIFLibraryEncode2021,
  title = {{{ProLIF}}: A Library to Encode Molecular Interactions as Fingerprints},
  shorttitle = {{{ProLIF}}},
  author = {Bouysset, Cédric and Fiorucci, Sébastien},
  date = {2021-09-25},
  journaltitle = {Journal of Cheminformatics},
  shortjournal = {Journal of Cheminformatics},
  volume = {13},
  number = {1},
  pages = {72},
  issn = {1758-2946},
  doi = {10.1186/s13321-021-00548-6},
  url = {https://doi.org/10.1186/s13321-021-00548-6},
  urldate = {2024-05-04},
  abstract = {Interaction fingerprints are vector representations that summarize the three-dimensional nature of interactions in molecular complexes, typically formed between a protein and a ligand. This kind of encoding has found many applications in drug-discovery projects, from structure-based virtual-screening to machine-learning. Here, we present ProLIF, a Python library designed to generate interaction fingerprints for molecular complexes extracted from molecular dynamics trajectories, experimental structures, and docking simulations. It can handle complexes formed of any combination of ligand, protein, DNA, or RNA molecules. The available interaction types can be fully reparametrized or extended by user-defined ones. Several tutorials that cover typical use-case scenarios are available, and the documentation is accompanied with code snippets showcasing the integration with other data-analysis libraries for a more seamless user-experience. The library can be freely installed from our GitHub repository (https://github.com/chemosim-lab/ProLIF).},
  keywords = {Docking,Interaction fingerprint,Molecular dynamics,Python,Structural biology,Virtual screening},
  annotation = {99 citations (Semantic Scholar/DOI) [2024-05-03]},
  file = {/Users/michaelvolk/Zotero/storage/ILS2R937/Bouysset_Fiorucci_2021_ProLIF.pdf;/Users/michaelvolk/Zotero/storage/IT9PLS7I/s13321-021-00548-6.html}
}

@article{breslowComprehensiveStrategyEnabling2008a,
  title = {A Comprehensive Strategy Enabling High-Resolution Functional Analysis of the Yeast Genome},
  author = {Breslow, David K. and Cameron, Dale M. and Collins, Sean R. and Schuldiner, Maya and Stewart-Ornstein, Jacob and Newman, Heather W. and Braun, Sigurd and Madhani, Hiten D. and Krogan, Nevan J. and Weissman, Jonathan S.},
  date = {2008-08},
  journaltitle = {Nature Methods},
  shortjournal = {Nat Methods},
  volume = {5},
  number = {8},
  pages = {711--718},
  publisher = {Nature Publishing Group},
  issn = {1548-7105},
  doi = {10.1038/nmeth.1234},
  url = {https://www.nature.com/articles/nmeth.1234},
  urldate = {2023-12-06},
  abstract = {To increase the range and precision of genetic interaction studies in Saccharomyces cerevisiae, a collection of hypomorphic alleles of essential yeast genes and a highly sensitive flow cytometry–based growth competition assay are presented. Also in this issue, Yan et al. present a similar strain collection, tagged with unique bar-code identifiers, and use this collection in pooled chemical genetic screens.},
  issue = {8},
  langid = {english},
  keywords = {Bioinformatics,Biological Microscopy,Biological Techniques,Biomedical Engineering/Biotechnology,general,Life Sciences,Proteomics},
  annotation = {506 citations (Semantic Scholar/DOI) [2023-12-05]},
  file = {/Users/michaelvolk/Zotero/storage/GBTET3T6/Breslow et al_2008_A comprehensive strategy enabling high-resolution functional analysis of the.pdf}
}

@article{bruggemanTradeoffsInstantaneousGrowth2023,
  title = {Trade-Offs between the Instantaneous Growth Rate and Long-Term Fitness: {{Consequences}} for Microbial Physiology and Predictive Computational Models},
  shorttitle = {Trade-Offs between the Instantaneous Growth Rate and Long-Term Fitness},
  author = {Bruggeman, Frank J. and Teusink, Bas and Steuer, Ralf},
  date = {2023},
  journaltitle = {BioEssays},
  volume = {45},
  number = {10},
  pages = {2300015},
  issn = {1521-1878},
  doi = {10.1002/bies.202300015},
  url = {https://onlinelibrary.wiley.com/doi/abs/10.1002/bies.202300015},
  urldate = {2024-06-21},
  abstract = {Microbial systems biology has made enormous advances in relating microbial physiology to the underlying biochemistry and molecular biology. By meticulously studying model microorganisms, in particular Escherichia coli and Saccharomyces cerevisiae, increasingly comprehensive computational models predict metabolic fluxes, protein expression, and growth. The modeling rationale is that cells are constrained by a limited pool of resources that they allocate optimally to maximize fitness. As a consequence, the expression of particular proteins is at the expense of others, causing trade-offs between cellular objectives such as instantaneous growth, stress tolerance, and capacity to adapt to new environments. While current computational models are remarkably predictive for E. coli and S. cerevisiae when grown in laboratory environments, this may not hold for other growth conditions and other microorganisms. In this contribution, we therefore discuss the relationship between the instantaneous growth rate, limited resources, and long-term fitness. We discuss uses and limitations of current computational models, in particular for rapidly changing and adverse environments, and propose to classify microbial growth strategies based on Grimes's CSR framework.},
  langid = {english},
  keywords = {E. coli,evolution,flux balance analysis,metabolism,microbial growth strategies,microbial physiology,microbial systems biology,resource allocation,S. cerevisiae},
  annotation = {7 citations (Semantic Scholar/DOI) [2024-06-21]},
  file = {/Users/michaelvolk/Zotero/storage/6ALRZFKS/Bruggeman et al_2023_Trade-offs between the instantaneous growth rate and long-term fitness.pdf;/Users/michaelvolk/Zotero/storage/48NDLYIM/bies.html}
}

@article{brun-usanGenotypephenotypeMapsPhenotypecentered2022,
  title = {Beyond Genotype-Phenotype Maps: {{Toward}} a Phenotype-Centered Perspective on Evolution},
  shorttitle = {Beyond Genotype-Phenotype Maps},
  author = {Brun-Usan, Miguel and Zimm, Roland and Uller, Tobias},
  date = {2022},
  journaltitle = {BioEssays},
  volume = {44},
  number = {9},
  pages = {2100225},
  issn = {1521-1878},
  doi = {10.1002/bies.202100225},
  url = {https://onlinelibrary.wiley.com/doi/abs/10.1002/bies.202100225},
  urldate = {2024-06-22},
  abstract = {Evolutionary biology is paying increasing attention to the mechanisms that enable phenotypic plasticity, evolvability, and extra-genetic inheritance. Yet, there is a concern that these phenomena remain insufficiently integrated within evolutionary theory. Understanding their evolutionary implications would require focusing on phenotypes and their variation, but this does not always fit well with the prevalent genetic representation of evolution that screens off developmental mechanisms. Here, we instead use development as a starting point, and represent it in a way that allows genetic, environmental and epigenetic sources of phenotypic variation to be independent. We show why this representation helps to understand the evolutionary consequences of both genetic and non-genetic phenotype determinants, and discuss how this approach can instigate future areas of empirical and theoretical research.},
  langid = {english},
  keywords = {conceptual framework,development,evolutionary theory,evolvability,genotype-phenotype map,maternal effects,phenotypic plasticity},
  annotation = {11 citations (Semantic Scholar/DOI) [2024-06-21]},
  file = {/Users/michaelvolk/Zotero/storage/MHTBIRU9/Brun-Usan et al_2022_Beyond genotype-phenotype maps.pdf;/Users/michaelvolk/Zotero/storage/UU4B5L4G/bies.html}
}

@article{brun-usanGenotypephenotypeMapsPhenotypecentered2022,
  title = {Beyond Genotype-Phenotype Maps: {{Toward}} a Phenotype-Centered Perspective on Evolution},
  shorttitle = {Beyond Genotype-Phenotype Maps},
  author = {Brun-Usan, Miguel and Zimm, Roland and Uller, Tobias},
  date = {2022},
  journaltitle = {BioEssays},
  volume = {44},
  number = {9},
  pages = {2100225},
  issn = {1521-1878},
  doi = {10.1002/bies.202100225},
  url = {https://onlinelibrary.wiley.com/doi/abs/10.1002/bies.202100225},
  urldate = {2024-07-04},
  abstract = {Evolutionary biology is paying increasing attention to the mechanisms that enable phenotypic plasticity, evolvability, and extra-genetic inheritance. Yet, there is a concern that these phenomena remain insufficiently integrated within evolutionary theory. Understanding their evolutionary implications would require focusing on phenotypes and their variation, but this does not always fit well with the prevalent genetic representation of evolution that screens off developmental mechanisms. Here, we instead use development as a starting point, and represent it in a way that allows genetic, environmental and epigenetic sources of phenotypic variation to be independent. We show why this representation helps to understand the evolutionary consequences of both genetic and non-genetic phenotype determinants, and discuss how this approach can instigate future areas of empirical and theoretical research.},
  langid = {english},
  keywords = {conceptual framework,development,evolutionary theory,evolvability,genotype-phenotype map,maternal effects,phenotypic plasticity},
  annotation = {11 citations (Semantic Scholar/DOI) [2024-07-04]},
  file = {/Users/michaelvolk/Zotero/storage/I3MLJ56V/Brun-Usan et al. - 2022 - Beyond genotype-phenotype maps Toward a phenotype.pdf;/Users/michaelvolk/Zotero/storage/UI2SXYFC/bies.html}
}

@online{buricAminoAcidSequence2023,
  title = {The Amino Acid Sequence Determines Protein Abundance through Its Conformational Stability and Reduced Synthesis Cost},
  author = {Buric, Filip and Viknander, Sandra and Fu, Xiaozhi and Lemke, Oliver and Zrimec, Jan and Szyrwiel, Lukasz and Mueleder, Michael and Ralser, Markus and Zelezniak, Aleksej},
  date = {2023-10-04},
  eprinttype = {bioRxiv},
  eprintclass = {New Results},
  pages = {2023.10.02.560091},
  doi = {10.1101/2023.10.02.560091},
  url = {https://www.biorxiv.org/content/10.1101/2023.10.02.560091v1},
  urldate = {2023-10-09},
  abstract = {Understanding what drives protein abundance is essential to biology, medicine, and biotechnology. Driven by evolutionary selection, the amino acid sequence is tailored to meet the required abundance of proteomes, underscoring the intricate relationship between sequence and functional demand. Yet, the specific role of amino acid sequences in determining proteome abundance remains elusive. Here, we demonstrate that the amino acid sequence predicts abundance by shaping a protein’s conformational stability. We show that increasing the abundance provides metabolic cost benefits, underscoring the evolutionary advantage of maintaining a highly abundant and stable proteome. Specifically, using a deep learning model (BERT), we predict 56\% of protein abundance variation in Saccharomyces cerevisiae solely based on amino acid sequence. The model reveals latent factors linking sequence features to protein stability. To probe these relationships, we introduce MGEM (Mutation Guided by an Embedded Manifold), a methodology for guiding protein abundance through sequence modifications. We find that mutations increasing abundance significantly alter protein polarity and hydrophobicity, underscoring a connection between protein stability and abundance. Through molecular dynamics simulations and in vivo experiments in yeast, we confirm that abundance-enhancing mutations result in longer-lasting and more stable protein expression. Importantly, these sequence changes also reduce metabolic costs of protein synthesis, elucidating the evolutionary advantage of cost-effective, high-abundance, stable proteomes. Our findings support the role of amino acid sequence as a pivotal determinant of protein abundance and stability, revealing an evolutionary optimization for metabolic efficiency.},
  langid = {english},
  pubstate = {prepublished},
  file = {/Users/michaelvolk/Zotero/storage/MYWC6BNZ/Buric et al_2023_The amino acid sequence determines protein abundance through its conformational.pdf}
}

@unpublished{busbridgeRelationalGraphAttention2019,
  title = {Relational {{Graph Attention Networks}}},
  author = {Busbridge, Dan and Sherburn, Dane and Cavallo, Pietro and Hammerla, Nils Y.},
  date = {2019-04-11},
  eprint = {1904.05811},
  eprinttype = {arXiv},
  eprintclass = {cs, stat},
  url = {http://arxiv.org/abs/1904.05811},
  urldate = {2022-04-19},
  abstract = {We investigate Relational Graph Attention Networks, a class of models that extends non-relational graph attention mechanisms to incorporate relational information, opening up these methods to a wider variety of problems. A thorough evaluation of these models is performed, and comparisons are made against established benchmarks. To provide a meaningful comparison, we retrain Relational Graph Convolutional Networks, the spectral counterpart of Relational Graph Attention Networks, and evaluate them under the same conditions. We find that Relational Graph Attention Networks perform worse than anticipated, although some configurations are marginally beneficial for modelling molecular properties. We provide insights as to why this may be, and suggest both modifications to evaluation strategies, as well as directions to investigate for future work.},
  keywords = {📚,🦌,artificial-intelligence,machine-learning},
  annotation = {55 citations (Semantic Scholar/arXiv) [2022-11-26]},
  file = {/Users/michaelvolk/Zotero/storage/KTXKZZLV/Busbridge et al_2019_Relational Graph Attention Networks.pdf;/Users/michaelvolk/Zotero/storage/9Q75ENLC/1904.html}
}

@online{buterezEndtoendAttentionbasedApproach2024,
  title = {An End-to-End Attention-Based Approach for Learning on Graphs},
  author = {Buterez, David and Janet, Jon Paul and Oglic, Dino and Lio, Pietro},
  date = {2024-12-06},
  eprint = {2402.10793},
  eprinttype = {arXiv},
  eprintclass = {cs},
  doi = {10.48550/arXiv.2402.10793},
  url = {http://arxiv.org/abs/2402.10793},
  urldate = {2025-02-12},
  abstract = {There has been a recent surge in transformer-based architectures for learning on graphs, mainly motivated by attention as an effective learning mechanism and the desire to supersede handcrafted operators characteristic of message passing schemes. However, concerns over their empirical effectiveness, scalability, and complexity of the pre-processing steps have been raised, especially in relation to much simpler graph neural networks that typically perform on par with them across a wide range of benchmarks. To tackle these shortcomings, we consider graphs as sets of edges and propose a purely attention-based approach consisting of an encoder and an attention pooling mechanism. The encoder vertically interleaves masked and vanilla self-attention modules to learn an effective representations of edges, while allowing for tackling possible misspecifications in input graphs. Despite its simplicity, the approach outperforms fine-tuned message passing baselines and recently proposed transformer-based methods on more than 70 node and graph-level tasks, including challenging long-range benchmarks. Moreover, we demonstrate state-of-the-art performance across different tasks, ranging from molecular to vision graphs, and heterophilous node classification. The approach also outperforms graph neural networks and transformers in transfer learning settings, and scales much better than alternatives with a similar performance level or expressive power.},
  pubstate = {prepublished},
  keywords = {Computer Science - Artificial Intelligence,Computer Science - Machine Learning},
  annotation = {2 citations (Semantic Scholar/arXiv) [2025-02-12]},
  file = {/Users/michaelvolk/Zotero/storage/QQQ266SI/Buterez et al_2024_An end-to-end attention-based approach for learning on graphs.pdf;/Users/michaelvolk/Zotero/storage/QUHEAALE/2402.html}
}

@online{buterezGraphNeuralNetworks2022,
  title = {Graph {{Neural Networks}} with {{Adaptive Readouts}}},
  author = {Buterez, David and Janet, Jon Paul and Kiddle, Steven J. and Oglic, Dino and Liò, Pietro},
  date = {2022-11-09},
  eprint = {2211.04952},
  eprinttype = {arXiv},
  eprintclass = {cs},
  doi = {10.48550/arXiv.2211.04952},
  url = {http://arxiv.org/abs/2211.04952},
  urldate = {2024-06-21},
  abstract = {An effective aggregation of node features into a graph-level representation via readout functions is an essential step in numerous learning tasks involving graph neural networks. Typically, readouts are simple and non-adaptive functions designed such that the resulting hypothesis space is permutation invariant. Prior work on deep sets indicates that such readouts might require complex node embeddings that can be difficult to learn via standard neighborhood aggregation schemes. Motivated by this, we investigate the potential of adaptive readouts given by neural networks that do not necessarily give rise to permutation invariant hypothesis spaces. We argue that in some problems such as binding affinity prediction where molecules are typically presented in a canonical form it might be possible to relax the constraints on permutation invariance of the hypothesis space and learn a more effective model of the affinity by employing an adaptive readout function. Our empirical results demonstrate the effectiveness of neural readouts on more than 40 datasets spanning different domains and graph characteristics. Moreover, we observe a consistent improvement over standard readouts (i.e., sum, max, and mean) relative to the number of neighborhood aggregation iterations and different convolutional operators.},
  pubstate = {prepublished},
  keywords = {Computer Science - Artificial Intelligence,Computer Science - Machine Learning},
  annotation = {29 citations (Semantic Scholar/arXiv) [2024-06-20]\\
29 citations (Semantic Scholar/DOI) [2024-06-20]},
  file = {/Users/michaelvolk/Zotero/storage/MDXMLPUP/Buterez et al_2022_Graph Neural Networks with Adaptive Readouts.pdf;/Users/michaelvolk/Zotero/storage/6VIJ8YFL/2211.html}
}

@inproceedings{caiHypergraphStructureLearning2022,
  title = {Hypergraph {{Structure Learning}} for {{Hypergraph Neural Networks}}},
  author = {Cai, Derun and Song, Moxian and Sun, Chenxi and Zhang, Baofeng and Hong, Shenda and Li, Hongyan},
  date = {2022-07-16},
  volume = {3},
  pages = {1923--1929},
  issn = {1045-0823},
  doi = {10.24963/ijcai.2022/267},
  url = {https://www.ijcai.org/proceedings/2022/267},
  urldate = {2025-04-24},
  abstract = {Electronic proceedings of IJCAI 2022},
  eventtitle = {Thirty-{{First International Joint Conference}} on {{Artificial Intelligence}}},
  langid = {english},
  annotation = {38 citations (Semantic Scholar/DOI) [2025-04-23]},
  file = {/Users/michaelvolk/Zotero/storage/8XTB4FFU/Cai et al_2022_Hypergraph Structure Learning for Hypergraph Neural Networks.pdf}
}

@article{caiIntegratingScRNAseqScATACseq2025,
  title = {Integrating {{scRNA-seq}} and {{scATAC-seq}} with Inter-Type Attention Heterogeneous Graph Neural Networks},
  author = {Cai, Lingsheng and Ma, Xiuli and Ma, Jianzhu},
  date = {2025-01-01},
  journaltitle = {Briefings in Bioinformatics},
  shortjournal = {Briefings in Bioinformatics},
  volume = {26},
  number = {1},
  pages = {bbae711},
  issn = {1477-4054},
  doi = {10.1093/bib/bbae711},
  url = {https://doi.org/10.1093/bib/bbae711},
  urldate = {2025-05-08},
  abstract = {Single-cell multi-omics techniques, which enable the simultaneous measurement of multiple modalities such as RNA gene expression and Assay for Transposase-Accessible Chromatin (ATAC) within individual cells, have become a powerful tool for deciphering the intricate complexity of cellular systems. Most current methods rely on motif databases to establish cross-modality relationships between genes from RNA-seq data and peaks from ATAC-seq data. However, these approaches are constrained by incomplete database coverage, particularly for novel or poorly characterized relationships. To address these limitations, we introduce single-cell Multi-omics Integration (scMI), a heterogeneous graph embedding method that encodes both cells and modality features from single-cell RNA-seq and ATAC-seq data into a shared latent space by learning cross-modality relationships. By modeling cells and modality features as distinct node types, we design an inter-type attention mechanism to effectively capture long-range cross-modality interactions between genes and peaks. Benchmark results demonstrate that embeddings learned by scMI preserve more biological information and achieve comparable or superior performance in downstream tasks including modality prediction, cell clustering, and gene regulatory network inference compared to methods that rely on databases. Furthermore, scMI significantly improves the alignment and integration of unmatched multi-omics data, enabling more accurate embedding and improved outcomes in downstream tasks.},
  annotation = {0 citations (Semantic Scholar/DOI) [2025-05-08]},
  file = {/Users/michaelvolk/Zotero/storage/2MTXDP9D/Cai et al_2025_Integrating scRNA-seq and scATAC-seq with inter-type attention heterogeneous.pdf;/Users/michaelvolk/Zotero/storage/EKVW7TQY/7952005.html}
}

@online{cangeaSparseHierarchicalGraph2018,
  title = {Towards {{Sparse Hierarchical Graph Classifiers}}},
  author = {Cangea, Cătălina and Veličković, Petar and Jovanović, Nikola and Kipf, Thomas and Liò, Pietro},
  date = {2018-11-03},
  eprint = {1811.01287},
  eprinttype = {arXiv},
  eprintclass = {stat},
  doi = {10.48550/arXiv.1811.01287},
  url = {http://arxiv.org/abs/1811.01287},
  urldate = {2025-03-01},
  abstract = {Recent advances in representation learning on graphs, mainly leveraging graph convolutional networks, have brought a substantial improvement on many graph-based benchmark tasks. While novel approaches to learning node embeddings are highly suitable for node classification and link prediction, their application to graph classification (predicting a single label for the entire graph) remains mostly rudimentary, typically using a single global pooling step to aggregate node features or a hand-designed, fixed heuristic for hierarchical coarsening of the graph structure. An important step towards ameliorating this is differentiable graph coarsening---the ability to reduce the size of the graph in an adaptive, data-dependent manner within a graph neural network pipeline, analogous to image downsampling within CNNs. However, the previous prominent approach to pooling has quadratic memory requirements during training and is therefore not scalable to large graphs. Here we combine several recent advances in graph neural network design to demonstrate that competitive hierarchical graph classification results are possible without sacrificing sparsity. Our results are verified on several established graph classification benchmarks, and highlight an important direction for future research in graph-based neural networks.},
  pubstate = {prepublished},
  keywords = {Computer Science - Artificial Intelligence,Computer Science - Machine Learning,Computer Science - Social and Information Networks,Statistics - Machine Learning},
  annotation = {252 citations (Semantic Scholar/arXiv) [2025-03-01]},
  file = {/Users/michaelvolk/Zotero/storage/RCWMMHW4/Cangea et al_2018_Towards Sparse Hierarchical Graph Classifiers.pdf;/Users/michaelvolk/Zotero/storage/FUTU6A2D/1811.html}
}

@article{caoMultiomicsSinglecellData2022,
  title = {Multi-Omics Single-Cell Data Integration and Regulatory Inference with Graph-Linked Embedding},
  author = {Cao, Zhi-Jie and Gao, Ge},
  date = {2022-05-02},
  journaltitle = {Nature Biotechnology},
  shortjournal = {Nat Biotechnol},
  pages = {1--9},
  publisher = {Nature Publishing Group},
  issn = {1546-1696},
  doi = {10.1038/s41587-022-01284-4},
  url = {https://www.nature.com/articles/s41587-022-01284-4},
  urldate = {2022-05-10},
  abstract = {Despite the emergence of experimental methods for simultaneous measurement of multiple omics modalities in single cells, most single-cell datasets include only one modality. A major obstacle in integrating omics data from multiple modalities is that different omics layers typically have distinct feature spaces. Here, we propose a computational framework called GLUE (graph-linked unified embedding), which bridges the gap by modeling regulatory interactions across omics layers explicitly. Systematic benchmarking demonstrated that GLUE is more accurate, robust and scalable than state-of-the-art tools for heterogeneous single-cell multi-omics data. We applied GLUE to various challenging tasks, including triple-omics integration, integrative regulatory inference and multi-omics human cell atlas construction over millions of cells, where GLUE was able to correct previous annotations. GLUE features a modular design that can be flexibly extended and enhanced for new analysis tasks. The full package is available online at https://github.com/gao-lab/GLUE.},
  langid = {english},
  keywords = {☁️,📌,📚,🦌,Data integration,data-integration,Gene regulation,gene-regulation,Machine learning,machine-learning,Software},
  annotation = {16 citations (Semantic Scholar/DOI) [2022-11-26]},
  file = {/Users/michaelvolk/Zotero/storage/EFKDVZPC/Cao_Gao_2022_Multi-omics single-cell data integration and regulatory inference with.pdf;/Users/michaelvolk/Zotero/storage/VWT7NCG5/s41587-022-01284-4.html}
}

@unpublished{caoRelationalMultitaskLearning2023,
  title = {Relational Multi-Task Learning: {{Modeling}} Relations between Data and Tasks},
  shorttitle = {Relational Multi-Task Learning},
  author = {Cao, Kaidi and You, Jiaxuan and Leskovec, Jure},
  date = {2023},
  eprint = {2303.07666},
  eprinttype = {arXiv}
}

@article{cappartCombinatorialOptimizationReasoning2023,
  title = {Combinatorial Optimization and Reasoning with Graph Neural Networks},
  author = {Cappart, Quentin and Chételat, Didier and Khalil, Elias B. and Lodi, Andrea and Morris, Christopher and Veličković, Petar},
  date = {2023},
  journaltitle = {Journal of Machine Learning Research},
  volume = {24},
  number = {130},
  pages = {1--61},
  url = {http://www.jmlr.org/papers/v24/21-0449.html},
  urldate = {2025-03-01},
  file = {/Users/michaelvolk/Zotero/storage/QGTKRPAC/Cappart et al_2023_Combinatorial optimization and reasoning with graph neural networks.pdf}
}

@article{carlquistPhysiologicalHeterogeneitiesMicrobial2012,
  title = {Physiological Heterogeneities in Microbial Populations and Implications for Physical Stress Tolerance},
  author = {Carlquist, Magnus and Fernandes, Rita Lencastre and Helmark, Søren and Heins, Anna-Lena and Lundin, Luisa and Sørensen, Søren J. and Gernaey, Krist V. and Lantz, Anna Eliasson},
  date = {2012-07-16},
  journaltitle = {Microbial Cell Factories},
  shortjournal = {Microb Cell Fact},
  volume = {11},
  number = {1},
  pages = {94},
  issn = {1475-2859},
  doi = {10.1186/1475-2859-11-94},
  url = {https://doi.org/10.1186/1475-2859-11-94},
  urldate = {2024-07-07},
  abstract = {Traditionally average values of the whole population are considered when analysing microbial cell cultivations. However, a typical microbial population in a bioreactor is heterogeneous in most phenotypes measurable at a single-cell level. There are indications that such heterogeneity may be unfavourable on the one hand (reduces yields and productivities), but also beneficial on the other hand (facilitates quick adaptation to new conditions - i.e. increases the robustness of the fermentation process). Understanding and control of microbial population heterogeneity is thus of major importance for improving microbial cell factory processes.},
  langid = {english},
  keywords = {Budding yeast,Cell factory optimisation,Cell fitness,Cell membrane robustness,Flow cytometry,Population heterogeneity,Reporter strain},
  annotation = {76 citations (Semantic Scholar/DOI) [2024-07-06]},
  file = {/Users/michaelvolk/Zotero/storage/FSPZWXY3/Carlquist et al_2012_Physiological heterogeneities in microbial populations and implications for.pdf}
}

@article{castroMultistudyInferenceRegulatory2019,
  title = {Multi-Study Inference of Regulatory Networks for More Accurate Models of Gene Regulation},
  author = {Castro, Dayanne M. and family=Veaux, given=Nicholas R., prefix=de, useprefix=false and Miraldi, Emily R. and Bonneau, Richard},
  date = {2019-01-24},
  journaltitle = {PLOS Computational Biology},
  shortjournal = {PLOS Computational Biology},
  volume = {15},
  number = {1},
  pages = {e1006591},
  publisher = {Public Library of Science},
  issn = {1553-7358},
  doi = {10.1371/journal.pcbi.1006591},
  url = {https://journals.plos.org/ploscompbiol/article?id=10.1371/journal.pcbi.1006591},
  urldate = {2023-10-14},
  abstract = {Gene regulatory networks are composed of sub-networks that are often shared across biological processes, cell-types, and organisms. Leveraging multiple sources of information, such as publicly available gene expression datasets, could therefore be helpful when learning a network of interest. Integrating data across different studies, however, raises numerous technical concerns. Hence, a common approach in network inference, and broadly in genomics research, is to separately learn models from each dataset and combine the results. Individual models, however, often suffer from under-sampling, poor generalization and limited network recovery. In this study, we explore previous integration strategies, such as batch-correction and model ensembles, and introduce a new multitask learning approach for joint network inference across several datasets. Our method initially estimates the activities of transcription factors, and subsequently, infers the relevant network topology. As regulatory interactions are context-dependent, we estimate model coefficients as a combination of both dataset-specific and conserved components. In addition, adaptive penalties may be used to favor models that include interactions derived from multiple sources of prior knowledge including orthogonal genomics experiments. We evaluate generalization and network recovery using examples from Bacillus subtilis and Saccharomyces cerevisiae, and show that sharing information across models improves network reconstruction. Finally, we demonstrate robustness to both false positives in the prior information and heterogeneity among datasets.},
  langid = {english},
  keywords = {Bacillus subtilis,Gene expression,Gene regulation,Network analysis,Regulator genes,Saccharomyces cerevisiae,Transcription factors,Yeast},
  annotation = {55 citations (Semantic Scholar/DOI) [2023-10-14]},
  file = {/Users/michaelvolk/Zotero/storage/BMXZUEGC/Castro et al_2019_Multi-study inference of regulatory networks for more accurate models of gene.pdf}
}

@article{castroMultistudyInferenceRegulatory2019a,
  title = {Multi-Study Inference of Regulatory Networks for More Accurate Models of Gene Regulation},
  author = {Castro, Dayanne M. and De Veaux, Nicholas R. and Miraldi, Emily R. and Bonneau, Richard},
  editor = {Van Nimwegen, Erik},
  date = {2019-01-24},
  journaltitle = {PLOS Computational Biology},
  shortjournal = {PLoS Comput Biol},
  volume = {15},
  number = {1},
  pages = {e1006591},
  issn = {1553-7358},
  doi = {10.1371/journal.pcbi.1006591},
  url = {https://dx.plos.org/10.1371/journal.pcbi.1006591},
  urldate = {2023-10-14},
  langid = {english},
  annotation = {55 citations (Semantic Scholar/DOI) [2023-10-14]},
  file = {/Users/michaelvolk/Zotero/storage/EJJ2J5ZY/Castro et al_2019_Multi-study inference of regulatory networks for more accurate models of gene.pdf}
}

@article{caudalPantranscriptomeRevealsLarge2024,
  title = {Pan-Transcriptome Reveals a Large Accessory Genome Contribution to Gene Expression Variation in Yeast},
  author = {Caudal, Élodie and Loegler, Victor and Dutreux, Fabien and Vakirlis, Nikolaos and Teyssonnière, Élie and Caradec, Claudia and Friedrich, Anne and Hou, Jing and Schacherer, Joseph},
  date = {2024-06},
  journaltitle = {Nature Genetics},
  shortjournal = {Nat Genet},
  volume = {56},
  number = {6},
  pages = {1278--1287},
  publisher = {Nature Publishing Group},
  issn = {1546-1718},
  doi = {10.1038/s41588-024-01769-9},
  url = {https://www.nature.com/articles/s41588-024-01769-9},
  urldate = {2025-03-17},
  abstract = {Gene expression is an essential step in the translation of genotypes into phenotypes. However, little is known about the transcriptome architecture and the underlying genetic effects at the species level. Here we generated and analyzed the pan-transcriptome of \textasciitilde 1,000 yeast natural isolates across 4,977 core and 1,468 accessory genes. We found that the accessory genome is an underappreciated driver of transcriptome divergence. Global gene expression patterns combined with population structure showed that variation in heritable expression mainly lies within subpopulation-specific signatures, for which accessory genes are overrepresented. Genome-wide association analyses consistently highlighted that accessory genes are associated with proportionally more variants with larger effect sizes, illustrating the critical role of the accessory genome on the transcriptional landscape within and between populations.},
  langid = {english},
  keywords = {🦌✅,Gene expression,Gene regulation},
  annotation = {19 citations (Semantic Scholar/DOI) [2025-03-17]},
  file = {/Users/michaelvolk/Zotero/storage/UCPJJI58/Caudal et al_2024_Pan-transcriptome reveals a large accessory genome contribution to gene.pdf}
}

@article{CausalInferenceML,
  title = {Causal {{Inference}} with {{ML}} and {{AI}}},
  langid = {english},
  file = {/Users/michaelvolk/Zotero/storage/ZAW9BB9P/Causal Inference with ML and AI.pdf}
}

@article{chaiHypergraphModelingHypergraph2024a,
  title = {Hypergraph Modeling and Hypergraph Multi-View Attention Neural Network for Link Prediction},
  author = {Chai, Lang and Tu, Lilan and Wang, Xianjia and Su, Qingqing},
  date = {2024-05-01},
  journaltitle = {Pattern Recognition},
  shortjournal = {Pattern Recognition},
  volume = {149},
  pages = {110292},
  issn = {0031-3203},
  doi = {10.1016/j.patcog.2024.110292},
  url = {https://www.sciencedirect.com/science/article/pii/S0031320324000438},
  urldate = {2025-04-29},
  abstract = {Hypergraph neural networks are widely used in link prediction because of their ability to learn the high-order structure relationship. However, most existing hypergraph modeling relies on the attribute information of nodes. And as for the link prediction, missing links are not utilized when training link predictors, so conventional transductive hypergraph learning are generally not consistent with link prediction tasks. To address these limitations, we propose the Network Structure Linear Representation (NSLR) method to model hypergraph for general networks without node attribute information and the inductive hypergraph learning method Hypergraph Multi-view Attention Neural Network (HMANN) that learns the rich high-order structure information from node-level and hyperedge-level. Also, this paper put forwards a novel NSLR-HMANN link prediction algorithm based on NSLR and HMANN methods. Extensive comparison and ablation experiments show that the NSLR-HMANN link prediction algorithm achieves state-of-the-art performance on link prediction and has better performance on robustness.},
  keywords = {Hypergraph learning,Hypergraph modeling,Hypergraph neural network,Link prediction,Network structure representation},
  annotation = {9 citations (Semantic Scholar/DOI) [2025-04-28]},
  file = {/Users/michaelvolk/Zotero/storage/SE365QYP/Chai et al. - 2024 - Hypergraph modeling and hypergraph multi-view atte.pdf;/Users/michaelvolk/Zotero/storage/TY95WWHV/S0031320324000438.html}
}

@article{chaiReviewComputationalApproaches2014,
  title = {A Review on the Computational Approaches for Gene Regulatory Network Construction},
  author = {Chai, Lian En and Loh, Swee Kuan and Low, Swee Thing and Mohamad, Mohd Saberi and Deris, Safaai and Zakaria, Zalmiyah},
  date = {2014-05-01},
  journaltitle = {Computers in Biology and Medicine},
  shortjournal = {Computers in Biology and Medicine},
  volume = {48},
  pages = {55--65},
  issn = {0010-4825},
  doi = {10.1016/j.compbiomed.2014.02.011},
  url = {https://www.sciencedirect.com/science/article/pii/S0010482514000420},
  urldate = {2023-10-14},
  abstract = {Many biological research areas such as drug design require gene regulatory networks to provide clear insight and understanding of the cellular process in living cells. This is because interactions among the genes and their products play an important role in many molecular processes. A gene regulatory network can act as a blueprint for the researchers to observe the relationships among genes. Due to its importance, several computational approaches have been proposed to infer gene regulatory networks from gene expression data. In this review, six inference approaches are discussed: Boolean network, probabilistic Boolean network, ordinary differential equation, neural network, Bayesian network, and dynamic Bayesian network. These approaches are discussed in terms of introduction, methodology and recent applications of these approaches in gene regulatory network construction. These approaches are also compared in the discussion section. Furthermore, the strengths and weaknesses of these computational approaches are described.},
  keywords = {Bayesian network,Boolean network,Computational approaches,Dynamic Bayesian network,Gene expression data,Gene regulatory network,Neural network,Ordinary differential equation,Probabilistic Boolean network},
  file = {/Users/michaelvolk/Zotero/storage/WREGCQYV/S0010482514000420.html}
}

@article{chengCisregulatoryElementsExplain,
  title = {Cis-Regulatory Elements Explain Most of the {{mRNA}} Stability Variation across Genes in Yeast},
  author = {Cheng, Jun and Maier, Kerstin C and Avsec, Iga and Rus, Petra and Gagneur, Julien},
  abstract = {The stability of mRNA is one of the major determinants of gene expression. Although a wealth of sequence elements regulating mRNA stability has been described, their quantitative contributions to half-life are unknown. Here, we built a quantitative model for Saccharomyces cerevisiae based on functional mRNA sequence features that explains 59\% of the half-life variation between genes and predicts half-life at a median relative error of 30\%. The model revealed a new destabilizing 3′ UTR motif, ATATTC, which we functionally validated. Codon usage proves to be the major determinant of mRNA stability. Nonetheless, single-nucleotide variations have the largest effect when occurring on 3′ UTR motifs or upstream AUGs. Analyzing mRNA half-life data of 34 knockout strains showed that the effect of codon usage not only requires functional decapping and deadenylation, but also the 5′ -to-3′ exonuclease Xrn1, the nonsense-mediated decay genes, but not no-go decay. Altogether, this study quantitatively delineates the contributions of mRNA sequence features on stability in yeast, reveals their functional dependencies on degradation pathways, and allows accurate prediction of half-life from mRNA sequence.},
  langid = {english},
  keywords = {nt-transformer.s-cerevisiae.prediciton.half-life},
  file = {/Users/michaelvolk/Zotero/storage/NJDFSJ9K/Cheng et al. - Cis-regulatory elements explain most of the mRNA s.pdf}
}

@article{chenGenomescaleModelingYeast2022a,
  title = {Genome-Scale Modeling of Yeast Metabolism: Retrospectives and Perspectives},
  shorttitle = {Genome-Scale Modeling of Yeast Metabolism},
  author = {Chen, Yu and Li, Feiran and Nielsen, Jens},
  date = {2022-01-01},
  journaltitle = {FEMS Yeast Research},
  shortjournal = {FEMS Yeast Research},
  volume = {22},
  number = {1},
  pages = {foac003},
  issn = {1567-1356},
  doi = {10.1093/femsyr/foac003},
  url = {https://doi.org/10.1093/femsyr/foac003},
  urldate = {2024-08-07},
  abstract = {Yeasts have been widely used for production of bread, beer and wine, as well as for production of bioethanol, but they have also been designed as cell factories to produce various chemicals, advanced biofuels and recombinant proteins. To systematically understand and rationally engineer yeast metabolism, genome-scale metabolic models (GEMs) have been reconstructed for the model yeast Saccharomyces cerevisiae and nonconventional yeasts. Here, we review the historical development of yeast GEMs together with their recent applications, including metabolic flux prediction, cell factory design, culture condition optimization and multi-yeast comparative analysis. Furthermore, we present an emerging effort, namely the integration of proteome constraints into yeast GEMs, resulting in models with improved performance. At last, we discuss challenges and perspectives on the development of yeast GEMs and the integration of proteome constraints.},
  annotation = {9 citations (Semantic Scholar/DOI) [2024-08-06]},
  file = {/Users/michaelvolk/Zotero/storage/UXL7F8E5/Chen et al_2022_Genome-scale modeling of yeast metabolism.pdf;/Users/michaelvolk/Zotero/storage/YEZNPUB7/6517476.html}
}

@article{chenTeasingOutMissing2023,
  title = {Teasing out Missing Reactions in Genome-Scale Metabolic Networks through Hypergraph Learning},
  author = {Chen, Can and Liao, Chen and Liu, Yang-Yu},
  date = {2023-04-25},
  journaltitle = {Nature Communications},
  shortjournal = {Nat Commun},
  volume = {14},
  number = {1},
  pages = {2375},
  publisher = {Nature Publishing Group},
  issn = {2041-1723},
  doi = {10.1038/s41467-023-38110-7},
  url = {https://www.nature.com/articles/s41467-023-38110-7},
  urldate = {2025-04-29},
  abstract = {GEnome-scale Metabolic models (GEMs) are powerful tools to predict cellular metabolism and physiological states in living organisms. However, due to our imperfect knowledge of metabolic processes, even highly curated GEMs have knowledge gaps (e.g., missing reactions). Existing gap-filling methods typically require phenotypic data as input to tease out missing reactions. We still lack a computational method for rapid and accurate gap-filling of metabolic networks before experimental data is available. Here we present a deep learning-based method — CHEbyshev Spectral HyperlInk pREdictor (CHESHIRE) — to predict missing reactions in GEMs purely from metabolic network topology. We demonstrate that CHESHIRE outperforms other topology-based methods in predicting artificially removed reactions over 926 high- and intermediate-quality GEMs. Furthermore, CHESHIRE is able to improve the phenotypic predictions of 49 draft GEMs for fermentation products and amino acids secretions. Both types of validation suggest that CHESHIRE is a powerful tool for GEM curation to reveal unknown links between reactions and observed metabolic phenotypes.},
  langid = {english},
  keywords = {Applied microbiology,Biochemical reaction networks,Machine learning,Metabolic engineering},
  annotation = {39 citations (Semantic Scholar/DOI) [2025-04-28]},
  file = {/Users/michaelvolk/Zotero/storage/XLHH6XEN/Chen et al_2023_Teasing out missing reactions in genome-scale metabolic networks through.pdf}
}

@article{chenTranscriptionalProfilingReveals2016,
  title = {Transcriptional Profiling Reveals Molecular Basis and Novel Genetic Targets for Improved Resistance to Multiple Fermentation Inhibitors in {{Saccharomyces}} Cerevisiae},
  author = {Chen, Yingying and Sheng, Jiayuan and Jiang, Tao and Stevens, Joseph and Feng, Xueyang and Wei, Na},
  date = {2016-01-13},
  journaltitle = {Biotechnology for Biofuels},
  shortjournal = {Biotechnol Biofuels},
  volume = {9},
  number = {1},
  pages = {9},
  issn = {1754-6834},
  doi = {10.1186/s13068-015-0418-5},
  url = {https://doi.org/10.1186/s13068-015-0418-5},
  urldate = {2023-08-01},
  abstract = {Lignocellulosic biomass is a promising source of renewable biofuels. However, pretreatment of lignocellulosic biomass generates fermentation inhibitors that adversely affect the growth of industrial microorganisms such as Saccharomyces cerevisiae and prevent economic production of lignocellulosic biofuels. A critical challenge on developing S. cerevisiae with improved inhibitor resistance lies in incomplete understanding of molecular basis for inhibitor stress response and limited information on effective genetic targets for increasing yeast resistance to mixed fermentation inhibitors. In this study, we applied comparative transcriptomic analysis to determine the molecular basis for acetic acid and/or furfural resistance in S. cerevisiae.},
  langid = {english},
  keywords = {Acetic acid,Furfural,inhibitor-tolerance.data,Metabolic engineering,RNA-seq,Transcription factors,Yeast},
  annotation = {85 citations (Semantic Scholar/DOI) [2023-08-01]},
  file = {/Users/michaelvolk/Zotero/storage/86DD9TLT/Chen et al_2016_Transcriptional profiling reveals molecular basis and novel genetic targets for.pdf}
}

@article{cherrySGDSaccharomycesGenome1998,
  title = {{{SGD}}: {{Saccharomyces Genome Database}}},
  shorttitle = {{{SGD}}},
  author = {Cherry, J. Michael and Adler, Caroline and Ball, Catherine and Chervitz, Stephen A. and Dwight, Selina S. and Hester, Erich T. and Jia, Yankai and Juvik, Gail and Roe, TaiYun and Schroeder, Mark and Weng, Shuai and Botstein, David},
  date = {1998-01-01},
  journaltitle = {Nucleic Acids Research},
  shortjournal = {Nucleic Acids Research},
  volume = {26},
  number = {1},
  pages = {73--79},
  issn = {0305-1048},
  doi = {10.1093/nar/26.1.73},
  url = {https://doi.org/10.1093/nar/26.1.73},
  urldate = {2023-09-10},
  abstract = {The Saccharomyces Genome Database (SGD) provides Internet access to the complete Saccharomyces cerevisiae genomic sequence, its genes and their products, the phenotypes of its mutants, and the literature supporting these data. The amount of information and the number of features provided by SGD have increased greatly following the release of the S.cerevisiae genomic sequence, which is currently the only complete sequence of a eukaryotic genome. SGD aids researchers by providing not only basic information, but also tools such as sequence similarity searching that lead to detailed information about features of the genome and relationships between genes. SGD presents information using a variety of user-friendly, dynamically created graphical displays illustrating physical, genetic and sequence feature maps. SGD can be accessed via the World Wide Web at http://genome-www.stanford.edu/Saccharomyces/},
  annotation = {1104 citations (Semantic Scholar/DOI) [2023-09-10]},
  file = {/Users/michaelvolk/Zotero/storage/P7APUL5V/Cherry et al_1998_SGD.pdf;/Users/michaelvolk/Zotero/storage/IZ9FCXZS/2379479.html}
}

@article{childs-disneyTargetingRNAStructures2022,
  title = {Targeting {{RNA}} Structures with Small Molecules},
  author = {Childs-Disney, Jessica L. and Yang, Xueyi and Gibaut, Quentin M. R. and Tong, Yuquan and Batey, Robert T. and Disney, Matthew D.},
  date = {2022-10},
  journaltitle = {Nature Reviews Drug Discovery},
  shortjournal = {Nat Rev Drug Discov},
  volume = {21},
  number = {10},
  pages = {736--762},
  publisher = {Nature Publishing Group},
  issn = {1474-1784},
  doi = {10.1038/s41573-022-00521-4},
  url = {https://www.nature.com/articles/s41573-022-00521-4},
  urldate = {2024-06-24},
  abstract = {RNA adopts 3D structures that confer varied functional roles in human biology and dysfunction in disease. Approaches to therapeutically target RNA structures with small molecules are being actively pursued, aided by key advances in the field including the development of computational tools that predict evolutionarily conserved RNA structures, as well as strategies that expand mode of action and facilitate interactions with cellular machinery. Existing RNA-targeted small molecules use a range of mechanisms including directing splicing — by acting as molecular glues with cellular proteins (such as branaplam and the FDA-approved risdiplam), inhibition of translation of undruggable proteins and deactivation of functional structures in noncoding RNAs. Here, we describe strategies to identify, validate and optimize small molecules that target the functional transcriptome, laying out a roadmap to advance these agents into the next decade.},
  langid = {english},
  keywords = {Drug screening,RNA},
  annotation = {153 citations (Semantic Scholar/DOI) [2024-06-23]},
  file = {/Users/michaelvolk/Zotero/storage/RNT9NPLN/Childs-Disney et al_2022_Targeting RNA structures with small molecules.pdf}
}

@inproceedings{choiTopologyInformedGraphTransformer2024,
  title = {Topology-{{Informed Graph Transformer}}},
  booktitle = {Proceedings of the {{Geometry-grounded Representation Learning}} and {{Generative Modeling Workshop}} ({{GRaM}})},
  author = {Choi, Yun Young and Park, Sun Woo and Lee, Minho and Woo, Youngho},
  date = {2024-10-12},
  pages = {20--34},
  publisher = {PMLR},
  issn = {2640-3498},
  url = {https://proceedings.mlr.press/v251/choi24a.html},
  urldate = {2025-02-28},
  abstract = {Transformers, through their self-attention mechanisms, have revolutionized performance in Natural Language Processing and Vision. Recently,there has been increasing interest in integrating Transformers with Graph Neural Networks (GNNs) to enhance analyzing geometric properties of graphs by employing global attention mechanisms. A key challenge in improving graph transformers is enhancing their ability to distinguish between isomorphic graphs, which can potentially boost their predictive performance. To address this challenge, we introduce ’Topology-Informed Graph Transformer (TIGT)’, a novel transformer enhancing both discriminative power in detecting graph isomorphisms and the overall performance of Graph Transformers. TIGT consists of four components: (1) a topological positional embedding layer using non-isomorphic universal covers based on cyclic subgraphs of graphs to ensure unique graph representation, (2) a dual-path message-passing layer to explicitly encode topological characteristics throughout the encoder layers, (3) a global attention mechanism, and (4) a graph information layer to recalibrate channel-wise graph features for improved feature representation. TIGT outperforms previous Graph Transformers in classifying synthetic dataset aimed at distinguishing isomorphism classes of graphs. Additionally, mathematical analysis and empirical evaluations highlight our model’s competitive edge over state-of-the-art Graph Transformers across various benchmark datasets.},
  eventtitle = {Geometry-Grounded {{Representation Learning}} and {{Generative Modeling Workshop}} ({{GRaM}}) at {{ICML}} 2024},
  langid = {english},
  file = {/Users/michaelvolk/Zotero/storage/LKTAEMFV/Choi et al_2024_Topology-Informed Graph Transformer.pdf}
}

@online{choromanskiRethinkingAttentionPerformers2022,
  title = {Rethinking {{Attention}} with {{Performers}}},
  author = {Choromanski, Krzysztof and Likhosherstov, Valerii and Dohan, David and Song, Xingyou and Gane, Andreea and Sarlos, Tamas and Hawkins, Peter and Davis, Jared and Mohiuddin, Afroz and Kaiser, Lukasz and Belanger, David and Colwell, Lucy and Weller, Adrian},
  date = {2022-11-19},
  eprint = {2009.14794},
  eprinttype = {arXiv},
  eprintclass = {cs},
  doi = {10.48550/arXiv.2009.14794},
  url = {http://arxiv.org/abs/2009.14794},
  urldate = {2025-02-12},
  abstract = {We introduce Performers, Transformer architectures which can estimate regular (softmax) full-rank-attention Transformers with provable accuracy, but using only linear (as opposed to quadratic) space and time complexity, without relying on any priors such as sparsity or low-rankness. To approximate softmax attention-kernels, Performers use a novel Fast Attention Via positive Orthogonal Random features approach (FAVOR+), which may be of independent interest for scalable kernel methods. FAVOR+ can be also used to efficiently model kernelizable attention mechanisms beyond softmax. This representational power is crucial to accurately compare softmax with other kernels for the first time on large-scale tasks, beyond the reach of regular Transformers, and investigate optimal attention-kernels. Performers are linear architectures fully compatible with regular Transformers and with strong theoretical guarantees: unbiased or nearly-unbiased estimation of the attention matrix, uniform convergence and low estimation variance. We tested Performers on a rich set of tasks stretching from pixel-prediction through text models to protein sequence modeling. We demonstrate competitive results with other examined efficient sparse and dense attention methods, showcasing effectiveness of the novel attention-learning paradigm leveraged by Performers.},
  pubstate = {prepublished},
  keywords = {Computer Science - Computation and Language,Computer Science - Machine Learning,Statistics - Machine Learning},
  annotation = {1383 citations (Semantic Scholar/arXiv) [2025-02-12]},
  file = {/Users/michaelvolk/Zotero/storage/QVCDFSRN/Choromanski et al_2022_Rethinking Attention with Performers.pdf;/Users/michaelvolk/Zotero/storage/3WK96HU3/2009.html}
}

@article{corsoGraphNeuralNetworks2024,
  title = {Graph Neural Networks},
  author = {Corso, Gabriele and Stark, Hannes and Jegelka, Stefanie and Jaakkola, Tommi and Barzilay, Regina},
  date = {2024-03-07},
  journaltitle = {Nature Reviews Methods Primers},
  shortjournal = {Nat Rev Methods Primers},
  volume = {4},
  number = {1},
  pages = {1--13},
  publisher = {Nature Publishing Group},
  issn = {2662-8449},
  doi = {10.1038/s43586-024-00294-7},
  url = {https://www.nature.com/articles/s43586-024-00294-7},
  urldate = {2024-03-12},
  abstract = {iGraphs are flexible mathematical objects that can represent many entities and knowledge from different domains, including in the life sciences. Graph neural networks (GNNs) are mathematical models that can learn functions over graphs and are a leading approach for building predictive models on graph-structured data. This combination has enabled GNNs to advance the state of the art in many disciplines, from discovering new antibiotics and identifying drug-repurposing candidates to modelling physical systems and generating new molecules. This Primer provides a practical and accessible introduction to GNNs, describing their properties and applications to the life and physical sciences. Emphasis is placed on the practical implications of key theoretical limitations, new ideas to solve these challenges and important considerations when using GNNs on a new task.},
  langid = {english},
  keywords = {✅🦌,Computational biology and bioinformatics,Statistics},
  file = {/Users/michaelvolk/Zotero/storage/6AKYLCMG/Corso et al. - 2024 - Graph neural networks.pdf}
}

@article{cosmoGraphKernelNeural2024,
  title = {Graph Kernel Neural Networks},
  author = {Cosmo, Luca and Minello, Giorgia and Bicciato, Alessandro and Bronstein, Michael M. and Rodolà, Emanuele and Rossi, Luca and Torsello, Andrea},
  date = {2024},
  journaltitle = {IEEE transactions on neural networks and learning systems},
  publisher = {IEEE},
  url = {https://ieeexplore.ieee.org/abstract/document/10542111/},
  urldate = {2025-02-27},
  file = {/Users/michaelvolk/Zotero/storage/CFSDQXDK/Cosmo et al_2024_Graph kernel neural networks.pdf}
}

@article{costanzoChartingGeneticInteraction2011a,
  title = {Charting the Genetic Interaction Map of a Cell},
  author = {Costanzo, Michael and Baryshnikova, Anastasia and Myers, Chad L and Andrews, Brenda and Boone, Charles},
  date = {2011-02-01},
  journaltitle = {Current Opinion in Biotechnology},
  shortjournal = {Current Opinion in Biotechnology},
  series = {Analytical Biotechnology},
  volume = {22},
  number = {1},
  pages = {66--74},
  issn = {0958-1669},
  doi = {10.1016/j.copbio.2010.11.001},
  url = {https://www.sciencedirect.com/science/article/pii/S0958166910002193},
  urldate = {2023-12-06},
  abstract = {Genome sequencing projects have revealed a massive catalog of genes and astounding genetic diversity in a variety of organisms. We are now faced with the formidable challenge of assigning functions to thousands of genes, and how to use this information to understand how genes interact and coordinate cell function. Studies indicate that the majority of eukaryotic genes are dispensable, highlighting the extensive buffering of genomes against genetic and environmental perturbations. Such robustness poses a significant challenge to those seeking to understand the wiring diagram of the cell. Genome-scale screens for genetic interactions are an effective means to chart the network that underlies this functional redundancy. A complete atlas of genetic interactions offers the potential to assign functions to most genes identified by whole genome sequencing projects and to delineate a functional wiring diagram of the cell. Perhaps more importantly, mapping genetic networks on a large-scale will shed light on the general principles and rules governing genetic networks and provide valuable information regarding the important but elusive relationship between genotype and phenotype.},
  annotation = {126 citations (Semantic Scholar/DOI) [2023-12-05]},
  file = {/Users/michaelvolk/Zotero/storage/QD3YAXI2/S0958166910002193.html}
}

@article{costanzoGlobalGeneticInteraction2016,
  title = {A Global Genetic Interaction Network Maps a Wiring Diagram of Cellular Function},
  author = {Costanzo, M. and VanderSluis, B. and Koch, E. N. and Baryshnikova, A. and Pons, C. and Tan, G. and Wang, W. and Usaj, M. and Hanchard, J. and Lee, S. D. and Pelechano, V. and Styles, E. B. and Billmann, M. and family=Leeuwen, given=J., prefix=van, useprefix=true and family=Dyk, given=N., prefix=van, useprefix=true and Lin, Z.-Y. and Kuzmin, E. and Nelson, J. and Piotrowski, J. S. and Srikumar, T. and Bahr, S. and Chen, Y. and Deshpande, R. and Kurat, C. F. and Li, S. C. and Li, Z. and Usaj, M. M. and Okada, H. and Pascoe, N. and San Luis, B.-J. and Sharifpoor, S. and Shuteriqi, E. and Simpkins, S. W. and Snider, J. and Suresh, H. G. and Tan, Y. and Zhu, H. and Malod-Dognin, N. and Janjic, V. and Przulj, N. and Troyanskaya, O. G. and Stagljar, I. and Xia, T. and Ohya, Y. and Gingras, A.-C. and Raught, B. and Boutros, M. and Steinmetz, L. M. and Moore, C. L. and Rosebrock, A. P. and Caudy, A. A. and Myers, C. L. and Andrews, B. and Boone, C.},
  date = {2016-09-23},
  journaltitle = {Science},
  shortjournal = {Science},
  volume = {353},
  number = {6306},
  pages = {aaf1420-aaf1420},
  issn = {0036-8075, 1095-9203},
  doi = {10.1126/science.aaf1420},
  url = {https://www.sciencemag.org/lookup/doi/10.1126/science.aaf1420},
  urldate = {2022-02-08},
  langid = {english},
  keywords = {✅,🦌},
  annotation = {844 citations (Semantic Scholar/DOI) [2022-11-26]\\
683 citations (Crossref) [2022-04-15]},
  file = {/Users/michaelvolk/Zotero/storage/8I7IN8JR/Costanzo et al. - 2016 - A global genetic interaction network maps a wiring.pdf;/Users/michaelvolk/Zotero/storage/CB56ZJ74/SI-Costanzo et al. - 2016 - A global genetic interaction network maps a wiring.pdf}
}

@article{costanzoGlobalGeneticNetworks2019a,
  title = {Global {{Genetic Networks}} and the {{Genotype-to-Phenotype Relationship}}},
  author = {Costanzo, Michael and Kuzmin, Elena and family=Leeuwen, given=Jolanda, prefix=van, useprefix=false and Mair, Barbara and Moffat, Jason and Boone, Charles and Andrews, Brenda},
  date = {2019-03-21},
  journaltitle = {Cell},
  shortjournal = {Cell},
  volume = {177},
  number = {1},
  eprint = {30901552},
  eprinttype = {pmid},
  pages = {85--100},
  publisher = {Elsevier},
  issn = {0092-8674, 1097-4172},
  doi = {10.1016/j.cell.2019.01.033},
  url = {https://www.cell.com/cell/abstract/S0092-8674(19)30096-0},
  urldate = {2024-07-01},
  langid = {english},
  annotation = {158 citations (Semantic Scholar/DOI) [2024-07-01]},
  file = {/Users/michaelvolk/Zotero/storage/S5UDAEVG/Costanzo et al_2019_Global Genetic Networks and the Genotype-to-Phenotype Relationship.pdf}
}

@article{covingtonUnlockingHiddenTreasures2025,
  title = {Unlocking Hidden Treasures: The Evolution of High-Throughput Mass Spectrometry in Screening for Cryptic Natural Products},
  shorttitle = {Unlocking Hidden Treasures},
  author = {Covington, Brett C. and Seyedsayamdost, Mohammad R.},
  date = {2025-01-20},
  journaltitle = {Natural Product Reports},
  shortjournal = {Nat. Prod. Rep.},
  publisher = {The Royal Society of Chemistry},
  issn = {1460-4752},
  doi = {10.1039/D4NP00026A},
  url = {https://pubs.rsc.org/en/content/articlelanding/2025/np/d4np00026a},
  urldate = {2025-04-06},
  abstract = {Covering: 1994 to 2024Historically, microbial natural product discovery has been predominantly guided by biological activity from crude microbial extracts with metabolite characterization proceeding one molecule at a time. Despite decades of bioactivity-guided isolations, genomic evidence now suggests that we have only accessed a small fraction of the total natural product potential from microorganisms and that the products of the vast majority of biosynthetic pathways remain to be identified. Here we describe recent advancements that have enabled high-throughput mass spectrometry and comparative metabolomics, which in turn facilitate high-throughput natural product discovery. These advancement promise to fully unlock the reservoir of microbial natural products.},
  langid = {english},
  annotation = {0 citations (Semantic Scholar/DOI) [2025-04-06]},
  file = {/Users/michaelvolk/Zotero/storage/A9LXMEAH/Covington and Seyedsayamdost - 2025 - Unlocking hidden treasures the evolution of high-.pdf}
}

@article{coxPredictionPeptideMass2023,
  title = {Prediction of Peptide Mass Spectral Libraries with Machine Learning},
  author = {Cox, Jürgen},
  date = {2023-01},
  journaltitle = {Nature Biotechnology},
  shortjournal = {Nat Biotechnol},
  volume = {41},
  number = {1},
  pages = {33--43},
  publisher = {Nature Publishing Group},
  issn = {1546-1696},
  doi = {10.1038/s41587-022-01424-w},
  url = {https://www.nature.com/articles/s41587-022-01424-w},
  urldate = {2024-03-11},
  abstract = {The recent development of machine learning methods to identify peptides in complex mass spectrometric data constitutes a major breakthrough in proteomics. Longstanding methods for peptide identification, such as search engines and experimental spectral libraries, are being superseded by deep learning models that allow the fragmentation spectra of peptides to be predicted from their amino acid sequence. These new approaches, including recurrent neural networks and convolutional neural networks, use predicted in silico spectral libraries rather than experimental libraries to achieve higher sensitivity and/or specificity in the analysis of proteomics data. Machine learning is galvanizing applications that involve large search spaces, such as immunopeptidomics and proteogenomics. Current challenges in the field include the prediction of spectra for peptides with post-translational modifications and for cross-linked pairs of peptides. Permeation of machine-learning-based spectral prediction into search engines and spectrum-centric data-independent acquisition workflows for diverse peptide classes and measurement conditions will continue to push sensitivity and dynamic range in proteomics applications in the coming years.},
  langid = {english},
  keywords = {Machine learning,Proteome informatics,Proteomics},
  annotation = {26 citations (Semantic Scholar/DOI) [2024-03-11]},
  file = {/Users/michaelvolk/Zotero/storage/BTSBWC7W/Cox_2023_Prediction of peptide mass spectral libraries with machine learning.pdf}
}

@online{crawshawSLAWScaledLoss2021,
  title = {{{SLAW}}: {{Scaled Loss Approximate Weighting}} for {{Efficient Multi-Task Learning}}},
  shorttitle = {{{SLAW}}},
  author = {Crawshaw, Michael and Košecká, Jana},
  date = {2021-09-16},
  eprint = {2109.08218},
  eprinttype = {arXiv},
  eprintclass = {cs},
  doi = {10.48550/arXiv.2109.08218},
  url = {http://arxiv.org/abs/2109.08218},
  urldate = {2025-02-27},
  abstract = {Multi-task learning (MTL) is a subfield of machine learning with important applications, but the multi-objective nature of optimization in MTL leads to difficulties in balancing training between tasks. The best MTL optimization methods require individually computing the gradient of each task's loss function, which impedes scalability to a large number of tasks. In this paper, we propose Scaled Loss Approximate Weighting (SLAW), a method for multi-task optimization that matches the performance of the best existing methods while being much more efficient. SLAW balances learning between tasks by estimating the magnitudes of each task's gradient without performing any extra backward passes. We provide theoretical and empirical justification for SLAW's estimation of gradient magnitudes. Experimental results on non-linear regression, multi-task computer vision, and virtual screening for drug discovery demonstrate that SLAW is significantly more efficient than strong baselines without sacrificing performance and applicable to a diverse range of domains.},
  pubstate = {prepublished},
  keywords = {Computer Science - Machine Learning},
  annotation = {7 citations (Semantic Scholar/arXiv) [2025-02-27]},
  file = {/Users/michaelvolk/Zotero/storage/MRUWQB2I/Crawshaw_Košecká_2021_SLAW.pdf;/Users/michaelvolk/Zotero/storage/W5T6HXEK/2109.html}
}

@online{cuiDecoupledKullbackLeiblerDivergence2024,
  title = {Decoupled {{Kullback-Leibler Divergence Loss}}},
  author = {Cui, Jiequan and Tian, Zhuotao and Zhong, Zhisheng and Qi, Xiaojuan and Yu, Bei and Zhang, Hanwang},
  date = {2024-10-27},
  eprint = {2305.13948},
  eprinttype = {arXiv},
  eprintclass = {cs},
  doi = {10.48550/arXiv.2305.13948},
  url = {http://arxiv.org/abs/2305.13948},
  urldate = {2025-02-27},
  abstract = {In this paper, we delve deeper into the Kullback-Leibler (KL) Divergence loss and mathematically prove that it is equivalent to the Decoupled Kullback-Leibler (DKL) Divergence loss that consists of 1) a weighted Mean Square Error (wMSE) loss and 2) a Cross-Entropy loss incorporating soft labels. Thanks to the decomposed formulation of DKL loss, we have identified two areas for improvement. Firstly, we address the limitation of KL/DKL in scenarios like knowledge distillation by breaking its asymmetric optimization property. This modification ensures that the \$\textbackslash mathbf\{w\}\$MSE component is always effective during training, providing extra constructive cues. Secondly, we introduce class-wise global information into KL/DKL to mitigate bias from individual samples. With these two enhancements, we derive the Improved Kullback-Leibler (IKL) Divergence loss and evaluate its effectiveness by conducting experiments on CIFAR-10/100 and ImageNet datasets, focusing on adversarial training, and knowledge distillation tasks. The proposed approach achieves new state-of-the-art adversarial robustness on the public leaderboard -- RobustBench and competitive performance on knowledge distillation, demonstrating the substantial practical merits. Our code is available at https://github.com/jiequancui/DKL.},
  pubstate = {prepublished},
  keywords = {Computer Science - Computer Vision and Pattern Recognition,Computer Science - Machine Learning},
  annotation = {31 citations (Semantic Scholar/arXiv) [2025-02-27]\\
31 citations (Semantic Scholar/DOI) [2025-02-27]},
  file = {/Users/michaelvolk/Zotero/storage/V2DKF68M/Cui et al_2024_Decoupled Kullback-Leibler Divergence Loss.pdf;/Users/michaelvolk/Zotero/storage/FWQTXEEN/2305.html}
}

@article{cuiScGPTBuildingFoundation2024,
  title = {{{scGPT}}: Toward Building a Foundation Model for Single-Cell Multi-Omics Using Generative {{AI}}},
  shorttitle = {{{scGPT}}},
  author = {Cui, Haotian and Wang, Chloe and Maan, Hassaan and Pang, Kuan and Luo, Fengning and Duan, Nan and Wang, Bo},
  date = {2024-08},
  journaltitle = {Nature Methods},
  shortjournal = {Nat Methods},
  volume = {21},
  number = {8},
  pages = {1470--1480},
  publisher = {Nature Publishing Group},
  issn = {1548-7105},
  doi = {10.1038/s41592-024-02201-0},
  url = {https://www.nature.com/articles/s41592-024-02201-0},
  urldate = {2025-02-13},
  abstract = {Generative pretrained models have achieved remarkable success in various domains such as language and computer vision. Specifically, the combination of large-scale diverse datasets and pretrained transformers has emerged as a promising approach for developing foundation models. Drawing parallels between language and cellular biology (in which texts comprise words; similarly, cells are defined by genes), our study probes the applicability of foundation models to advance cellular biology and genetic research. Using burgeoning single-cell sequencing data, we have constructed a foundation model for single-cell biology, scGPT, based on a generative pretrained transformer across a repository of over 33 million cells. Our findings illustrate that scGPT effectively distills critical biological insights concerning genes and cells. Through further adaptation of transfer learning, scGPT can be optimized to achieve superior performance across diverse downstream applications. This includes tasks such as cell type annotation, multi-batch integration, multi-omic integration, perturbation response prediction and gene network inference.},
  langid = {english},
  keywords = {Computational models,Machine learning,Software,Transcriptomics},
  annotation = {202 citations (Semantic Scholar/DOI) [2025-02-13]},
  file = {/Users/michaelvolk/Zotero/storage/46CZYPAL/Cui et al. - 2024 - scGPT toward building a foundation model for sing.pdf}
}

@article{cuiScGPTBuildingFoundation2024a,
  title = {{{scGPT}}: Toward Building a Foundation Model for Single-Cell Multi-Omics Using Generative {{AI}}},
  shorttitle = {{{scGPT}}},
  author = {Cui, Haotian and Wang, Chloe and Maan, Hassaan and Pang, Kuan and Luo, Fengning and Duan, Nan and Wang, Bo},
  date = {2024-08},
  journaltitle = {Nature Methods},
  shortjournal = {Nat Methods},
  volume = {21},
  number = {8},
  pages = {1470--1480},
  publisher = {Nature Publishing Group},
  issn = {1548-7105},
  doi = {10.1038/s41592-024-02201-0},
  url = {https://www.nature.com/articles/s41592-024-02201-0},
  urldate = {2025-02-18},
  abstract = {Generative pretrained models have achieved remarkable success in various domains such as language and computer vision. Specifically, the combination of large-scale diverse datasets and pretrained transformers has emerged as a promising approach for developing foundation models. Drawing parallels between language and cellular biology (in which texts comprise words; similarly, cells are defined by genes), our study probes the applicability of foundation models to advance cellular biology and genetic research. Using burgeoning single-cell sequencing data, we have constructed a foundation model for single-cell biology, scGPT, based on a generative pretrained transformer across a repository of over 33 million cells. Our findings illustrate that scGPT effectively distills critical biological insights concerning genes and cells. Through further adaptation of transfer learning, scGPT can be optimized to achieve superior performance across diverse downstream applications. This includes tasks such as cell type annotation, multi-batch integration, multi-omic integration, perturbation response prediction and gene network inference.},
  langid = {english},
  keywords = {Computational models,Machine learning,Software,Transcriptomics},
  annotation = {205 citations (Semantic Scholar/DOI) [2025-02-17]},
  file = {/Users/michaelvolk/Zotero/storage/EJHUJ87B/Cui et al_2024_scGPT.pdf;/Users/michaelvolk/Zotero/storage/Q6ECAYJR/SI - Cui et al. - 2024 - scGPT toward building a foundation model for sing.pdf}
}

@article{culleyMechanismawareMultiomicMachinelearning2020,
  title = {A Mechanism-Aware and Multiomic Machine-Learning Pipeline Characterizes Yeast Cell Growth},
  author = {Culley, Christopher and Vijayakumar, Supreeta and Zampieri, Guido and Angione, Claudio},
  date = {2020-08-04},
  journaltitle = {Proceedings of the National Academy of Sciences},
  shortjournal = {Proc Natl Acad Sci USA},
  volume = {117},
  number = {31},
  pages = {18869--18879},
  issn = {0027-8424, 1091-6490},
  doi = {10.1073/pnas.2002959117},
  url = {http://www.pnas.org/lookup/doi/10.1073/pnas.2002959117},
  urldate = {2022-02-08},
  abstract = {Metabolic modeling and machine learning are key components in the emerging next generation of systems and synthetic biology tools, targeting the genotype–phenotype–environment relationship. Rather than being used in isolation, it is becoming clear that their value is maximized when they are combined. However, the potential of integrating these two frameworks for omic data augmentation and integration is largely unexplored. We propose, rigorously assess, and compare machine-learning–based data integration techniques, combining gene expression profiles with computationally generated metabolic flux data to predict yeast cell growth. To this end, we create strain-specific metabolic models for 1,143               Saccharomyces cerevisiae               mutants and we test 27 machine-learning methods, incorporating state-of-the-art feature selection and multiview learning approaches. We propose a multiview neural network using fluxomic and transcriptomic data, showing that the former increases the predictive accuracy of the latter and reveals functional patterns that are not directly deducible from gene expression alone. We test the proposed neural network on a further 86 strains generated in a different experiment, therefore verifying its robustness to an additional independent dataset. Finally, we show that introducing mechanistic flux features improves the predictions also for knockout strains whose genes were not modeled in the metabolic reconstruction. Our results thus demonstrate that fusing experimental cues with in silico models, based on known biochemistry, can contribute with disjoint information toward biologically informed and interpretable machine learning. Overall, this study provides tools for understanding and manipulating complex phenotypes, increasing both the prediction accuracy and the extent of discernible mechanistic biological insights.},
  langid = {english},
  keywords = {✅,🦌,machine-learning,multiomics},
  annotation = {30 citations (Semantic Scholar/DOI) [2022-11-26]\\
14 citations (Crossref) [2022-04-15]},
  file = {/Users/michaelvolk/Zotero/storage/IZVJ2Q44/Culley et al. - 2020 - A mechanism-aware and multiomic machine-learning p.pdf;/Users/michaelvolk/Zotero/storage/U82ZTZVL/SI - Culley et al. - 2020 - A mechanism-aware and multiomic machine-learning p.pdf}
}

@online{dalla-torreNucleotideTransformerBuilding2023,
  title = {The {{Nucleotide Transformer}}: {{Building}} and {{Evaluating Robust Foundation Models}} for {{Human Genomics}}},
  shorttitle = {The {{Nucleotide Transformer}}},
  author = {Dalla-Torre, Hugo and Gonzalez, Liam and Revilla, Javier Mendoza and Carranza, Nicolas Lopez and Grzywaczewski, Adam Henryk and Oteri, Francesco and Dallago, Christian and Trop, Evan and Sirelkhatim, Hassan and Richard, Guillaume and Skwark, Marcin and Beguir, Karim and Lopez, Marie and Pierrot, Thomas},
  date = {2023-01-15},
  eprinttype = {bioRxiv},
  eprintclass = {New Results},
  pages = {2023.01.11.523679},
  doi = {10.1101/2023.01.11.523679},
  url = {https://www.biorxiv.org/content/10.1101/2023.01.11.523679v1},
  urldate = {2023-05-27},
  abstract = {Closing the gap between measurable genetic information and observable traits is a longstanding challenge in genomics. Yet, the prediction of molecular phenotypes from DNA sequences alone remains limited and inaccurate, often driven by the scarcity of annotated data and the inability to transfer learnings between prediction tasks. Here, we present an extensive study of foundation models pre-trained on DNA sequences, named the Nucleotide Transformer, integrating information from 3,202 diverse human genomes, as well as 850 genomes from a wide range of species, including model and non-model organisms. These transformer models yield transferable, context-specific representations of nucleotide sequences, which allow for accurate molecular phenotype prediction even in low-data settings. We show that the representations alone match or outperform specialized methods on 11 of 18 prediction tasks, and up to 15 after fine-tuning. Despite no supervision, the transformer models learnt to focus attention on key genomic elements, including those that regulate gene expression, such as enhancers. Lastly, we demonstrate that utilizing model representations alone can improve the prioritization of functional genetic variants. The training and application of foundational models in genomics explored in this study provide a widely applicable stepping stone to bridge the gap of accurate molecular phenotype prediction from DNA sequence alone.},
  langid = {english},
  pubstate = {prepublished},
  keywords = {🦌✅},
  annotation = {1 citations (Semantic Scholar/DOI) [2023-05-27]},
  file = {/Users/michaelvolk/Zotero/storage/M2XTQGDZ/Dalla-Torre et al. - 2023 - The Nucleotide Transformer Building and Evaluatin.pdf}
}

@inproceedings{deacExpanderGraphPropagation2022a,
  title = {Expander {{Graph Propagation}}},
  booktitle = {Proceedings of the {{First Learning}} on {{Graphs Conference}}},
  author = {Deac, Andreea and Lackenby, Marc and Veličković, Petar},
  date = {2022-12-21},
  pages = {38:1-38:18},
  publisher = {PMLR},
  issn = {2640-3498},
  url = {https://proceedings.mlr.press/v198/deac22a.html},
  urldate = {2025-03-01},
  abstract = {Deploying graph neural networks (GNNs) on whole-graph classification or regression tasks is known to be challenging: it often requires computing node features that are mindful of both local interactions in their neighbourhood and the global context of the graph structure. GNN architectures that navigate this space need to avoid pathological behaviours, such as bottlenecks and oversquashing, while ideally having linear time and space complexity requirements. In this work, we propose an elegant approach based on propagating information over expander graphs. We leverage an efficient method for constructing expander graphs of a given size, and use this insight to propose the EGP model. We show that EGP is able to address all of the above concerns, while requiring minimal effort to set up, and provide evidence of its empirical utility on relevant graph classification datasets and baselines in the Open Graph Benchmark. Importantly, using expander graphs as a template for message passing necessarily gives rise to negative curvature. While this appears to be counterintuitive in light of recent related work on oversquashing, we theoretically demonstrate that negatively curved edges are likely to be required to obtain scalable message passing without bottlenecks. To the best of our knowledge, this is a previously unstudied result in the context of graph representation learning, and we believe our analysis paves the way to a novel class of scalable methods to counter oversquashing in GNNs.},
  eventtitle = {Learning on {{Graphs Conference}}},
  langid = {english},
  file = {/Users/michaelvolk/Zotero/storage/T2AEDVL3/Deac et al_2022_Expander Graph Propagation.pdf}
}

@article{deboerDecipheringEukaryoticGeneregulatory2020,
  title = {Deciphering Eukaryotic Gene-Regulatory Logic with 100 Million Random Promoters},
  author = {family=Boer, given=Carl G., prefix=de, useprefix=true and Vaishnav, Eeshit Dhaval and Sadeh, Ronen and Abeyta, Esteban Luis and Friedman, Nir and Regev, Aviv},
  date = {2020-01},
  journaltitle = {Nature Biotechnology},
  shortjournal = {Nat Biotechnol},
  volume = {38},
  number = {1},
  pages = {56--65},
  publisher = {Nature Publishing Group},
  issn = {1546-1696},
  doi = {10.1038/s41587-019-0315-8},
  url = {https://www.nature.com/articles/s41587-019-0315-8},
  urldate = {2023-06-28},
  abstract = {How transcription factors (TFs) interpret cis-regulatory DNA sequence to control gene expression remains unclear, largely because past studies using native and engineered sequences had insufficient scale. Here, we measure the expression output of {$>$}100 million synthetic yeast promoter sequences that are fully random. These sequences yield diverse, reproducible expression levels that can be explained by their chance inclusion of functional TF binding sites. We use machine learning to build interpretable models of transcriptional regulation that predict \textasciitilde 94\% of the expression driven from independent test promoters and \textasciitilde 89\% of the expression driven from native yeast promoter fragments. These models allow us to characterize each TF’s specificity, activity and interactions with chromatin. TF activity depends on binding-site strand, position, DNA helical face and chromatin context. Notably, expression level is influenced by weak regulatory interactions, which confound designed-sequence studies. Our analyses show that massive-throughput assays of fully random DNA can provide the big data necessary to develop complex, predictive models of gene regulation.},
  issue = {1},
  langid = {english},
  keywords = {Gene expression,Gene regulation,Gene regulatory networks,Machine learning,Regulatory networks},
  annotation = {0 citations (Semantic Scholar/DOI) [2023-06-28]},
  file = {/Users/michaelvolk/Zotero/storage/7NBIKNYD/de Boer et al_2020_Deciphering eukaryotic gene-regulatory logic with 100 million random promoters.pdf}
}

@book{DefinitiveGuideGraph,
  title = {The {{Definitive Guide}} to {{Graph Databases}} for the {{RDBMS Developer}}},
  author = {Hunger, Michael and Boyd, Ryan and Lyon, William},
  url = {https://neo4j.com/whitepapers/definitive-guide-graph-databases-rdbms-developer/},
  urldate = {2023-11-20},
  abstract = {Read this ebook to learn the differences between RDBMS and graph database data models, query languages, and more.},
  langid = {english},
  keywords = {neo4j,RDBMS,relational-database},
  file = {/Users/michaelvolk/Zotero/storage/R8QJCGCE/Hunger et al. - The Definitive Guide to Graph Databases for the RD.pdf;/Users/michaelvolk/Zotero/storage/FH4UQPTT/thanks.html}
}

@article{delgadoComputationalMethodsGene2019a,
  title = {Computational Methods for {{Gene Regulatory Networks}} Reconstruction and Analysis: {{A}} Review},
  shorttitle = {Computational Methods for {{Gene Regulatory Networks}} Reconstruction and Analysis},
  author = {Delgado, Fernando M. and Gómez-Vela, Francisco},
  date = {2019-04},
  journaltitle = {Artificial Intelligence in Medicine},
  shortjournal = {Artificial Intelligence in Medicine},
  volume = {95},
  pages = {133--145},
  issn = {09333657},
  doi = {10.1016/j.artmed.2018.10.006},
  url = {https://linkinghub.elsevier.com/retrieve/pii/S0933365718303865},
  urldate = {2023-10-14},
  abstract = {In the recent years, the vast amount of genetic information generated by new-generation approaches, have led to the need of new data handling methods. The integrative analysis of diverse-nature gene information could provide a much-sought overview to study complex biological systems and processes. In this sense, Gene Regulatory Networks (GRN) arise as an increasingly-promising tool for the modelling and analysis of biological processes. This review is an attempt to summarize the state of the art in the field of GRNs. Essential points in the field are addressed, thereof: (a) the type of data used for network generation, (b) machine learning methods and tools used for network generation, (c) model optimization and (d) computational approaches used for network validation. This survey is intended to provide an overview of the subject for readers to improve their knowledge in the field of GRN for future research.},
  langid = {english},
  annotation = {92 citations (Semantic Scholar/DOI) [2023-10-14]},
  file = {/Users/michaelvolk/Zotero/storage/UUBVZ7XJ/Delgado and Gómez-Vela - 2019 - Computational methods for Gene Regulatory Networks.pdf}
}

@online{dengPhyGCNPretrainedHypergraph2023,
  title = {{{PhyGCN}}: {{Pre-trained Hypergraph Convolutional Neural Networks}} with {{Self-supervised Learning}}},
  shorttitle = {{{PhyGCN}}},
  author = {Deng, Yihe and Zhang, Ruochi and Xu, Pan and Ma, Jian and Gu, Quanquan},
  date = {2023-10-02},
  eprinttype = {bioRxiv},
  eprintclass = {New Results},
  pages = {2023.10.01.560404},
  doi = {10.1101/2023.10.01.560404},
  url = {https://www.biorxiv.org/content/10.1101/2023.10.01.560404v1},
  urldate = {2025-04-24},
  abstract = {Hypergraphs are powerful tools for modeling complex interactions across various domains, including biomedicine. However, learning meaningful node representations from hypergraphs remains a challenge. Existing supervised methods often lack generalizability, thereby limiting their real-world applications. We propose a new method, Pre-trained Hypergraph Convolutional Neural Networks with Self-supervised Learning (PhyGCN), which leverages hypergraph structure for self-supervision to enhance node representations. PhyGCN introduces a unique training strategy that integrates variable hyperedge sizes with self-supervised learning, enabling improved generalization to unseen data. Applications on multi-way chromatin interactions and polypharmacy side-effects demonstrate the effectiveness of PhyGCN. As a generic framework for high-order interaction datasets with abundant unlabeled data, PhyGCN holds strong potential for enhancing hypergraph node representations across various domains.},
  langid = {english},
  pubstate = {prepublished},
  annotation = {0 citations (Semantic Scholar/DOI) [2025-04-23]},
  file = {/Users/michaelvolk/Zotero/storage/2WRNZKHX/Deng et al_2023_PhyGCN.pdf}
}

@online{dengPolynormerPolynomialExpressiveGraph2024,
  title = {Polynormer: {{Polynomial-Expressive Graph Transformer}} in {{Linear Time}}},
  shorttitle = {Polynormer},
  author = {Deng, Chenhui and Yue, Zichao and Zhang, Zhiru},
  date = {2024-04-06},
  eprint = {2403.01232},
  eprinttype = {arXiv},
  eprintclass = {cs},
  doi = {10.48550/arXiv.2403.01232},
  url = {http://arxiv.org/abs/2403.01232},
  urldate = {2025-02-27},
  abstract = {Graph transformers (GTs) have emerged as a promising architecture that is theoretically more expressive than message-passing graph neural networks (GNNs). However, typical GT models have at least quadratic complexity and thus cannot scale to large graphs. While there are several linear GTs recently proposed, they still lag behind GNN counterparts on several popular graph datasets, which poses a critical concern on their practical expressivity. To balance the trade-off between expressivity and scalability of GTs, we propose Polynormer, a polynomial-expressive GT model with linear complexity. Polynormer is built upon a novel base model that learns a high-degree polynomial on input features. To enable the base model permutation equivariant, we integrate it with graph topology and node features separately, resulting in local and global equivariant attention models. Consequently, Polynormer adopts a linear local-to-global attention scheme to learn high-degree equivariant polynomials whose coefficients are controlled by attention scores. Polynormer has been evaluated on \$13\$ homophilic and heterophilic datasets, including large graphs with millions of nodes. Our extensive experiment results show that Polynormer outperforms state-of-the-art GNN and GT baselines on most datasets, even without the use of nonlinear activation functions.},
  pubstate = {prepublished},
  keywords = {Computer Science - Artificial Intelligence,Computer Science - Machine Learning},
  annotation = {21 citations (Semantic Scholar/arXiv) [2025-02-27]\\
21 citations (Semantic Scholar/DOI) [2025-02-27]},
  file = {/Users/michaelvolk/Zotero/storage/7NAYZYZD/Deng et al_2024_Polynormer.pdf;/Users/michaelvolk/Zotero/storage/9YIYK7CW/2403.html}
}

@article{dengPretrainedHypergraphConvolutional2024,
  title = {Pre-Trained {{Hypergraph Convolutional Neural Networks}} with {{Self-supervised Learning}}},
  author = {Deng, Yihe and Zhang, Ruochi and Xu, Pan and Ma, Jian and Gu, Quanquan},
  date = {2024-04-25},
  journaltitle = {Transactions on Machine Learning Research},
  issn = {2835-8856},
  url = {https://openreview.net/forum?id=0VWXWPmctm},
  urldate = {2025-04-24},
  abstract = {Hypergraphs are powerful tools for modeling complex interactions across various domains, including biomedicine. However, learning meaningful node representations from hypergraphs remains a challenge. Existing supervised methods often lack generalizability, thereby limiting their real-world applications. We propose a new method, Pre-trained Hypergraph Convolutional Neural Networks with Self-supervised Learning (PhyGCN), which leverages hypergraph structure for self-supervision to enhance node representations. PhyGCN introduces a unique training strategy that integrates variable hyperedge sizes with self-supervised learning, enabling improved generalization to unseen data. Applications on multi-way chromatin interactions and polypharmacy side-effects demonstrate the effectiveness of PhyGCN. As a generic framework for high-order interaction datasets with abundant unlabeled data, PhyGCN holds strong potential for enhancing hypergraph node representations across various domains.},
  langid = {english},
  file = {/Users/michaelvolk/Zotero/storage/C6EPMGFB/Deng et al_2024_Pre-trained Hypergraph Convolutional Neural Networks with Self-supervised.pdf}
}

@inproceedings{digiovanniOversquashingMessagePassing2023,
  title = {On Over-Squashing in Message Passing Neural Networks: {{The}} Impact of Width, Depth, and Topology},
  shorttitle = {On Over-Squashing in Message Passing Neural Networks},
  booktitle = {International Conference on Machine Learning},
  author = {Di Giovanni, Francesco and Giusti, Lorenzo and Barbero, Federico and Luise, Giulia and Lio, Pietro and Bronstein, Michael M.},
  date = {2023},
  pages = {7865--7885},
  publisher = {PMLR},
  url = {http://proceedings.mlr.press/v202/di-giovanni23a.html},
  urldate = {2025-02-27},
  file = {/Users/michaelvolk/Zotero/storage/SSYFB3RV/Di Giovanni et al_2023_On over-squashing in message passing neural networks.pdf}
}

@article{dixitPerturbSeqDissectingMolecular2016,
  title = {Perturb-{{Seq}}: {{Dissecting Molecular Circuits}} with {{Scalable Single-Cell RNA Profiling}} of {{Pooled Genetic Screens}}},
  shorttitle = {Perturb-{{Seq}}},
  author = {Dixit, Atray and Parnas, Oren and Li, Biyu and Chen, Jenny and Fulco, Charles P. and Jerby-Arnon, Livnat and Marjanovic, Nemanja D. and Dionne, Danielle and Burks, Tyler and Raychowdhury, Raktima and Adamson, Britt and Norman, Thomas M. and Lander, Eric S. and Weissman, Jonathan S. and Friedman, Nir and Regev, Aviv},
  date = {2016-12-15},
  journaltitle = {Cell},
  shortjournal = {Cell},
  volume = {167},
  number = {7},
  eprint = {27984732},
  eprinttype = {pmid},
  pages = {1853-1866.e17},
  publisher = {Elsevier},
  issn = {0092-8674, 1097-4172},
  doi = {10.1016/j.cell.2016.11.038},
  url = {https://www.cell.com/cell/abstract/S0092-8674(16)31610-5},
  urldate = {2025-03-17},
  langid = {english},
  keywords = {CRISPR,epistasis,genetic interactions,pooled screen,single-cell RNA-seq},
  annotation = {1263 citations (Semantic Scholar/DOI) [2025-03-16]},
  file = {/Users/michaelvolk/Zotero/storage/K2W8RV8D/Dixit et al_2016_Perturb-Seq.pdf}
}

@inproceedings{dongRayleighQuotientGraph2023,
  title = {Rayleigh {{Quotient Graph Neural Networks}} for {{Graph-level Anomaly Detection}}},
  author = {Dong, Xiangyu and Zhang, Xingyi and Wang, Sibo},
  date = {2023-10-13},
  url = {https://openreview.net/forum?id=4UIBysXjVq},
  urldate = {2025-02-27},
  abstract = {Graph-level anomaly detection has gained significant attention as it finds applications in various domains, such as cancer diagnosis and enzyme prediction. However, existing methods fail to capture the spectral properties of graph anomalies, resulting in unexplainable framework design and unsatisfying performance. In this paper, we re-investigate the spectral differences between anomalous and normal graphs. Our main observation shows a significant disparity in the accumulated spectral energy between these two classes. Moreover, we prove that the accumulated spectral energy of the graph signal can be represented by its Rayleigh Quotient, indicating that the Rayleigh Quotient is a driving factor behind the anomalous properties of graphs. Motivated by this, we propose Rayleigh Quotient Graph Neural Network (RQGNN), the first spectral GNN that explores the inherent spectral features of anomalous graphs for graph-level anomaly detection. Specifically, we introduce a novel framework with two components: the Rayleigh Quotient learning component (RQL) and Chebyshev Wavelet GNN with RQ-pooling (CWGNN-RQ). RQL explicitly captures the Rayleigh Quotient of graphs and CWGNN-RQ implicitly explores the spectral space of graphs. Extensive experiments on 10 real-world datasets show that RQGNN outperforms the best rival by 6.74\% in Macro-F1 score and 1.44\% in AUC, demonstrating the effectiveness of our framework. Our code is available at https://github.com/xydong127/RQGNN.},
  eventtitle = {The {{Twelfth International Conference}} on {{Learning Representations}}},
  langid = {english},
  file = {/Users/michaelvolk/Zotero/storage/C8VQCUBL/Dong et al_2023_Rayleigh Quotient Graph Neural Networks for Graph-level Anomaly Detection.pdf}
}

@article{dubois-mignonGeneEssentialityVariability2022,
  title = {Gene Essentiality and Variability: {{What}} Is the Link? {{A}} within- and between-Species Perspective},
  shorttitle = {Gene Essentiality and Variability},
  author = {Dubois-Mignon, Tania and Monget, Philippe},
  date = {2022},
  journaltitle = {BioEssays},
  volume = {44},
  number = {11},
  pages = {2200132},
  issn = {1521-1878},
  doi = {10.1002/bies.202200132},
  url = {https://onlinelibrary.wiley.com/doi/abs/10.1002/bies.202200132},
  urldate = {2024-06-22},
  abstract = {A gene is considered essential when its loss of function results in a deleterious phenotype, hugely reducing the organism's viability or fitness. However, the link between the essentiality of a gene and its degree of polymorphism is unclear. In this review, we show that there is a place for a certain degree of variability, even for essential genes. We first study the role of infectious diseases in the prevalence of genetic disorders among humans: balancing selection has selected harmful variants due to the selective pressure of pathogens because the heterozygous carrier can resist them. Then we show that the environment can induce adaptation of species by rapidly evolving genes. We also study the role of positive selection on speciation, particularly upon genes of the immune, reproductive and nervous systems. Finally, we highlight the role of regulatory sequences in changes in morphology between species and adaptation to the environment within species.},
  langid = {english},
  keywords = {evolution,gene essentiality,gene variability,human,human disease},
  annotation = {1 citations (Semantic Scholar/DOI) [2024-06-21]},
  file = {/Users/michaelvolk/Zotero/storage/IN5BEFB9/Dubois-Mignon_Monget_2022_Gene essentiality and variability.pdf;/Users/michaelvolk/Zotero/storage/4Z7XBCTM/bies.html}
}

@article{dutkowskiGeneOntologyInferred2013,
  title = {A Gene Ontology Inferred from Molecular Networks},
  author = {Dutkowski, Janusz and Kramer, Michael and Surma, Michal A. and Balakrishnan, Rama and Cherry, J. Michael and Krogan, Nevan J. and Ideker, Trey},
  date = {2013-01},
  journaltitle = {Nature Biotechnology},
  shortjournal = {Nat Biotechnol},
  volume = {31},
  number = {1},
  pages = {38--45},
  publisher = {Nature Publishing Group},
  issn = {1546-1696},
  doi = {10.1038/nbt.2463},
  url = {https://www.nature.com/articles/nbt.2463},
  urldate = {2023-10-24},
  abstract = {High-throughput network maps are used to automatically (or semi-automatically) reconstruct an ontology that recapitulates much of the Gene Ontology and finds additional terms and relations.},
  issue = {1},
  langid = {english},
  keywords = {Functional genomics,Gene ontology},
  annotation = {176 citations (Semantic Scholar/DOI) [2023-10-24]},
  file = {/Users/michaelvolk/Zotero/storage/I69TMR68/Dutkowski et al_2013_A gene ontology inferred from molecular networks.pdf}
}

@online{dwivediGeneralizationTransformerNetworks2021,
  title = {A {{Generalization}} of {{Transformer Networks}} to {{Graphs}}},
  author = {Dwivedi, Vijay Prakash and Bresson, Xavier},
  date = {2021-01-24},
  eprint = {2012.09699},
  eprinttype = {arXiv},
  eprintclass = {cs},
  doi = {10.48550/arXiv.2012.09699},
  url = {http://arxiv.org/abs/2012.09699},
  urldate = {2025-02-27},
  abstract = {We propose a generalization of transformer neural network architecture for arbitrary graphs. The original transformer was designed for Natural Language Processing (NLP), which operates on fully connected graphs representing all connections between the words in a sequence. Such architecture does not leverage the graph connectivity inductive bias, and can perform poorly when the graph topology is important and has not been encoded into the node features. We introduce a graph transformer with four new properties compared to the standard model. First, the attention mechanism is a function of the neighborhood connectivity for each node in the graph. Second, the positional encoding is represented by the Laplacian eigenvectors, which naturally generalize the sinusoidal positional encodings often used in NLP. Third, the layer normalization is replaced by a batch normalization layer, which provides faster training and better generalization performance. Finally, the architecture is extended to edge feature representation, which can be critical to tasks s.a. chemistry (bond type) or link prediction (entity relationship in knowledge graphs). Numerical experiments on a graph benchmark demonstrate the performance of the proposed graph transformer architecture. This work closes the gap between the original transformer, which was designed for the limited case of line graphs, and graph neural networks, that can work with arbitrary graphs. As our architecture is simple and generic, we believe it can be used as a black box for future applications that wish to consider transformer and graphs.},
  pubstate = {prepublished},
  keywords = {Computer Science - Machine Learning},
  annotation = {665 citations (Semantic Scholar/arXiv) [2025-02-27]},
  file = {/Users/michaelvolk/Zotero/storage/TUV6CQF2/Dwivedi_Bresson_2021_A Generalization of Transformer Networks to Graphs.pdf;/Users/michaelvolk/Zotero/storage/YKGZMRMM/2012.html}
}

@online{dwivediGeneralizationTransformerNetworks2021a,
  title = {A {{Generalization}} of {{Transformer Networks}} to {{Graphs}}},
  author = {Dwivedi, Vijay Prakash and Bresson, Xavier},
  date = {2021-01-24},
  eprint = {2012.09699},
  eprinttype = {arXiv},
  eprintclass = {cs},
  doi = {10.48550/arXiv.2012.09699},
  url = {http://arxiv.org/abs/2012.09699},
  urldate = {2025-02-27},
  abstract = {We propose a generalization of transformer neural network architecture for arbitrary graphs. The original transformer was designed for Natural Language Processing (NLP), which operates on fully connected graphs representing all connections between the words in a sequence. Such architecture does not leverage the graph connectivity inductive bias, and can perform poorly when the graph topology is important and has not been encoded into the node features. We introduce a graph transformer with four new properties compared to the standard model. First, the attention mechanism is a function of the neighborhood connectivity for each node in the graph. Second, the positional encoding is represented by the Laplacian eigenvectors, which naturally generalize the sinusoidal positional encodings often used in NLP. Third, the layer normalization is replaced by a batch normalization layer, which provides faster training and better generalization performance. Finally, the architecture is extended to edge feature representation, which can be critical to tasks s.a. chemistry (bond type) or link prediction (entity relationship in knowledge graphs). Numerical experiments on a graph benchmark demonstrate the performance of the proposed graph transformer architecture. This work closes the gap between the original transformer, which was designed for the limited case of line graphs, and graph neural networks, that can work with arbitrary graphs. As our architecture is simple and generic, we believe it can be used as a black box for future applications that wish to consider transformer and graphs.},
  pubstate = {prepublished},
  keywords = {Computer Science - Machine Learning},
  annotation = {665 citations (Semantic Scholar/arXiv) [2025-02-27]},
  file = {/Users/michaelvolk/Zotero/storage/3QYRZZRU/Dwivedi_Bresson_2021_A Generalization of Transformer Networks to Graphs.pdf;/Users/michaelvolk/Zotero/storage/482VCWUN/2012.html}
}

@inproceedings{dwivediGraphNeuralNetworks2021,
  title = {Graph {{Neural Networks}} with {{Learnable Structural}} and {{Positional Representations}}},
  author = {Dwivedi, Vijay Prakash and Luu, Anh Tuan and Laurent, Thomas and Bengio, Yoshua and Bresson, Xavier},
  date = {2021-10-06},
  url = {https://openreview.net/forum?id=wTTjnvGphYj},
  urldate = {2023-10-13},
  abstract = {Graph neural networks (GNNs) have become the standard learning architectures for graphs. GNNs have been applied to numerous domains ranging from quantum chemistry, recommender systems to knowledge graphs and natural language processing. A major issue with arbitrary graphs is the absence of canonical positional information of nodes, which decreases the representation power of GNNs to distinguish e.g. isomorphic nodes and other graph symmetries. An approach to tackle this issue is to introduce Positional Encoding (PE) of nodes, and inject it into the input layer, like in Transformers. Possible graph PE are Laplacian eigenvectors. In this work, we propose to decouple structural and positional representations to make easy for the network to learn these two essential properties. We introduce a novel generic architecture which we call \textbackslash texttt\{LSPE\} (Learnable Structural and Positional Encodings). We investigate several sparse and fully-connected (Transformer-like) GNNs, and observe a performance increase for molecular datasets, from \$1.79\textbackslash\%\$ up to \$64.14\textbackslash\%\$ when considering learnable PE for both GNN classes.},
  eventtitle = {International {{Conference}} on {{Learning Representations}}},
  langid = {english},
  file = {/Users/michaelvolk/Zotero/storage/ARZKGV3E/Dwivedi et al_2021_Graph Neural Networks with Learnable Structural and Positional Representations.pdf}
}

@article{ebrahimCOBRApyCOnstraintsBasedReconstruction2013,
  title = {{{COBRApy}}: {{COnstraints-Based Reconstruction}} and {{Analysis}} for {{Python}}},
  shorttitle = {{{COBRApy}}},
  author = {Ebrahim, Ali and Lerman, Joshua A. and Palsson, Bernhard O. and Hyduke, Daniel R.},
  date = {2013-08-08},
  journaltitle = {BMC Systems Biology},
  shortjournal = {BMC Systems Biology},
  volume = {7},
  number = {1},
  pages = {74},
  issn = {1752-0509},
  doi = {10.1186/1752-0509-7-74},
  url = {https://doi.org/10.1186/1752-0509-7-74},
  urldate = {2023-05-26},
  abstract = {COnstraint-Based Reconstruction and Analysis (COBRA) methods are widely used for genome-scale modeling of metabolic networks in both prokaryotes and eukaryotes. Due to the successes with metabolism, there is an increasing effort to apply COBRA methods to reconstruct and analyze integrated models of cellular processes. The COBRA Toolbox for MATLAB is a leading software package for genome-scale analysis of metabolism; however, it was not designed to elegantly capture the complexity inherent in integrated biological networks and lacks an integration framework for the multiomics data used in systems biology. The openCOBRA Project is a community effort to promote constraints-based research through the distribution of freely available software.},
  keywords = {Constraint-based modeling,Gene expression,Genome-scale,Metabolism,Network reconstruction},
  annotation = {791 citations (Semantic Scholar/DOI) [2023-05-26]},
  file = {/Users/michaelvolk/Zotero/storage/5RCY8P67/Ebrahim et al_2013_COBRApy.pdf;/Users/michaelvolk/Zotero/storage/3T33TRCH/1752-0509-7-74.html}
}

@article{eckmannDimensionalReductionComplex2021,
  title = {Dimensional Reduction in Complex Living Systems: {{Where}}, Why, and How},
  shorttitle = {Dimensional Reduction in Complex Living Systems},
  author = {Eckmann, Jean-Pierre and Tlusty, Tsvi},
  date = {2021},
  journaltitle = {BioEssays},
  volume = {43},
  number = {9},
  pages = {2100062},
  issn = {1521-1878},
  doi = {10.1002/bies.202100062},
  url = {https://onlinelibrary.wiley.com/doi/abs/10.1002/bies.202100062},
  urldate = {2024-07-04},
  abstract = {The unprecedented prowess of measurement techniques provides a detailed, multi-scale look into the depths of living systems. Understanding these avalanches of high-dimensional data—by distilling underlying principles and mechanisms—necessitates dimensional reduction. We propose that living systems achieve exquisite dimensional reduction, originating from their capacity to learn, through evolution and phenotypic plasticity, the relevant aspects of a non-random, smooth physical reality. We explain how geometric insights by mathematicians allow one to identify these genuine hallmarks of life and distinguish them from universal properties of generic data sets. We illustrate these principles in a concrete example of protein evolution, suggesting a simple general recipe that can be applied to understand other biological systems.},
  langid = {english},
  keywords = {allostery,data compression,dimensional reduction,genotype-to-phenotype map,intrinsic dimension,learning,protein evolution},
  annotation = {12 citations (Semantic Scholar/DOI) [2024-07-04]},
  file = {/Users/michaelvolk/Zotero/storage/INGJB4G5/Eckmann and Tlusty - 2021 - Dimensional reduction in complex living systems W.pdf;/Users/michaelvolk/Zotero/storage/SR7FNTQZ/bies.html}
}

@online{elMechanisticInterpretabilityGraph2025,
  title = {Towards {{Mechanistic Interpretability}} of {{Graph Transformers}} via {{Attention Graphs}}},
  author = {El, Batu and Choudhury, Deepro and Liò, Pietro and Joshi, Chaitanya K.},
  date = {2025-02-17},
  eprint = {2502.12352},
  eprinttype = {arXiv},
  eprintclass = {cs},
  doi = {10.48550/arXiv.2502.12352},
  url = {http://arxiv.org/abs/2502.12352},
  urldate = {2025-05-14},
  abstract = {We introduce Attention Graphs, a new tool for mechanistic interpretability of Graph Neural Networks (GNNs) and Graph Transformers based on the mathematical equivalence between message passing in GNNs and the self-attention mechanism in Transformers. Attention Graphs aggregate attention matrices across Transformer layers and heads to describe how information flows among input nodes. Through experiments on homophilous and heterophilous node classification tasks, we analyze Attention Graphs from a network science perspective and find that: (1) When Graph Transformers are allowed to learn the optimal graph structure using all-to-all attention among input nodes, the Attention Graphs learned by the model do not tend to correlate with the input/original graph structure; and (2) For heterophilous graphs, different Graph Transformer variants can achieve similar performance while utilising distinct information flow patterns. Open source code: https://github.com/batu-el/understanding-inductive-biases-of-gnns},
  pubstate = {prepublished},
  version = {1},
  keywords = {Computer Science - Artificial Intelligence,Computer Science - Machine Learning},
  annotation = {2 citations (Semantic Scholar/arXiv) [2025-05-14]\\
2 citations (Semantic Scholar/DOI) [2025-05-14]},
  file = {/Users/michaelvolk/Zotero/storage/HZVGW3NQ/El et al_2025_Towards Mechanistic Interpretability of Graph Transformers via Attention Graphs.pdf;/Users/michaelvolk/Zotero/storage/RT5D3LX2/2502.html}
}

@article{elnaggarProtTransUnderstandingLanguage2022,
  title = {{{ProtTrans}}: {{Toward Understanding}} the {{Language}} of {{Life Through Self-Supervised Learning}}},
  shorttitle = {{{ProtTrans}}},
  author = {Elnaggar, Ahmed and Heinzinger, Michael and Dallago, Christian and Rehawi, Ghalia and Wang, Yu and Jones, Llion and Gibbs, Tom and Feher, Tamas and Angerer, Christoph and Steinegger, Martin and Bhowmik, Debsindhu and Rost, Burkhard},
  date = {2022-10},
  journaltitle = {IEEE Transactions on Pattern Analysis and Machine Intelligence},
  volume = {44},
  number = {10},
  pages = {7112--7127},
  issn = {1939-3539},
  doi = {10.1109/TPAMI.2021.3095381},
  url = {https://ieeexplore.ieee.org/document/9477085},
  urldate = {2023-10-17},
  abstract = {Computational biology and bioinformatics provide vast data gold-mines from protein sequences, ideal for Language Models (LMs) taken from Natural Language Processing (NLP). These LMs reach for new prediction frontiers at low inference costs. Here, we trained two auto-regressive models (Transformer-XL, XLNet) and four auto-encoder models (BERT, Albert, Electra, T5) on data from UniRef and BFD containing up to 393 billion amino acids. The protein LMs (pLMs) were trained on the Summit supercomputer using 5616 GPUs and TPU Pod up-to 1024 cores. Dimensionality reduction revealed that the raw pLM-embeddings from unlabeled data captured some biophysical features of protein sequences. We validated the advantage of using the embeddings as exclusive input for several subsequent tasks: (1) a per-residue (per-token) prediction of protein secondary structure (3-state accuracy Q3=81\%-87\%); (2) per-protein (pooling) predictions of protein sub-cellular location (ten-state accuracy: Q10=81\%) and membrane versus water-soluble (2-state accuracy Q2=91\%). For secondary structure, the most informative embeddings (ProtT5) for the first time outperformed the state-of-the-art without multiple sequence alignments (MSAs) or evolutionary information thereby bypassing expensive database searches. Taken together, the results implied that pLMs learned some of the grammar of the language of life. All our models are available through https://github.com/agemagician/ProtTrans.},
  eventtitle = {{{IEEE Transactions}} on {{Pattern Analysis}} and {{Machine Intelligence}}},
  annotation = {507 citations (Semantic Scholar/DOI) [2023-10-16]},
  file = {/Users/michaelvolk/Zotero/storage/HMD9SDQ2/Elnaggar et al_2022_ProtTrans.pdf;/Users/michaelvolk/Zotero/storage/CZECJDSU/9477085.html}
}

@article{engelNewDataCollaborations2022,
  title = {New Data and Collaborations at the {{Saccharomyces Genome Database}}: Updated Reference Genome, Alleles, and the {{Alliance}} of {{Genome Resources}}},
  shorttitle = {New Data and Collaborations at the {{Saccharomyces Genome Database}}},
  author = {Engel, Stacia R and Wong, Edith D and Nash, Robert S and Aleksander, Suzi and Alexander, Micheal and Douglass, Eric and Karra, Kalpana and Miyasato, Stuart R and Simison, Matt and Skrzypek, Marek S and Weng, Shuai and Cherry, J Michael},
  date = {2022-04-01},
  journaltitle = {Genetics},
  shortjournal = {Genetics},
  volume = {220},
  number = {4},
  pages = {iyab224},
  issn = {1943-2631},
  doi = {10.1093/genetics/iyab224},
  url = {https://doi.org/10.1093/genetics/iyab224},
  urldate = {2023-08-01},
  abstract = {Saccharomyces cerevisiae is used to provide fundamental understanding of eukaryotic genetics, gene product function, and cellular biological processes. Saccharomyces Genome Database (SGD) has been supporting the yeast research community since 1993, serving as its de facto hub. Over the years, SGD has maintained the genetic nomenclature, chromosome maps, and functional annotation, and developed various tools and methods for analysis and curation of a variety of emerging data types. More recently, SGD and six other model organism focused knowledgebases have come together to create the Alliance of Genome Resources to develop sustainable genome information resources that promote and support the use of various model organisms to understand the genetic and genomic bases of human biology and disease. Here we describe recent activities at SGD, including the latest reference genome annotation update, the development of a curation system for mutant alleles, and new pages addressing homology across model organisms as well as the use of yeast to study human disease.},
  keywords = {🦌✅,SGD,SGD.data},
  annotation = {18 citations (Semantic Scholar/DOI) [2023-08-01]},
  file = {/Users/michaelvolk/Zotero/storage/GF7RFNWL/Engel et al. - 2022 - New data and collaborations at the Saccharomyces G.pdf;/Users/michaelvolk/Zotero/storage/5EUQC34Q/6460340.html}
}

@article{erhardTimeresolvedSinglecellRNAseq2022a,
  title = {Time-Resolved Single-Cell {{RNA-seq}} Using Metabolic {{RNA}} Labelling},
  author = {Erhard, Florian and Saliba, Antoine-Emmanuel and Lusser, Alexandra and Toussaint, Christophe and Hennig, Thomas and Prusty, Bhupesh K. and Kirschenbaum, Daniel and Abadie, Kathleen and Miska, Eric A. and Friedel, Caroline C. and Amit, Ido and Micura, Ronald and Dölken, Lars},
  date = {2022-09-29},
  journaltitle = {Nature Reviews Methods Primers},
  shortjournal = {Nat Rev Methods Primers},
  volume = {2},
  number = {1},
  pages = {1--18},
  publisher = {Nature Publishing Group},
  issn = {2662-8449},
  doi = {10.1038/s43586-022-00157-z},
  url = {https://www.nature.com/articles/s43586-022-00157-z},
  urldate = {2023-07-25},
  abstract = {Single-cell RNA genomics technologies are revolutionizing biomedical science by profiling single cells with unprecedented resolution, providing fundamental insights into the role of different cellular states and intercellular heterogeneity in health and disease. The combination of single-cell RNA sequencing (scRNA-seq) with metabolic RNA labelling approaches now enables time-resolved monitoring of transcriptional responses for thousands of genes in thousands of individual cells in parallel. This facilitates and accelerates direct characterization of the temporal dimension of biological processes, which has been largely missing in current data. In this Primer, we provide an overview of the various metabolic RNA labelling approaches and their combination with currently available scRNA-seq and multi-omics platforms. We summarize the main challenges in the design of such experiments and discuss the various applications of time-resolved scRNA-seq in vitro and in vivo. We outline the computational tools and challenges to the analyses of the temporal dynamics of transcriptional responses at the single-cell level. We discuss the prospect of integrating data obtained by the respective time-resolved scRNA-seq approaches with complementary methods to elucidate gene regulatory networks that underlie molecular mechanisms. Finally, we discuss open questions and challenges in the field and give our thoughts for future development and applications.},
  issue = {1},
  langid = {english},
  keywords = {Gene expression analysis,Systems biology,Transcriptomics},
  annotation = {10 citations (Semantic Scholar/DOI) [2023-07-25]},
  file = {/Users/michaelvolk/Zotero/storage/KNLSU2HR/Erhard et al. - 2022 - Time-resolved single-cell RNA-seq using metabolic .pdf}
}

@article{eslamiArtificialIntelligenceSynthetic2022,
  title = {Artificial Intelligence for Synthetic Biology},
  author = {Eslami, Mohammed and Adler, Aaron and Caceres, Rajmonda S. and Dunn, Joshua G. and Kelley-Loughnane, Nancy and Varaljay, Vanessa A. and Martin, Hector Garcia},
  date = {2022-04-25},
  journaltitle = {Communications of the ACM},
  shortjournal = {Commun. ACM},
  volume = {65},
  number = {5},
  pages = {88--97},
  issn = {0001-0782},
  doi = {10.1145/3500922},
  url = {https://dl.acm.org/doi/10.1145/3500922},
  urldate = {2024-02-06},
  abstract = {The opportunities and challenges of adapting and applying AI principles to synbio.},
  annotation = {5 citations (Semantic Scholar/DOI) [2024-02-06]},
  file = {/Users/michaelvolk/Zotero/storage/VMY6KHUS/Eslami et al_2022_Artificial intelligence for synthetic biology.pdf}
}

@article{familiConvexBasisLeft2003,
  title = {The {{Convex Basis}} of the {{Left Null Space}} of the {{Stoichiometric Matrix Leads}} to the {{Definition}} of {{Metabolically Meaningful Pools}}},
  author = {Famili, Iman and Palsson, Bernhard O.},
  date = {2003-07-01},
  journaltitle = {Biophysical Journal},
  shortjournal = {Biophysical Journal},
  volume = {85},
  number = {1},
  pages = {16--26},
  issn = {0006-3495},
  doi = {10.1016/S0006-3495(03)74450-6},
  url = {https://www.sciencedirect.com/science/article/pii/S0006349503744506},
  urldate = {2023-04-05},
  abstract = {The stoichiometric matrix, S, represents a mapping of reaction rate vectors into a space of concentration time derivatives. The left null space of the stoichiometric matrix contains the dynamic invariants: a combination of concentration variables, referred to as metabolic pools, whose total concentration does not change over time. By analogy to the traditional reaction map formed by S, a compound map can be derived from −ST. The analogy to flux analysis of the (right) null space of S enables us to classify the metabolic pools into three categories: Type A that contains chemical elements and their combinations in the form of certain moieties, Type B that contains such moieties in addition to cofactors carrying such moieties that are internal to the network, and Type C that contains only the cofactors. A convex formulation of the basis for the left null space allows us to directly classify the metabolic pools into these three categories. Type B metabolic pools include conservation pools that form conjugates of moiety-occupied and moiety-vacant concentration states of metabolites and cofactors. Type B metabolic pools thus describe the various states of moiety exchange between the primary substrates and the cofactors that capture properties like energy and redox potential. The convex basis gives clear insight into this exchange for glycolytic pathway in human red blood cell, including the identification of high and low energy pools that form conjugates. Examples suggest that pool maps may be more appropriate for signaling pathways than flux maps. The analysis of the left null space of the stoichiometric matrix allows us to define the achievable states of the cell and their physiological relevance.},
  langid = {english},
  annotation = {96 citations (Semantic Scholar/DOI) [2023-04-04]},
  file = {/Users/michaelvolk/Zotero/storage/XF9HTV6Z/Famili_Palsson_2003_The Convex Basis of the Left Null Space of the Stoichiometric Matrix Leads to.pdf;/Users/michaelvolk/Zotero/storage/2GHIAARX/S0006349503744506.html}
}

@article{fanGeneralizingGraphNeural2024,
  title = {Generalizing {{Graph Neural Networks}} on {{Out-of-Distribution Graphs}}},
  author = {Fan, Shaohua and Wang, Xiao and Shi, Chuan and Cui, Peng and Wang, Bai},
  date = {2024-01},
  journaltitle = {IEEE Transactions on Pattern Analysis and Machine Intelligence},
  volume = {46},
  number = {1},
  pages = {322--337},
  issn = {1939-3539},
  doi = {10.1109/TPAMI.2023.3321097},
  url = {https://ieeexplore.ieee.org/abstract/document/10268633?casa_token=VTTtpWO1ud4AAAAA:puboL4VKuquc3X3Qy7Fl5hBuaIJf8CXPtdmVu_gln96cG0KXHzeKRf5wHITRElTb8xfEB671ZA},
  urldate = {2025-02-27},
  abstract = {Graph Neural Networks (GNNs) are proposed without considering the agnostic distribution shifts between training graphs and testing graphs, inducing the degeneration of the generalization ability of GNNs in Out-Of-Distribution (OOD) settings. The fundamental reason for such degeneration is that most GNNs are developed based on the I.I.D hypothesis. In such a setting, GNNs tend to exploit subtle statistical correlations existing in the training set for predictions, even though it is a spurious correlation. This learning mechanism inherits from the common characteristics of machine learning approaches. However, such spurious correlations may change in the wild testing environments, leading to the failure of GNNs. Therefore, eliminating the impact of spurious correlations is crucial for stable GNN models. To this end, in this paper, we argue that the spurious correlation exists among subgraph-level units and analyze the degeneration of GNN in causal view. Based on the causal view analysis, we propose a general causal representation framework for stable GNN, called StableGNN. The main idea of this framework is to extract high-level representations from raw graph data first and resort to the distinguishing ability of causal inference to help the model get rid of spurious correlations. Particularly, to extract meaningful high-level representations, we exploit a differentiable graph pooling layer to extract subgraph-based representations by an end-to-end manner. Furthermore, inspired by the confounder balancing techniques from causal inference, based on the learned high-level representations, we propose a causal variable distinguishing regularizer to correct the biased training distribution by learning a set of sample weights. Hence, GNNs would concentrate more on the true connection between discriminative substructures and labels. Extensive experiments are conducted on both synthetic datasets with various distribution shift degrees and eight real-world OOD graph datasets. The results well verify that the proposed model StableGNN not only outperforms the state-of-the-arts but also provides a flexible framework to enhance existing GNNs. In addition, the interpretability experiments validate that StableGNN could leverage causal structures for predictions.},
  eventtitle = {{{IEEE Transactions}} on {{Pattern Analysis}} and {{Machine Intelligence}}},
  keywords = {Causal representation learning,Correlation,Graph neural networks,graph neural networks (GNNs),out-of-distribution generalization (OOD),Predictive models,stable learning,Stars,Task analysis,Testing,Training},
  annotation = {68 citations (Semantic Scholar/DOI) [2025-02-27]},
  file = {/Users/michaelvolk/Zotero/storage/PJ5BRVKT/Fan et al_2024_Generalizing Graph Neural Networks on Out-of-Distribution Graphs.pdf;/Users/michaelvolk/Zotero/storage/9ZMQIKUT/10268633.html}
}

@article{faureNeuralmechanisticHybridApproach2023,
  title = {A Neural-Mechanistic Hybrid Approach Improving the Predictive Power of Genome-Scale Metabolic Models},
  author = {Faure, Léon and Mollet, Bastien and Liebermeister, Wolfram and Faulon, Jean-Loup},
  date = {2023-08-03},
  journaltitle = {Nature Communications},
  shortjournal = {Nat Commun},
  volume = {14},
  number = {1},
  pages = {4669},
  publisher = {Nature Publishing Group},
  issn = {2041-1723},
  doi = {10.1038/s41467-023-40380-0},
  url = {https://www.nature.com/articles/s41467-023-40380-0},
  urldate = {2023-09-10},
  abstract = {Constraint-based metabolic models have been used for decades to predict the phenotype of microorganisms in different environments. However, quantitative predictions are limited unless labor-intensive measurements of media uptake fluxes are performed. We show how hybrid neural-mechanistic models can serve as an architecture for machine learning providing a way to improve phenotype predictions. We illustrate our hybrid models with growth rate predictions of Escherichia coli and Pseudomonas putida grown in different media and with phenotype predictions of gene knocked-out Escherichia coli mutants. Our neural-mechanistic models systematically outperform constraint-based models and require training set sizes orders of magnitude smaller than classical machine learning methods. Our hybrid approach opens a doorway to enhancing constraint-based modeling: instead of constraining mechanistic models with additional experimental measurements, our hybrid models grasp the power of machine learning while fulfilling mechanistic constrains, thus saving time and resources in typical systems biology or biological engineering projects.},
  issue = {1},
  langid = {english},
  keywords = {Biochemical networks,Biochemical reaction networks,Dynamic networks,Machine learning,Metabolic engineering},
  annotation = {3 citations (Semantic Scholar/DOI) [2023-09-10]},
  file = {/Users/michaelvolk/Zotero/storage/UC35W9QY/Faure et al_2023_A neural-mechanistic hybrid approach improving the predictive power of.pdf}
}

@article{faureNeuralmechanisticHybridApproach2023a,
  title = {A Neural-Mechanistic Hybrid Approach Improving the Predictive Power of Genome-Scale Metabolic Models},
  author = {Faure, Léon and Mollet, Bastien and Liebermeister, Wolfram and Faulon, Jean-Loup},
  date = {2023-08-03},
  journaltitle = {Nature Communications},
  shortjournal = {Nat Commun},
  volume = {14},
  number = {1},
  pages = {4669},
  publisher = {Nature Publishing Group},
  issn = {2041-1723},
  doi = {10.1038/s41467-023-40380-0},
  url = {https://www.nature.com/articles/s41467-023-40380-0},
  urldate = {2023-08-04},
  abstract = {Constraint-based metabolic models have been used for decades to predict the phenotype of microorganisms in different environments. However, quantitative predictions are limited unless labor-intensive measurements of media uptake fluxes are performed. We show how hybrid neural-mechanistic models can serve as an architecture for machine learning providing a way to improve phenotype predictions. We illustrate our hybrid models with growth rate predictions of Escherichia coli and Pseudomonas putida grown in different media and with phenotype predictions of gene knocked-out Escherichia coli mutants. Our neural-mechanistic models systematically outperform constraint-based models and require training set sizes orders of magnitude smaller than classical machine learning methods. Our hybrid approach opens a doorway to enhancing constraint-based modeling: instead of constraining mechanistic models with additional experimental measurements, our hybrid models grasp the power of machine learning while fulfilling mechanistic constrains, thus saving time and resources in typical systems biology or biological engineering projects.},
  issue = {1},
  langid = {english},
  keywords = {Biochemical networks,Biochemical reaction networks,Dynamic networks,Machine learning,Metabolic engineering},
  file = {/Users/michaelvolk/Zotero/storage/DPNGFFSL/Faure et al_2023_A neural-mechanistic hybrid approach improving the predictive power of.pdf}
}

@article{felippeNetworkMutualInformation2024,
  title = {Network Mutual Information Measures for Graph Similarity},
  author = {Felippe, Helcio and Battiston, Federico and Kirkley, Alec},
  date = {2024-10-14},
  journaltitle = {Communications Physics},
  shortjournal = {Commun Phys},
  volume = {7},
  number = {1},
  pages = {1--12},
  publisher = {Nature Publishing Group},
  issn = {2399-3650},
  doi = {10.1038/s42005-024-01830-3},
  url = {https://www.nature.com/articles/s42005-024-01830-3},
  urldate = {2025-02-27},
  abstract = {A wide range of tasks in network analysis, such as clustering network populations or identifying anomalies in temporal graph streams, require a measure of the similarity between two graphs. To provide a meaningful data summary for downstream scientific analyses, the graph similarity measures used for these tasks must be principled, interpretable, and capable of distinguishing meaningful overlapping network structure from statistical noise at different scales of interest. Here we derive a family of graph mutual information measures that satisfy these criteria and are constructed using only fundamental information theoretic principles. Our measures capture the information shared among networks according to different encodings of their structural information, with our mesoscale mutual information measure allowing for network comparison under any specified network coarse-graining. We test our measures in a range of applications on real and synthetic network data, finding that they effectively highlight intuitive aspects of network similarity across scales in a variety of systems.},
  langid = {english},
  keywords = {Complex networks,Statistical physics},
  annotation = {1 citations (Semantic Scholar/DOI) [2025-02-27]},
  file = {/Users/michaelvolk/Zotero/storage/PXJDTX8P/Felippe et al_2024_Network mutual information measures for graph similarity.pdf}
}

@article{fengBenchmarkingMachineLearning2024,
  title = {Benchmarking Machine Learning Methods for Synthetic Lethality Prediction in Cancer},
  author = {Feng, Yimiao and Long, Yahui and Wang, He and Ouyang, Yang and Li, Quan and Wu, Min and Zheng, Jie},
  date = {2024-10-20},
  journaltitle = {Nature Communications},
  shortjournal = {Nat Commun},
  volume = {15},
  number = {1},
  pages = {9058},
  publisher = {Nature Publishing Group},
  issn = {2041-1723},
  doi = {10.1038/s41467-024-52900-7},
  url = {https://www.nature.com/articles/s41467-024-52900-7},
  urldate = {2025-02-27},
  abstract = {Synthetic lethality (SL) is a gold mine of anticancer drug targets, exposing cancer-specific dependencies of cellular survival. To complement resource-intensive experimental screening, many machine learning methods for SL prediction have emerged recently. However, a comprehensive benchmarking is lacking. This study systematically benchmarks 12 recent machine learning methods for SL prediction, assessing their performance across diverse data splitting scenarios, negative sample ratios, and negative sampling techniques, on both classification and ranking tasks. We observe that all the methods can perform significantly better by improving data quality, e.g., excluding computationally derived SLs from training and sampling negative labels based on gene expression. Among the methods, SLMGAE performs the best. Furthermore, the methods have limitations in realistic scenarios such as cold-start independent tests and context-specific SLs. These results, together with source code and datasets made freely available, provide guidance for selecting suitable methods and developing more powerful techniques for SL virtual screening.},
  langid = {english},
  keywords = {Cancer genetics,Data mining,Genetic interaction,Machine learning,Target identification},
  file = {/Users/michaelvolk/Zotero/storage/JFVIP8UR/Feng et al_2024_Benchmarking machine learning methods for synthetic lethality prediction in.pdf}
}

@article{fengHypergraphNeuralNetworks2019,
  title = {Hypergraph {{Neural Networks}}},
  author = {Feng, Yifan and You, Haoxuan and Zhang, Zizhao and Ji, Rongrong and Gao, Yue},
  date = {2019-07-17},
  journaltitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  volume = {33},
  number = {01},
  pages = {3558--3565},
  issn = {2374-3468},
  doi = {10.1609/aaai.v33i01.33013558},
  url = {https://ojs.aaai.org/index.php/AAAI/article/view/4235},
  urldate = {2025-02-27},
  abstract = {In this paper, we present a hypergraph neural networks (HGNN) framework for data representation learning, which can encode high-order data correlation in a hypergraph structure. Confronting the challenges of learning representation for complex data in real practice, we propose to incorporate such data structure in a hypergraph, which is more flexible on data modeling, especially when dealing with complex data. In this method, a hyperedge convolution operation is designed to handle the data correlation during representation learning. In this way, traditional hypergraph learning procedure can be conducted using hyperedge convolution operations efficiently. HGNN is able to learn the hidden layer representation considering the high-order data structure, which is a general framework considering the complex data correlations. We have conducted experiments on citation network classification and visual object recognition tasks and compared HGNN with graph convolutional networks and other traditional methods. Experimental results demonstrate that the proposed HGNN method outperforms recent state-of-theart methods. We can also reveal from the results that the proposed HGNN is superior when dealing with multi-modal data compared with existing methods.},
  issue = {01},
  langid = {english},
  annotation = {1212 citations (Semantic Scholar/DOI) [2025-02-27]},
  file = {/Users/michaelvolk/Zotero/storage/MDD37Y2W/Feng et al_2019_Hypergraph Neural Networks.pdf}
}

@article{fericFunctionMovesBiomolecular2022,
  title = {Function Moves Biomolecular Condensates in Phase Space},
  author = {Feric, Marina and Misteli, Tom},
  date = {2022},
  journaltitle = {BioEssays},
  volume = {44},
  number = {5},
  pages = {2200001},
  issn = {1521-1878},
  doi = {10.1002/bies.202200001},
  url = {https://onlinelibrary.wiley.com/doi/abs/10.1002/bies.202200001},
  urldate = {2024-07-04},
  abstract = {Phase separation underlies the formation of biomolecular condensates. We hypothesize the cellular processes that occur within condensates shape their structural features. We use the example of transcription to discuss structure–function relationships in condensates. Various types of transcriptional condensates have been reported across the evolutionary spectrum in the cell nucleus as well as in mitochondrial and bacterial nucleoids. In vitro and in vivo observations suggest that transcriptional activity of condensates influences their supramolecular structure, which in turn affects their function. Condensate organization thus becomes driven by differences in miscibility among the DNA and proteins of the transcription machinery and the RNA transcripts they generate. These considerations are in line with the notion that cellular processes shape the structural properties of condensates, leading to a dynamic, mutual interplay between structure and function in the cell.},
  langid = {english},
  keywords = {biomolecular condensates,mitochondria,nucleoid,nucleolus,nucleus,phase separation,transcription},
  annotation = {7 citations (Semantic Scholar/DOI) [2024-07-04]},
  file = {/Users/michaelvolk/Zotero/storage/R7JFVKX7/Feric and Misteli - 2022 - Function moves biomolecular condensates in phase s.pdf;/Users/michaelvolk/Zotero/storage/VGYG3HAD/bies.html}
}

@article{fernandesExperimentalMethodsModeling2011,
  title = {Experimental Methods and Modeling Techniques for Description of Cell Population Heterogeneity},
  author = {Fernandes, R. Lencastre and Nierychlo, Marta and Lundin, Luisa and Pedersen, Anne Egholm and Tellez, PE Puentes and Dutta, Abhishek and Carlquist, Magnus and Bolic, Andrijana and Schäpper, Daniel and Brunetti, Anna Chiara},
  date = {2011},
  journaltitle = {Biotechnology advances},
  volume = {29},
  number = {6},
  pages = {575--599},
  publisher = {Elsevier},
  url = {https://www.sciencedirect.com/science/article/pii/S0734975011000425},
  urldate = {2024-07-07},
  file = {/Users/michaelvolk/Zotero/storage/8HF2DIB3/Fernandes et al. - 2011 - Experimental methods and modeling techniques for d.pdf;/Users/michaelvolk/Zotero/storage/FGEQ9V9C/Lencastre Fernandes et al. - 2011 - Experimental methods and modeling techniques for d.pdf}
}

@article{fiedlerFunctionalOrganizationCerevisiae2009,
  title = {Functional {{Organization}} of the {{S}}. Cerevisiae {{Phosphorylation Network}}},
  author = {Fiedler, Dorothea and Braberg, Hannes and Mehta, Monika and Chechik, Gal and Cagney, Gerard and Mukherjee, Paromita and Silva, Andrea C. and Shales, Michael and Collins, Sean R. and family=Wageningen, given=Sake, prefix=van, useprefix=false and Kemmeren, Patrick and Holstege, Frank C. P. and Weissman, Jonathan S. and Keogh, Michael-Christopher and Koller, Daphne and Shokat, Kevan M. and Krogan, Nevan J.},
  date = {2009-03-06},
  journaltitle = {Cell},
  shortjournal = {Cell},
  volume = {136},
  number = {5},
  eprint = {19269370},
  eprinttype = {pmid},
  pages = {952--963},
  publisher = {Elsevier},
  issn = {0092-8674, 1097-4172},
  doi = {10.1016/j.cell.2008.12.039},
  url = {https://www.cell.com/cell/abstract/S0092-8674(09)00002-6},
  urldate = {2024-07-18},
  langid = {english},
  keywords = {SIGNALING},
  annotation = {273 citations (Semantic Scholar/DOI) [2024-07-18]},
  file = {/Users/michaelvolk/Zotero/storage/IZK5IZAD/Fiedler et al_2009_Functional Organization of the S.pdf}
}

@online{fishmanGENALMFamilyOpenSource2023,
  title = {{{GENA-LM}}: {{A Family}} of {{Open-Source Foundational Models}} for {{Long DNA Sequences}}},
  shorttitle = {{{GENA-LM}}},
  author = {Fishman, Veniamin and Kuratov, Yuri and Petrov, Maxim and Shmelev, Aleksei and Shepelin, Denis and Chekanov, Nikolay and Kardymon, Olga and Burtsev, Mikhail},
  date = {2023-06-13},
  eprinttype = {bioRxiv},
  eprintclass = {New Results},
  pages = {2023.06.12.544594},
  doi = {10.1101/2023.06.12.544594},
  url = {https://www.biorxiv.org/content/10.1101/2023.06.12.544594v1},
  urldate = {2023-07-07},
  abstract = {The field of genomics has seen substantial advancements through the application of artificial intelligence (AI), with machine learning revealing the potential to interpret genomic sequences without necessitating an exhaustive experimental analysis of all the intricate and interconnected molecular processes involved in DNA functioning. However, precise decoding of genomic sequences demands the comprehension of rich contextual information spread over thousands of nucleotides. Presently, only a few architectures exist that can process such extensive inputs, and they require exceptional computational resources. To address this need, we introduce GENA-LM, a suite of transformer-based foundational DNA language models capable of handling input lengths up to 36 thousands base pairs. We offer pre-trained versions of GENA-LM and demonstrate their capacity for fine-tuning to address complex biological questions with modest computational requirements. We also illustrate diverse applications of GENA-LM for various downstream genomic tasks, showcasing its performance in either matching or exceeding that of prior models, whether task-specific or universal. All models are publicly accessible on GitHub https://github.com/AIRI-Institute/GENA\_LM and as pre-trained models with gena-lm-prefix on HuggingFace https://huggingface.co/AIRI-Institute. Contacts minja-f\{at\}ya.ru, kardymon\{at\}airi.net, am\{at\}lims.ac.uk},
  langid = {english},
  pubstate = {prepublished},
  annotation = {0 citations (Semantic Scholar/DOI) [2023-07-07]},
  file = {/Users/michaelvolk/Zotero/storage/D2I8D6AU/Fishman et al_2023_GENA-LM.pdf}
}

@article{fornasieroGeneralizingDefinitionProtein2023,
  title = {Generalizing the Definition of Protein Turnover to Out-of-Equilibrium Conditions},
  author = {Fornasiero, Eugenio F.},
  date = {2023},
  journaltitle = {BioEssays},
  volume = {45},
  number = {6},
  pages = {2300059},
  issn = {1521-1878},
  doi = {10.1002/bies.202300059},
  url = {https://onlinelibrary.wiley.com/doi/abs/10.1002/bies.202300059},
  urldate = {2024-07-04},
  langid = {english},
  annotation = {0 citations (Semantic Scholar/DOI) [2024-07-04]},
  file = {/Users/michaelvolk/Zotero/storage/TYHK49KD/bies.html}
}

@online{forsterBIONICBiologicalNetwork2021,
  title = {{{BIONIC}}: {{Biological Network Integration}} Using {{Convolutions}}},
  shorttitle = {{{BIONIC}}},
  author = {Forster, Duncan T. and Boone, Charles and Bader, Gary D. and Wang, Bo},
  date = {2021-03-16},
  eprinttype = {bioRxiv},
  eprintclass = {New Results},
  pages = {2021.03.15.435515},
  doi = {10.1101/2021.03.15.435515},
  url = {https://www.biorxiv.org/content/10.1101/2021.03.15.435515v1},
  urldate = {2024-02-19},
  abstract = {Biological networks constructed from varied data, including protein-protein interactions, gene expression data, and genetic interactions can be used to map cellular function, but each data type has individual limitations such as bias and incompleteness. Unsupervised network integration promises to address these limitations by combining and automatically weighting input information to obtain a more accurate and comprehensive result. However, existing unsupervised network integration methods fail to adequately scale to the number of nodes and networks present in genome-scale data and do not handle partial network overlap. To address these issues, we developed an unsupervised deep learning-based network integration algorithm that incorporates recent advances in reasoning over unstructured data – namely the graph convolutional network (GCN) – and can effectively learn dependencies between any input network, such as those composed of protein-protein interactions, gene co-expression, or genetic interactions. Our method, BIONIC (Biological Network Integration using Convolutions), learns features which contain substantially more functional information compared to existing approaches, linking genes that share diverse functional relationships, including co-complex and shared bioprocess annotation. BIONIC is scalable in both size and quantity of the input networks, making it feasible to integrate numerous networks on the scale of the human genome.},
  langid = {english},
  pubstate = {prepublished},
  keywords = {🦌✅},
  file = {/Users/michaelvolk/Zotero/storage/VF476WAJ/Forster et al. - 2021 - BIONIC Biological Network Integration using Convo.pdf}
}

@article{forsterBIONICBiologicalNetwork2022,
  title = {{{BIONIC}}: Biological Network Integration Using Convolutions},
  shorttitle = {{{BIONIC}}},
  author = {Forster, Duncan T. and Li, Sheena C. and Yashiroda, Yoko and Yoshimura, Mami and Li, Zhijian and Isuhuaylas, Luis Alberto Vega and Itto-Nakama, Kaori and Yamanaka, Daisuke and Ohya, Yoshikazu and Osada, Hiroyuki and Wang, Bo and Bader, Gary D. and Boone, Charles},
  date = {2022-10-03},
  journaltitle = {Nature Methods},
  shortjournal = {Nat Methods},
  pages = {1--12},
  publisher = {Nature Publishing Group},
  issn = {1548-7105},
  doi = {10.1038/s41592-022-01616-x},
  url = {https://www.nature.com/articles/s41592-022-01616-x},
  urldate = {2022-10-06},
  abstract = {Biological networks constructed from varied data can be used to map cellular function, but each data type has limitations. Network integration promises to address these limitations by combining and automatically weighting input information to obtain a more accurate and comprehensive representation of the underlying biology. We developed a deep learning-based network integration algorithm that incorporates a graph convolutional network framework. Our method, BIONIC (Biological Network Integration using Convolutions), learns features that contain substantially more functional information compared to existing approaches. BIONIC has unsupervised and semisupervised learning modes, making use of available gene function annotations. BIONIC is scalable in both size and quantity of the input networks, making it feasible to integrate numerous networks on the scale of the human genome. To demonstrate the use of BIONIC in identifying new biology, we predicted and experimentally validated essential gene chemical–genetic interactions from nonessential gene profiles in yeast.},
  langid = {english},
  keywords = {🦌✅,data-integration,functional-clustering,functional-genomics,machine-learning,network-topology},
  annotation = {1 citations (Semantic Scholar/DOI) [2022-11-26]},
  file = {/Users/michaelvolk/Zotero/storage/72JJSI8P/Forster et al. - 2022 - BIONIC biological network integration using convo.pdf;/Users/michaelvolk/Zotero/storage/965G3C3Z/s41592-022-01616-x.html}
}

@online{fuchsFabianFuchs,
  title = {Review: {{Deep Learning}} on {{Sets}}},
  author = {Fuchs, Fabian},
  url = {https://fabianfuchsml.github.io/learningonsets/},
  urldate = {2023-10-09},
  abstract = {\# Review: Deep Learning on Sets [Fabian Fuchs](https://twitter.com/fabianfuchsml), [Ed Wagstaff](https://twitter.com/EdWagstaff), [Martin Engelcke](https://twitter.com/martinengelcke) \_\_\_ \_In this blog, we analyse and categorise the different approaches in set based learning. We conducted this literature review as part of our recent paper [Universal Approximation of Functions on Sets](https://arxiv.org/abs/2107.01959) with [Michael Osborne](https://twitter.com/maosbot) and [Ingmar Posner](https://twitter.com/IngmarPosner).\_...},
  langid = {english},
  file = {/Users/michaelvolk/Zotero/storage/IIEYKPYH/learningonsets.html}
}

@article{fuLeveragingMachineLearning2021a,
  title = {Leveraging Machine Learning Essentiality Predictions and Chemogenomic Interactions to Identify Antifungal Targets},
  author = {Fu, Ci and Zhang, Xiang and Veri, Amanda O. and Iyer, Kali R. and Lash, Emma and Xue, Alice and Yan, Huijuan and Revie, Nicole M. and Wong, Cassandra and Lin, Zhen-Yuan and Polvi, Elizabeth J. and Liston, Sean D. and VanderSluis, Benjamin and Hou, Jing and Yashiroda, Yoko and Gingras, Anne-Claude and Boone, Charles and O’Meara, Teresa R. and O’Meara, Matthew J. and Noble, Suzanne and Robbins, Nicole and Myers, Chad L. and Cowen, Leah E.},
  date = {2021-11-11},
  journaltitle = {Nature Communications},
  shortjournal = {Nat Commun},
  volume = {12},
  number = {1},
  pages = {6497},
  publisher = {Nature Publishing Group},
  issn = {2041-1723},
  doi = {10.1038/s41467-021-26850-3},
  url = {https://www.nature.com/articles/s41467-021-26850-3},
  urldate = {2024-07-01},
  abstract = {Fungal pathogens pose a global threat to human health, with Candida albicans among the leading killers. Systematic analysis of essential genes provides a powerful strategy to discover potential antifungal targets. Here, we build a machine learning model to generate genome-wide gene essentiality predictions for C. albicans and expand the largest functional genomics resource in this pathogen (the GRACE collection) by 866 genes. Using this model and chemogenomic analyses, we define the function of three uncharacterized essential genes with roles in kinetochore function, mitochondrial integrity, and translation, and identify the glutaminyl-tRNA synthetase Gln4 as the target of N-pyrimidinyl-β-thiophenylacrylamide (NP-BTA), an antifungal compound.},
  langid = {english},
  keywords = {Antifungal agents,Functional genomics,Fungal systems biology,Pathogens},
  annotation = {26 citations (Semantic Scholar/DOI) [2024-07-01]},
  file = {/Users/michaelvolk/Zotero/storage/KLR95MZL/Fu et al_2021_Leveraging machine learning essentiality predictions and chemogenomic.pdf}
}

@article{ganHierarchicalTranscriptionalRegulatory2022,
  title = {A {{Hierarchical Transcriptional Regulatory Network Required}} for {{Long-Term Thermal Stress Tolerance}} in an {{Industrial Saccharomyces}} Cerevisiae {{Strain}}},
  author = {Gan, Yuman and Qi, Xianni and Lin, Yuping and Guo, Yufeng and Zhang, Yuanyuan and Wang, Qinhong},
  date = {2022},
  journaltitle = {Frontiers in Bioengineering and Biotechnology},
  volume = {9},
  issn = {2296-4185},
  url = {https://www.frontiersin.org/article/10.3389/fbioe.2021.826238},
  urldate = {2022-04-15},
  abstract = {Yeast cells suffer from continuous and long-term thermal stress during high-temperature ethanol fermentation. Understanding the mechanism of yeast thermotolerance is important not only for studying microbial stress biology in basic research but also for developing thermotolerant strains for industrial application. Here, we compared the effects of 23 transcription factor (TF) deletions on high-temperature ethanol fermentation and cell survival after heat shock treatment and identified three core TFs, Sin3p, Srb2p and Mig1p, that are involved in regulating the response to long-term thermotolerance. Further analyses of comparative transcriptome profiling of the core TF deletions and transcription regulatory associations revealed a hierarchical transcriptional regulatory network centered on these three~TFs. This global transcriptional regulatory network provided a better understanding of the regulatory mechanism behind long-term thermal stress tolerance as well as potential targets for transcriptome engineering to improve the performance of high-temperature ethanol fermentation by an industrial Saccharomyces cerevisiae strain.},
  keywords = {✅,📰-chemical-reviews-review,🦌,gene-graph,hierarchical-regulatory-network,regulatory-networks,s-cerevisiae},
  file = {/Users/michaelvolk/Zotero/storage/WH4FRTWD/Gan et al_2022_A Hierarchical Transcriptional Regulatory Network Required for Long-Term.pdf}
}

@article{gaoGenerativeLearningForecasting2024,
  title = {Generative Learning for Forecasting the Dynamics of High-Dimensional Complex Systems},
  author = {Gao, Han and Kaltenbach, Sebastian and Koumoutsakos, Petros},
  date = {2024-10-16},
  journaltitle = {Nature Communications},
  shortjournal = {Nat Commun},
  volume = {15},
  number = {1},
  pages = {8904},
  publisher = {Nature Publishing Group},
  issn = {2041-1723},
  doi = {10.1038/s41467-024-53165-w},
  url = {https://www.nature.com/articles/s41467-024-53165-w},
  urldate = {2025-02-27},
  abstract = {We introduce generative models for accelerating simulations of high-dimensional systems through learning and evolving their effective dynamics. In the proposed Generative Learning of Effective Dynamics (G-LED), instances of high dimensional data are down sampled to a lower dimensional manifold that is evolved through an auto-regressive attention mechanism. In turn, Bayesian diffusion models, that map this low-dimensional manifold onto its corresponding high-dimensional space, operate on batches of physics correlated, time sequences of data and capture the statistics of the system dynamics. We demonstrate the capabilities and drawbacks of G-LED in simulations of several benchmark systems, including the Kuramoto-Sivashinsky (KS) equation, two-dimensional high Reynolds number flow over a backward-facing step, and simulations of three-dimensional turbulent channel flow. The results demonstrate that generative learning offers new frontiers for the accurate forecasting of the statistical properties of high-dimensional systems at a reduced computational cost.},
  langid = {english},
  keywords = {Applied mathematics,Computational science},
  annotation = {5 citations (Semantic Scholar/DOI) [2025-02-27]},
  file = {/Users/michaelvolk/Zotero/storage/KNN64LSD/Gao et al_2024_Generative learning for forecasting the dynamics of high-dimensional complex.pdf}
}

@article{garbinDropoutVsBatch2020,
  title = {Dropout vs. Batch Normalization: An Empirical Study of Their Impact to Deep Learning},
  shorttitle = {Dropout vs. Batch Normalization},
  author = {Garbin, Christian and Zhu, Xingquan and Marques, Oge},
  date = {2020-05-01},
  journaltitle = {Multimedia Tools and Applications},
  shortjournal = {Multimed Tools Appl},
  volume = {79},
  number = {19},
  pages = {12777--12815},
  issn = {1573-7721},
  doi = {10.1007/s11042-019-08453-9},
  url = {https://doi.org/10.1007/s11042-019-08453-9},
  urldate = {2023-09-12},
  abstract = {Overfitting and long training time are two fundamental challenges in multilayered neural network learning and deep learning in particular. Dropout and batch normalization are two well-recognized approaches to tackle these challenges. While both approaches share overlapping design principles, numerous research results have shown that they have unique strengths to improve deep learning. Many tools simplify these two approaches as a simple function call, allowing flexible stacking to form deep learning architectures. Although their usage guidelines are available, unfortunately no well-defined set of rules or comprehensive studies to investigate them concerning data input, network configurations, learning efficiency, and accuracy. It is not clear when users should consider using dropout and/or batch normalization, and how they should be combined (or used alternatively) to achieve optimized deep learning outcomes. In this paper we conduct an empirical study to investigate the effect of dropout and batch normalization on training deep learning models. We use multilayered dense neural networks and convolutional neural networks (CNN) as the deep learning models, and mix dropout and batch normalization to design different architectures and subsequently observe their performance in terms of training and test CPU time, number of parameters in the model (as a proxy for model size), and classification accuracy. The interplay between network structures, dropout, and batch normalization, allow us to conclude when and how dropout and batch normalization should be considered in deep learning. The empirical study quantified the increase in training time when dropout and batch normalization are used, as well as the increase in prediction time (important for constrained environments, such as smartphones and low-powered IoT devices). It showed that a non-adaptive optimizer (e.g. SGD) can outperform adaptive optimizers, but only at the cost of a significant amount of training times to perform hyperparameter tuning, while an adaptive optimizer (e.g. RMSProp) performs well without much tuning. Finally, it showed that dropout and batch normalization should be used in CNNs only with caution and experimentation (when in doubt and short on time to experiment, use only batch normalization).},
  langid = {english},
  keywords = {Batch normalization,Deep learning,Dropout,Optimization,Overfitting,Regularization},
  annotation = {199 citations (Semantic Scholar/DOI) [2023-09-12]},
  file = {/Users/michaelvolk/Zotero/storage/PBTLJMHF/Garbin et al_2020_Dropout vs.pdf}
}

@article{garcia-blayExploringRoleTranscriptional2023,
  title = {Exploring the Role of Transcriptional and Post-Transcriptional Processes in {{mRNA}} Co-Expression},
  author = {García-Blay, Óscar and Verhagen, Pieter G. A. and Martin, Benjamin and Hansen, Maike M. K.},
  date = {2023},
  journaltitle = {BioEssays},
  volume = {45},
  number = {12},
  pages = {2300130},
  issn = {1521-1878},
  doi = {10.1002/bies.202300130},
  url = {https://onlinelibrary.wiley.com/doi/abs/10.1002/bies.202300130},
  urldate = {2024-07-04},
  abstract = {Co-expression of two or more genes at the single-cell level is usually associated with functional co-regulation. While mRNA co-expression—measured as the correlation in mRNA levels—can be influenced by both transcriptional and post-transcriptional events, transcriptional regulation is typically considered dominant. We review and connect the literature describing transcriptional and post-transcriptional regulation of co-expression. To enhance our understanding, we integrate four datasets spanning single-cell gene expression data, single-cell promoter activity data and individual transcript half-lives. Confirming expectations, we find that positive co-expression necessitates promoter coordination and similar mRNA half-lives. Surprisingly, negative co-expression is favored by differences in mRNA half-lives, contrary to initial predictions from stochastic simulations. Notably, this association manifests specifically within clusters of genes. We further observe a striking compensation between promoter coordination and mRNA half-lives, which additional stochastic simulations suggest might give rise to the observed co-expression patterns. These findings raise intriguing questions about the functional advantages conferred by this compensation between distal kinetic steps.},
  langid = {english},
  keywords = {gene regulation,intron seqFISH,mRNA co-expression,mRNA degradation,promoter toggling},
  annotation = {0 citations (Semantic Scholar/DOI) [2024-07-04]},
  file = {/Users/michaelvolk/Zotero/storage/2XPXCXUC/García-Blay et al. - 2023 - Exploring the role of transcriptional and post-tra.pdf;/Users/michaelvolk/Zotero/storage/8FDS2R4M/bies.html}
}

@online{gavranovicFundamentalComponentsDeep2024a,
  title = {Fundamental {{Components}} of {{Deep Learning}}: {{A}} Category-Theoretic Approach},
  shorttitle = {Fundamental {{Components}} of {{Deep Learning}}},
  author = {Gavranović, Bruno},
  date = {2024-03-12},
  eprint = {2403.13001},
  eprinttype = {arXiv},
  eprintclass = {cs, math},
  doi = {10.48550/arXiv.2403.13001},
  url = {http://arxiv.org/abs/2403.13001},
  urldate = {2024-07-07},
  abstract = {Deep learning, despite its remarkable achievements, is still a young field. Like the early stages of many scientific disciplines, it is marked by the discovery of new phenomena, ad-hoc design decisions, and the lack of a uniform and compositional mathematical foundation. From the intricacies of the implementation of backpropagation, through a growing zoo of neural network architectures, to the new and poorly understood phenomena such as double descent, scaling laws or in-context learning, there are few unifying principles in deep learning. This thesis develops a novel mathematical foundation for deep learning based on the language of category theory. We develop a new framework that is a) end-to-end, b) unform, and c) not merely descriptive, but prescriptive, meaning it is amenable to direct implementation in programming languages with sufficient features. We also systematise many existing approaches, placing many existing constructions and concepts from the literature under the same umbrella. In Part I we identify and model two main properties of deep learning systems parametricity and bidirectionality by we expand on the previously defined construction of actegories and Para to study the former, and define weighted optics to study the latter. Combining them yields parametric weighted optics, a categorical model of artificial neural networks, and more. Part II justifies the abstractions from Part I, applying them to model backpropagation, architectures, and supervised learning. We provide a lens-theoretic axiomatisation of differentiation, covering not just smooth spaces, but discrete settings of boolean circuits as well. We survey existing, and develop new categorical models of neural network architectures. We formalise the notion of optimisers and lastly, combine all the existing concepts together, providing a uniform and compositional framework for supervised learning.},
  pubstate = {prepublished},
  keywords = {Computer Science - Artificial Intelligence,Computer Science - Machine Learning,Mathematics - Category Theory},
  annotation = {3 citations (Semantic Scholar/arXiv) [2024-07-07]\\
3 citations (Semantic Scholar/DOI) [2024-07-07]},
  file = {/Users/michaelvolk/Zotero/storage/DZ6YLVUP/Gavranović_2024_Fundamental Components of Deep Learning.pdf;/Users/michaelvolk/Zotero/storage/9S99VJLW/2403.html}
}

@article{georgouliMultiscaleModelsWhole2023,
  title = {Multi-Scale Models of Whole Cells: Progress and Challenges},
  shorttitle = {Multi-Scale Models of Whole Cells},
  author = {Georgouli, Konstantia and Yeom, Jae-Seung and Blake, Robert C. and Navid, Ali},
  date = {2023-11-07},
  journaltitle = {Frontiers in Cell and Developmental Biology},
  shortjournal = {Front. Cell Dev. Biol.},
  volume = {11},
  publisher = {Frontiers},
  issn = {2296-634X},
  doi = {10.3389/fcell.2023.1260507},
  url = {https://www.frontiersin.org/journals/cell-and-developmental-biology/articles/10.3389/fcell.2023.1260507/full},
  urldate = {2024-08-07},
  abstract = {{$<$}p{$>$}Whole-cell modeling is “the ultimate goal” of computational systems biology and “a grand challenge for 21st century” (Tomita, Trends in Biotechnology, 2001, 19(6), 205–10). These complex, highly detailed models account for the activity of every molecule in a cell and serve as comprehensive knowledgebases for the modeled system. Their scope and utility far surpass those of other systems models. In fact, whole-cell models (WCMs) are an amalgam of several types of “system” models. The models are simulated using a hybrid modeling method where the appropriate mathematical methods for each biological process are used to simulate their behavior. Given the complexity of the models, the process of developing and curating these models is labor-intensive and to date only a handful of these models have been developed. While whole-cell models provide valuable and novel biological insights, and to date have identified some novel biological phenomena, their most important contribution has been to highlight the discrepancy between available data and observations that are used for the parametrization and validation of complex biological models. Another realization has been that current whole-cell modeling simulators are slow and to run models that mimic more complex (e.g., multi-cellular) biosystems, those need to be executed in an accelerated fashion on high-performance computing platforms. In this manuscript, we review the progress of whole-cell modeling to date and discuss some of the ways that they can be improved.{$<$}/p{$>$}},
  langid = {english},
  keywords = {data integration4,high performance computing5,multi-scale models3,systems biology2,whole cell modeling1},
  annotation = {0 citations (Semantic Scholar/DOI) [2024-08-06]},
  file = {/Users/michaelvolk/Zotero/storage/WFIYZ8EC/Georgouli et al_2023_Multi-scale models of whole cells.pdf}
}

@article{giacolettoHistoryConceptualFramework2023,
  title = {The History and Conceptual Framework of Assays and Screens},
  author = {Giacoletto, Christopher J. and Schiller, Martin R.},
  date = {2023},
  journaltitle = {BioEssays},
  volume = {45},
  number = {4},
  pages = {2200191},
  issn = {1521-1878},
  doi = {10.1002/bies.202200191},
  url = {https://onlinelibrary.wiley.com/doi/abs/10.1002/bies.202200191},
  urldate = {2024-07-04},
  abstract = {Since the 16th century, assays and screens have been essential for scientific investigation. However, most methods could be significantly improved, especially in accuracy, scalability, and often lack adequate comparisons to negative controls. There is a lack of consistency in distinguishing assays, in which accuracy is the main goal, from screens, in which scalability is prioritized over accuracy. We dissected and modernized the original definitions of assays and screens based upon recent developments and the conceptual framework of the original definitions. All methods have three components: design/measurement, performance, and interpretation. We propose a model of method development in which reproducible observations become new methods, initially assessed by sensitivity. Further development can proceed along a path to either screens or assays. The screen path focuses on scalability first, but can later prioritize analysis of negatives. Alternatively, the assay path first compares results to negative controls, assessing specificity and accuracy, later adding scalability. Both pathways converge on a high-accuracy and throughput (HAT) assay, like next generation sequencing, which we suggest should be the ultimate goal of all testing methods. Our model will help scientists better select among available methods, as well as improve existing methods, expanding their impact on science.},
  langid = {english},
  keywords = {accuracy,assay,fabrication,HAT assay,high-throughput,method,screen},
  annotation = {2 citations (Semantic Scholar/DOI) [2024-07-04]},
  file = {/Users/michaelvolk/Zotero/storage/B7KEXAVU/Giacoletto and Schiller - 2023 - The history and conceptual framework of assays and.pdf;/Users/michaelvolk/Zotero/storage/E5MDXLT9/bies.html}
}

@article{giaeverFunctionalProfilingSaccharomyces2002a,
  title = {Functional Profiling of the {{Saccharomyces}} Cerevisiae Genome},
  author = {Giaever, Guri and Chu, Angela M. and Ni, Li and Connelly, Carla and Riles, Linda and Véronneau, Steeve and Dow, Sally and Lucau-Danila, Ankuta and Anderson, Keith and André, Bruno and Arkin, Adam P. and Astromoff, Anna and El Bakkoury, Mohamed and Bangham, Rhonda and Benito, Rocio and Brachat, Sophie and Campanaro, Stefano and Curtiss, Matt and Davis, Karen and Deutschbauer, Adam and Entian, Karl-Dieter and Flaherty, Patrick and Foury, Francoise and Garfinkel, David J. and Gerstein, Mark and Gotte, Deanna and Güldener, Ulrich and Hegemann, Johannes H. and Hempel, Svenja and Herman, Zelek and Jaramillo, Daniel F. and Kelly, Diane E. and Kelly, Steven L. and Kötter, Peter and LaBonte, Darlene and Lamb, David C. and Lan, Ning and Liang, Hong and Liao, Hong and Liu, Lucy and Luo, Chuanyun and Lussier, Marc and Mao, Rong and Menard, Patrice and Ooi, Siew Loon and Revuelta, Jose L. and Roberts, Christopher J. and Rose, Matthias and Ross-Macdonald, Petra and Scherens, Bart and Schimmack, Greg and Shafer, Brenda and Shoemaker, Daniel D. and Sookhai-Mahadeo, Sharon and Storms, Reginald K. and Strathern, Jeffrey N. and Valle, Giorgio and Voet, Marleen and Volckaert, Guido and Wang, Ching-yun and Ward, Teresa R. and Wilhelmy, Julie and Winzeler, Elizabeth A. and Yang, Yonghong and Yen, Grace and Youngman, Elaine and Yu, Kexin and Bussey, Howard and Boeke, Jef D. and Snyder, Michael and Philippsen, Peter and Davis, Ronald W. and Johnston, Mark},
  date = {2002-07},
  journaltitle = {Nature},
  volume = {418},
  number = {6896},
  pages = {387--391},
  publisher = {Nature Publishing Group},
  issn = {1476-4687},
  doi = {10.1038/nature00935},
  url = {https://www.nature.com/articles/nature00935},
  urldate = {2023-10-13},
  abstract = {Determining the effect of gene deletion is a fundamental approach to understanding gene function. Conventional genetic screens exhibit biases, and genes contributing to a phenotype are often missed. We systematically constructed a nearly complete collection of gene-deletion mutants (96\% of annotated open reading frames, or ORFs) of the yeast Saccharomyces cerevisiae. DNA sequences dubbed ‘molecular bar codes’ uniquely identify each strain, enabling their growth to be analysed in parallel and the fitness contribution of each gene to be quantitatively assessed by hybridization to high-density oligonucleotide arrays. We show that previously known and new genes are necessary for optimal growth under six well-studied conditions: high salt, sorbitol, galactose, pH 8, minimal medium and nystatin treatment. Less than 7\% of genes that exhibit a significant increase in messenger RNA expression are also required for optimal growth in four of the tested conditions. Our results validate the yeast gene-deletion collection as a valuable resource for functional genomics.},
  issue = {6896},
  langid = {english},
  keywords = {Humanities and Social Sciences,multidisciplinary,Science},
  annotation = {4148 citations (Semantic Scholar/DOI) [2023-10-13]},
  file = {/Users/michaelvolk/Zotero/storage/WHRPEXCA/Giaever et al_2002_Functional profiling of the Saccharomyces cerevisiae genome.pdf}
}

@article{giererTheoryBiologicalPattern1972,
  title = {A Theory of Biological Pattern Formation},
  author = {Gierer, A. and Meinhardt, H.},
  date = {1972-12-01},
  journaltitle = {Kybernetik},
  shortjournal = {Kybernetik},
  volume = {12},
  number = {1},
  pages = {30--39},
  issn = {1432-0770},
  doi = {10.1007/BF00289234},
  url = {https://doi.org/10.1007/BF00289234},
  urldate = {2024-06-21},
  abstract = {One of the elementary processes in morphogenesis is the formation of a spatial pattern of tissue structures, starting from almost homogeneous tissue. It will be shown that relatively simple molecular mechanisms based on auto- and cross catalysis can account for a primary pattern of morphogens to determine pattern formation of the tissue. The theory is based on short range activation, long range inhibition, and a distinction between activator and inhibitor concentrations on one hand, and the densities of their sources on the other. While source density is expected to change slowly, e.g. as an effect of cell differentiation, the concentration of activators and inhibitors can change rapidly to establish the primary pattern; this results from auto- and cross catalytic effects on the sources, spreading by diffusion or other mechanisms, and degradation.},
  langid = {english},
  keywords = {Head Formation,Pattern Formation,Periodic Pattern,Source Distribution,Striking Pattern},
  annotation = {2316 citations (Semantic Scholar/DOI) [2024-06-21]},
  file = {/Users/michaelvolk/Zotero/storage/SSGQYGNU/Gierer_Meinhardt_1972_A theory of biological pattern formation.pdf}
}

@online{giovanniHowDoesOversquashing2024,
  title = {How Does Over-Squashing Affect the Power of {{GNNs}}?},
  author = {Giovanni, Francesco Di and Rusch, T. Konstantin and Bronstein, Michael M. and Deac, Andreea and Lackenby, Marc and Mishra, Siddhartha and Veličković, Petar},
  date = {2024-02-12},
  eprint = {2306.03589},
  eprinttype = {arXiv},
  eprintclass = {cs},
  doi = {10.48550/arXiv.2306.03589},
  url = {http://arxiv.org/abs/2306.03589},
  urldate = {2025-03-01},
  abstract = {Graph Neural Networks (GNNs) are the state-of-the-art model for machine learning on graph-structured data. The most popular class of GNNs operate by exchanging information between adjacent nodes, and are known as Message Passing Neural Networks (MPNNs). Given their widespread use, understanding the expressive power of MPNNs is a key question. However, existing results typically consider settings with uninformative node features. In this paper, we provide a rigorous analysis to determine which function classes of node features can be learned by an MPNN of a given capacity. We do so by measuring the level of pairwise interactions between nodes that MPNNs allow for. This measure provides a novel quantitative characterization of the so-called over-squashing effect, which is observed to occur when a large volume of messages is aggregated into fixed-size vectors. Using our measure, we prove that, to guarantee sufficient communication between pairs of nodes, the capacity of the MPNN must be large enough, depending on properties of the input graph structure, such as commute times. For many relevant scenarios, our analysis results in impossibility statements in practice, showing that over-squashing hinders the expressive power of MPNNs. We validate our theoretical findings through extensive controlled experiments and ablation studies.},
  pubstate = {prepublished},
  keywords = {Computer Science - Machine Learning,Statistics - Machine Learning},
  annotation = {30 citations (Semantic Scholar/arXiv) [2025-03-01]\\
30 citations (Semantic Scholar/DOI) [2025-03-01]},
  file = {/Users/michaelvolk/Zotero/storage/LTZGZ7YG/Giovanni et al_2024_How does over-squashing affect the power of GNNs.pdf;/Users/michaelvolk/Zotero/storage/H2DJYTBD/2306.html}
}

@inproceedings{giraldoTradeoffOversmoothingOversquashing2023,
  title = {On the {{Trade-off}} between {{Over-smoothing}} and {{Over-squashing}} in {{Deep Graph Neural Networks}}},
  booktitle = {Proceedings of the 32nd {{ACM International Conference}} on {{Information}} and {{Knowledge Management}}},
  author = {Giraldo, Jhony H. and Skianis, Konstantinos and Bouwmans, Thierry and Malliaros, Fragkiskos D.},
  date = {2023-10-21},
  eprint = {2212.02374},
  eprinttype = {arXiv},
  eprintclass = {cs},
  pages = {566--576},
  doi = {10.1145/3583780.3614997},
  url = {http://arxiv.org/abs/2212.02374},
  urldate = {2025-02-27},
  abstract = {Graph Neural Networks (GNNs) have succeeded in various computer science applications, yet deep GNNs underperform their shallow counterparts despite deep learning's success in other domains. Over-smoothing and over-squashing are key challenges when stacking graph convolutional layers, hindering deep representation learning and information propagation from distant nodes. Our work reveals that over-smoothing and over-squashing are intrinsically related to the spectral gap of the graph Laplacian, resulting in an inevitable trade-off between these two issues, as they cannot be alleviated simultaneously. To achieve a suitable compromise, we propose adding and removing edges as a viable approach. We introduce the Stochastic Jost and Liu Curvature Rewiring (SJLR) algorithm, which is computationally efficient and preserves fundamental properties compared to previous curvature-based methods. Unlike existing approaches, SJLR performs edge addition and removal during GNN training while maintaining the graph unchanged during testing. Comprehensive comparisons demonstrate SJLR's competitive performance in addressing over-smoothing and over-squashing.},
  keywords = {Computer Science - Artificial Intelligence,Computer Science - Machine Learning},
  file = {/Users/michaelvolk/Zotero/storage/ELVAA52R/Giraldo et al_2023_On the Trade-off between Over-smoothing and Over-squashing in Deep Graph Neural.pdf;/Users/michaelvolk/Zotero/storage/CKBWH3JA/2212.html}
}

@article{gombertMathematicalModellingMetabolism2000,
  title = {Mathematical Modelling of Metabolism},
  author = {Gombert, Andreas Karoly and Nielsen, Jens},
  date = {2000-04-01},
  journaltitle = {Current Opinion in Biotechnology},
  shortjournal = {Current Opinion in Biotechnology},
  volume = {11},
  number = {2},
  pages = {180--186},
  issn = {0958-1669},
  doi = {10.1016/S0958-1669(00)00079-3},
  url = {https://www.sciencedirect.com/science/article/pii/S0958166900000793},
  urldate = {2023-04-04},
  abstract = {Mathematical models of the cellular metabolism have a special interest within biotechnology. Many different kinds of commercially important products are derived from the cell factory, and metabolic engineering can be applied to improve existing production processes, as well as to make new processes available. Both stoichiometric and kinetic models have been used to investigate the metabolism, which has resulted in defining the optimal fermentation conditions, as well as in directing the genetic changes to be introduced in order to obtain a good producer strain or cell line. With the increasing availability of genomic information and powerful analytical techniques, mathematical models also serve as a tool for understanding the cellular metabolism and physiology.},
  langid = {english},
  keywords = {Cellular metabolism,Kinetic models,MFA,Stoichiometric models},
  annotation = {128 citations (Semantic Scholar/DOI) [2023-04-04]},
  file = {/Users/michaelvolk/Zotero/storage/R72F6LL8/S0958166900000793.html}
}

@article{grafahrend-belauModularizationBiochemicalNetworks2008,
  title = {Modularization of Biochemical Networks Based on Classification of {{Petri}} Net T-Invariants},
  author = {Grafahrend-Belau, Eva and Schreiber, Falk and Heiner, Monika and Sackmann, Andrea and Junker, Björn H. and Grunwald, Stefanie and Speer, Astrid and Winder, Katja and Koch, Ina},
  date = {2008-02-08},
  journaltitle = {BMC Bioinformatics},
  shortjournal = {BMC Bioinformatics},
  volume = {9},
  number = {1},
  pages = {90},
  issn = {1471-2105},
  doi = {10.1186/1471-2105-9-90},
  url = {https://doi.org/10.1186/1471-2105-9-90},
  urldate = {2023-04-05},
  abstract = {Structural analysis of biochemical networks is a growing field in bioinformatics and systems biology. The availability of an increasing amount of biological data from molecular biological networks promises a deeper understanding but confronts researchers with the problem of combinatorial explosion. The amount of qualitative network data is growing much faster than the amount of quantitative data, such as enzyme kinetics. In many cases it is even impossible to measure quantitative data because of limitations of experimental methods, or for ethical reasons. Thus, a huge amount of qualitative data, such as interaction data, is available, but it was not sufficiently used for modeling purposes, until now. New approaches have been developed, but the complexity of data often limits the application of many of the methods. Biochemical Petri nets make it possible to explore static and dynamic qualitative system properties. One Petri net approach is model validation based on the computation of the system's invariant properties, focusing on t-invariants. T-invariants correspond to subnetworks, which describe the basic system behavior.},
  langid = {english},
  keywords = {Biochemical Network,Complete Linkage,Duchenne Muscular Dystrophy,Silhouette Width},
  annotation = {94 citations (Semantic Scholar/DOI) [2023-04-05]},
  file = {/Users/michaelvolk/Zotero/storage/TW77Q2V8/Grafahrend-Belau et al_2008_Modularization of biochemical networks based on classification of Petri net.pdf}
}

@online{GraphAttentionNetworks,
  title = {Graph {{Attention Networks}} with {{Positional Embeddings}} - {{Meta Research}}},
  url = {https://research.facebook.com/publications/graph-attention-networks-with-positional-embeddings/},
  urldate = {2023-10-13},
  abstract = {In this work, we focus on addressing this limitation and enable Graph Attention Networks (GAT), a commonly used variant of GNNs, to explore the structural information within each graph locality. Inspired by the positional encoding in the Transformers, we propose a framework, termed Graph Attentional Networks with Positional Embeddings (GAT-POS), to enhance GATs with positional embeddings which capture structural and positional information of the nodes in the graph.},
  langid = {english},
  organization = {Meta Research}
}

@article{grattarolaUnderstandingPoolingGraph2024,
  title = {Understanding {{Pooling}} in {{Graph Neural Networks}}},
  author = {Grattarola, Daniele and Zambon, Daniele and Bianchi, Filippo Maria and Alippi, Cesare},
  date = {2024-02},
  journaltitle = {IEEE Transactions on Neural Networks and Learning Systems},
  volume = {35},
  number = {2},
  pages = {2708--2718},
  issn = {2162-2388},
  doi = {10.1109/TNNLS.2022.3190922},
  url = {https://ieeexplore.ieee.org/abstract/document/9836996?casa_token=jxA9ayXjtz8AAAAA:1ZGFkYM3XwjjzAn_yltINiopvEp3e9um5uFU3T0-volDn_F8aR7CP5Il9F7QWUXEREVUrzw1Xg0},
  urldate = {2024-03-11},
  abstract = {Many recent works in the field of graph machine learning have introduced pooling operators to reduce the size of graphs. In this article, we present an operational framework to unify this vast and diverse literature by describing pooling operators as the combination of three functions: selection, reduction, and connection (SRC). We then introduce a taxonomy of pooling operators, based on some of their key characteristics and implementation differences under the SRC framework. Finally, we propose three criteria to evaluate the performance of pooling operators and use them to investigate the behavior of different operators on a variety of tasks.},
  eventtitle = {{{IEEE Transactions}} on {{Neural Networks}} and {{Learning Systems}}},
  keywords = {Aggregates,Clustering algorithms,Convolution,Dimensionality reduction,graph neural networks (GNNs),Laplace equations,Point cloud compression,Task analysis,Taxonomy},
  annotation = {50 citations (Semantic Scholar/DOI) [2024-03-11]},
  file = {/Users/michaelvolk/Zotero/storage/NK5RENQX/Grattarola et al_2024_Understanding Pooling in Graph Neural Networks.pdf;/Users/michaelvolk/Zotero/storage/7FH5KN39/9836996.html}
}

@article{haasDesigningInterpretingMultiomic2017,
  title = {Designing and Interpreting ‘Multi-Omic’ Experiments That May Change Our Understanding of Biology},
  author = {Haas, Robert and Zelezniak, Aleksej and Iacovacci, Jacopo and Kamrad, Stephan and Townsend, StJohn and Ralser, Markus},
  date = {2017-12-01},
  journaltitle = {Current Opinion in Systems Biology},
  shortjournal = {Current Opinion in Systems Biology},
  series = {Systems Biology of Model Organisms},
  volume = {6},
  pages = {37--45},
  issn = {2452-3100},
  doi = {10.1016/j.coisb.2017.08.009},
  url = {https://www.sciencedirect.com/science/article/pii/S2452310017300835},
  urldate = {2023-11-02},
  abstract = {Most biological mechanisms involve more than one type of biomolecule, and hence operate not solely at the level of either genome, transcriptome, proteome, metabolome or ionome. Datasets resulting from single-omic analysis are rapidly increasing in throughput and quality, rendering multi-omic studies feasible. These should offer a comprehensive, structured and interactive overview of a biological mechanism. However, combining single-omic datasets in a meaningful manner has so far proved challenging, and the discovery of new biological information lags behind expectation. One reason is that experiments conducted in different laboratories can typically not to be combined without restriction. Second, the interpretation of multi-omic datasets represents a significant challenge by nature, as the biological datasets are heterogeneous not only for technical, but also for biological, chemical, and physical reasons. Here, multi-layer network theory and methods of artificial intelligence might contribute to solve these problems. For the efficient application of machine learning however, biological datasets need to become more systematic, more precise – and much larger. We conclude our review with basic guidelines for the successful set-up of a multi-omic experiment.},
  annotation = {82 citations (Semantic Scholar/DOI) [2023-11-02]},
  file = {/Users/michaelvolk/Zotero/storage/RS3SRV2D/Haas et al_2017_Designing and interpreting ‘multi-omic’ experiments that may change our.pdf;/Users/michaelvolk/Zotero/storage/SFKC44P5/S2452310017300835.html}
}

@article{haoDictionaryLearningIntegrative2023,
  title = {Dictionary Learning for Integrative, Multimodal and Scalable Single-Cell Analysis},
  author = {Hao, Yuhan and Stuart, Tim and Kowalski, Madeline H. and Choudhary, Saket and Hoffman, Paul and Hartman, Austin and Srivastava, Avi and Molla, Gesmira and Madad, Shaista and Fernandez-Granda, Carlos and Satija, Rahul},
  date = {2023-05-25},
  journaltitle = {Nature Biotechnology},
  shortjournal = {Nat Biotechnol},
  pages = {1--12},
  publisher = {Nature Publishing Group},
  issn = {1546-1696},
  doi = {10.1038/s41587-023-01767-y},
  url = {https://www.nature.com/articles/s41587-023-01767-y},
  urldate = {2023-09-14},
  abstract = {Mapping single-cell sequencing profiles to comprehensive reference datasets provides a powerful alternative to unsupervised analysis. However, most reference datasets are constructed from single-cell RNA-sequencing data and cannot be used to annotate datasets that do not measure gene expression. Here we introduce ‘bridge integration’, a method to integrate single-cell datasets across modalities using a multiomic dataset as a molecular bridge. Each cell in the multiomic dataset constitutes an element in a ‘dictionary’, which is used to reconstruct unimodal datasets and transform them into a shared space. Our procedure accurately integrates transcriptomic data with independent single-cell measurements of chromatin accessibility, histone modifications, DNA methylation and protein levels. Moreover, we demonstrate how dictionary learning can be combined with sketching techniques to improve computational scalability and harmonize 8.6 million human immune cell profiles from sequencing and mass cytometry experiments. Our approach, implemented in version 5 of our Seurat toolkit (http://www.satijalab.org/seurat), broadens the utility of single-cell reference datasets and facilitates comparisons across diverse molecular modalities.},
  langid = {english},
  keywords = {Epigenomics,Genomics},
  file = {/Users/michaelvolk/Zotero/storage/I2Z7XNGS/Hao et al_2023_Dictionary learning for integrative, multimodal and scalable single-cell.pdf}
}

@article{haoLargescaleFoundationModel2024,
  title = {Large-Scale Foundation Model on Single-Cell Transcriptomics},
  author = {Hao, Minsheng and Gong, Jing and Zeng, Xin and Liu, Chiming and Guo, Yucheng and Cheng, Xingyi and Wang, Taifeng and Ma, Jianzhu and Zhang, Xuegong and Song, Le},
  date = {2024-08},
  journaltitle = {Nature Methods},
  shortjournal = {Nat Methods},
  volume = {21},
  number = {8},
  pages = {1481--1491},
  publisher = {Nature Publishing Group},
  issn = {1548-7105},
  doi = {10.1038/s41592-024-02305-7},
  url = {https://www.nature.com/articles/s41592-024-02305-7},
  urldate = {2025-02-13},
  abstract = {Large pretrained models have become foundation models leading to breakthroughs in natural language processing and related fields. Developing foundation models for deciphering the ‘languages’ of cells and facilitating biomedical research is promising yet challenging. Here we developed a large pretrained model scFoundation, also named ‘xTrimoscFoundationα’, with 100 million parameters covering about 20,000 genes, pretrained on over 50 million human single-cell transcriptomic profiles. scFoundation is a large-scale model in terms of the size of trainable parameters, dimensionality of genes and volume of training data. Its asymmetric transformer-like architecture and pretraining task design empower effectively capturing complex context relations among genes in a variety of cell types and states. Experiments showed its merit as a foundation model that achieved state-of-the-art performances in a diverse array of single-cell analysis tasks such as gene expression enhancement, tissue drug response prediction, single-cell drug response classification, single-cell perturbation prediction, cell type annotation and gene module inference.},
  langid = {english},
  keywords = {Computational models,Machine learning,Software,Transcriptomics},
  file = {/Users/michaelvolk/Zotero/storage/TPXTMSML/Hao et al_2024_Large-scale foundation model on single-cell transcriptomics.pdf}
}

@article{haoLargescaleFoundationModel2024a,
  title = {Large-Scale Foundation Model on Single-Cell Transcriptomics},
  author = {Hao, Minsheng and Gong, Jing and Zeng, Xin and Liu, Chiming and Guo, Yucheng and Cheng, Xingyi and Wang, Taifeng and Ma, Jianzhu and Zhang, Xuegong and Song, Le},
  date = {2024-08},
  journaltitle = {Nature Methods},
  shortjournal = {Nat Methods},
  volume = {21},
  number = {8},
  pages = {1481--1491},
  publisher = {Nature Publishing Group},
  issn = {1548-7105},
  doi = {10.1038/s41592-024-02305-7},
  url = {https://www.nature.com/articles/s41592-024-02305-7},
  urldate = {2025-05-08},
  abstract = {Large pretrained models have become foundation models leading to breakthroughs in natural language processing and related fields. Developing foundation models for deciphering the ‘languages’ of cells and facilitating biomedical research is promising yet challenging. Here we developed a large pretrained model scFoundation, also named ‘xTrimoscFoundationα’, with 100 million parameters covering about 20,000 genes, pretrained on over 50 million human single-cell transcriptomic profiles. scFoundation is a large-scale model in terms of the size of trainable parameters, dimensionality of genes and volume of training data. Its asymmetric transformer-like architecture and pretraining task design empower effectively capturing complex context relations among genes in a variety of cell types and states. Experiments showed its merit as a foundation model that achieved state-of-the-art performances in a diverse array of single-cell analysis tasks such as gene expression enhancement, tissue drug response prediction, single-cell drug response classification, single-cell perturbation prediction, cell type annotation and gene module inference.},
  langid = {english},
  keywords = {Computational models,Machine learning,Software,Transcriptomics},
  file = {/Users/michaelvolk/Zotero/storage/MBP2APYG/Hao et al_2024_Large-scale foundation model on single-cell transcriptomics.pdf}
}

@article{hardwickEditorialYeastDifferentiation2022,
  title = {Editorial: {{Yeast Differentiation}}: {{From Cell-to-Cell Heterogeneity}} to {{Replicative Aging}} and {{Regulated Cell Death}}},
  shorttitle = {Editorial},
  author = {Hardwick, J. Marie and Knorre, Dmitry and Palkova, Zdena and Winderickx, Joris},
  date = {2022-01-04},
  journaltitle = {Frontiers in Cell and Developmental Biology},
  shortjournal = {Front. Cell Dev. Biol.},
  volume = {9},
  publisher = {Frontiers},
  issn = {2296-634X},
  doi = {10.3389/fcell.2021.823447},
  url = {https://www.frontiersin.org/journals/cell-and-developmental-biology/articles/10.3389/fcell.2021.823447/full},
  urldate = {2024-07-07},
  langid = {english},
  keywords = {Biofilm,differentiation,heterogeneity,programmed cell death,yeast},
  file = {/Users/michaelvolk/Zotero/storage/UBMXHNVY/Hardwick et al_2022_Editorial.pdf}
}

@article{hardwickEditorialYeastDifferentiation2022a,
  title = {Editorial: {{Yeast Differentiation}}: {{From Cell-to-Cell Heterogeneity}} to {{Replicative Aging}} and {{Regulated Cell Death}}},
  shorttitle = {Editorial},
  author = {Hardwick, J. Marie and Knorre, Dmitry and Palkova, Zdena and Winderickx, Joris},
  date = {2022-01-04},
  journaltitle = {Frontiers in Cell and Developmental Biology},
  shortjournal = {Front. Cell Dev. Biol.},
  volume = {9},
  publisher = {Frontiers},
  issn = {2296-634X},
  doi = {10.3389/fcell.2021.823447},
  url = {https://www.frontiersin.org/journals/cell-and-developmental-biology/articles/10.3389/fcell.2021.823447/full},
  urldate = {2024-07-07},
  langid = {english},
  keywords = {Biofilm,differentiation,heterogeneity,programmed cell death,yeast},
  annotation = {2 citations (Semantic Scholar/DOI) [2024-07-06]},
  file = {/Users/michaelvolk/Zotero/storage/UZAG5B6H/Hardwick et al_2022_Editorial.pdf}
}

@article{hasibiIntegrationGraphNeural2024,
  title = {Integration of Graph Neural Networks and Genome-Scale Metabolic Models for Predicting Gene Essentiality},
  author = {Hasibi, Ramin and Michoel, Tom and Oyarzún, Diego A.},
  date = {2024-03-06},
  journaltitle = {npj Systems Biology and Applications},
  shortjournal = {npj Syst Biol Appl},
  volume = {10},
  number = {1},
  pages = {1--10},
  publisher = {Nature Publishing Group},
  issn = {2056-7189},
  doi = {10.1038/s41540-024-00348-2},
  url = {https://www.nature.com/articles/s41540-024-00348-2},
  urldate = {2024-03-29},
  abstract = {Genome-scale metabolic models are powerful tools for understanding cellular physiology. Flux balance analysis (FBA), in particular, is an optimization-based approach widely employed for predicting metabolic phenotypes. In model microbes such as Escherichia coli, FBA has been successful at predicting essential genes, i.e. those genes that impair survival when deleted. A central assumption in this approach is that both wild type and deletion strains optimize the same fitness objective. Although the optimality assumption may hold for the wild type metabolic network, deletion strains are not subject to the same evolutionary pressures and knock-out mutants may steer their metabolism to meet other objectives for survival. Here, we present FlowGAT, a hybrid FBA-machine learning strategy for predicting essentiality directly from wild type metabolic phenotypes. The approach is based on graph-structured representation of metabolic fluxes predicted by FBA, where nodes correspond to enzymatic reactions and edges quantify the propagation of metabolite mass flow between a reaction and its neighbours. We integrate this information into a graph neural network that can be trained on knock-out fitness assay data. Comparisons across different model architectures reveal that FlowGAT predictions for E. coli are close to those of FBA for several growth conditions. This suggests that essentiality of enzymatic genes can be predicted by exploiting the inherent network structure of metabolism. Our approach demonstrates the benefits of combining the mechanistic insights afforded by genome-scale models with the ability of deep learning to infer patterns from complex datasets.},
  langid = {english},
  keywords = {🦌✅,Biochemical networks,Cell biology,Computational science},
  file = {/Users/michaelvolk/Zotero/storage/WBSQKAEZ/Hasibi et al_2024_Integration of graph neural networks and genome-scale metabolic models for.pdf}
}

@incollection{hastieGeneralizedAdditiveModels1992,
  title = {Generalized {{Additive Models}}},
  booktitle = {Statistical {{Models}} in {{S}}},
  author = {Hastie, Trevor J.},
  date = {1992},
  publisher = {Routledge},
  abstract = {This chapter discusses the innovations of additional flexible methods for modeling an individual term in an additive model. It focuses on how we fit additive models. A general and efficient algorithm for fitting a generalized additive model consists of a hierarchy of three modules: scatterplot smoothers, backfitting algorithm, and local-scoring algorithm. These three steps are a rather natural and intuitive generalization of the usual linear model algorithms, and that is how they were originally conceived. The algorithm for fitting a gam is exactly analogous to the algorithm for glms. The chapter presents the S functions for fitting and understanding generalized additive models. In some cases, especially for generalized linear or additive models, adding residuals to a plot is unhelpful because they can distort the scale dramatically. Any interesting features in the functions get lost because of a few large residuals, even though they may carry a very small weight.},
  isbn = {978-0-203-73853-5},
  pagetotal = {59},
  file = {/Users/michaelvolk/Zotero/storage/A2PQVH73/1177013604.pdf}
}

@inproceedings{hayhoeTransferableHypergraphNeural2024,
  title = {Transferable {{Hypergraph Neural Networks}} via {{Spectral Similarity}}},
  booktitle = {Proceedings of the {{Second Learning}} on {{Graphs Conference}}},
  author = {Hayhoe, Mikhail and Riess, Hans Matthew and Zavlanos, Michael M. and Preciado, Victor and Ribeiro, Alejandro},
  date = {2024-04-17},
  pages = {18:1-18:23},
  publisher = {PMLR},
  issn = {2640-3498},
  url = {https://proceedings.mlr.press/v231/hayhoe24a.html},
  urldate = {2025-04-23},
  abstract = {Hypergraphs model higher-order interactions in complex systems, e.g., chemicals reacting only in the presence of an enzyme or rumors spreading across groups, and encompass both the notion of an undirected graph and a simplicial complex. Nonetheless, due to computational complexity, machine learning on hypergraph-structured data is notoriously challenging. In an effort to transfer hypergraph neural network models, addressing this challenge, we extend results on the transferability of Graph Neural Networks (GNNs) to design a convolutional architecture for processing signals supported on hypergraphs via GNNs, which we call Hypergraph Expansion Neural Networks (HENNs). Exploiting multiple spectrally-similar graph representations of hypergraphs, we establish bounds on the transferability error. Experimental results illustrate the importance of considering multiple graph representations in HENNs, and show promise of superior performance when transferability is required.},
  eventtitle = {Learning on {{Graphs Conference}}},
  langid = {english},
  file = {/Users/michaelvolk/Zotero/storage/85NL3LTM/Hayhoe et al_2024_Transferable Hypergraph Neural Networks via Spectral Similarity.pdf}
}

@online{heGeneralizingGraphTransformers2024,
  title = {Generalizing {{Graph Transformers Across Diverse Graphs}} and {{Tasks}} via {{Pre-Training}} on {{Industrial-Scale Data}}},
  author = {He, Yufei and Hou, Zhenyu and Cen, Yukuo and He, Feng and Cheng, Xu and Hooi, Bryan},
  date = {2024-09-13},
  eprint = {2407.03953},
  eprinttype = {arXiv},
  eprintclass = {cs},
  doi = {10.48550/arXiv.2407.03953},
  url = {http://arxiv.org/abs/2407.03953},
  urldate = {2025-02-19},
  abstract = {Graph pre-training has been concentrated on graph-level on small graphs (e.g., molecular graphs) or learning node representations on a fixed graph. Extending graph pre-trained models to web-scale graphs with billions of nodes in industrial scenarios, while avoiding negative transfer across graphs or tasks, remains a challenge. We aim to develop a general graph pre-trained model with inductive ability that can make predictions for unseen new nodes and even new graphs. In this work, we introduce a scalable transformer-based graph pre-training framework called PGT (Pre-trained Graph Transformer). Specifically, we design a flexible and scalable graph transformer as the backbone network. Meanwhile, based on the masked autoencoder architecture, we design two pre-training tasks: one for reconstructing node features and the other one for reconstructing local structures. Unlike the original autoencoder architecture where the pre-trained decoder is discarded, we propose a novel strategy that utilizes the decoder for feature augmentation. We have deployed our framework on Tencent's online game data. Extensive experiments have demonstrated that our framework can perform pre-training on real-world web-scale graphs with over 540 million nodes and 12 billion edges and generalizes effectively to unseen new graphs with different downstream tasks. We further conduct experiments on the publicly available ogbn-papers100M dataset, which consists of 111 million nodes and 1.6 billion edges. Our framework achieves state-of-the-art performance on both industrial datasets and public datasets, while also enjoying scalability and efficiency.},
  pubstate = {prepublished},
  version = {3},
  keywords = {Computer Science - Machine Learning,Computer Science - Social and Information Networks},
  annotation = {1 citations (Semantic Scholar/arXiv) [2025-02-19]\\
1 citations (Semantic Scholar/DOI) [2025-02-19]},
  file = {/Users/michaelvolk/Zotero/storage/N4E5Q8BA/He et al_2024_Generalizing Graph Transformers Across Diverse Graphs and Tasks via.pdf;/Users/michaelvolk/Zotero/storage/57HL5E7H/2407.html}
}

@online{heHDTHierarchicalDocument2024,
  title = {{{HDT}}: {{Hierarchical Document Transformer}}},
  shorttitle = {{{HDT}}},
  author = {He, Haoyu and Flicke, Markus and Buchmann, Jan and Gurevych, Iryna and Geiger, Andreas},
  date = {2024-07-11},
  eprint = {2407.08330},
  eprinttype = {arXiv},
  eprintclass = {cs},
  doi = {10.48550/arXiv.2407.08330},
  url = {http://arxiv.org/abs/2407.08330},
  urldate = {2025-02-12},
  abstract = {In this paper, we propose the Hierarchical Document Transformer (HDT), a novel sparse Transformer architecture tailored for structured hierarchical documents. Such documents are extremely important in numerous domains, including science, law or medicine. However, most existing solutions are inefficient and fail to make use of the structure inherent to documents. HDT exploits document structure by introducing auxiliary anchor tokens and redesigning the attention mechanism into a sparse multi-level hierarchy. This approach facilitates information exchange between tokens at different levels while maintaining sparsity, thereby enhancing computational and memory efficiency while exploiting the document structure as an inductive bias. We address the technical challenge of implementing HDT's sample-dependent hierarchical attention pattern by developing a novel sparse attention kernel that considers the hierarchical structure of documents. As demonstrated by our experiments, utilizing structural information present in documents leads to faster convergence, higher sample efficiency and better performance on downstream tasks.},
  pubstate = {prepublished},
  keywords = {Computer Science - Machine Learning},
  annotation = {0 citations (Semantic Scholar/arXiv) [2025-02-12]\\
0 citations (Semantic Scholar/DOI) [2025-02-12]},
  file = {/Users/michaelvolk/Zotero/storage/H28ZDFVC/He et al_2024_HDT.pdf;/Users/michaelvolk/Zotero/storage/3GPSIWSD/2407.html}
}

@article{heinsQuantitativeFlowCytometry2019a,
  title = {Quantitative {{Flow Cytometry}} to {{Understand Population Heterogeneity}} in {{Response}} to {{Changes}} in {{Substrate Availability}} in {{Escherichia}} Coli and {{Saccharomyces}} Cerevisiae {{Chemostats}}},
  author = {Heins, Anna-Lena and Johanson, Ted and Han, Shanshan and Lundin, Luisa and Carlquist, Magnus and Gernaey, Krist V. and Sørensen, Søren J. and Eliasson Lantz, Anna},
  date = {2019-08-05},
  journaltitle = {Frontiers in Bioengineering and Biotechnology},
  shortjournal = {Front. Bioeng. Biotechnol.},
  volume = {7},
  publisher = {Frontiers},
  issn = {2296-4185},
  doi = {10.3389/fbioe.2019.00187},
  url = {https://www.frontiersin.org/journals/bioengineering-and-biotechnology/articles/10.3389/fbioe.2019.00187/full},
  urldate = {2024-07-07},
  abstract = {{$<$}p{$>$}Microbial cells in bioprocesses are usually described with averaged parameters. But in fact, single cells within populations vary greatly in characteristics such as stress resistance, especially in response to carbon source gradients. Our aim was to introduce tools to quantify population heterogeneity in bioprocesses using a combination of reporter strains, flow cytometry, and easily comprehensible parameters. We calculated mean, mode, peak width, and coefficient of variance to describe distribution characteristics and temporal shifts in fluorescence intensity. The skewness and the slope of cumulative distribution function plots illustrated differences in distribution shape. These parameters are person-independent and precise. We demonstrated this by quantifying growth-related population heterogeneity of {$<$}italic{$>$}Saccharomyces cerevisiae{$<$}/italic{$>$} and {$<$}italic{$>$}Escherichia coli{$<$}/italic{$>$} reporter strains in steady-state of aerobic glucose-limited chemostat cultures at different dilution rates and in response to glucose pulses. Generally, slow-growing cells showed stronger responses to glucose excess than fast-growing cells. Cell robustness, measured as membrane integrity after exposure to freeze-thaw treatment, of fast-growing cells was strongly affected in subpopulations of low membrane robustness. Glucose pulses protected subpopulations of fast-growing but not slower-growing yeast cells against membrane damage. Our parameters could successfully describe population heterogeneity, thereby revealing physiological characteristics that might have been overlooked during traditional averaged analysis.{$<$}/p{$>$}},
  langid = {english},
  keywords = {Flow Cytometry,Membrane robustness,population heterogeneity,Quantitative flow cytometry,Reporter strain},
  annotation = {23 citations (Semantic Scholar/DOI) [2024-07-06]},
  file = {/Users/michaelvolk/Zotero/storage/BERXTZSZ/Heins et al_2019_Quantitative Flow Cytometry to Understand Population Heterogeneity in Response.pdf}
}

@article{helmyTenSimpleRules2016,
  title = {Ten {{Simple Rules}} for {{Developing Public Biological Databases}}},
  author = {Helmy, Mohamed and Crits-Christoph, Alexander and Bader, Gary D.},
  date = {2016-11-10},
  journaltitle = {PLOS Computational Biology},
  shortjournal = {PLOS Computational Biology},
  volume = {12},
  number = {11},
  pages = {e1005128},
  publisher = {Public Library of Science},
  issn = {1553-7358},
  doi = {10.1371/journal.pcbi.1005128},
  url = {https://journals.plos.org/ploscompbiol/article?id=10.1371/journal.pcbi.1005128},
  urldate = {2023-11-23},
  langid = {english},
  keywords = {Biological databases,Computer software,Data visualization,Database searching,Graphical user interfaces,Internet,Protein interactions,Web-based applications},
  annotation = {27 citations (Semantic Scholar/DOI) [2023-11-23]},
  file = {/Users/michaelvolk/Zotero/storage/6KIZZJYU/Helmy et al_2016_Ten Simple Rules for Developing Public Biological Databases.pdf}
}

@article{hetzelGraphRepresentationLearning2021,
  title = {Graph Representation Learning for Single-Cell Biology},
  author = {Hetzel, Leon and Fischer, David S. and Günnemann, Stephan and Theis, Fabian J.},
  date = {2021-12-01},
  journaltitle = {Current Opinion in Systems Biology},
  shortjournal = {Current Opinion in Systems Biology},
  volume = {28},
  pages = {100347},
  issn = {2452-3100},
  doi = {10.1016/j.coisb.2021.05.008},
  url = {https://www.sciencedirect.com/science/article/pii/S2452310021000329},
  urldate = {2023-05-12},
  abstract = {Single-cell RNA sequencing measures gene expression at an unprecedented resolution and scale and allows the analysis of cellular phenotypes which was not possible before. In this context, graphs occur as a natural representation of the system —both as gene-centric and cell-centric. However, many advances in machine learning on graphs are not yet harnessed in models on single-cell data. Taking the inference of cell types or gene interactions as examples, graph representation learning has a wide applicability to both cell and gene graphs. Recent advances in spatial molecular profiling additionally put graph learning in the focus of attention because of the innate resemblance of spatial information to spatial graphs. We argue that graph embedding techniques have great potential for various applications across single-cell biology. Here, we discuss how graph representation learning maps to current models and concepts used in single-cell biology and formalise overlaps to developments in graph-based deep learning.},
  langid = {english},
  keywords = {Deep learning,Graph representation learning,Graphs,Single cell},
  annotation = {9 citations (Semantic Scholar/DOI) [2023-05-12]},
  file = {/Users/michaelvolk/Zotero/storage/PKKW2828/Hetzel et al. - 2021 - Graph representation learning for single-cell biol.pdf;/Users/michaelvolk/Zotero/storage/XCKDZ63G/S2452310021000329.html}
}

@article{heydaribeniDistributedConstrainedCombinatorial2024,
  title = {Distributed Constrained Combinatorial Optimization Leveraging Hypergraph Neural Networks},
  author = {Heydaribeni, Nasimeh and Zhan, Xinrui and Zhang, Ruisi and Eliassi-Rad, Tina and Koushanfar, Farinaz},
  date = {2024-05-30},
  journaltitle = {Nature Machine Intelligence},
  shortjournal = {Nat Mach Intell},
  pages = {1--9},
  publisher = {Nature Publishing Group},
  issn = {2522-5839},
  doi = {10.1038/s42256-024-00833-7},
  url = {https://www.nature.com/articles/s42256-024-00833-7},
  urldate = {2024-06-24},
  abstract = {Scalable addressing of high-dimensional constrained combinatorial optimization problems is a challenge that arises in several science and engineering disciplines. Recent work introduced novel applications of graph neural networks for solving quadratic-cost combinatorial optimization problems. However, effective utilization of models such as graph neural networks to address general problems with higher-order constraints is an unresolved challenge. This paper presents a framework, HypOp, that advances the state of the art for solving combinatorial optimization problems in several aspects: (1) it generalizes the prior results to higher-order constrained problems with arbitrary cost functions by leveraging hypergraph neural networks; (2) it enables scalability to larger problems by introducing a new distributed and parallel training architecture; (3) it demonstrates generalizability across different problem formulations by transferring knowledge within the same hypergraph; (4) it substantially boosts the solution accuracy compared with the prior art by suggesting a fine-tuning step using simulated annealing; and (5) it shows remarkable progress on numerous benchmark examples, including hypergraph MaxCut, satisfiability and resource allocation problems, with notable run-time improvements using a combination of fine-tuning and distributed training techniques. We showcase the application of HypOp in scientific discovery by solving a hypergraph MaxCut problem on a National Drug Code drug-substance hypergraph. Through extensive experimentation on various optimization problems, HypOp demonstrates superiority over existing unsupervised-learning-based solvers and generic optimization methods.},
  langid = {english},
  keywords = {Computational science,Computer science},
  file = {/Users/michaelvolk/Zotero/storage/RLNFNJA4/Heydaribeni et al_2024_Distributed constrained combinatorial optimization leveraging hypergraph neural.pdf}
}

@article{hillenmeyerChemicalGenomicPortrait2008b,
  title = {The {{Chemical Genomic Portrait}} of {{Yeast}}: {{Uncovering}} a {{Phenotype}} for {{All Genes}}},
  shorttitle = {The {{Chemical Genomic Portrait}} of {{Yeast}}},
  author = {Hillenmeyer, Maureen E. and Fung, Eula and Wildenhain, Jan and Pierce, Sarah E. and Hoon, Shawn and Lee, William and Proctor, Michael and St.Onge, Robert P. and Tyers, Mike and Koller, Daphne and Altman, Russ B. and Davis, Ronald W. and Nislow, Corey and Giaever, Guri},
  date = {2008-04-18},
  journaltitle = {Science},
  shortjournal = {Science},
  volume = {320},
  number = {5874},
  pages = {362--365},
  issn = {0036-8075, 1095-9203},
  doi = {10.1126/science.1150021},
  url = {https://www.science.org/doi/10.1126/science.1150021},
  urldate = {2023-10-20},
  abstract = {Genetics aims to understand the relation between genotype and phenotype. However, because complete deletion of most yeast genes (∼80\%) has no obvious phenotypic consequence in rich medium, it is difficult to study their functions. To uncover phenotypes for this nonessential fraction of the genome, we performed 1144 chemical genomic assays on the yeast whole-genome heterozygous and homozygous deletion collections and quantified the growth fitness of each deletion strain in the presence of chemical or environmental stress conditions. We found that 97\% of gene deletions exhibited a measurable growth phenotype, suggesting that nearly all genes are essential for optimal growth in at least one condition.},
  langid = {english},
  annotation = {964 citations (Semantic Scholar/DOI) [2023-10-19]},
  file = {/Users/michaelvolk/Zotero/storage/LCXQA35U/Hillenmeyer et al_2008_The Chemical Genomic Portrait of Yeast.pdf}
}

@online{hollmannTabPFNTransformerThat2023,
  title = {{{TabPFN}}: {{A Transformer That Solves Small Tabular Classification Problems}} in a {{Second}}},
  shorttitle = {{{TabPFN}}},
  author = {Hollmann, Noah and Müller, Samuel and Eggensperger, Katharina and Hutter, Frank},
  date = {2023-09-16},
  eprint = {2207.01848},
  eprinttype = {arXiv},
  eprintclass = {cs},
  doi = {10.48550/arXiv.2207.01848},
  url = {http://arxiv.org/abs/2207.01848},
  urldate = {2025-05-09},
  abstract = {We present TabPFN, a trained Transformer that can do supervised classification for small tabular datasets in less than a second, needs no hyperparameter tuning and is competitive with state-of-the-art classification methods. TabPFN performs in-context learning (ICL), it learns to make predictions using sequences of labeled examples (x, f(x)) given in the input, without requiring further parameter updates. TabPFN is fully entailed in the weights of our network, which accepts training and test samples as a set-valued input and yields predictions for the entire test set in a single forward pass. TabPFN is a Prior-Data Fitted Network (PFN) and is trained offline once, to approximate Bayesian inference on synthetic datasets drawn from our prior. This prior incorporates ideas from causal reasoning: It entails a large space of structural causal models with a preference for simple structures. On the 18 datasets in the OpenML-CC18 suite that contain up to 1 000 training data points, up to 100 purely numerical features without missing values, and up to 10 classes, we show that our method clearly outperforms boosted trees and performs on par with complex state-of-the-art AutoML systems with up to 230\$\textbackslash times\$ speedup. This increases to a 5 700\$\textbackslash times\$ speedup when using a GPU. We also validate these results on an additional 67 small numerical datasets from OpenML. We provide all our code, the trained TabPFN, an interactive browser demo and a Colab notebook at https://github.com/automl/TabPFN.},
  pubstate = {prepublished},
  keywords = {Computer Science - Machine Learning,Statistics - Machine Learning},
  annotation = {248 citations (Semantic Scholar/arXiv) [2025-05-09]},
  file = {/Users/michaelvolk/Zotero/storage/94PPJ54N/2207.html}
}

@inproceedings{hongGraphInducedTransformersEfficient2022,
  title = {Graph-{{Induced Transformers}} for {{Efficient Multi-Hop Question Answering}}},
  booktitle = {Proceedings of the 2022 {{Conference}} on {{Empirical Methods}} in {{Natural Language Processing}}},
  author = {Hong, Giwon and Kim, Jeonghwan and Kang, Junmo and Myaeng, Sung-Hyon},
  editor = {Goldberg, Yoav and Kozareva, Zornitsa and Zhang, Yue},
  date = {2022-12},
  pages = {10288--10294},
  publisher = {Association for Computational Linguistics},
  location = {Abu Dhabi, United Arab Emirates},
  doi = {10.18653/v1/2022.emnlp-main.702},
  url = {https://aclanthology.org/2022.emnlp-main.702/},
  urldate = {2025-02-12},
  abstract = {A graph is a suitable data structure to represent the structural information of text. Recently, multi-hop question answering (MHQA) tasks, which require inter-paragraph/sentence linkages, have come to exploit such properties of a graph. Previous approaches to MHQA relied on leveraging the graph information along with the pre-trained language model (PLM) encoders. However, this trend exhibits the following drawbacks: (i) sample inefficiency while training in a low-resource setting; (ii) lack of reusability due to changes in the model structure or input. Our work proposes the Graph-Induced Transformer (GIT) that applies graph-derived attention patterns directly into a PLM, without the need to employ external graph modules. GIT can leverage the useful inductive bias of graphs while retaining the unperturbed Transformer structure and parameters. Our experiments on HotpotQA successfully demonstrate both the sample efficient characteristic of GIT and its capacity to replace the graph modules while preserving model performance.},
  eventtitle = {{{EMNLP}} 2022},
  annotation = {4 citations (Semantic Scholar/DOI) [2025-02-12]},
  file = {/Users/michaelvolk/Zotero/storage/Z2K62MAF/Hong et al_2022_Graph-Induced Transformers for Efficient Multi-Hop Question Answering.pdf}
}

@article{huangHighthroughputMicrobialCulturomics2023,
  title = {High-Throughput Microbial Culturomics Using Automation and Machine Learning},
  author = {Huang, Yiming and Sheth, Ravi U. and Zhao, Shijie and Cohen, Lucas A. and Dabaghi, Kendall and Moody, Thomas and Sun, Yiwei and Ricaurte, Deirdre and Richardson, Miles and Velez-Cortes, Florencia and Blazejewski, Tomasz and Kaufman, Andrew and Ronda, Carlotta and Wang, Harris H.},
  date = {2023-10},
  journaltitle = {Nature Biotechnology},
  shortjournal = {Nat Biotechnol},
  volume = {41},
  number = {10},
  pages = {1424--1433},
  publisher = {Nature Publishing Group},
  issn = {1546-1696},
  doi = {10.1038/s41587-023-01674-2},
  url = {https://www.nature.com/articles/s41587-023-01674-2},
  urldate = {2024-03-11},
  abstract = {Pure bacterial cultures remain essential for detailed experimental and mechanistic studies in microbiome research, and traditional methods to isolate individual bacteria from complex microbial ecosystems are labor-intensive, difficult-to-scale and lack phenotype–genotype integration. Here we describe an open-source high-throughput robotic strain isolation platform for the rapid generation of isolates on demand. We develop a machine learning approach that leverages colony morphology and genomic data to maximize the diversity of microbes isolated and enable targeted picking of specific genera. Application of this platform on fecal samples from 20 humans yields personalized gut microbiome biobanks totaling 26,997 isolates that represented {$>$}80\% of all abundant taxa. Spatial analysis on {$>$}100,000 visually captured colonies reveals cogrowth patterns between Ruminococcaceae, Bacteroidaceae, Coriobacteriaceae and Bifidobacteriaceae families that suggest important microbial interactions. Comparative analysis of 1,197 high-quality genomes from these biobanks shows interesting intra- and interpersonal strain evolution, selection and horizontal gene transfer. This culturomics framework should empower new research efforts to systematize the collection and quantitative analysis of imaging-based phenotypes with high-resolution genomics data for many emerging microbiome studies.},
  langid = {english},
  keywords = {Bacterial techniques and applications,Microbiology techniques,Microbiome},
  annotation = {32 citations (Semantic Scholar/DOI) [2024-03-11]},
  file = {/Users/michaelvolk/Zotero/storage/Y57BJLUB/Huang et al_2023_High-throughput microbial culturomics using automation and machine learning.pdf}
}

@online{huangUniGNNUnifiedFramework2021,
  title = {{{UniGNN}}: A {{Unified Framework}} for {{Graph}} and {{Hypergraph Neural Networks}}},
  shorttitle = {{{UniGNN}}},
  author = {Huang, Jing and Yang, Jie},
  date = {2021-05-03},
  eprint = {2105.00956},
  eprinttype = {arXiv},
  eprintclass = {cs},
  doi = {10.48550/arXiv.2105.00956},
  url = {http://arxiv.org/abs/2105.00956},
  urldate = {2023-04-21},
  abstract = {Hypergraph, an expressive structure with flexibility to model the higher-order correlations among entities, has recently attracted increasing attention from various research domains. Despite the success of Graph Neural Networks (GNNs) for graph representation learning, how to adapt the powerful GNN-variants directly into hypergraphs remains a challenging problem. In this paper, we propose UniGNN, a unified framework for interpreting the message passing process in graph and hypergraph neural networks, which can generalize general GNN models into hypergraphs. In this framework, meticulously-designed architectures aiming to deepen GNNs can also be incorporated into hypergraphs with the least effort. Extensive experiments have been conducted to demonstrate the effectiveness of UniGNN on multiple real-world datasets, which outperform the state-of-the-art approaches with a large margin. Especially for the DBLP dataset, we increase the accuracy from 77.4\textbackslash\% to 88.8\textbackslash\% in the semi-supervised hypernode classification task. We further prove that the proposed message-passing based UniGNN models are at most as powerful as the 1-dimensional Generalized Weisfeiler-Leman (1-GWL) algorithm in terms of distinguishing non-isomorphic hypergraphs. Our code is available at \textbackslash url\{https://github.com/OneForward/UniGNN\}.},
  pubstate = {prepublished},
  keywords = {Computer Science - Machine Learning,Computer Science - Social and Information Networks}
}

@article{huCrossfeedingPromotesHeterogeneity2024,
  title = {Cross-Feeding Promotes Heterogeneity within Yeast Cell Populations},
  author = {Hu, Kevin K. Y. and Suri, Ankita and Dumsday, Geoff and Haritos, Victoria S.},
  date = {2024-01-10},
  journaltitle = {Nature Communications},
  shortjournal = {Nat Commun},
  volume = {15},
  number = {1},
  pages = {418},
  publisher = {Nature Publishing Group},
  issn = {2041-1723},
  doi = {10.1038/s41467-023-44623-y},
  url = {https://www.nature.com/articles/s41467-023-44623-y},
  urldate = {2024-07-07},
  abstract = {Cellular heterogeneity in cell populations~of isogenic origin is driven by intrinsic factors such as stochastic gene expression, as well as external factors like nutrient availability and interactions with neighbouring cells. Heterogeneity promotes population fitness and thus has important implications in antimicrobial and anticancer treatments, where stress tolerance plays a significant role. Here, we study plasmid retention dynamics within a population of plasmid-complemented ura3∆0 yeast cells, and show that the exchange of complementary metabolites between plasmid-carrying prototrophs and plasmid-free auxotrophs allows the latter to survive and proliferate in selective environments. This process also affects plasmid copy number in plasmid-carrying prototrophs, further promoting cellular functional heterogeneity. Finally, we show that targeted genetic engineering can be used to suppress cross-feeding and reduce the frequency of plasmid-free auxotrophs, or to exploit it for intentional population diversification and division of labour in co-culture systems.},
  langid = {english},
  keywords = {Applied microbiology,Cellular microbiology,Expression systems,Fungi},
  annotation = {0 citations (Semantic Scholar/DOI) [2024-07-06]},
  file = {/Users/michaelvolk/Zotero/storage/MU8B62H8/Hu et al_2024_Cross-feeding promotes heterogeneity within yeast cell populations.pdf}
}

@article{hughesMappingYeastTranscriptional2013,
  title = {Mapping {{Yeast Transcriptional Networks}}},
  author = {Hughes, Timothy R and family=Boer, given=Carl G, prefix=de, useprefix=true},
  date = {2013-09-01},
  journaltitle = {Genetics},
  shortjournal = {Genetics},
  volume = {195},
  number = {1},
  pages = {9--36},
  issn = {1943-2631},
  doi = {10.1534/genetics.113.153262},
  url = {https://doi.org/10.1534/genetics.113.153262},
  urldate = {2023-10-20},
  abstract = {The term “transcriptional network” refers to the mechanism(s) that underlies coordinated expression of genes, typically involving transcription factors (TFs) binding to the promoters of multiple genes, and individual genes controlled by multiple TFs. A multitude of studies in the last two decades have aimed to map and characterize transcriptional networks in the yeast Saccharomyces cerevisiae. We review the methodologies and accomplishments of these studies, as well as challenges we now face. For most yeast TFs, data have been collected on their sequence preferences, in vivo promoter occupancy, and gene expression profiles in deletion mutants. These systematic studies have led to the identification of new regulators of numerous cellular functions and shed light on the overall organization of yeast gene regulation. However, many yeast TFs appear to be inactive under standard laboratory growth conditions, and many of the available data were collected using techniques that have since been improved. Perhaps as a consequence, comprehensive and accurate mapping among TF sequence preferences, promoter binding, and gene expression remains an open challenge. We propose that the time is ripe for renewed systematic efforts toward a complete mapping of yeast transcriptional regulatory mechanisms.},
  annotation = {65 citations (Semantic Scholar/DOI) [2023-10-20]},
  file = {/Users/michaelvolk/Zotero/storage/ZDN7ZZSL/Hughes_de Boer_2013_Mapping Yeast Transcriptional Networks.pdf}
}

@online{huHeterogeneousGraphTransformer2020,
  title = {Heterogeneous {{Graph Transformer}}},
  author = {Hu, Ziniu and Dong, Yuxiao and Wang, Kuansan and Sun, Yizhou},
  date = {2020-03-03},
  eprint = {2003.01332},
  eprinttype = {arXiv},
  eprintclass = {cs},
  doi = {10.48550/arXiv.2003.01332},
  url = {http://arxiv.org/abs/2003.01332},
  urldate = {2025-02-13},
  abstract = {Recent years have witnessed the emerging success of graph neural networks (GNNs) for modeling structured data. However, most GNNs are designed for homogeneous graphs, in which all nodes and edges belong to the same types, making them infeasible to represent heterogeneous structures. In this paper, we present the Heterogeneous Graph Transformer (HGT) architecture for modeling Web-scale heterogeneous graphs. To model heterogeneity, we design node- and edge-type dependent parameters to characterize the heterogeneous attention over each edge, empowering HGT to maintain dedicated representations for different types of nodes and edges. To handle dynamic heterogeneous graphs, we introduce the relative temporal encoding technique into HGT, which is able to capture the dynamic structural dependency with arbitrary durations. To handle Web-scale graph data, we design the heterogeneous mini-batch graph sampling algorithm---HGSampling---for efficient and scalable training. Extensive experiments on the Open Academic Graph of 179 million nodes and 2 billion edges show that the proposed HGT model consistently outperforms all the state-of-the-art GNN baselines by 9\%--21\% on various downstream tasks.},
  pubstate = {prepublished},
  keywords = {Computer Science - Machine Learning,Computer Science - Social and Information Networks,Statistics - Machine Learning},
  annotation = {1070 citations (Semantic Scholar/arXiv) [2025-02-12]},
  file = {/Users/michaelvolk/Zotero/storage/NZVPIMLW/Hu et al. - 2020 - Heterogeneous Graph Transformer.pdf;/Users/michaelvolk/Zotero/storage/CYFKDHFG/2003.html}
}

@online{huHeterogeneousGraphTransformer2020a,
  title = {Heterogeneous {{Graph Transformer}}},
  author = {Hu, Ziniu and Dong, Yuxiao and Wang, Kuansan and Sun, Yizhou},
  date = {2020-03-03},
  eprint = {2003.01332},
  eprinttype = {arXiv},
  eprintclass = {cs},
  doi = {10.48550/arXiv.2003.01332},
  url = {http://arxiv.org/abs/2003.01332},
  urldate = {2025-02-27},
  abstract = {Recent years have witnessed the emerging success of graph neural networks (GNNs) for modeling structured data. However, most GNNs are designed for homogeneous graphs, in which all nodes and edges belong to the same types, making them infeasible to represent heterogeneous structures. In this paper, we present the Heterogeneous Graph Transformer (HGT) architecture for modeling Web-scale heterogeneous graphs. To model heterogeneity, we design node- and edge-type dependent parameters to characterize the heterogeneous attention over each edge, empowering HGT to maintain dedicated representations for different types of nodes and edges. To handle dynamic heterogeneous graphs, we introduce the relative temporal encoding technique into HGT, which is able to capture the dynamic structural dependency with arbitrary durations. To handle Web-scale graph data, we design the heterogeneous mini-batch graph sampling algorithm---HGSampling---for efficient and scalable training. Extensive experiments on the Open Academic Graph of 179 million nodes and 2 billion edges show that the proposed HGT model consistently outperforms all the state-of-the-art GNN baselines by 9\%--21\% on various downstream tasks.},
  pubstate = {prepublished},
  keywords = {Computer Science - Machine Learning,Computer Science - Social and Information Networks,Statistics - Machine Learning},
  annotation = {1093 citations (Semantic Scholar/arXiv) [2025-02-27]},
  file = {/Users/michaelvolk/Zotero/storage/VLBXJB4C/Hu et al_2020_Heterogeneous Graph Transformer.pdf;/Users/michaelvolk/Zotero/storage/3AGS2F6M/2003.html}
}

@online{humayunDeepNetworksAlways2024,
  title = {Deep {{Networks Always Grok}} and {{Here}} Is {{Why}}},
  author = {Humayun, Ahmed Imtiaz and Balestriero, Randall and Baraniuk, Richard},
  date = {2024-06-06},
  eprint = {2402.15555},
  eprinttype = {arXiv},
  eprintclass = {cs},
  doi = {10.48550/arXiv.2402.15555},
  url = {http://arxiv.org/abs/2402.15555},
  urldate = {2025-03-10},
  abstract = {Grokking, or delayed generalization, is a phenomenon where generalization in a deep neural network (DNN) occurs long after achieving near zero training error. Previous studies have reported the occurrence of grokking in specific controlled settings, such as DNNs initialized with large-norm parameters or transformers trained on algorithmic datasets. We demonstrate that grokking is actually much more widespread and materializes in a wide range of practical settings, such as training of a convolutional neural network (CNN) on CIFAR10 or a Resnet on Imagenette. We introduce the new concept of delayed robustness, whereby a DNN groks adversarial examples and becomes robust, long after interpolation and/or generalization. We develop an analytical explanation for the emergence of both delayed generalization and delayed robustness based on the local complexity of a DNN's input-output mapping. Our local complexity measures the density of so-called linear regions (aka, spline partition regions) that tile the DNN input space and serves as a utile progress measure for training. We provide the first evidence that, for classification problems, the linear regions undergo a phase transition during training whereafter they migrate away from the training samples (making the DNN mapping smoother there) and towards the decision boundary (making the DNN mapping less smooth there). Grokking occurs post phase transition as a robust partition of the input space thanks to the linearization of the DNN mapping around the training points. Website: https://bit.ly/grok-adversarial},
  pubstate = {prepublished},
  keywords = {Computer Science - Artificial Intelligence,Computer Science - Computer Vision and Pattern Recognition,Computer Science - Machine Learning},
  annotation = {12 citations (Semantic Scholar/arXiv) [2025-03-09]\\
12 citations (Semantic Scholar/DOI) [2025-03-09]},
  file = {/Users/michaelvolk/Zotero/storage/B3GV3VT4/Humayun et al_2024_Deep Networks Always Grok and Here is Why.pdf;/Users/michaelvolk/Zotero/storage/5Y5JKMBH/2402.html}
}

@article{hunterMolecularBiologyComputer,
  title = {Molecular {{Biology}} for {{Computer Scientists}}},
  author = {Hunter, Lawrence},
  langid = {english},
  keywords = {🦌✅},
  file = {/Users/michaelvolk/Zotero/storage/LGZ7QQK7/Hunter - Molecular Biology for Computer Scientists.pdf}
}

@unpublished{huOpenGraphBenchmark2021,
  title = {Open {{Graph Benchmark}}: {{Datasets}} for {{Machine Learning}} on {{Graphs}}},
  shorttitle = {Open {{Graph Benchmark}}},
  author = {Hu, Weihua and Fey, Matthias and Zitnik, Marinka and Dong, Yuxiao and Ren, Hongyu and Liu, Bowen and Catasta, Michele and Leskovec, Jure},
  date = {2021-02-24},
  eprint = {2005.00687},
  eprinttype = {arXiv},
  eprintclass = {cs, stat},
  url = {http://arxiv.org/abs/2005.00687},
  urldate = {2022-03-21},
  abstract = {We present the Open Graph Benchmark (OGB), a diverse set of challenging and realistic benchmark datasets to facilitate scalable, robust, and reproducible graph machine learning (ML) research. OGB datasets are large-scale, encompass multiple important graph ML tasks, and cover a diverse range of domains, ranging from social and information networks to biological networks, molecular graphs, source code ASTs, and knowledge graphs. For each dataset, we provide a unified evaluation protocol using meaningful application-specific data splits and evaluation metrics. In addition to building the datasets, we also perform extensive benchmark experiments for each dataset. Our experiments suggest that OGB datasets present significant challenges of scalability to large-scale graphs and out-of-distribution generalization under realistic data splits, indicating fruitful opportunities for future research. Finally, OGB provides an automated end-to-end graph ML pipeline that simplifies and standardizes the process of graph data loading, experimental setup, and model evaluation. OGB will be regularly updated and welcomes inputs from the community. OGB datasets as well as data loaders, evaluation scripts, baseline code, and leaderboards are publicly available at https://ogb.stanford.edu .},
  keywords = {📖,🦌,graph-datasets,machine-learning,machine-learning-benchmarks},
  annotation = {895 citations (Semantic Scholar/arXiv) [2022-11-26]},
  file = {/Users/michaelvolk/Zotero/storage/SGZESQJA/Hu et al_2021_Open Graph Benchmark.pdf;/Users/michaelvolk/Zotero/storage/AU2AMHED/2005.html}
}

@unpublished{huStrategiesPretrainingGraph2020,
  title = {Strategies for {{Pre-training Graph Neural Networks}}},
  author = {Hu, Weihua and Liu, Bowen and Gomes, Joseph and Zitnik, Marinka and Liang, Percy and Pande, Vijay and Leskovec, Jure},
  date = {2020-02-18},
  eprint = {1905.12265},
  eprinttype = {arXiv},
  eprintclass = {cs, stat},
  url = {http://arxiv.org/abs/1905.12265},
  urldate = {2022-02-08},
  abstract = {Many applications of machine learning require a model to make accurate predictions on test examples that are distributionally different from training ones, while task-specific labels are scarce during training. An effective approach to this challenge is to pre-train a model on related tasks where data is abundant, and then fine-tune it on a downstream task of interest. While pre-training has been effective in many language and vision domains, it remains an open question how to effectively use pre-training on graph datasets. In this paper, we develop a new strategy and self-supervised methods for pre-training Graph Neural Networks (GNNs). The key to the success of our strategy is to pre-train an expressive GNN at the level of individual nodes as well as entire graphs so that the GNN can learn useful local and global representations simultaneously. We systematically study pre-training on multiple graph classification datasets. We find that naïve strategies, which pre-train GNNs at the level of either entire graphs or individual nodes, give limited improvement and can even lead to negative transfer on many downstream tasks. In contrast, our strategy avoids negative transfer and improves generalization significantly across downstream tasks, leading up to 9.4\% absolute improvements in ROC-AUC over non-pre-trained models and achieving state-of-the-art performance for molecular property prediction and protein function prediction.},
  langid = {english},
  keywords = {✅,🦌,machine-learning},
  annotation = {162 citations (Semantic Scholar/arXiv) [2022-11-26]},
  file = {/Users/michaelvolk/Zotero/storage/MIBEBXDH/Hu et al. - 2020 - Strategies for Pre-training Graph Neural Networks.pdf}
}

@article{ieremieTransformerGOPredictingProtein2022,
  title = {{{TransformerGO}}: Predicting Protein–Protein Interactions by Modelling the Attention between Sets of Gene Ontology Terms},
  shorttitle = {{{TransformerGO}}},
  author = {Ieremie, Ioan and Ewing, Rob M and Niranjan, Mahesan},
  date = {2022-04-12},
  journaltitle = {Bioinformatics},
  shortjournal = {Bioinformatics},
  volume = {38},
  number = {8},
  pages = {2269--2277},
  issn = {1367-4803},
  doi = {10.1093/bioinformatics/btac104},
  url = {https://doi.org/10.1093/bioinformatics/btac104},
  urldate = {2023-10-17},
  abstract = {Protein–protein interactions (PPIs) play a key role in diverse biological processes but only a small subset of the interactions has been experimentally identified. Additionally, high-throughput experimental techniques that detect PPIs are known to suffer various limitations, such as exaggerated false positives and negatives rates. The semantic similarity derived from the Gene Ontology (GO) annotation is regarded as one of the most powerful indicators for protein interactions. However, while computational approaches for prediction of PPIs have gained popularity in recent years, most methods fail to capture the specificity of GO terms.We propose TransformerGO, a model that is capable of capturing the semantic similarity between GO sets dynamically using an attention mechanism. We generate dense graph embeddings for GO terms using an algorithmic framework for learning continuous representations of nodes in networks called node2vec. TransformerGO learns deep semantic relations between annotated terms and can distinguish between negative and positive interactions with high accuracy. TransformerGO outperforms classic semantic similarity measures on gold standard PPI datasets and state-of-the-art machine-learning-based approaches on large datasets from Saccharomyces cerevisiae and Homo sapiens. We show how the neural attention mechanism embedded in the transformer architecture detects relevant functional terms when predicting interactions.https://github.com/Ieremie/TransformerGO.Supplementary data are available at Bioinformatics online.},
  annotation = {12 citations (Semantic Scholar/DOI) [2023-10-16]},
  file = {/Users/michaelvolk/Zotero/storage/JTEPA9NC/Ieremie et al_2022_TransformerGO.pdf;/Users/michaelvolk/Zotero/storage/MKA8FK4B/6530277.html}
}

@article{jacksonROBOTToolAutomating2019a,
  title = {{{ROBOT}}: {{A Tool}} for {{Automating Ontology Workflows}}},
  shorttitle = {{{ROBOT}}},
  author = {Jackson, Rebecca C. and Balhoff, James P. and Douglass, Eric and Harris, Nomi L. and Mungall, Christopher J. and Overton, James A.},
  date = {2019-07-29},
  journaltitle = {BMC Bioinformatics},
  shortjournal = {BMC Bioinformatics},
  volume = {20},
  number = {1},
  pages = {407},
  issn = {1471-2105},
  doi = {10.1186/s12859-019-3002-3},
  url = {https://doi.org/10.1186/s12859-019-3002-3},
  urldate = {2023-11-29},
  abstract = {Ontologies are invaluable in the life sciences, but building and maintaining ontologies often requires a challenging number of distinct tasks such as running automated reasoners and quality control checks, extracting dependencies and application-specific subsets, generating standard reports, and generating release files in multiple formats. Similar to more general software development, automation is the key to executing and managing these tasks effectively and to releasing more robust products in standard forms.},
  keywords = {Automation,Import management,Ontology development,Ontology release,Quality control,Reasoning,Workflows},
  annotation = {94 citations (Semantic Scholar/DOI) [2023-11-29]},
  file = {/Users/michaelvolk/Zotero/storage/U8KHLEJ4/Jackson et al_2019_ROBOT.pdf;/Users/michaelvolk/Zotero/storage/TPF6NXWY/s12859-019-3002-3.html}
}

@article{jagtapBRANEnetEmbeddingMultilayer2022,
  title = {{{BRANEnet}}: Embedding Multilayer Networks for Omics Data Integration},
  shorttitle = {{{BRANEnet}}},
  author = {Jagtap, Surabhi and Pirayre, Aurélie and Bidard, Frédérique and Duval, Laurent and Malliaros, Fragkiskos D.},
  date = {2022-10-17},
  journaltitle = {BMC Bioinformatics},
  shortjournal = {BMC Bioinformatics},
  volume = {23},
  number = {1},
  pages = {429},
  issn = {1471-2105},
  doi = {10.1186/s12859-022-04955-w},
  url = {https://doi.org/10.1186/s12859-022-04955-w},
  urldate = {2023-10-17},
  abstract = {Gene expression is regulated at different molecular levels, including chromatin accessibility, transcription, RNA maturation, and transport. These regulatory mechanisms have strong connections with cellular metabolism. In order to study the cellular system and its functioning, omics data at each molecular level can be generated and efficiently integrated. Here, we propose BRANEnet, a novel multi-omics integration framework for multilayer heterogeneous networks. BRANEnet is an expressive, scalable, and versatile method to learn node embeddings, leveraging random walk information within a matrix factorization framework. Our goal is to efficiently integrate multi-omics data to study different regulatory aspects of multilayered processes that occur in organisms. We evaluate our framework using multi-omics data of Saccharomyces cerevisiae, a well-studied yeast model organism.},
  keywords = {Biological network integration,Graph representation learning,Multi-omics data,Multilayer network,Regulatory network inference},
  annotation = {3 citations (Semantic Scholar/DOI) [2023-10-16]},
  file = {/Users/michaelvolk/Zotero/storage/GIG49CT2/Jagtap et al_2022_BRANEnet.pdf;/Users/michaelvolk/Zotero/storage/CF7QJ3JA/s12859-022-04955-w.html}
}

@article{janPixelsInsightsMachine2024,
  title = {From Pixels to Insights: {{Machine}} Learning and Deep Learning for Bioimage Analysis},
  shorttitle = {From Pixels to Insights},
  author = {Jan, Mahta and Spangaro, Allie and Lenartowicz, Michelle and Mattiazzi Usaj, Mojca},
  date = {2024},
  journaltitle = {BioEssays},
  volume = {46},
  number = {2},
  pages = {2300114},
  issn = {1521-1878},
  doi = {10.1002/bies.202300114},
  url = {https://onlinelibrary.wiley.com/doi/abs/10.1002/bies.202300114},
  urldate = {2024-07-04},
  abstract = {Bioimage analysis plays a critical role in extracting information from biological images, enabling deeper insights into cellular structures and processes. The integration of machine learning and deep learning techniques has revolutionized the field, enabling the automated, reproducible, and accurate analysis of biological images. Here, we provide an overview of the history and principles of machine learning and deep learning in the context of bioimage analysis. We discuss the essential steps of the bioimage analysis workflow, emphasizing how machine learning and deep learning have improved preprocessing, segmentation, feature extraction, object tracking, and classification. We provide examples that showcase the application of machine learning and deep learning in bioimage analysis. We examine user-friendly software and tools that enable biologists to leverage these techniques without extensive computational expertise. This review is a resource for researchers seeking to incorporate machine learning and deep learning in their bioimage analysis workflows and enhance their research in this rapidly evolving field.},
  langid = {english},
  keywords = {bioimage analysis,bioimage analysis tools,deep learning,image processing,machine learning,microscopy},
  annotation = {2 citations (Semantic Scholar/DOI) [2024-07-04]},
  file = {/Users/michaelvolk/Zotero/storage/E2XRS27B/Jan et al. - 2024 - From pixels to insights Machine learning and deep.pdf;/Users/michaelvolk/Zotero/storage/GCPQPG4B/bies.html}
}

@inproceedings{jetteArchitectureSlurmWorkload2023,
  title = {Architecture of~the~{{Slurm Workload Manager}}},
  booktitle = {Job {{Scheduling Strategies}} for {{Parallel Processing}}},
  author = {Jette, Morris A. and Wickberg, Tim},
  editor = {Klusáček, Dalibor and Corbalán, Julita and Rodrigo, Gonzalo P.},
  date = {2023},
  pages = {3--23},
  publisher = {Springer Nature Switzerland},
  location = {Cham},
  doi = {10.1007/978-3-031-43943-8_1},
  abstract = {Slurm is an open source, fault-tolerant, and highly scalable workload manager used on many of the world’s supercomputers and computer clusters. As a cluster workload manager, Slurm has three key functions. First, it allocates exclusive and/or non-exclusive access to resources for some duration of time. Second, it provides a framework for starting, executing, and monitoring work on the allocated resources. Finally, it arbitrates contention for resources by managing queues of pending work and enforcing administrative policies. This paper describes the current design and capabilities of Slurm.},
  isbn = {978-3-031-43943-8},
  langid = {english},
  keywords = {✅🦌,hpc,scheduling,slurm},
  annotation = {2 citations (Semantic Scholar/DOI) [2024-06-06]},
  file = {/Users/michaelvolk/Zotero/storage/PHNLMUHT/Jette_Wickberg_2023_Architecture of the Slurm Workload Manager.pdf}
}

@article{jinDeepLearningIdentifies2021,
  title = {Deep Learning Identifies Synergistic Drug Combinations for Treating {{COVID-19}}},
  author = {Jin, Wengong and Stokes, Jonathan M. and Eastman, Richard T. and Itkin, Zina and Zakharov, Alexey V. and Collins, James J. and Jaakkola, Tommi S. and Barzilay, Regina},
  date = {2021-09-28},
  journaltitle = {Proceedings of the National Academy of Sciences},
  volume = {118},
  number = {39},
  pages = {e2105070118},
  publisher = {Proceedings of the National Academy of Sciences},
  doi = {10.1073/pnas.2105070118},
  url = {https://www.pnas.org/doi/10.1073/pnas.2105070118},
  urldate = {2023-09-10},
  abstract = {Effective treatments for COVID-19 are urgently needed. However, discovering single-agent therapies with activity against severe acute respiratory syndrome coronavirus 2 (SARS-CoV-2) has been challenging. Combination therapies play an important role in antiviral therapies, due to their improved efficacy and reduced toxicity. Recent approaches have applied deep learning to identify synergistic drug combinations for diseases with vast preexisting datasets, but these are not applicable to new diseases with limited combination data, such as COVID-19. Given that drug synergy often occurs through inhibition of discrete biological targets, here we propose a neural network architecture that jointly learns drug−target interaction and drug−drug synergy. The model consists of two parts: a drug−target interaction module and a target−disease association module. This design enables the model to utilize drug−target interaction data and single-agent antiviral activity data, in addition to available drug−drug combination datasets, which may be small in nature. By incorporating additional biological information, our model performs significantly better in synergy prediction accuracy than previous methods with limited drug combination training data. We empirically validated our model predictions and discovered two drug combinations, remdesivir and reserpine as well as remdesivir and IQ-1S, which display strong antiviral SARS-CoV-2 synergy in vitro. Our approach, which was applied here to address the urgent threat of COVID-19, can be readily extended to other diseases for which a dearth of chemical−chemical combination data exists.},
  annotation = {64 citations (Semantic Scholar/DOI) [2023-09-10]},
  file = {/Users/michaelvolk/Zotero/storage/EXQRSC8Z/Jin et al_2021_Deep learning identifies synergistic drug combinations for treating COVID-19.pdf}
}

@online{jinSelfsupervisedLearningGraphs2020,
  title = {Self-Supervised {{Learning}} on {{Graphs}}: {{Deep Insights}} and {{New Direction}}},
  shorttitle = {Self-Supervised {{Learning}} on {{Graphs}}},
  author = {Jin, Wei and Derr, Tyler and Liu, Haochen and Wang, Yiqi and Wang, Suhang and Liu, Zitao and Tang, Jiliang},
  date = {2020-06-17},
  eprint = {2006.10141},
  eprinttype = {arXiv},
  eprintclass = {cs},
  doi = {10.48550/arXiv.2006.10141},
  url = {http://arxiv.org/abs/2006.10141},
  urldate = {2025-02-27},
  abstract = {The success of deep learning notoriously requires larger amounts of costly annotated data. This has led to the development of self-supervised learning (SSL) that aims to alleviate this limitation by creating domain specific pretext tasks on unlabeled data. Simultaneously, there are increasing interests in generalizing deep learning to the graph domain in the form of graph neural networks (GNNs). GNNs can naturally utilize unlabeled nodes through the simple neighborhood aggregation that is unable to thoroughly make use of unlabeled nodes. Thus, we seek to harness SSL for GNNs to fully exploit the unlabeled data. Different from data instances in the image and text domains, nodes in graphs present unique structure information and they are inherently linked indicating not independent and identically distributed (or i.i.d.). Such complexity is a double-edged sword for SSL on graphs. On the one hand, it determines that it is challenging to adopt solutions from the image and text domains to graphs and dedicated efforts are desired. On the other hand, it provides rich information that enables us to build SSL from a variety of perspectives. Thus, in this paper, we first deepen our understandings on when, why, and which strategies of SSL work with GNNs by empirically studying numerous basic SSL pretext tasks on graphs. Inspired by deep insights from the empirical studies, we propose a new direction SelfTask to build advanced pretext tasks that are able to achieve state-of-the-art performance on various real-world datasets. The specific experimental settings to reproduce our results can be found in \textbackslash url\{https://github.com/ChandlerBang/SelfTask-GNN\}.},
  pubstate = {prepublished},
  keywords = {Computer Science - Machine Learning,Statistics - Machine Learning},
  annotation = {165 citations (Semantic Scholar/arXiv) [2025-02-27]},
  file = {/Users/michaelvolk/Zotero/storage/Z2NJE2EI/Jin et al_2020_Self-supervised Learning on Graphs.pdf;/Users/michaelvolk/Zotero/storage/KBGWZ45C/2006.html}
}

@article{johanssonLargeScaleMicrofluidic2023,
  title = {Large Scale Microfluidic {{CRISPR}} Screening for Increased Amylase Secretion in Yeast},
  author = {Johansson, S. Andreas and Dulermo, Thierry and Jann, Cosimo and Smith, Justin D. and Pryszlak, Anna and Pignede, Georges and Schraivogel, Daniel and Colavizza, Didier and Desfougères, Thomas and Rave, Christophe and Farwick, Alexander and Merten, Christoph A. and Roy, Kevin R. and Wei, Wu and Steinmetz, Lars M.},
  date = {2023},
  journaltitle = {Lab on a Chip},
  shortjournal = {Lab Chip},
  volume = {23},
  number = {16},
  pages = {3704--3715},
  issn = {1473-0197, 1473-0189},
  doi = {10.1039/D3LC00111C},
  url = {https://xlink.rsc.org/?DOI=D3LC00111C},
  urldate = {2025-03-17},
  abstract = {Large scale perturbation of gene expression in yeast using CRISPR libraries, coupled with high-throughput screening using fluorescence-based sorting of microfluidic droplets, to identify genes important for increased α-amylase secretion.           ,                             Key to our ability to increase recombinant protein production through secretion is a better understanding of the pathways that interact to translate, process and export mature proteins to the surrounding environment, including the supporting cellular machinery that supplies necessary energy and building blocks. By combining droplet microfluidic screening with large-scale CRISPR libraries that perturb the expression of the majority of coding and non-coding genes in               S. cerevisiae               , we identified 345 genes for which an increase or decrease in gene expression resulted in increased secretion of α-amylase. Our results show that modulating the expression of genes involved in the trafficking of vesicles, endosome to Golgi transport, the phagophore assembly site, the cell cycle and energy supply improve α-amylase secretion. Besides protein-coding genes, we also find multiple long non-coding RNAs enriched in the vicinity of genes associated with endosomal, Golgi and vacuolar processes. We validated our results by overexpressing or deleting selected genes, which resulted in significant improvements in α-amylase secretion. The advantages, in terms of precision and speed, inherent to CRISPR based perturbations, enables iterative testing of new strains for increased protein secretion.},
  langid = {english},
  annotation = {6 citations (Semantic Scholar/DOI) [2025-03-17]},
  file = {/Users/michaelvolk/Zotero/storage/JFD3ZFP8/Johansson et al. - 2023 - Large scale microfluidic CRISPR screening for incr.pdf}
}

@article{juComprehensiveSurveyDeep2024,
  title = {A {{Comprehensive Survey}} on {{Deep Graph Representation Learning}}},
  author = {Ju, Wei and Fang, Zheng and Gu, Yiyang and Liu, Zequn and Long, Qingqing and Qiao, Ziyue and Qin, Yifang and Shen, Jianhao and Sun, Fang and Xiao, Zhiping and Yang, Junwei and Yuan, Jingyang and Zhao, Yusheng and Wang, Yifan and Luo, Xiao and Zhang, Ming},
  date = {2024-05-01},
  journaltitle = {Neural Networks},
  shortjournal = {Neural Networks},
  volume = {173},
  pages = {106207},
  issn = {0893-6080},
  doi = {10.1016/j.neunet.2024.106207},
  url = {https://www.sciencedirect.com/science/article/pii/S089360802400131X},
  urldate = {2025-02-27},
  abstract = {Graph representation learning aims to effectively encode high-dimensional sparse graph-structured data into low-dimensional dense vectors, which is a fundamental task that has been widely studied in a range of fields, including machine learning and data mining. Classic graph embedding methods follow the basic idea that the embedding vectors of interconnected nodes in the graph can still maintain a relatively close distance, thereby preserving the structural information between the nodes in the graph. However, this is sub-optimal due to: (i) traditional methods have limited model capacity which limits the learning performance; (ii) existing techniques typically rely on unsupervised learning strategies and fail to couple with the latest learning paradigms; (iii) representation learning and downstream tasks are dependent on each other which should be jointly enhanced. With the remarkable success of deep learning, deep graph representation learning has shown great potential and advantages over shallow (traditional) methods, there exist a large number of deep graph representation learning techniques have been proposed in the past decade, especially graph neural networks. In this survey, we conduct a comprehensive survey on current deep graph representation learning algorithms by proposing a new taxonomy of existing state-of-the-art literature. Specifically, we systematically summarize the essential components of graph representation learning and categorize existing approaches by the ways of graph neural network architectures and the most recent advanced learning paradigms. Moreover, this survey also provides the practical and promising applications of deep graph representation learning. Last but not least, we state new perspectives and suggest challenging directions which deserve further investigations in the future.},
  keywords = {Deep learning on graphs,Graph neural network,Graph representation learning,Survey},
  annotation = {117 citations (Semantic Scholar/DOI) [2025-02-27]},
  file = {/Users/michaelvolk/Zotero/storage/QKAXJSSA/Ju et al_2024_A Comprehensive Survey on Deep Graph Representation Learning.pdf;/Users/michaelvolk/Zotero/storage/UP5DCRG9/S089360802400131X.html}
}

@online{kalfonScPRINTPretraining502024a,
  title = {{{scPRINT}}: Pre-Training on 50 Million Cells Allows Robust Gene Network Predictions},
  shorttitle = {{{scPRINT}}},
  author = {Kalfon, Jérémie and Samaran, Jules and Peyré, Gabriel and Cantini, Laura},
  date = {2024-07-29},
  eprinttype = {bioRxiv},
  eprintclass = {New Results},
  pages = {2024.07.29.605556},
  doi = {10.1101/2024.07.29.605556},
  url = {https://www.biorxiv.org/content/10.1101/2024.07.29.605556v1},
  urldate = {2025-03-03},
  abstract = {A cell is governed by the interaction of myriads of macromolecules. Such a network of interaction has remained an elusive milestone in cellular biology. Building on recent advances in large foundation models and their ability to learn without supervision, we present scPRINT, a large cell model for the inference of gene networks pre-trained on more than 50M cells from the cellxgene database. Using novel pretraining methods and model architecture, scPRINT pushes large transformer models towards more interpretability and usability in uncovering the complex biology of the cell. Based on our atlas-level benchmarks, scPRINT demonstrates superior performance in gene network inference to the state of the art, as well as competitive zero-shot abilities in denoising, batch effect correction, and cell label prediction. On an atlas of benign prostatic hyperplasia, scPRINT highlights the profound connections between ion exchange, senescence, and chronic inflammation.},
  langid = {english},
  pubstate = {prepublished},
  annotation = {0 citations (Semantic Scholar/DOI) [2025-03-02]},
  file = {/Users/michaelvolk/Zotero/storage/NB8F2AXI/Kalfon et al_2024_scPRINT.pdf}
}

@article{kangComprehensiveGraphNeural2025,
  title = {A Comprehensive Graph Neural Network Method for Predicting Triplet Motifs in Disease–Drug–Gene Interactions},
  author = {Kang, Chuanze and Liu, Zonghuan and Zhang, Han},
  date = {2025-02-01},
  journaltitle = {Bioinformatics},
  shortjournal = {Bioinformatics},
  volume = {41},
  number = {2},
  pages = {btaf023},
  issn = {1367-4811},
  doi = {10.1093/bioinformatics/btaf023},
  url = {https://doi.org/10.1093/bioinformatics/btaf023},
  urldate = {2025-04-23},
  abstract = {The drug–disease, gene–disease, and drug–gene relationships, as high-frequency edge types, describe complex biological processes within the biomedical knowledge graph. The structural patterns formed by these three edges are the graph motifs of (disease, drug, gene) triplets. Among them, the triangle is a steady and important motif structure in the network, and other various motifs different from the triangle also indicate rich semantic relationships. However, existing methods only focus on the triangle representation learning for classification, and fail to further discriminate various motifs of triplets. A comprehensive method is needed to predict the various motifs within triplets, which will uncover new pharmacological mechanisms and improve our understanding of disease–gene–drug interactions. Identifying complex motif structures within triplets can also help us to study the structural properties of triangles.We consider the seven typical motifs within the triplets and propose a novel graph contrastive learning-based method for triplet motif prediction (TriMoGCL). TriMoGCL utilizes a graph convolutional encoder to extract node features from the global network topology. Next, node pooling and edge pooling extract context information as the triplet features from global and local views. To avoid the redundant context information and motif imbalance problem caused by dense edges, we use node and class-prototype contrastive learning to denoise triplet features and enhance discrimination between motifs. The experiments on two different-scale knowledge graphs demonstrate the effectiveness and reliability of TriMoGCL in identifying various motif types. In addition, our model reveals new pharmacological mechanisms, providing a comprehensive analysis of triplet motifs.Codes and datasets are available at https://github.com/zhanglabNKU/TriMoGCL and https://doi.org/10.5281/zenodo.14633572.},
  annotation = {0 citations (Semantic Scholar/DOI) [2025-04-23]},
  file = {/Users/michaelvolk/Zotero/storage/6VGCHJJY/Kang et al_2025_A comprehensive graph neural network method for predicting triplet motifs in.pdf;/Users/michaelvolk/Zotero/storage/95YF7A3F/7964716.html}
}

@inproceedings{kaoADVANCINGDNALANGUAGE2024,
  title = {{{ADVANCING DNA LANGUAGE MODELS}}: {{THE GENOMICS LONG-RANGE BENCHMARK}}},
  shorttitle = {{{ADVANCING DNA LANGUAGE MODELS}}},
  author = {Kao, Chia Hsiang and Trop, Evan and Polen, McKinley and Schiff, Yair and family=Almeida, given=Bernardo P., prefix=de, useprefix=false and Gokaslan, Aaron and Pierrot, Thomas and Kuleshov, Volodymyr},
  date = {2024-03-13},
  url = {https://openreview.net/forum?id=M3VlreGcC1},
  urldate = {2024-03-31},
  abstract = {Building on the successes in other domains, there has been rapid development of language models (LMs) for genomics. Key to this development is the establishment of proper benchmarks and systematic evaluation approaches. The benchmarks that have been proposed so far have focused on tasks that depend on short-range sequence contexts, while the evaluation of models for long-range tasks that are integral to genomics, such as gene expression and genetic variant prediction, is lacking. In this work, we propose a benchmark that fills this need and introduce the genomics long-range benchmark -- an evaluation tool that is designed to encompass tasks requiring long-range sequence dependencies, an aspect which we deem crucial to genomic applications of DNA language models. In addition to clearly defining and organizing relevant tasks into a cohesive benchmark, we provide preliminary results of several prominent and recent DNA LMs evaluated on the proposed benchmark. Finally, we probe the tasks in our benchmarks by exploring the effect of context length extension methods for one of the evaluated DNA LMs, the Nucleotide Transformer. By proposing this benchmark we hope to stimulate the ongoing development of DNA LMs and provide a fruitful testing ground for future developments that aim to capture long-range sequence modeling in genomics.},
  eventtitle = {{{ICLR}} 2024 {{Workshop}} on {{Machine Learning}} for {{Genomics Explorations}}},
  langid = {english},
  file = {/Users/michaelvolk/Zotero/storage/PD8KYJSJ/Kao et al_2024_ADVANCING DNA LANGUAGE MODELS.pdf}
}

@article{karlebachModellingAnalysisGene2008,
  title = {Modelling and Analysis of Gene Regulatory Networks},
  author = {Karlebach, Guy and Shamir, Ron},
  date = {2008-10},
  journaltitle = {Nature Reviews Molecular Cell Biology},
  shortjournal = {Nat Rev Mol Cell Biol},
  volume = {9},
  number = {10},
  pages = {770--780},
  publisher = {Nature Publishing Group},
  issn = {1471-0080},
  doi = {10.1038/nrm2503},
  url = {https://www.nature.com/articles/nrm2503},
  urldate = {2023-10-14},
  abstract = {Gene regulatory networks control many cellular processes such as cell cycle, cell differentiation, metabolism and signal transduction. Computational methods, both for supporting the development of network models and for the analysis of their functionality, have already proved to be a valuable research tool.},
  issue = {10},
  langid = {english},
  keywords = {Biochemistry,Cancer Research,Cell Biology,Developmental Biology,general,Life Sciences,Stem Cells},
  annotation = {1068 citations (Semantic Scholar/DOI) [2023-10-14]},
  file = {/Users/michaelvolk/Zotero/storage/XPXYYT2R/Karlebach_Shamir_2008_Modelling and analysis of gene regulatory networks.pdf}
}

@online{karollusSpeciesawareDNALanguage2023,
  title = {Species-Aware {{DNA}} Language Models Capture Regulatory Elements and Their Evolution},
  author = {Karollus, Alexander and Hingerl, Johannes and Gankin, Dennis and Grosshauser, Martin and Klemon, Kristian and Gagneur, Julien},
  date = {2023-07-22},
  eprinttype = {bioRxiv},
  eprintclass = {New Results},
  pages = {2023.01.26.525670},
  doi = {10.1101/2023.01.26.525670},
  url = {https://www.biorxiv.org/content/10.1101/2023.01.26.525670v2},
  urldate = {2023-07-28},
  abstract = {The rise of large-scale multi-species genome sequencing projects promises to shed new light on how genomes encode gene regulatory instructions. To this end, new algorithms are needed that can leverage conservation to capture regulatory elements while accounting for their evolution. Here we introduce species-aware DNA language models (LMs), which we trained on more than 800 species spanning over 500 million years of evolution. Investigating their ability to predict masked nucleotides from context, we show that DNA LMs distinguish transcription factor and RNA-binding protein motifs from background non-coding sequence. Owing to their flexibility, DNA LMs capture conserved regulatory elements over much further evolutionary distances than sequence alignment would allow. Remarkably, DNA LMs reconstruct motif instances bound in vivo better than unbound ones and account for the evolution of motif sequences and their positional constraints, showing that these models capture functional high-order sequence and evolutionary context. We further show that species-aware training yields improved sequence representations for endogenous and MPRA-based gene expression prediction, as well as motif discovery. Collectively, these results demonstrate that species-aware DNA language models are a powerful, flexible, and scalable tool to integrate information from large compendia of highly diverged genomes.},
  langid = {english},
  pubstate = {prepublished},
  keywords = {🦌½✅},
  annotation = {0 citations (Semantic Scholar/DOI) [2023-07-28]},
  file = {/Users/michaelvolk/Zotero/storage/44JJRDFN/Karollus et al_2023_Species-aware DNA language models capture regulatory elements and their.pdf}
}

@article{kassaniDeepNeuralNetworks2022a,
  title = {Deep Neural Networks with Controlled Variable Selection for the Identification of Putative Causal Genetic Variants},
  author = {Kassani, Peyman H. and Lu, Fred and Le Guen, Yann and Belloy, Michael E. and He, Zihuai},
  date = {2022-09},
  journaltitle = {Nature Machine Intelligence},
  shortjournal = {Nat Mach Intell},
  volume = {4},
  number = {9},
  pages = {761--771},
  publisher = {Nature Publishing Group},
  issn = {2522-5839},
  doi = {10.1038/s42256-022-00525-0},
  url = {https://www.nature.com/articles/s42256-022-00525-0},
  urldate = {2024-07-16},
  abstract = {Deep neural networks (DNNs) have been successfully utilized in many scientific problems for their high prediction accuracy, but their application to genetic studies remains challenging due to their poor interpretability. Here we consider the problem of scalable, robust variable selection in DNNs for the identification of putative causal genetic variants in genome sequencing studies. We identified a pronounced randomness in feature selection in DNNs due to its stochastic nature, which may hinder interpretability and give rise to misleading results. We propose an interpretable neural network model, stabilized using ensembling, with controlled variable selection for genetic studies. The merit of the proposed method includes: flexible modelling of the nonlinear effect of genetic variants to improve statistical power; multiple knockoffs in the input layer to rigorously control the false discovery rate; hierarchical layers to substantially reduce the number of weight parameters and activations, and improve computational efficiency; and stabilized feature selection to reduce the randomness in identified signals. We evaluate the proposed method in extensive simulation studies and apply it to the analysis of Alzheimer’s disease genetics. We show that the proposed method, when compared with conventional linear and nonlinear methods, can lead to substantially more discoveries.},
  langid = {english},
  keywords = {Computational science,Genetics,Statistics},
  annotation = {6 citations (Semantic Scholar/DOI) [2024-07-15]},
  file = {/Users/michaelvolk/Zotero/storage/BH9X7QCJ/Kassani et al_2022_Deep neural networks with controlled variable selection for the identification.pdf}
}

@article{kassoufUnderstandingFundamentalPrinciples2023,
  title = {Understanding Fundamental Principles of Enhancer Biology at a Model Locus},
  author = {Kassouf, Mira and Ford, Seren and Blayney, Joseph and Higgs, Doug},
  date = {2023},
  journaltitle = {BioEssays},
  volume = {45},
  number = {10},
  pages = {2300047},
  issn = {1521-1878},
  doi = {10.1002/bies.202300047},
  url = {https://onlinelibrary.wiley.com/doi/abs/10.1002/bies.202300047},
  urldate = {2024-07-04},
  abstract = {Despite ever-increasing accumulation of genomic data, the fundamental question of how individual genes are switched on during development, lineage-specification and differentiation is not fully answered. It is widely accepted that this involves the interaction between at least three fundamental regulatory elements: enhancers, promoters and insulators. Enhancers contain transcription factor binding sites which are bound by transcription factors (TFs) and co-factors expressed during cell fate decisions and maintain imposed patterns of activation, at least in part, via their epigenetic modification. This information is transferred from enhancers to their cognate promoters often by coming into close physical proximity to form a ‘transcriptional hub’ containing a high concentration of TFs and co-factors. The mechanisms underlying these stages of transcriptional activation are not fully explained. This review focuses on how enhancers and promoters are activated during differentiation and how multiple enhancers work together to regulate gene expression. We illustrate the currently understood principles of how mammalian enhancers work and how they may be perturbed in enhanceropathies using expression of the α-globin gene cluster during erythropoiesis, as a model.},
  langid = {english},
  keywords = {alpha globin locus,enhancer cluster,enhancer function,enhanceropathies,erythropoiesis,gene regulation,super-enhancer},
  annotation = {2 citations (Semantic Scholar/DOI) [2024-07-04]},
  file = {/Users/michaelvolk/Zotero/storage/EGEFQLVM/Kassouf et al. - 2023 - Understanding fundamental principles of enhancer b.pdf;/Users/michaelvolk/Zotero/storage/773IUF2G/bies.html}
}

@article{kelderWikiPathwaysBuildingResearch2012b,
  title = {{{WikiPathways}}: Building Research Communities on Biological Pathways},
  shorttitle = {{{WikiPathways}}},
  author = {Kelder, T. and Van Iersel, M. P. and Hanspers, K. and Kutmon, M. and Conklin, B. R. and Evelo, C. T. and Pico, A. R.},
  date = {2012-01-01},
  journaltitle = {Nucleic Acids Research},
  shortjournal = {Nucleic Acids Research},
  volume = {40},
  number = {D1},
  pages = {D1301-D1307},
  issn = {0305-1048, 1362-4962},
  doi = {10.1093/nar/gkr1074},
  url = {https://academic.oup.com/nar/article-lookup/doi/10.1093/nar/gkr1074},
  urldate = {2023-11-23},
  abstract = {Here, we describe the development of WikiPathways (http://www.wikipathways.org), a public wiki for pathway curation, since it was first published in 2008. New features are discussed, as well as developments in the community of contributors. New features include a zoomable pathway viewer, support for pathway ontology annotations, the ability to mark pathways as private for a limited time and the availability of stable hyperlinks to pathways and the elements therein. WikiPathways content is freely available in a variety of formats such as the BioPAX standard, and the content is increasingly adopted by external databases and tools, including Wikipedia. A recent development is the use of WikiPathways as a staging ground for centrally curated databases such as Reactome. WikiPathways is seeing steady growth in the number of users, page views and edits for each pathway. To assess whether the community curation experiment can be considered successful, here we analyze the relation between use and contribution, which gives results in line with other wiki projects. The novel use of pathway pages as supplementary material to publications, as well as the addition of tailored content for research domains, is expected to stimulate growth further.},
  langid = {english},
  annotation = {519 citations (Semantic Scholar/DOI) [2023-11-23]},
  file = {/Users/michaelvolk/Zotero/storage/RR236HKQ/Kelder et al. - 2012 - WikiPathways building research communities on bio.pdf}
}

@article{kellamMicroarrayGeneExpression2001,
  title = {Microarray Gene Expression Database: Progress towards an International Repository of Gene Expression Data},
  shorttitle = {Microarray Gene Expression Database},
  author = {Kellam, Paul},
  date = {2001-05-02},
  journaltitle = {Genome Biology},
  shortjournal = {Genome Biology},
  volume = {2},
  number = {5},
  pages = {reports4011.1},
  issn = {1474-760X},
  doi = {10.1186/gb-2001-2-5-reports4011},
  url = {https://doi.org/10.1186/gb-2001-2-5-reports4011},
  urldate = {2023-08-16},
  abstract = {A report on the third Microarray Gene Expression Database group meeting (MGED3), Stanford University, Palo Alto, California, USA, 29-31 March, 2001.},
  keywords = {Array Annotation,Array Database,Document Type Definition,Gene Ontology,Microarray Community},
  file = {/Users/michaelvolk/Zotero/storage/EA9T7SN3/Kellam_2001_Microarray gene expression database.pdf;/Users/michaelvolk/Zotero/storage/S8326JRA/gb-2001-2-5-reports4011.html}
}

@article{kellyReviewCausalDiscovery2022,
  title = {A Review of Causal Discovery Methods for Molecular Network Analysis},
  author = {Kelly, Jack and Berzuini, Carlo and Keavney, Bernard and Tomaszewski, Maciej and Guo, Hui},
  date = {2022},
  journaltitle = {Molecular Genetics \& Genomic Medicine},
  volume = {10},
  number = {10},
  pages = {e2055},
  issn = {2324-9269},
  doi = {10.1002/mgg3.2055},
  url = {https://onlinelibrary.wiley.com/doi/abs/10.1002/mgg3.2055},
  urldate = {2024-07-16},
  abstract = {Background With the increasing availability and size of multi-omics datasets, investigating the casual relationships between molecular phenotypes has become an important aspect of exploring underlying biology andgenetics. There are an increasing number of methodlogies that have been developed and applied to moleular networks to investigate these causal interactions. Methods We have introduced and reviewed the available methods for building large-scale causal molecular networks that have been developed and applied in the past decade. Results In this review we have identified and summarized the existing methods for infering causality in large-scale causal molecular networks, and discussed important factors that will need to be considered in future research in this area. Conclusion Existing methods to infering causal molecular networks have their own strengths and limitations so there is no one best approach, and it is instead down to the discretion of the researcher. This review also to discusses some of the current limitations to biological interpretation of these networks, and important factors to consider for future studies on molecular networks.},
  langid = {english},
  keywords = {Bayesian networks,causal inference,causal molecular network,mendelian randomisation,omics},
  annotation = {6 citations (Semantic Scholar/DOI) [2024-07-15]},
  file = {/Users/michaelvolk/Zotero/storage/YZG3J8NY/Kelly et al_2022_A review of causal discovery methods for molecular network analysis.pdf;/Users/michaelvolk/Zotero/storage/RV8X7UUJ/mgg3.html}
}

@article{kemmerenLargeScaleGeneticPerturbations2014,
  title = {Large-{{Scale Genetic Perturbations Reveal Regulatory Networks}} and an {{Abundance}} of {{Gene-Specific Repressors}}},
  author = {Kemmeren, Patrick and Sameith, Katrin and family=Pasch, given=Loes A. L., prefix=van de, useprefix=true and Benschop, Joris J. and Lenstra, Tineke L. and Margaritis, Thanasis and O’Duibhir, Eoghan and Apweiler, Eva and family=Wageningen, given=Sake, prefix=van, useprefix=true and Ko, Cheuk W. and family=Heesch, given=Sebastiaan, prefix=van, useprefix=true and Kashani, Mehdi M. and Ampatziadis-Michailidis, Giannis and Brok, Mariel O. and Brabers, Nathalie A. C. H. and Miles, Anthony J. and Bouwmeester, Diane and family=Hooff, given=Sander R., prefix=van, useprefix=true and family=Bakel, given=Harm, prefix=van, useprefix=true and Sluiters, Erik and Bakker, Linda V. and Snel, Berend and Lijnzaad, Philip and family=Leenen, given=Dik, prefix=van, useprefix=true and Groot Koerkamp, Marian J. A. and Holstege, Frank C. P.},
  date = {2014-04-24},
  journaltitle = {Cell},
  shortjournal = {Cell},
  volume = {157},
  number = {3},
  pages = {740--752},
  issn = {0092-8674},
  doi = {10.1016/j.cell.2014.02.054},
  url = {https://www.sciencedirect.com/science/article/pii/S0092867414003420},
  urldate = {2022-05-06},
  abstract = {To understand regulatory systems, it would be useful to uniformly determine how different components contribute to the expression of all other genes. We therefore monitored mRNA expression genome-wide, for individual deletions of one-quarter of yeast genes, focusing on (putative) regulators. The resulting genetic perturbation signatures reflect many different properties. These include the architecture of protein complexes and pathways, identification of expression changes compatible with viability, and the varying responsiveness to genetic perturbation. The data are assembled into a genetic perturbation network that shows different connectivities for different classes of regulators. Four feed-forward loop (FFL) types are overrepresented, including incoherent type 2 FFLs that likely represent feedback. Systematic transcription factor classification shows a surprisingly high abundance of gene-specific repressors, suggesting that yeast chromatin is not as generally restrictive to transcription as is often assumed. The data set is useful for studying individual genes and for discovering properties of an entire regulatory system.},
  langid = {english},
  keywords = {📖,🦌,gene-graph},
  annotation = {236 citations (Semantic Scholar/DOI) [2022-11-26]},
  file = {/Users/michaelvolk/Zotero/storage/W92UBF8M/Kemmeren et al. - 2014 - Large-Scale Genetic Perturbations Reveal Regulator.pdf;/Users/michaelvolk/Zotero/storage/UER8EVSK/S0092867414003420.html}
}

@article{keSingleCellRNAsequencing2022,
  title = {Single Cell {{RNA-sequencing}}: {{A}} Powerful yet Still Challenging Technology to Study Cellular Heterogeneity},
  shorttitle = {Single Cell {{RNA-sequencing}}},
  author = {Ke, May and Elshenawy, Badran and Sheldon, Helen and Arora, Anjali and Buffa, Francesca M},
  date = {2022},
  journaltitle = {BioEssays},
  volume = {44},
  number = {11},
  pages = {2200084},
  issn = {1521-1878},
  doi = {10.1002/bies.202200084},
  url = {https://onlinelibrary.wiley.com/doi/abs/10.1002/bies.202200084},
  urldate = {2024-07-04},
  abstract = {Almost all biomedical research to date has relied upon mean measurements from cell populations, however it is well established that what it is observed at this macroscopic level can be the result of many interactions of several different single cells. Thus, the observable macroscopic ‘average’ cannot outright be used as representative of the ‘average cell’. Rather, it is the resulting emerging behaviour of the actions and interactions of many different cells. Single-cell RNA sequencing (scRNA-Seq) enables the comparison of the transcriptomes of individual cells. This provides high-resolution maps of the dynamic cellular programmes allowing us to answer fundamental biological questions on their function and evolution. It also allows to address medical questions such as the role of rare cell populations contributing to disease progression and therapeutic resistance. Furthermore, it provides an understanding of context-specific dependencies, namely the behaviour and function that a cell has in a specific context, which can be crucial to understand some complex diseases, such as diabetes, cardiovascular disease and cancer. Here, we provide an overview of scRNA-Seq, including a comparative review of emerging technologies and computational pipelines. We discuss the current and emerging applications and focus on tumour heterogeneity a clear example of how scRNA-Seq can provide new understanding of a complex disease. Additionally, we review the limitations and highlight the need of powerful computational pipelines and reproducible protocols for the broader acceptance of this technique in basic and clinical research.},
  langid = {english},
  keywords = {bioinformatics,complex disease,computational biology,scRNA-seq,single-cell RNA sequencing,transcriptomics,tumour microenvironment},
  annotation = {25 citations (Semantic Scholar/DOI) [2024-07-04]},
  file = {/Users/michaelvolk/Zotero/storage/S24IC68X/Ke et al. - 2022 - Single cell RNA-sequencing A powerful yet still c.pdf;/Users/michaelvolk/Zotero/storage/892HE7ZK/bies.html}
}

@article{khanBenefitsCotranslationalComplex2023,
  title = {Benefits of Co-Translational Complex Assembly for Cellular Fitness},
  author = {Khan, Krishnendu and Fox, Paul L.},
  date = {2023},
  journaltitle = {BioEssays},
  volume = {45},
  number = {5},
  pages = {2300024},
  issn = {1521-1878},
  doi = {10.1002/bies.202300024},
  url = {https://onlinelibrary.wiley.com/doi/abs/10.1002/bies.202300024},
  urldate = {2024-07-04},
  abstract = {Complexes of two or more proteins form many, if not most, of the intracellular “machines” that execute physical and chemical work, and transmit information. Complexes can form from stochastic post-translational interactions of fully formed proteins, but recent attention has shifted to co-translational interactions in which the most common mechanism involves binding of a mature constituent to an incomplete polypeptide emerging from a translating ribosome. Studies in yeast have revealed co-translational interactions during formation of multiple major complexes, and together with recent mammalian cell studies, suggest widespread utilization of the mechanism. These translation-dependent interactions can involve a single or multiple mRNA templates, can be uni- or bi-directional, and can use multi-protein sub-complexes as a binding component. Here, we discuss benefits of co-translational complex assembly including accuracy and efficiency, overcoming hidden interfaces, localized and hierarchical assembly, and reduction of orphan protein degradation, toxicity, and dominant-negative pathogenesis, all serving to improve cell fitness.},
  langid = {english},
  keywords = {co-translational interaction,complex assembly,mRNA translation,multiprotein complex,protein–protein interaction,ribosome},
  annotation = {2 citations (Semantic Scholar/DOI) [2024-07-04]},
  file = {/Users/michaelvolk/Zotero/storage/FLKPNTMX/Khan and Fox - 2023 - Benefits of co-translational complex assembly for .pdf;/Users/michaelvolk/Zotero/storage/URVS6T6D/bies.html}
}

@article{khanReusabilityReportLearning2023,
  title = {Reusability Report: {{Learning}} the Transcriptional Grammar in Single-Cell {{RNA-sequencing}} Data Using Transformers},
  shorttitle = {Reusability Report},
  author = {Khan, Sumeer Ahmad and Maillo, Alberto and Lagani, Vincenzo and Lehmann, Robert and Kiani, Narsis A. and Gomez-Cabrero, David and Tegner, Jesper},
  date = {2023-12},
  journaltitle = {Nature Machine Intelligence},
  shortjournal = {Nat Mach Intell},
  volume = {5},
  number = {12},
  pages = {1437--1446},
  publisher = {Nature Publishing Group},
  issn = {2522-5839},
  doi = {10.1038/s42256-023-00757-8},
  url = {https://www.nature.com/articles/s42256-023-00757-8},
  urldate = {2025-02-13},
  abstract = {The rise of single-cell genomics is an attractive opportunity for data-hungry machine learning algorithms. The scBERT method, inspired by the success of BERT (‘bidirectional encoder representations from transformers’) in natural language processing, was recently introduced by Yang et al. as a data-driven tool to annotate cell types in single-cell genomics data. Analogous to contextual embedding in BERT, scBERT leverages pretraining and self-attention mechanisms to learn the ‘transcriptional grammar’ of cells. Here we investigate the reusability beyond the original datasets, assessing the generalizability of natural language techniques in single-cell genomics. The degree of imbalance in the cell-type distribution substantially influences the performance of scBERT. Anticipating an increased utilization of transformers, we highlight the necessity to consider data distribution carefully and introduce a subsampling technique to mitigate the influence of an imbalanced distribution. Our analysis serves as a stepping stone towards understanding and optimizing the use of transformers in single-cell genomics.},
  langid = {english},
  keywords = {Computational biology and bioinformatics,Scientific community},
  annotation = {11 citations (Semantic Scholar/DOI) [2025-02-13]},
  file = {/Users/michaelvolk/Zotero/storage/Q6PGSNSE/Khan et al_2023_Reusability report.pdf}
}

@article{khodayariGenomescaleEscherichiaColi2016,
  title = {A Genome-Scale {{Escherichia}} Coli Kinetic Metabolic Model k-Ecoli457 Satisfying Flux Data for Multiple Mutant Strains},
  author = {Khodayari, Ali and Maranas, Costas D.},
  date = {2016-12-20},
  journaltitle = {Nature Communications},
  shortjournal = {Nat Commun},
  volume = {7},
  number = {1},
  pages = {13806},
  publisher = {Nature Publishing Group},
  issn = {2041-1723},
  doi = {10.1038/ncomms13806},
  url = {https://www.nature.com/articles/ncomms13806},
  urldate = {2023-06-13},
  abstract = {Kinetic models of metabolism at a genome scale that faithfully recapitulate the effect of multiple genetic interventions would be transformative in our ability to reliably design novel overproducing microbial strains. Here, we introduce k-ecoli457, a genome-scale kinetic model of Escherichia coli metabolism that satisfies fluxomic data for wild-type and 25 mutant strains under different substrates and growth conditions. The k-ecoli457 model contains 457 model reactions, 337 metabolites and 295 substrate-level regulatory interactions. Parameterization is carried out using a genetic algorithm by simultaneously imposing all available fluxomic data (about 30 measured fluxes per mutant). The Pearson correlation coefficient between experimental data and predicted product yields for 320 engineered strains spanning 24 product metabolites is 0.84. This is substantially higher than that using flux balance analysis, minimization of metabolic adjustment or maximization of product yield exhibiting systematic errors with correlation coefficients of, respectively, 0.18, 0.37 and 0.47 (k-ecoli457 is available for download at http://www.maranasgroup.com).},
  issue = {1},
  langid = {english},
  keywords = {Bacteria,Computer modelling,Metabolic engineering},
  annotation = {175 citations (Semantic Scholar/DOI) [2023-06-13]},
  file = {/Users/michaelvolk/Zotero/storage/2W72I6HM/Khodayari and Maranas - 2016 - A genome-scale Escherichia coli kinetic metabolic .pdf}
}

@article{kimCombinatorialNeuralCode2025,
  title = {A Combinatorial Neural Code for Long-Term Motor Memory},
  author = {Kim, Jae-Hyun and Daie, Kayvon and Li, Nuo},
  date = {2025-01},
  journaltitle = {Nature},
  volume = {637},
  number = {8046},
  pages = {663--672},
  publisher = {Nature Publishing Group},
  issn = {1476-4687},
  doi = {10.1038/s41586-024-08193-3},
  url = {https://www.nature.com/articles/s41586-024-08193-3},
  urldate = {2025-02-27},
  abstract = {Motor skill repertoire can be stably retained over long periods, but the neural mechanism that underlies stable memory storage remains poorly understood1–8. Moreover, it is unknown how existing motor memories are maintained as new motor skills are continuously acquired. Here we tracked neural representation of learned actions throughout a significant portion of the lifespan of a mouse and show that learned actions are stably retained in combination with context, which protects existing memories from erasure during new motor learning. We established a continual learning paradigm in which mice learned to perform directional licking in different task contexts while we tracked motor cortex activity for up to six months using two-photon imaging. Within the same task context, activity driving directional licking was stable over time with little representational drift. When learning new task contexts, new preparatory activity emerged to drive the same licking actions. Learning created parallel new motor memories instead of modifying existing representations. Re-learning to make the same actions in the previous task context re-activated the previous preparatory activity, even months later. Continual learning of new task contexts kept creating new preparatory activity patterns. Context-specific memories, as we observed in the motor system, may provide a solution for stable memory storage throughout continual learning.},
  langid = {english},
  keywords = {Fluorescence imaging,Long-term memory,Motor cortex,Network models,Premotor cortex},
  annotation = {0 citations (Semantic Scholar/DOI) [2025-02-27]},
  file = {/Users/michaelvolk/Zotero/storage/A9WAJM7A/Kim et al_2025_A combinatorial neural code for long-term motor memory.pdf}
}

@inproceedings{kimHypergraphAttentionNetworks2020,
  title = {Hypergraph Attention Networks for Multimodal Learning},
  booktitle = {Proceedings of the {{IEEE}}/{{CVF}} Conference on Computer Vision and Pattern Recognition},
  author = {Kim, Eun-Sol and Kang, Woo Young and On, Kyoung-Woon and Heo, Yu-Jung and Zhang, Byoung-Tak},
  date = {2020},
  pages = {14581--14590},
  url = {http://openaccess.thecvf.com/content_CVPR_2020/html/Kim_Hypergraph_Attention_Networks_for_Multimodal_Learning_CVPR_2020_paper.html},
  urldate = {2025-02-19},
  file = {/Users/michaelvolk/Zotero/storage/HKJPF5UJ/Kim et al_2020_Hypergraph attention networks for multimodal learning.pdf}
}

@inproceedings{kimHypergraphAttentionNetworks2020a,
  title = {Hypergraph Attention Networks for Multimodal Learning},
  booktitle = {Proceedings of the {{IEEE}}/{{CVF}} Conference on Computer Vision and Pattern Recognition},
  author = {Kim, Eun-Sol and Kang, Woo Young and On, Kyoung-Woon and Heo, Yu-Jung and Zhang, Byoung-Tak},
  date = {2020},
  pages = {14581--14590},
  url = {http://openaccess.thecvf.com/content_CVPR_2020/html/Kim_Hypergraph_Attention_Networks_for_Multimodal_Learning_CVPR_2020_paper.html},
  urldate = {2025-02-27},
  file = {/Users/michaelvolk/Zotero/storage/WNKL6Q4K/Kim et al_2020_Hypergraph attention networks for multimodal learning.pdf}
}

@article{kimYeastNetV3Public2014,
  title = {{{YeastNet}} v3: A Public Database of Data-Specific and Integrated Functional Gene Networks for {{Saccharomyces}} Cerevisiae},
  shorttitle = {{{YeastNet}} V3},
  author = {Kim, Hanhae and Shin, Junha and Kim, Eiru and Kim, Hyojin and Hwang, Sohyun and Shim, Jung Eun and Lee, Insuk},
  date = {2014-01-01},
  journaltitle = {Nucleic Acids Research},
  shortjournal = {Nucleic Acids Research},
  volume = {42},
  number = {D1},
  pages = {D731-D736},
  issn = {0305-1048},
  doi = {10.1093/nar/gkt981},
  url = {https://doi.org/10.1093/nar/gkt981},
  urldate = {2023-10-24},
  abstract = {Saccharomyces cerevisiae, i.e. baker’s yeast, is a widely studied model organism in eukaryote genetics because of its simple protocols for genetic manipulation and phenotype profiling. The high abundance of publicly available data that has been generated through diverse ‘omics’ approaches has led to the use of yeast for many systems biology studies, including large-scale gene network modeling to better understand the molecular basis of the cellular phenotype. We have previously developed a genome-scale gene network for yeast, YeastNet v2, which has been used for various genetics and systems biology studies. Here, we present an updated version, YeastNet v3 (available at http://www.inetbio.org/yeastnet/), that significantly improves the prediction of gene–phenotype associations. The extended genome in YeastNet v3 covers up to 5818 genes (∼99\% of the coding genome) wired by 362 512 functional links. YeastNet v3 provides a new web interface to run the tools for network-guided hypothesis generations. YeastNet v3 also provides edge information for all data-specific networks (∼2 million functional links) as well as the integrated networks. Therefore, users can construct alternative versions of the integrated network by applying their own data integration algorithm to the same data-specific links.},
  annotation = {73 citations (Semantic Scholar/DOI) [2023-10-24]},
  file = {/Users/michaelvolk/Zotero/storage/FIU5R73I/Kim et al_2014_YeastNet v3.pdf;/Users/michaelvolk/Zotero/storage/UYLWSRDP/1070233.html}
}

@unpublished{kipfVariationalGraphAutoEncoders2016,
  title = {Variational {{Graph Auto-Encoders}}},
  author = {Kipf, Thomas N. and Welling, Max},
  date = {2016-11-21},
  eprint = {1611.07308},
  eprinttype = {arXiv},
  eprintclass = {cs, stat},
  publisher = {arXiv},
  doi = {10.48550/arXiv.1611.07308},
  url = {http://arxiv.org/abs/1611.07308},
  urldate = {2022-06-15},
  abstract = {We introduce the variational graph auto-encoder (VGAE), a framework for unsupervised learning on graph-structured data based on the variational auto-encoder (VAE). This model makes use of latent variables and is capable of learning interpretable latent representations for undirected graphs. We demonstrate this model using a graph convolutional network (GCN) encoder and a simple inner product decoder. Our model achieves competitive results on a link prediction task in citation networks. In contrast to most existing models for unsupervised learning on graph-structured data and link prediction, our model can naturally incorporate node features, which significantly improves predictive performance on a number of benchmark datasets.},
  keywords = {🦌📚,Computer Science - Machine Learning,Statistics - Machine Learning},
  annotation = {1751 citations (Semantic Scholar/arXiv) [2023-01-24]},
  file = {/Users/michaelvolk/Zotero/storage/S7FJSMA9/zendron_temp.md;/Users/michaelvolk/Zotero/storage/UIVEMQEC/Kipf_Welling_2016_Variational Graph Auto-Encoders.pdf}
}

@article{klopfensteinGOATOOLSPythonLibrary2018a,
  title = {{{GOATOOLS}}: {{A Python}} Library for {{Gene Ontology}} Analyses},
  shorttitle = {{{GOATOOLS}}},
  author = {Klopfenstein, D. V. and Zhang, Liangsheng and Pedersen, Brent S. and Ramírez, Fidel and Warwick Vesztrocy, Alex and Naldi, Aurélien and Mungall, Christopher J. and Yunes, Jeffrey M. and Botvinnik, Olga and Weigel, Mark and Dampier, Will and Dessimoz, Christophe and Flick, Patrick and Tang, Haibao},
  date = {2018-07-18},
  journaltitle = {Scientific Reports},
  shortjournal = {Sci Rep},
  volume = {8},
  number = {1},
  pages = {10872},
  publisher = {Nature Publishing Group},
  issn = {2045-2322},
  doi = {10.1038/s41598-018-28948-z},
  url = {https://www.nature.com/articles/s41598-018-28948-z},
  urldate = {2023-08-30},
  abstract = {The biological interpretation of gene lists with interesting shared properties, such as up- or down-regulation in a particular experiment, is typically accomplished using gene ontology enrichment analysis tools. Given a list of genes, a gene ontology (GO) enrichment analysis may return hundreds of statistically significant GO results in a “flat” list, which can be challenging to summarize. It can also be difficult to keep pace with rapidly expanding biological knowledge, which often results in daily changes to any of the over 47,000 gene ontologies that describe biological knowledge. GOATOOLS, a Python-based library, makes it more efficient to stay current with the latest ontologies and annotations, perform gene ontology enrichment analyses to determine over- and under-represented terms, and organize results for greater clarity and easier interpretation using a novel GOATOOLS GO grouping method. We performed functional analyses on both stochastic simulation data and real data from a published RNA-seq study to compare the enrichment results from GOATOOLS to two other popular tools: DAVID and GOstats. GOATOOLS is freely available through GitHub: https://github.com/tanghaibao/goatools.},
  issue = {1},
  langid = {english},
  keywords = {Gene ontology,Software},
  annotation = {0 citations (Semantic Scholar/DOI) [2023-08-30]},
  file = {/Users/michaelvolk/Zotero/storage/QBAGG766/Klopfenstein et al_2018_GOATOOLS.pdf}
}

@article{kobayashiInformationGeometryDynamics2024,
  title = {Information Geometry of Dynamics on Graphs and Hypergraphs},
  author = {Kobayashi, Tetsuya J. and Loutchko, Dimitri and Kamimura, Atsushi and Horiguchi, Shuhei A. and Sughiyama, Yuki},
  date = {2024-06-01},
  journaltitle = {Information Geometry},
  shortjournal = {Info. Geo.},
  volume = {7},
  number = {1},
  pages = {97--166},
  issn = {2511-249X},
  doi = {10.1007/s41884-023-00125-w},
  url = {https://doi.org/10.1007/s41884-023-00125-w},
  urldate = {2024-07-04},
  abstract = {We introduce a new information-geometric structure associated with the dynamics on discrete objects such as graphs and hypergraphs. The presented setup consists of two dually flat structures built on the vertex and edge spaces, respectively. The former is the conventional duality between density and potential, e.g., the probability density and its logarithmic form induced by a convex thermodynamic function. The latter is the duality between flux and force induced by a convex and symmetric dissipation function, which drives the dynamics of the density. These two are connected topologically by the homological algebraic relation induced by the underlying discrete objects. The generalized gradient flow in this doubly dual flat structure is an extension of the gradient flows on Riemannian manifolds, which include Markov jump processes and nonlinear chemical reaction dynamics as well as the natural gradient. The information-geometric projections on this doubly dual flat structure lead to information-geometric extensions of the Helmholtz–Hodge decomposition and the Otto structure in \$\$L\textasciicircum\{2\}\$\$-Wasserstein geometry. The structure can be extended to non-gradient nonequilibrium flows, from which we also obtain the induced dually flat structure on cycle spaces. This abstract but general framework can broaden the applicability of information geometry to various problems of linear and nonlinear dynamics.},
  langid = {english},
  keywords = {Discrete calculus,Dually flat structure,Helmholtz decomposition,Homological Algebra,Thermodynamics},
  file = {/Users/michaelvolk/Zotero/storage/AWKUTS9Q/Kobayashi et al_2024_Information geometry of dynamics on graphs and hypergraphs.pdf}
}

@article{koEnhancingHyperedgePrediction2025,
  title = {Enhancing {{Hyperedge Prediction}} with {{Context-Aware Self-Supervised Learning}}},
  author = {Ko, Yunyong and Tong, Hanghang and Kim, Sang-Wook},
  date = {2025},
  journaltitle = {IEEE Transactions on Knowledge and Data Engineering},
  shortjournal = {IEEE Trans. Knowl. Data Eng.},
  eprint = {2309.05798},
  eprinttype = {arXiv},
  eprintclass = {cs},
  pages = {1--13},
  issn = {1041-4347, 1558-2191, 2326-3865},
  doi = {10.1109/TKDE.2025.3532263},
  url = {http://arxiv.org/abs/2309.05798},
  urldate = {2025-02-27},
  abstract = {Hypergraphs can naturally model group-wise relations (e.g., a group of users who co-purchase an item) as hyperedges. Hyperedge prediction is to predict future or unobserved hyperedges, which is a fundamental task in many real-world applications (e.g., group recommendation). Despite the recent breakthrough of hyperedge prediction methods, the following challenges have been rarely studied: (C1) How to aggregate the nodes in each hyperedge candidate for accurate hyperedge prediction? and (C2) How to mitigate the inherent data sparsity problem in hyperedge prediction? To tackle both challenges together, in this paper, we propose a novel hyperedge prediction framework (CASH) that employs (1) context-aware node aggregation to precisely capture complex relations among nodes in each hyperedge for (C1) and (2) self-supervised contrastive learning in the context of hyperedge prediction to enhance hypergraph representations for (C2). Furthermore, as for (C2), we propose a hyperedge-aware augmentation method to fully exploit the latent semantics behind the original hypergraph and consider both node-level and group-level contrasts (i.e., dual contrasts) for better node and hyperedge representations. Extensive experiments on six real-world hypergraphs reveal that CASH consistently outperforms all competing methods in terms of the accuracy in hyperedge prediction and each of the proposed strategies is effective in improving the model accuracy of CASH. For the detailed information of CASH, we provide the code and datasets at: https://github.com/yy-ko/cash.},
  keywords = {Computer Science - Machine Learning,Computer Science - Social and Information Networks},
  annotation = {0 citations (Semantic Scholar/arXiv) [2025-02-27]\\
0 citations (Semantic Scholar/DOI) [2025-02-27]},
  file = {/Users/michaelvolk/Zotero/storage/EJSG4JJ4/Ko et al_2025_Enhancing Hyperedge Prediction with Context-Aware Self-Supervised Learning.pdf;/Users/michaelvolk/Zotero/storage/ZRLIH9CQ/2309.html}
}

@article{konigAIModelsFuture2021,
  title = {{{AI}} Models and the Future of Genomic Research and Medicine: {{True}} Sons of Knowledge?},
  shorttitle = {{{AI}} Models and the Future of Genomic Research and Medicine},
  author = {König, Harald and Frank, Daniel and Baumann, Martina and Heil, Reinhard},
  date = {2021},
  journaltitle = {BioEssays},
  volume = {43},
  number = {10},
  pages = {2100025},
  issn = {1521-1878},
  doi = {10.1002/bies.202100025},
  url = {https://onlinelibrary.wiley.com/doi/abs/10.1002/bies.202100025},
  urldate = {2024-07-04},
  abstract = {The increasing availability of large-scale, complex data has made research into how human genomes determine physiology in health and disease, as well as its application to drug development and medicine, an attractive field for artificial intelligence (AI) approaches. Looking at recent developments, we explore how such approaches interconnect and may conflict with needs for and notions of causal knowledge in molecular genetics and genomic medicine. We provide reasons to suggest that—while capable of generating predictive knowledge at unprecedented pace and scale—if and how these approaches will be integrated with prevailing causal concepts will not only determine the future of scientific understanding and self-conceptions in these fields. But these questions will also be key to develop differentiated policies, such as for education and regulation, in order to harness societal benefits of AI for genomic research and medicine.},
  langid = {english},
  keywords = {artificial intelligence,causality,genomic medicine,molecular genetics,policy implications,scientific understanding},
  annotation = {3 citations (Semantic Scholar/DOI) [2024-07-04]},
  file = {/Users/michaelvolk/Zotero/storage/VCY8ST8C/König et al. - 2021 - AI models and the future of genomic research and m.pdf;/Users/michaelvolk/Zotero/storage/I27IFZI9/bies.html}
}

@article{kratzMultiscaleMapProtein2023a,
  title = {A Multi-Scale Map of Protein Assemblies in the {{DNA}} Damage Response},
  author = {Kratz, Anton and Kim, Minkyu and Kelly, Marcus R. and Zheng, Fan and Koczor, Christopher A. and Li, Jianfeng and Ono, Keiichiro and Qin, Yue and Churas, Christopher and Chen, Jing and Pillich, Rudolf T. and Park, Jisoo and Modak, Maya and Collier, Rachel and Licon, Kate and Pratt, Dexter and Sobol, Robert W. and Krogan, Nevan J. and Ideker, Trey},
  date = {2023-06},
  journaltitle = {Cell Systems},
  shortjournal = {Cell Systems},
  volume = {14},
  number = {6},
  pages = {447-463.e8},
  issn = {24054712},
  doi = {10.1016/j.cels.2023.04.007},
  url = {https://linkinghub.elsevier.com/retrieve/pii/S2405471223001163},
  urldate = {2023-08-30},
  abstract = {The DNA damage response (DDR) ensures error-free DNA replication and transcription and is disrupted in numerous diseases. An ongoing challenge is to determine the proteins orchestrating DDR and their organization into complexes, including constitutive interactions and those responding to genomic insult. Here, we use multi-conditional network analysis to systematically map DDR assemblies at multiple scales. Affinity purifications of 21 DDR proteins, with/without genotoxin exposure, are combined with multi-omics data to reveal a hierarchical organization of 605 proteins into 109 assemblies. The map captures canonical repair mechanisms and proposes new DDR-associated proteins extending to stress, transport, and chromatin functions. We find that protein assemblies closely align with genetic dependencies in processing specific genotoxins and that proteins in multiple assemblies typically act in multiple genotoxin responses. Followup by DDR functional readouts newly implicates 12 assembly members in double-strand-break repair. The DNA damage response assemblies map is available for interactive visualization and query (ccmi.org/ ddram/).},
  langid = {english},
  annotation = {1 citations (Semantic Scholar/DOI) [2023-08-30]},
  file = {/Users/michaelvolk/Zotero/storage/TT8FGNTV/Kratz et al. - 2023 - A multi-scale map of protein assemblies in the DNA.pdf}
}

@article{krollTurnoverNumberPredictions2023,
  title = {Turnover Number Predictions for Kinetically Uncharacterized Enzymes Using Machine and Deep Learning},
  author = {Kroll, Alexander and Rousset, Yvan and Hu, Xiao-Pan and Liebrand, Nina A. and Lercher, Martin J.},
  date = {2023-07-12},
  journaltitle = {Nature Communications},
  shortjournal = {Nat Commun},
  volume = {14},
  number = {1},
  pages = {4139},
  publisher = {Nature Publishing Group},
  issn = {2041-1723},
  doi = {10.1038/s41467-023-39840-4},
  url = {https://www.nature.com/articles/s41467-023-39840-4},
  urldate = {2023-09-13},
  abstract = {The turnover number kcat, a measure of enzyme efficiency, is central to understanding cellular physiology and resource allocation. As experimental kcat estimates are unavailable for the vast majority of enzymatic reactions, the development of accurate computational prediction methods is highly desirable. However, existing machine learning models are limited to a single, well-studied organism, or they provide inaccurate predictions except for enzymes that are highly similar to proteins in the training set. Here, we present TurNuP, a general and organism-independent model that successfully predicts turnover numbers for natural reactions of wild-type enzymes. We constructed model inputs by representing complete chemical reactions through differential reaction fingerprints and by representing enzymes through a modified and re-trained Transformer Network model for protein sequences. TurNuP outperforms previous models and generalizes well even to enzymes that are not similar to proteins in the training set. Parameterizing metabolic models with TurNuP-predicted kcat values leads to improved proteome allocation predictions. To provide a powerful and convenient tool for the study of molecular biochemistry and physiology, we implemented a TurNuP web server.},
  issue = {1},
  langid = {english},
  keywords = {Enzymes,Machine learning},
  annotation = {4 citations (Semantic Scholar/DOI) [2023-09-13]},
  file = {/Users/michaelvolk/Zotero/storage/UY6VT6KT/Kroll et al_2023_Turnover number predictions for kinetically uncharacterized enzymes using.pdf}
}

@article{ktenaMetricLearningSpectral2018,
  title = {Metric Learning with Spectral Graph Convolutions on Brain Connectivity Networks},
  author = {Ktena, Sofia Ira and Parisot, Sarah and Ferrante, Enzo and Rajchl, Martin and Lee, Matthew and Glocker, Ben and Rueckert, Daniel},
  date = {2018-04-01},
  journaltitle = {NeuroImage},
  shortjournal = {NeuroImage},
  volume = {169},
  pages = {431--442},
  issn = {1053-8119},
  doi = {10.1016/j.neuroimage.2017.12.052},
  url = {https://www.sciencedirect.com/science/article/pii/S1053811917310765},
  urldate = {2025-02-27},
  abstract = {Graph representations are often used to model structured data at an individual or population level and have numerous applications in pattern recognition problems. In the field of neuroscience, where such representations are commonly used to model structural or functional connectivity between a set of brain regions, graphs have proven to be of great importance. This is mainly due to the capability of revealing patterns related to brain development and disease, which were previously unknown. Evaluating similarity between these brain connectivity networks in a manner that accounts for the graph structure and is tailored for a particular application is, however, non-trivial. Most existing methods fail to accommodate the graph structure, discarding information that could be beneficial for further classification or regression analyses based on these similarities. We propose to learn a graph similarity metric using a siamese graph convolutional neural network (s-GCN) in a supervised setting. The proposed framework takes into consideration the graph structure for the evaluation of similarity between a pair of graphs, by employing spectral graph convolutions that allow the generalisation of traditional convolutions to irregular graphs and operates in the graph spectral domain. We apply the proposed model on two datasets: the challenging ABIDE database, which comprises functional MRI data of 403 patients with autism spectrum disorder (ASD) and 468 healthy controls aggregated from multiple acquisition sites, and a set of 2500 subjects from UK Biobank. We demonstrate the performance of the method for the tasks of classification between matching and non-matching graphs, as well as individual subject classification and manifold learning, showing that it leads to significantly improved results compared to traditional methods.},
  keywords = {Autism spectrum disorder,Convolutional neural networks,Functional brain connectivity,Spectral graph convolutions,UK biobank},
  annotation = {304 citations (Semantic Scholar/DOI) [2025-02-27]},
  file = {/Users/michaelvolk/Zotero/storage/JMT6CMKV/Ktena et al_2018_Metric learning with spectral graph convolutions on brain connectivity networks.pdf;/Users/michaelvolk/Zotero/storage/B8QH3VYC/S1053811917310765.html}
}

@article{kumarProductionLevulinicAcid2020,
  title = {Production of Levulinic Acid: {{A}} Promising Building Block Material for Pharmaceutical and Food Industry},
  shorttitle = {Production of Levulinic Acid},
  author = {Kumar, Anuj and Shende, Diwakar Z. and Wasewar, K. L.},
  date = {2020-01-01},
  journaltitle = {Materials Today: Proceedings},
  shortjournal = {Materials Today: Proceedings},
  series = {11th {{National Conference}} on {{Solid State Chemistry}} and {{Allied Areas}}},
  volume = {29},
  pages = {790--793},
  issn = {2214-7853},
  doi = {10.1016/j.matpr.2020.04.749},
  url = {https://www.sciencedirect.com/science/article/pii/S2214785320333976},
  urldate = {2025-02-27},
  abstract = {Levulinic acid can be produced through various routes; synthesis, bio, and extraction routes. These routes release toxic gases and waste materials during the levulinic acid production. Therefore, it needs an environment-friendly method for the manufacture of levulinic acid. In synthesis route, various substrates viz. xylose, maltose, and sucrose translate to levulinic acid. Also, the bio route uses H2SO4, HCl for pre-treatment in the fermentation process during the production of levulinic acid and generates toxic wastes. In the present paper, an attempt is made to discuss the opportunities and challenges for the production of levulinic acid by synthesis, bio, and extraction routes.},
  keywords = {Bio routes,Extraction,Levulinic acid,Production,Synthesis},
  annotation = {24 citations (Semantic Scholar/DOI) [2025-02-27]},
  file = {/Users/michaelvolk/Zotero/storage/V2NW2LK4/S2214785320333976.html}
}

@article{kuzminExploringWholegenomeDuplicate2020,
  title = {Exploring Whole-Genome Duplicate Gene Retention with Complex Genetic Interaction Analysis},
  author = {Kuzmin, Elena and VanderSluis, Benjamin and Nguyen Ba, Alex N. and Wang, Wen and Koch, Elizabeth N. and Usaj, Matej and Khmelinskii, Anton and Usaj, Mojca Mattiazzi and family=Leeuwen, given=Jolanda, prefix=van, useprefix=true and Kraus, Oren and Tresenrider, Amy and Pryszlak, Michael and Hu, Ming-Che and Varriano, Brenda and Costanzo, Michael and Knop, Michael and Moses, Alan and Myers, Chad L. and Andrews, Brenda J. and Boone, Charles},
  date = {2020-06-26},
  journaltitle = {Science},
  volume = {368},
  number = {6498},
  pages = {eaaz5667},
  publisher = {American Association for the Advancement of Science},
  doi = {10.1126/science.aaz5667},
  url = {https://www.science.org/doi/10.1126/science.aaz5667},
  urldate = {2024-08-09},
  abstract = {Whole-genome duplication has played a central role in the genome evolution of many organisms, including the human genome. Most duplicated genes are eliminated, and factors that influence the retention of persisting duplicates remain poorly understood. We describe a systematic complex genetic interaction analysis with yeast paralogs derived from the whole-genome duplication event. Mapping of digenic interactions for a deletion mutant of each paralog, and of trigenic interactions for the double mutant, provides insight into their roles and a quantitative measure of their functional redundancy. Trigenic interaction analysis distinguishes two classes of paralogs: a more functionally divergent subset and another that retained more functional overlap. Gene feature analysis and modeling suggest that evolutionary trajectories of duplicated genes are dictated by combined functional and structural entanglement factors.},
  annotation = {71 citations (Semantic Scholar/DOI) [2024-08-09]},
  file = {/Users/michaelvolk/Zotero/storage/T57VMSB8/SI-aaz5667_kuzmin_sm.pdf;/Users/michaelvolk/Zotero/storage/XFG6JLKH/Kuzmin et al_2020_Exploring whole-genome duplicate gene retention with complex genetic.pdf}
}

@article{kuzminSystematicAnalysisComplex2018,
  title = {Systematic Analysis of Complex Genetic Interactions},
  author = {Kuzmin, Elena and VanderSluis, Benjamin and Wang, Wen and Tan, Guihong and Deshpande, Raamesh and Chen, Yiqun and Usaj, Matej and Balint, Attila and Mattiazzi Usaj, Mojca and family=Leeuwen, given=Jolanda, prefix=van, useprefix=true and Koch, Elizabeth N. and Pons, Carles and Dagilis, Andrius J. and Pryszlak, Michael and Wang, Jason Zi Yang and Hanchard, Julia and Riggi, Margot and Xu, Kaicong and Heydari, Hamed and San Luis, Bryan-Joseph and Shuteriqi, Ermira and Zhu, Hongwei and Van Dyk, Nydia and Sharifpoor, Sara and Costanzo, Michael and Loewith, Robbie and Caudy, Amy and Bolnick, Daniel and Brown, Grant W. and Andrews, Brenda J. and Boone, Charles and Myers, Chad L.},
  date = {2018-04-20},
  journaltitle = {Science},
  shortjournal = {Science},
  volume = {360},
  number = {6386},
  pages = {eaao1729},
  issn = {0036-8075, 1095-9203},
  doi = {10.1126/science.aao1729},
  url = {https://www.science.org/doi/10.1126/science.aao1729},
  urldate = {2022-02-08},
  abstract = {Trigenic interactions in yeast link bioprocesses                            To dissect the genotype-phenotype landscape of a cell, it is necessary to understand interactions between genes. Building on the digenic protein-protein interaction network, Kuzmin               et al.               created a trigenic landscape of yeast by using a synthetic genetic array (see the Perspective by Walhout). Triple-mutant analyses indicated that the majority of genes with trigenic associations functioned within the same biological processes. These converged on networks identified in the digenic interaction landscape. Although the overall effects were weaker for trigenic than for digenic interactions, trigenic interactions were more likely to bridge biological processes in the cell.                                         Science               , this issue p.               eaao1729               ; see also p.               269                        ,              Trigenic interactions in yeast link bioprocesses are explored.           ,                             INTRODUCTION               Genetic interactions occur when mutations in different genes combine to result in a phenotype that is different from expectation based on those of the individual mutations. Negative genetic interactions occur when a combination of mutations leads to a fitness defect that is more exacerbated than expected. For example, synthetic lethality occurs when two mutations, neither of which is lethal on its own, generate an inviable double mutant. Alternatively, positive genetic interactions occur when genetic perturbations combine to generate a double mutant with a greater fitness than expected. Global digenic interaction studies have been useful for understanding the functional wiring diagram of the cell and may also provide insight into the genotype-to-phenotype relationship, which is important for tracking the missing heritability of human health and disease. Here we describe a network of higher-order trigenic interactions and explore its implications.                                         RATIONALE               Variation in phenotypic outcomes in different individuals is caused by genetic determinants that act as modifiers. Modifier loci are prevalent in human populations, but knowledge regarding how variants interact to modulate phenotype in different individuals is lacking. Similarly, in yeast, traits including conditional essentiality—in which certain genes are essential in one genetic background but nonessential in another—often result from an interplay of multiple modifier loci. Because complex modifiers may underlie the genetic basis of physiological states found in natural populations, it is critical to understand the landscape of higher-order genetic interactions.                                         RESULTS               To survey trigenic interactions, we designed query strains that sampled key features of the global digenic interaction network: (i) digenic interaction strength, (ii) average number of digenic interactions, and (iii) digenic interaction profile similarity. In total, we tested \textasciitilde 400,000 double and \textasciitilde 200,000 triple mutants for fitness defects and identified \textasciitilde 9500 digenic and \textasciitilde 3200 trigenic negative interactions. Although trigenic interactions tend to be weaker than digenic interactions, they were both enriched for functional relationships. About one-third of trigenic interactions identified “novel” connections that were not observed in our digenic control network, whereas the remaining approximately two-thirds of trigenic interactions “modified” a digenic interaction, suggesting that the global digenic interaction network is important for understanding the trigenic interaction network. Despite their functional enrichment, trigenic interactions also bridged distant bioprocesses. We estimate that the global trigenic interaction network is \textasciitilde 100 times as large as the global digenic network, highlighting the potential for complex genetic interactions to affect the biology of inheritance.                                         CONCLUSION               The extensive network of trigenic interactions and their ability to generate functionally diverse phenotypes suggest that higher-order genetic interactions may play a key role in the genotype-to-phenotype relationship, genome size, and speciation.                                                   Systematic analysis of trigenic interactions.                                        We surveyed                                          for trigenic interactions and found that they are \textasciitilde 100 times as prevalent as digenic interactions, often modify a digenic interaction, and connect functionally related genes as well as genes in more diverse bioprocesses (multicolored nodes). PPI, protein-protein interaction.                                                                                            ,              To systematically explore complex genetic interactions, we constructed \textasciitilde 200,000 yeast triple mutants and scored negative trigenic interactions. We selected double-mutant query genes across a broad spectrum of biological processes, spanning a range of quantitative features of the global digenic interaction network and tested for a genetic interaction with a third mutation. Trigenic interactions often occurred among functionally related genes, and essential genes were hubs on the trigenic network. Despite their functional enrichment, trigenic interactions tended to link genes in distant bioprocesses and displayed a weaker magnitude than digenic interactions. We estimate that the global trigenic interaction network is \textasciitilde 100 times as large as the global digenic network, highlighting the potential for complex genetic interactions to affect the biology of inheritance, including the genotype-to-phenotype relationship.},
  langid = {english},
  keywords = {✅,🦌},
  annotation = {171 citations (Semantic Scholar/DOI) [2022-11-26]\\
139 citations (Crossref) [2022-04-15]},
  file = {/Users/michaelvolk/Zotero/storage/B5SLF7QS/Kuzmin et al. - 2018 - Systematic analysis of complex genetic interaction.pdf;/Users/michaelvolk/Zotero/storage/ZGRTXZEA/SI-Kuzmin et al. - 2018 - Systematic analysis of complex genetic interaction.pdf}
}

@article{kuzminTSGASyntheticGenetic2021,
  title = {τ-{{SGA}}: Synthetic Genetic Array Analysis for Systematically Screening and Quantifying Trigenic Interactions in Yeast},
  shorttitle = {τ-{{SGA}}},
  author = {Kuzmin, Elena and Rahman, Mahfuzur and VanderSluis, Benjamin and Costanzo, Michael and Myers, Chad L. and Andrews, Brenda J. and Boone, Charles},
  date = {2021-02},
  journaltitle = {Nature Protocols},
  shortjournal = {Nat Protoc},
  volume = {16},
  number = {2},
  pages = {1219--1250},
  publisher = {Nature Publishing Group},
  issn = {1750-2799},
  doi = {10.1038/s41596-020-00456-3},
  url = {https://www.nature.com/articles/s41596-020-00456-3},
  urldate = {2024-08-09},
  abstract = {Systematic complex genetic interaction studies have provided insight into high-order functional redundancies and genetic network wiring of the cell. Here, we describe a method for screening and quantifying trigenic interactions from ordered arrays of yeast strains grown on agar plates as individual colonies. The protocol instructs users on the trigenic synthetic genetic array analysis technique, τ-SGA, for high-throughput screens. The steps describe construction of the double-mutant query strains and the corresponding single-mutant control query strains, which are screened in parallel in two replicates. The screening experimental set-up consists of sequential replica-pinning steps that enable automated mating, meiotic recombination and successive haploid selection steps for the generation of triple mutants, which are scored for colony size as a proxy for fitness, which enables the calculation of trigenic interactions. The procedure described here was used to conduct 422 trigenic interaction screens, which generated \textasciitilde 460,000 yeast triple mutants for trigenic interaction analysis. Users should be familiar with robotic equipment required for high-throughput genetic interaction screens and be proficient at the command line to execute the scoring pipeline. Large-scale screen computational analysis is achieved by using MATLAB pipelines that score raw colony size data to produce τ-SGA interaction scores. Additional recommendations are included for optimizing experimental design and analysis of smaller-scale trigenic interaction screens by using a web-based analysis system, SGAtools. This protocol provides a resource for those who would like to gain a deeper, more practical understanding of trigenic interaction screening and quantification methodology.},
  langid = {english},
  keywords = {Epistasis,Saccharomyces cerevisiae,Software},
  annotation = {8 citations (Semantic Scholar/DOI) [2024-08-08]},
  file = {/Users/michaelvolk/Zotero/storage/8BZYYTD3/Kuzmin et al_2021_τ-SGA.pdf}
}

@article{lagemannDeepLearningCausal2023,
  title = {Deep Learning of Causal Structures in High Dimensions under Data Limitations},
  author = {Lagemann, Kai and Lagemann, Christian and Taschler, Bernd and Mukherjee, Sach},
  date = {2023-11},
  journaltitle = {Nature Machine Intelligence},
  shortjournal = {Nat Mach Intell},
  volume = {5},
  number = {11},
  pages = {1306--1316},
  publisher = {Nature Publishing Group},
  issn = {2522-5839},
  doi = {10.1038/s42256-023-00744-z},
  url = {https://www.nature.com/articles/s42256-023-00744-z},
  urldate = {2024-07-16},
  abstract = {Causal learning is a key challenge in scientific artificial intelligence as it allows researchers to go beyond purely correlative or predictive analyses towards learning underlying cause-and-effect relationships, which are important for scientific understanding as well as for a wide range of downstream tasks. Here, motivated by emerging biomedical questions, we propose a deep neural architecture for learning causal relationships between variables from a combination of high-dimensional data and prior causal knowledge. We combine convolutional and graph neural networks within a causal risk framework to provide an approach that is demonstrably effective under the conditions of high dimensionality, noise and data limitations that are characteristic of many applications, including in large-scale biology. In experiments, we find that the proposed learners can effectively identify novel causal relationships across thousands of variables. Results include extensive (linear and nonlinear) simulations (where the ground truth is known and can be directly compared against), as well as real biological examples where the models are applied to high-dimensional molecular data and their outputs compared against entirely unseen validation experiments. These results support the notion that deep learning approaches can be used to learn causal networks at large scale.},
  langid = {english},
  keywords = {Computational models,Machine learning},
  annotation = {10 citations (Semantic Scholar/DOI) [2024-07-15]},
  file = {/Users/michaelvolk/Zotero/storage/PPMWSAZI/Lagemann et al_2023_Deep learning of causal structures in high dimensions under data limitations.pdf}
}

@article{lamEngineeredYeastTolerance2021a,
  title = {Engineered Yeast Tolerance Enables Efficient Production from Toxified Lignocellulosic Feedstocks},
  author = {Lam, Felix H. and Turanlı-Yıldız, Burcu and Liu, Dany and Resch, Michael G. and Fink, Gerald R. and Stephanopoulos, Gregory},
  date = {2021-06-25},
  journaltitle = {Science Advances},
  volume = {7},
  number = {26},
  pages = {eabf7613},
  publisher = {American Association for the Advancement of Science},
  doi = {10.1126/sciadv.abf7613},
  url = {https://www.science.org/doi/10.1126/sciadv.abf7613},
  urldate = {2025-03-10},
  abstract = {Lignocellulosic biomass remains unharnessed for the production of renewable fuels and chemicals due to challenges in deconstruction and the toxicity its hydrolysates pose to fermentation microorganisms. Here, we show in Saccharomyces cerevisiae that engineered aldehyde reduction and elevated extracellular potassium and pH are sufficient to enable near-parity production between inhibitor-laden and inhibitor-free feedstocks. By specifically targeting the universal hydrolysate inhibitors, a single strain is enhanced to tolerate a broad diversity of highly toxified genuine feedstocks and consistently achieve industrial-scale titers (cellulosic ethanol of {$>$}100 grams per liter when toxified). Furthermore, a functionally orthogonal, lightweight design enables seamless transferability to existing metabolically engineered chassis strains: We endow full, multifeedstock tolerance on a xylose-consuming strain and one producing the biodegradable plastics precursor lactic acid. The demonstration of “drop-in” hydrolysate competence enables the potential of cost-effective, at-scale biomass utilization for cellulosic fuel and nonfuel products alike.},
  annotation = {28 citations (Semantic Scholar/DOI) [2025-03-09]},
  file = {/Users/michaelvolk/Zotero/storage/SRZVHH44/Lam et al_2021_Engineered yeast tolerance enables efficient production from toxified.pdf}
}

@article{lamyOwlreadyOntologyorientedProgramming2017,
  title = {Owlready: {{Ontology-oriented}} Programming in {{Python}} with Automatic Classification and High Level Constructs for Biomedical Ontologies},
  shorttitle = {Owlready},
  author = {Lamy, Jean-Baptiste},
  date = {2017-07-01},
  journaltitle = {Artificial Intelligence in Medicine},
  shortjournal = {Artificial Intelligence in Medicine},
  volume = {80},
  pages = {11--28},
  issn = {0933-3657},
  doi = {10.1016/j.artmed.2017.07.002},
  url = {https://www.sciencedirect.com/science/article/pii/S0933365717300271},
  urldate = {2023-11-30},
  abstract = {Objective Ontologies are widely used in the biomedical domain. While many tools exist for the edition, alignment or evaluation of ontologies, few solutions have been proposed for ontology programming interface, i.e. for accessing and modifying an ontology within a programming language. Existing query languages (such as SPARQL) and APIs (such as OWLAPI) are not as easy-to-use as object programming languages are. Moreover, they provide few solutions to difficulties encountered with biomedical ontologies. Our objective was to design a tool for accessing easily the entities of an OWL ontology, with high-level constructs helping with biomedical ontologies. Methods From our experience on medical ontologies, we identified two difficulties: (1) many entities are represented by classes (rather than individuals), but the existing tools do not permit manipulating classes as easily as individuals, (2) ontologies rely on the open-world assumption, whereas the medical reasoning must consider only evidence-based medical knowledge as true. We designed a Python module for ontology-oriented programming. It allows access to the entities of an OWL ontology as if they were objects in the programming language. We propose a simple high-level syntax for managing classes and the associated “role-filler” constraints. We also propose an algorithm for performing local closed world reasoning in simple situations. Results We developed Owlready, a Python module for a high-level access to OWL ontologies. The paper describes the architecture and the syntax of the module version 2. It details how we integrated the OWL ontology model with the Python object model. The paper provides examples based on Gene Ontology (GO). We also demonstrate the interest of Owlready in a use case focused on the automatic comparison of the contraindications of several drugs. This use case illustrates the use of the specific syntax proposed for manipulating classes and for performing local closed world reasoning. Conclusion Owlready has been successfully used in a medical research project. It has been published as Open-Source software and then used by many other researchers. Future developments will focus on the support of vagueness and additional non-monotonic reasoning feature, and automatic dialog box generation.},
  keywords = {Automatic classification,Biomedical ontology,Local closed world reasoning,Ontology-oriented programming,OWL,Semantic web},
  annotation = {218 citations (Semantic Scholar/DOI) [2023-11-29]},
  file = {/Users/michaelvolk/Zotero/storage/7LXTU37Y/Lamy_2017_Owlready.pdf;/Users/michaelvolk/Zotero/storage/EGLQ98FL/S0933365717300271.html}
}

@article{landgrebeMakingAIMeaningful2021,
  title = {Making {{AI}} Meaningful Again},
  author = {Landgrebe, Jobst and Smith, Barry},
  date = {2021-03},
  journaltitle = {Synthese},
  shortjournal = {Synthese},
  volume = {198},
  number = {3},
  pages = {2061--2081},
  issn = {0039-7857, 1573-0964},
  doi = {10.1007/s11229-019-02192-y},
  url = {http://link.springer.com/10.1007/s11229-019-02192-y},
  urldate = {2023-12-15},
  abstract = {Artificial intelligence (AI) research enjoyed an initial period of enthusiasm in the 1970s and 80s, but this enthusiasm was tempered by a long interlude of frustration when genuinely useful AI applications failed to be forthcoming. Today, we are experiencing once again a period of enthusiasm, fired above all by the successes of the technology of deep neural networks or deep machine learning. In this paper we draw attention to what we take to be serious problems underlying current views of artificial intelligence encouraged by these successes, especially in the domain of language processing. We then show an alternative approach to language-centric AI, in which we identify a role for philosophy.},
  langid = {english},
  annotation = {0 citations (Semantic Scholar/DOI) [2023-12-15]},
  file = {/Users/michaelvolk/Zotero/storage/3D4N558W/Landgrebe and Smith - 2021 - Making AI meaningful again.pdf}
}

@article{lauberMinimalMetabolismKey2021,
  title = {“{{Minimal}} Metabolism”: {{A}} Key Concept to Investigate the Origins and Nature of Biological Systems},
  shorttitle = {“{{Minimal}} Metabolism”},
  author = {Lauber, Nino and Flamm, Christoph and Ruiz-Mirazo, Kepa},
  date = {2021},
  journaltitle = {BioEssays},
  volume = {43},
  number = {10},
  pages = {2100103},
  issn = {1521-1878},
  doi = {10.1002/bies.202100103},
  url = {https://onlinelibrary.wiley.com/doi/abs/10.1002/bies.202100103},
  urldate = {2024-07-04},
  abstract = {The systems view on life and its emergence from complex chemistry has remarkably increased the scientific attention on metabolism in the last two decades. However, during this time there has not been much theoretical discussion on what constitutes a metabolism and what role it actually played in biogenesis. A critical and updated review on the topic is here offered, including some references to classical models from last century, but focusing more on current and future research. Metabolism is considered as intrinsically related to the living but not necessarily equivalent to it. More precisely, the idea of “minimal metabolism”, in contrast to previous, top-down conceptions, is formulated as a heuristic construct, halfway between chemistry and biology. Thus, rather than providing a complete or final characterization of metabolism, our aim is to encourage further investigations on it, particularly in the context of life's origin, for which some concrete methodological suggestions are provided. Also see the video abstract here: https://youtu.be/DP7VMKk2qpA},
  langid = {english},
  keywords = {autonomous control,constructive self-maintenance,functional bootstrapping,metabolism,origins of life,prebiotic systems chemistry,rule-based computational chemistry},
  annotation = {10 citations (Semantic Scholar/DOI) [2024-07-04]},
  file = {/Users/michaelvolk/Zotero/storage/UTDEQ2DQ/Lauber et al. - 2021 - “Minimal metabolism” A key concept to investigate.pdf;/Users/michaelvolk/Zotero/storage/VQLFDXAX/bies.html}
}

@article{leccaMachineLearningCausal2021a,
  title = {Machine {{Learning}} for {{Causal Inference}} in {{Biological Networks}}: {{Perspectives}} of {{This Challenge}}},
  shorttitle = {Machine {{Learning}} for {{Causal Inference}} in {{Biological Networks}}},
  author = {Lecca, Paola},
  date = {2021-09-22},
  journaltitle = {Frontiers in Bioinformatics},
  shortjournal = {Front. Bioinform.},
  volume = {1},
  publisher = {Frontiers},
  issn = {2673-7647},
  doi = {10.3389/fbinf.2021.746712},
  url = {https://www.frontiersin.org/journals/bioinformatics/articles/10.3389/fbinf.2021.746712/full},
  urldate = {2024-07-16},
  abstract = {{$<$}p{$>$}Most machine learning-based methods predict outcomes rather than understanding causality. Machine learning methods have been proved to be efficient in finding correlations in data, but unskilful to determine causation. This issue severely limits the applicability of machine learning methods to infer the causal relationships between the entities of a biological network, and more in general of any dynamical system, such as medical intervention strategies and clinical outcomes system, that is representable as a network. From the perspective of those who want to use the results of network inference not only to understand the mechanisms underlying the dynamics, but also to understand how the network reacts to external stimuli (e. g. environmental factors, therapeutic treatments), tools that can understand the causal relationships between data are highly demanded. Given the increasing popularity of machine learning techniques in computational biology and the recent literature proposing the use of machine learning techniques for the inference of biological networks, we would like to present the challenges that mathematics and computer science research faces in generalising machine learning to an approach capable of understanding causal relationships, and the prospects that achieving this will open up for the medical application domains of systems biology, the main paradigm of which is precisely network biology at any physical scale.{$<$}/p{$>$}},
  langid = {english},
  keywords = {artificial intelligence,Causal thinking,causality,deep learning,inference,machine learning,Systems Biology},
  annotation = {26 citations (Semantic Scholar/DOI) [2024-07-15]},
  file = {/Users/michaelvolk/Zotero/storage/43HVEPER/Lecca_2021_Machine Learning for Causal Inference in Biological Networks.pdf}
}

@book{leeMetabolicEngineeringConcepts2021,
  title = {Metabolic {{Engineering}}: {{Concepts}} and {{Applications}}},
  shorttitle = {Metabolic {{Engineering}}},
  author = {Lee, Sang Yup and Nielsen, Jens and Stephanopoulos, Gregory},
  date = {2021-06-02},
  eprint = {FoMxEAAAQBAJ},
  eprinttype = {googlebooks},
  publisher = {John Wiley \& Sons},
  abstract = {Learn more about foundational and advanced topics in metabolic engineering in this comprehensive resource edited by leaders in the field Metabolic Engineering: Concepts and Applications delivers a one-stop resource for readers seeking a complete description of the concepts, models, and applications of metabolic engineering. This guide offers practical insights into the metabolic engineering of major cell lines, including E. Coli, Bacillus and Yarrowia Lipolytica, and organisms, including human, animal, and plant). The distinguished editors also offer readers resources on microbiome engineering and the use of metabolic engineering in bioremediation. Written in two parts, Metabolic Engineering begins with the essential models and strategies of the field, like Flux Balance Analysis, Quantitative Flux Analysis, and Proteome Constrained Models. It also provides an overview of topics like Pathway Design, Metabolomics, and Genome Editing of Bacteria and Eukarya. The second part contains insightful descriptions of the practical applications of metabolic engineering, including specific examples that shed light on the topics within. In addition to subjects like the metabolic engineering of animals, humans, and plants, you’ll learn more about:  Metabolic engineering concepts and a historical perspective on their development The different modes of analysis, including flux balance analysis and quantitative flux analysis An illuminating and complete discussion of the thermodynamics of metabolic pathways The Genome architecture of E. coli, as well as genome editing of both bacteria and eukarya An in-depth treatment of the application of metabolic engineering techniques to organisms including corynebacterial, bacillus, and pseudomonas, and more  Perfect for students of biotechnology, bioengineers, and biotechnologists, Metabolic Engineering: Concepts and Applications also has a place on the bookshelves of research institutes, biotechnological institutes and industry labs, and university libraries. It's comprehensive treatment of all relevant metabolic engineering concepts, models, and applications will be of use to practicing biotechnologists and bioengineers who wish to solidify their understanding of the field.},
  isbn = {978-3-527-82345-1},
  langid = {english},
  pagetotal = {1075},
  keywords = {📖,🦌,biology,biotechnology,chemistry,metabolic-engineering,systems-metabolic-engineering},
  file = {/Users/michaelvolk/Zotero/storage/V6A3VSJH/Lee et al_2021_Metabolic Engineering.pdf}
}

@online{leeSelfAttentionGraphPooling2019,
  title = {Self-{{Attention Graph Pooling}}},
  author = {Lee, Junhyun and Lee, Inyeop and Kang, Jaewoo},
  date = {2019-06-13},
  eprint = {1904.08082},
  eprinttype = {arXiv},
  eprintclass = {cs, stat},
  doi = {10.48550/arXiv.1904.08082},
  url = {http://arxiv.org/abs/1904.08082},
  urldate = {2024-02-08},
  abstract = {Advanced methods of applying deep learning to structured data such as graphs have been proposed in recent years. In particular, studies have focused on generalizing convolutional neural networks to graph data, which includes redefining the convolution and the downsampling (pooling) operations for graphs. The method of generalizing the convolution operation to graphs has been proven to improve performance and is widely used. However, the method of applying downsampling to graphs is still difficult to perform and has room for improvement. In this paper, we propose a graph pooling method based on self-attention. Self-attention using graph convolution allows our pooling method to consider both node features and graph topology. To ensure a fair comparison, the same training procedures and model architectures were used for the existing pooling methods and our method. The experimental results demonstrate that our method achieves superior graph classification performance on the benchmark datasets using a reasonable number of parameters.},
  pubstate = {prepublished},
  keywords = {Computer Science - Machine Learning,I.2.6,Statistics - Machine Learning},
  annotation = {813 citations (Semantic Scholar/arXiv) [2024-02-08]},
  file = {/Users/michaelvolk/Zotero/storage/Q75SKMKP/Lee et al. - 2019 - Self-Attention Graph Pooling.pdf}
}

@inproceedings{leeSelfAttentionGraphPooling2019a,
  title = {Self-{{Attention Graph Pooling}}},
  booktitle = {Proceedings of the 36th {{International Conference}} on {{Machine Learning}}},
  author = {Lee, Junhyun and Lee, Inyeop and Kang, Jaewoo},
  date = {2019-05-24},
  pages = {3734--3743},
  publisher = {PMLR},
  issn = {2640-3498},
  url = {https://proceedings.mlr.press/v97/lee19c.html},
  urldate = {2024-03-11},
  abstract = {Advanced methods of applying deep learning to structured data such as graphs have been proposed in recent years. In particular, studies have focused on generalizing convolutional neural networks to graph data, which includes redefining the convolution and the downsampling (pooling) operations for graphs. The method of generalizing the convolution operation to graphs has been proven to improve performance and is widely used. However, the method of applying downsampling to graphs is still difficult to perform and has room for improvement. In this paper, we propose a graph pooling method based on self-attention. Self-attention using graph convolution allows our pooling method to consider both node features and graph topology. To ensure a fair comparison, the same training procedures and model architectures were used for the existing pooling methods and our method. The experimental results demonstrate that our method achieves superior graph classification performance on the benchmark datasets using a reasonable number of parameters.},
  eventtitle = {International {{Conference}} on {{Machine Learning}}},
  langid = {english},
  file = {/Users/michaelvolk/Zotero/storage/2W8KZQ8H/Lee et al_2019_Self-Attention Graph Pooling.pdf}
}

@inproceedings{leeSetTransformerFramework2019,
  title = {Set {{Transformer}}: {{A Framework}} for {{Attention-based Permutation-Invariant Neural Networks}}},
  shorttitle = {Set {{Transformer}}},
  booktitle = {Proceedings of the 36th {{International Conference}} on {{Machine Learning}}},
  author = {Lee, Juho and Lee, Yoonho and Kim, Jungtaek and Kosiorek, Adam and Choi, Seungjin and Teh, Yee Whye},
  date = {2019-05-24},
  pages = {3744--3753},
  publisher = {PMLR},
  issn = {2640-3498},
  url = {https://proceedings.mlr.press/v97/lee19d.html},
  urldate = {2023-02-03},
  abstract = {Many machine learning tasks such as multiple instance learning, 3D shape recognition, and few-shot image classification are defined on sets of instances. Since solutions to such problems do not depend on the order of elements of the set, models used to address them should be permutation invariant. We present an attention-based neural network module, the Set Transformer, specifically designed to model interactions among elements in the input set. The model consists of an encoder and a decoder, both of which rely on attention mechanisms. In an effort to reduce computational complexity, we introduce an attention scheme inspired by inducing point methods from sparse Gaussian process literature. It reduces the computation time of self-attention from quadratic to linear in the number of elements in the set. We show that our model is theoretically attractive and we evaluate it on a range of tasks, demonstrating the state-of-the-art performance compared to recent methods for set-structured data.},
  eventtitle = {International {{Conference}} on {{Machine Learning}}},
  langid = {english},
  file = {/Users/michaelvolk/Zotero/storage/MR7FRVSB/Lee et al. - 2019 - Set Transformer A Framework for Attention-based P.pdf;/Users/michaelvolk/Zotero/storage/ZTFESGW3/Lee et al_2019_Set Transformer.pdf}
}

@article{leonelliRethinkingOrganismsImpact2012a,
  title = {Re-Thinking Organisms: {{The}} Impact of Databases on Model Organism Biology},
  shorttitle = {Re-Thinking Organisms},
  author = {Leonelli, Sabina and Ankeny, Rachel A.},
  date = {2012-03},
  journaltitle = {Studies in History and Philosophy of Science Part C: Studies in History and Philosophy of Biological and Biomedical Sciences},
  shortjournal = {Studies in History and Philosophy of Science Part C: Studies in History and Philosophy of Biological and Biomedical Sciences},
  volume = {43},
  number = {1},
  pages = {29--36},
  issn = {13698486},
  doi = {10.1016/j.shpsc.2011.10.003},
  url = {https://linkinghub.elsevier.com/retrieve/pii/S1369848611000793},
  urldate = {2023-11-26},
  abstract = {Community databases have become crucial to the collection, ordering and retrieval of data gathered on model organisms, as well as to the ways in which these data are interpreted and used across a range of research contexts. This paper analyses the impact of community databases on research practices in model organism biology by focusing on the history and current use of four community databases: FlyBase, Mouse Genome Informatics, WormBase and The Arabidopsis Information Resource. We discuss the standards used by the curators of these databases for what counts as reliable evidence, acceptable terminology, appropriate experimental set-ups and adequate materials (e.g., specimens). On the one hand, these choices are informed by the collaborative research ethos characterising most model organism communities. On the other hand, the deployment of these standards in databases reinforces this ethos and gives it concrete and precise instantiations by shaping the skills, practices, values and background knowledge required of the database users. We conclude that the increasing reliance on community databases as vehicles to circulate data is having a major impact on how researchers conduct and communicate their research, which affects how they understand the biology of model organisms and its relation to the biology of other species.},
  langid = {english},
  annotation = {120 citations (Semantic Scholar/DOI) [2023-11-25]},
  file = {/Users/michaelvolk/Zotero/storage/KMEV3GX7/Leonelli and Ankeny - 2012 - Re-thinking organisms The impact of databases on .pdf}
}

@article{liBayesianGenomeScale2021,
  title = {Bayesian Genome Scale Modelling Identifies Thermal Determinants of Yeast Metabolism},
  author = {Li, Gang and Hu, Yating and {Jan Zrimec} and Luo, Hao and Wang, Hao and Zelezniak, Aleksej and Ji, Boyang and Nielsen, Jens},
  date = {2021-01-08},
  journaltitle = {Nature Communications},
  shortjournal = {Nat Commun},
  volume = {12},
  number = {1},
  pages = {190},
  publisher = {Nature Publishing Group},
  issn = {2041-1723},
  doi = {10.1038/s41467-020-20338-2},
  url = {https://www.nature.com/articles/s41467-020-20338-2},
  urldate = {2023-11-02},
  abstract = {The molecular basis of how temperature affects cell metabolism has been a long-standing question in biology, where the main obstacles are the lack of high-quality data and methods to associate temperature effects on the function of individual proteins as well as to combine them at a systems level. Here we develop and apply a Bayesian modeling approach to resolve the temperature effects in genome scale metabolic models (GEM). The approach minimizes uncertainties in enzymatic thermal parameters and greatly improves the predictive strength of the GEMs. The resulting temperature constrained yeast GEM uncovers enzymes that limit growth at superoptimal temperatures, and squalene epoxidase (ERG1) is predicted to be the most rate limiting. By replacing this single key enzyme with an ortholog from a thermotolerant yeast strain, we obtain a thermotolerant strain that outgrows the wild type, demonstrating the critical role of sterol metabolism in yeast thermosensitivity. Therefore, apart from identifying thermal determinants of cell metabolism and enabling the design of thermotolerant strains, our Bayesian GEM approach facilitates modelling of complex biological systems in the absence of high-quality data and therefore shows promise for becoming a standard tool for genome scale modeling.},
  issue = {1},
  langid = {english},
  keywords = {Bayesian inference,Computational models,Machine learning},
  annotation = {6 citations (Semantic Scholar/DOI) [2023-11-02]},
  file = {/Users/michaelvolk/Zotero/storage/SUFK8Y7M/Li et al_2021_Bayesian genome scale modelling identifies thermal determinants of yeast.pdf}
}

@article{ligetiProkBERTFamilyGenomic2024,
  title = {{{ProkBERT}} Family: Genomic Language Models for Microbiome Applications},
  shorttitle = {{{ProkBERT}} Family},
  author = {Ligeti, Balázs and Szepesi-Nagy, István and Bodnár, Babett and Ligeti-Nagy, Noémi and Juhász, János},
  date = {2024-01-12},
  journaltitle = {Frontiers in Microbiology},
  shortjournal = {Front. Microbiol.},
  volume = {14},
  publisher = {Frontiers},
  issn = {1664-302X},
  doi = {10.3389/fmicb.2023.1331233},
  url = {https://www.frontiersin.org/journals/microbiology/articles/10.3389/fmicb.2023.1331233/full},
  urldate = {2024-03-31},
  abstract = {{$<$}sec{$><$}title{$>$}Background{$<$}/title{$><$}p{$>$}In the evolving landscape of microbiology and microbiome analysis, the integration of machine learning is crucial for understanding complex microbial interactions, and predicting and recognizing novel functionalities within extensive datasets. However, the effectiveness of these methods in microbiology faces challenges due to the complex and heterogeneous nature of microbial data, further complicated by low signal-to-noise ratios, context-dependency, and a significant shortage of appropriately labeled datasets. This study introduces the ProkBERT model family, a collection of large language models, designed for genomic tasks. It provides a generalizable sequence representation for nucleotide sequences, learned from unlabeled genome data. This approach helps overcome the above-mentioned limitations in the field, thereby improving our understanding of microbial ecosystems and their impact on health and disease.{$<$}/p{$><$}/sec{$><$}sec{$><$}title{$>$}Methods{$<$}/title{$><$}p{$>$}ProkBERT models are based on transfer learning and self-supervised methodologies, enabling them to use the abundant yet complex microbial data effectively. The introduction of the novel Local Context-Aware (LCA) tokenization technique marks a significant advancement, allowing ProkBERT to overcome the contextual limitations of traditional transformer models. This methodology not only retains rich local context but also demonstrates remarkable adaptability across various bioinformatics tasks.{$<$}/p{$><$}/sec{$><$}sec{$><$}title{$>$}Results{$<$}/title{$><$}p{$>$}In practical applications such as promoter prediction and phage identification, the ProkBERT models show superior performance. For promoter prediction tasks, the top-performing model achieved a Matthews Correlation Coefficient (MCC) of 0.74 for {$<$}italic{$>$}E. coli{$<$}/italic{$>$} and 0.62 in mixed-species contexts. In phage identification, ProkBERT models consistently outperformed established tools like VirSorter2 and DeepVirFinder, achieving an MCC of 0.85. These results underscore the models' exceptional accuracy and generalizability in both supervised and unsupervised tasks.{$<$}/p{$><$}/sec{$><$}sec{$><$}title{$>$}Conclusions{$<$}/title{$><$}p{$>$}The ProkBERT model family is a compact yet powerful tool in the field of microbiology and bioinformatics. Its capacity for rapid, accurate analyses and its adaptability across a spectrum of tasks marks a significant advancement in machine learning applications in microbiology. The models are available on GitHub ({$<$}ext-link ext-link-type="uri" xlink:href="https://github.com/nbrg-ppcu/prokbert" xmlns:xlink="http://www.w3.org/1999/xlink"{$>$}https://github.com/nbrg-ppcu/prokbert{$<$}/ext-link{$>$}) and HuggingFace ({$<$}ext-link ext-link-type="uri" xlink:href="https://huggingface.co/nerualbioinfo" xmlns:xlink="http://www.w3.org/1999/xlink"{$>$}https://huggingface.co/nerualbioinfo{$<$}/ext-link{$>$}) providing an accessible tool for the community.{$<$}/p{$><$}/sec{$>$}},
  langid = {english},
  keywords = {BERT,genomic language models,Language models,LCA tokenization,machine learning in microbiology,Phage,Promoter,Transformer models},
  annotation = {0 citations (Semantic Scholar/DOI) [2024-03-30]},
  file = {/Users/michaelvolk/Zotero/storage/XSZ7URU2/Ligeti et al_2024_ProkBERT family.pdf}
}

@article{liGraphRepresentationLearning2022,
  title = {Graph Representation Learning in Biomedicine and Healthcare},
  author = {Li, Michelle M. and Huang, Kexin and Zitnik, Marinka},
  date = {2022-12},
  journaltitle = {Nature Biomedical Engineering},
  shortjournal = {Nat. Biomed. Eng},
  volume = {6},
  number = {12},
  pages = {1353--1369},
  publisher = {Nature Publishing Group},
  issn = {2157-846X},
  doi = {10.1038/s41551-022-00942-x},
  url = {https://www.nature.com/articles/s41551-022-00942-x},
  urldate = {2023-09-10},
  abstract = {Networks—or graphs—are universal descriptors of systems of interacting elements. In biomedicine and healthcare, they can represent, for example, molecular interactions, signalling pathways, disease co-morbidities or healthcare systems. In this Perspective, we posit that representation learning can realize principles of network medicine, discuss successes and current limitations of the use of representation learning on graphs in biomedicine and healthcare, and outline algorithmic strategies that leverage the topology of graphs to embed them into compact vectorial spaces. We argue that graph representation learning will keep pushing forward machine learning for biomedicine and healthcare applications, including the identification of genetic variants underlying complex traits, the disentanglement of single-cell behaviours and their effects on health, the assistance of patients in diagnosis and treatment, and the development of safe and effective medicines.},
  issue = {12},
  langid = {english},
  keywords = {Health care,Machine learning,Molecular medicine,Network topology,Systems biology},
  annotation = {58 citations (Semantic Scholar/DOI) [2023-09-10]},
  file = {/Users/michaelvolk/Zotero/storage/GHNRYF57/Li et al_2022_Graph representation learning in biomedicine and healthcare.pdf}
}

@online{liHyperbandNovelBanditBased2018,
  title = {Hyperband: {{A Novel Bandit-Based Approach}} to {{Hyperparameter Optimization}}},
  shorttitle = {Hyperband},
  author = {Li, Lisha and Jamieson, Kevin and DeSalvo, Giulia and Rostamizadeh, Afshin and Talwalkar, Ameet},
  date = {2018-06-18},
  eprint = {1603.06560},
  eprinttype = {arXiv},
  eprintclass = {cs, stat},
  doi = {10.48550/arXiv.1603.06560},
  url = {http://arxiv.org/abs/1603.06560},
  urldate = {2024-03-27},
  abstract = {Performance of machine learning algorithms depends critically on identifying a good set of hyperparameters. While recent approaches use Bayesian optimization to adaptively select configurations, we focus on speeding up random search through adaptive resource allocation and early-stopping. We formulate hyperparameter optimization as a pure-exploration non-stochastic infinite-armed bandit problem where a predefined resource like iterations, data samples, or features is allocated to randomly sampled configurations. We introduce a novel algorithm, Hyperband, for this framework and analyze its theoretical properties, providing several desirable guarantees. Furthermore, we compare Hyperband with popular Bayesian optimization methods on a suite of hyperparameter optimization problems. We observe that Hyperband can provide over an order-of-magnitude speedup over our competitor set on a variety of deep-learning and kernel-based learning problems.},
  pubstate = {prepublished},
  keywords = {Computer Science - Machine Learning,Statistics - Machine Learning},
  annotation = {1837 citations (Semantic Scholar/arXiv) [2024-03-27]},
  file = {/Users/michaelvolk/Zotero/storage/5VHMU395/Li et al_2018_Hyperband.pdf;/Users/michaelvolk/Zotero/storage/6VGGKS62/1603.html}
}

@article{liImprovingRecombinantProtein2022a,
  title = {Improving Recombinant Protein Production by Yeast through Genome-Scale Modeling Using Proteome Constraints},
  author = {Li, Feiran and Chen, Yu and Qi, Qi and Wang, Yanyan and Yuan, Le and Huang, Mingtao and Elsemman, Ibrahim E. and Feizi, Amir and Kerkhoven, Eduard J. and Nielsen, Jens},
  date = {2022-05-27},
  journaltitle = {Nature Communications},
  shortjournal = {Nat Commun},
  volume = {13},
  number = {1},
  pages = {2969},
  publisher = {Nature Publishing Group},
  issn = {2041-1723},
  doi = {10.1038/s41467-022-30689-7},
  url = {https://www.nature.com/articles/s41467-022-30689-7},
  urldate = {2024-08-07},
  abstract = {Eukaryotic cells are used as cell factories to produce and secrete multitudes of recombinant pharmaceutical proteins, including several of the current top-selling drugs. Due to the essential role and complexity of the secretory pathway, improvement for recombinant protein production through metabolic engineering has traditionally been relatively ad-hoc; and a more systematic approach is required to generate novel design principles. Here, we present the proteome-constrained genome-scale protein secretory model of yeast Saccharomyces cerevisiae (pcSecYeast), which enables us to simulate and explain phenotypes caused by limited secretory capacity. We further apply the pcSecYeast model to predict overexpression targets for the production of several recombinant proteins. We experimentally validate many of the predicted targets for α-amylase production to demonstrate pcSecYeast application as a computational tool in guiding yeast engineering and improving recombinant protein production.},
  langid = {english},
  keywords = {Applied microbiology,Computer modelling,Metabolic engineering,Protein folding},
  annotation = {27 citations (Semantic Scholar/DOI) [2024-08-06]},
  file = {/Users/michaelvolk/Zotero/storage/9YSHZMN6/Li et al_2022_Improving recombinant protein production by yeast through genome-scale modeling.pdf}
}

@article{liInferringTranscriptionFactor2022,
  title = {Inferring Transcription Factor Regulatory Networks from Single-Cell {{ATAC-seq}} Data Based on Graph Neural Networks},
  author = {Li, Hao and Sun, Yu and Hong, Hao and Huang, Xin and Tao, Huan and Huang, Qiya and Wang, Longteng and Xu, Kang and Gan, Jingbo and Chen, Hebing and Bo, Xiaochen},
  date = {2022-04},
  journaltitle = {Nature Machine Intelligence},
  shortjournal = {Nat Mach Intell},
  volume = {4},
  number = {4},
  pages = {389--400},
  publisher = {Nature Publishing Group},
  issn = {2522-5839},
  doi = {10.1038/s42256-022-00469-5},
  url = {https://www.nature.com/articles/s42256-022-00469-5},
  urldate = {2022-06-03},
  abstract = {Sequence-specific transcription factors (TFs) are the key effectors of eukaryotic gene control and they regulate hundreds to thousands of downstream genes. Of particular interest are interactions in which a given TF regulates other TFs; these interactions define the TF regulatory networks (TRNs) that underlie cellular identity and major function. Chromatin accessibility depicts whether or not a DNA sequence is physically accessible and provides a direct measurement of transcriptional regulation. Benefiting from the accumulating chromatin accessibility data and deep learning advances, we developed a new computational method named DeepTFni to infer TRNs from the single-cell assay for transposase-accessible chromatin using sequencing (scATAC-seq) data. By implementing a graph neural network, which is more suitable for network representation, DeepTFni shows outstanding performance in TRN inference, which it supports with limited numbers of cells. Furthermore, by applying DeepTFni we identified hub TFs in tissue development and tumorigenesis and revealed that many mixed-phenotype acute leukemia associated genes undergo a prominent alteration to the TRN while there is moderate difference in messenger RNA level. The DeepTFni webserver is easy to use and has provided the predicted TRNs for several popular cell lines.},
  issue = {4},
  langid = {english},
  keywords = {☁️,📚,🦌,Gene regulatory networks,Machine learning},
  annotation = {3 citations (Semantic Scholar/DOI) [2022-11-26]},
  file = {/Users/michaelvolk/Zotero/storage/M5IM42NH/Li et al_2022_Inferring transcription factor regulatory networks from single-cell ATAC-seq.pdf;/Users/michaelvolk/Zotero/storage/2G83ZAQX/s42256-022-00469-5.html}
}

@online{liLeveragingLargeLanguage2024,
  title = {Leveraging Large Language Models for Metabolic Engineering Design},
  author = {Li, Xiongwen and Liang, Zhu and Guo, Zhetao and Liu, Ziyi and Wu, Ke and Luo, Jiahao and Zhang, Yuesheng and Liu, Lizheng and Sun, Manda and Huang, Yuanyuan and Tang, Hongting and Chen, Yu and Yu, Tao and Nielsen, Jens and Li, Feiran},
  date = {2024-09-13},
  eprinttype = {bioRxiv},
  eprintclass = {New Results},
  pages = {2024.09.09.612023},
  doi = {10.1101/2024.09.09.612023},
  url = {https://www.biorxiv.org/content/10.1101/2024.09.09.612023v1},
  urldate = {2024-12-02},
  abstract = {Establishing efficient cell factories involves a continuous process of trial and error due to the intricate nature of metabolism. This complexity makes predicting effective engineering targets a challenging task. Therefore, it is vital to learn from the accumulated successes of previous designs for advancing future cell factory development. In this study, we developed a method based on large language models (LLMs) to extract metabolic engineering strategies from research articles on a large scale. We created a database containing over 29006 metabolic engineering entries, 1210 products and 751 organisms. Using this extracted data, we trained a hybrid model combining deep learning and mechanistic approaches to predict engineering targets. Our model outperformed traditional metabolic engineering target prediction algorithms, excelled in predicting the effects of gene modifications, and generalized well to out-of-distribution products and multiple gene combinations. Our study provides a valuable dataset, a chatbot, and an engineering target prediction model for the metabolic engineering field and exemplifies an efficient method for leveraging existing knowledge for future predictions.},
  langid = {english},
  pubstate = {prepublished},
  keywords = {🦌✅},
  annotation = {0 citations (Semantic Scholar/DOI) [2024-12-02]},
  file = {/Users/michaelvolk/Zotero/storage/CGTXN2I2/20B090C5-FEC9-4D43-B030-B05F6D7D03F4.jpeg;/Users/michaelvolk/Zotero/storage/HWSMRLJG/Li et al_2024_Leveraging large language models for metabolic engineering design.pdf;/Users/michaelvolk/Zotero/storage/LMT63YE9/SI - Li et al. - 2024 - Leveraging large language models for metabolic eng.pdf}
}

@article{liModelingGeneInteractions2025,
  title = {Modeling Gene Interactions in Polygenic Prediction via Geometric Deep Learning},
  author = {Li, Han and Zeng, Jianyang and Snyder, Michael P. and Zhang, Sai},
  date = {2025-01-22},
  journaltitle = {Genome Research},
  shortjournal = {Genome Res},
  volume = {35},
  number = {1},
  eprint = {39562137},
  eprinttype = {pmid},
  pages = {178--187},
  issn = {1549-5469},
  doi = {10.1101/gr.279694.124},
  abstract = {Polygenic risk score (PRS) is a widely used approach for predicting individuals' genetic risk of complex diseases, playing a pivotal role in advancing precision medicine. Traditional PRS methods, predominantly following a linear structure, often fall short in capturing the intricate relationships between genotype and phenotype. In this study, we present PRS-Net, an interpretable geometric deep learning-based framework that effectively models the nonlinearity of biological systems for enhanced disease prediction and biological discovery. PRS-Net begins by deconvoluting the genome-wide PRS at the single-gene resolution and then explicitly encapsulates gene-gene interactions leveraging a graph neural network (GNN) for genetic risk prediction, enabling a systematic characterization of molecular interplay underpinning diseases. An attentive readout module is introduced to facilitate model interpretation. Extensive tests across multiple complex traits and diseases demonstrate the superior prediction performance of PRS-Net compared with a wide range of conventional PRS methods. The interpretability of PRS-Net further enhances the identification of disease-relevant genes and gene programs. PRS-Net provides a potent tool for concurrent genetic risk prediction and biological discovery for complex diseases.},
  langid = {english},
  pmcid = {PMC11789630},
  keywords = {Deep Learning,Epistasis Genetic,Genetic Predisposition to Disease,Genome-Wide Association Study,Humans,Models Genetic,Multifactorial Inheritance,Neural Networks Computer},
  annotation = {0 citations (Semantic Scholar/DOI) [2025-03-28]},
  file = {/Users/michaelvolk/Zotero/storage/VRWDI6KW/Li et al_2025_Modeling gene interactions in polygenic prediction via geometric deep learning.pdf}
}

@online{linEvolutionaryscalePredictionAtomic2022,
  title = {Evolutionary-Scale Prediction of Atomic Level Protein Structure with a Language Model},
  author = {Lin, Zeming and Akin, Halil and Rao, Roshan and Hie, Brian and Zhu, Zhongkai and Lu, Wenting and Smetanin, Nikita and Verkuil, Robert and Kabeli, Ori and Shmueli, Yaniv and Costa, Allan dos Santos and Fazel-Zarandi, Maryam and Sercu, Tom and Candido, Salvatore and Rives, Alexander},
  date = {2022-10-31},
  eprinttype = {bioRxiv},
  eprintclass = {New Results},
  pages = {2022.07.20.500902},
  doi = {10.1101/2022.07.20.500902},
  url = {https://www.biorxiv.org/content/10.1101/2022.07.20.500902v2},
  urldate = {2024-04-03},
  abstract = {Artificial intelligence has the potential to open insight into the structure of proteins at the scale of evolution. It has only recently been possible to extend protein structure prediction to two hundred million cataloged proteins. Characterizing the structures of the exponentially growing billions of protein sequences revealed by large scale gene sequencing experiments would necessitate a breakthrough in the speed of folding. Here we show that direct inference of structure from primary sequence using a large language model enables an order of magnitude speed-up in high resolution structure prediction. Leveraging the insight that language models learn evolutionary patterns across millions of sequences, we train models up to 15B parameters, the largest language model of proteins to date. As the language models are scaled they learn information that enables prediction of the three-dimensional structure of a protein at the resolution of individual atoms. This results in prediction that is up to 60x faster than state-of-the-art while maintaining resolution and accuracy. Building on this, we present the ESM Metagenomic Atlas. This is the first large-scale structural characterization of metagenomic proteins, with more than 617 million structures. The atlas reveals more than 225 million high confidence predictions, including millions whose structures are novel in comparison with experimentally determined structures, giving an unprecedented view into the vast breadth and diversity of the structures of some of the least understood proteins on earth.},
  langid = {english},
  pubstate = {prepublished},
  file = {/Users/michaelvolk/Zotero/storage/FD7RAB5R/Lin et al_2022_Evolutionary-scale prediction of atomic level protein structure with a language.pdf}
}

@online{linLanguageModelsProtein2022,
  title = {Language Models of Protein Sequences at the Scale of Evolution Enable Accurate Structure Prediction},
  author = {Lin, Zeming and Akin, Halil and Rao, Roshan and Hie, Brian and Zhu, Zhongkai and Lu, Wenting and Costa, Allan dos Santos and Fazel-Zarandi, Maryam and Sercu, Tom and Candido, Sal and Rives, Alexander},
  date = {2022-07-21},
  eprinttype = {bioRxiv},
  eprintclass = {New Results},
  pages = {2022.07.20.500902},
  doi = {10.1101/2022.07.20.500902},
  url = {https://www.biorxiv.org/content/10.1101/2022.07.20.500902v1},
  urldate = {2023-11-30},
  abstract = {Large language models have recently been shown to develop emergent capabilities with scale, going beyond simple pattern matching to perform higher level reasoning and generate lifelike images and text. While language models trained on protein sequences have been studied at a smaller scale, little is known about what they learn about biology as they are scaled up. In this work we train models up to 15 billion parameters, the largest language models of proteins to be evaluated to date. We find that as models are scaled they learn information enabling the prediction of the three-dimensional structure of a protein at the resolution of individual atoms. We present ESMFold for high accuracy end-to-end atomic level structure prediction directly from the individual sequence of a protein. ESMFold has similar accuracy to AlphaFold2 and RoseTTAFold for sequences with low perplexity that are well understood by the language model. ESMFold inference is an order of magnitude faster than AlphaFold2, enabling exploration of the structural space of metagenomic proteins in practical timescales.},
  langid = {english},
  pubstate = {prepublished},
  file = {/Users/michaelvolk/Zotero/storage/Z3LP8L9K/Lin et al. - 2022 - Language models of protein sequences at the scale .pdf}
}

@article{liRecentAdvancesChallenges2024,
  title = {Recent Advances and Challenges in Single Cell Protein ({{SCP}}) Technologies for Food and Feed Production},
  author = {Li, Yu Pin and Ahmadi, Fatemeh and Kariman, Khalil and Lackner, Maximilian},
  date = {2024-09-18},
  journaltitle = {npj Science of Food},
  shortjournal = {npj Sci Food},
  volume = {8},
  number = {1},
  pages = {66},
  publisher = {Nature Publishing Group},
  issn = {2396-8370},
  doi = {10.1038/s41538-024-00299-2},
  url = {https://www.nature.com/articles/s41538-024-00299-2},
  urldate = {2025-02-27},
  abstract = {The global population is increasing, with a predicted demand for 1250 million tonnes of animal-derived protein by 2050, which will be difficult to meet. Single-cell protein (SCP) offers a sustainable solution. This review covers SCP production mechanisms, microbial and substrate choices, and advancements in metabolic engineering and CRISPR-Cas. It emphasizes second-generation substrates and fermentation for a circular economy. Despite challenges like high nucleic acid content, SCP promises to solve the global nutrition problem.},
  langid = {english},
  keywords = {Environmental impact,Protein delivery},
  annotation = {7 citations (Semantic Scholar/DOI) [2025-02-27]},
  file = {/Users/michaelvolk/Zotero/storage/UNTXHJ2E/Li et al_2024_Recent advances and challenges in single cell protein (SCP) technologies for.pdf}
}

@online{liuAdvancingGraphConvolutional2024,
  title = {Advancing {{Graph Convolutional Networks}} via {{General Spectral Wavelets}}},
  author = {Liu, Nian and He, Xiaoxin and Laurent, Thomas and Giovanni, Francesco Di and Bronstein, Michael M. and Bresson, Xavier},
  date = {2024-05-22},
  eprint = {2405.13806},
  eprinttype = {arXiv},
  eprintclass = {cs},
  doi = {10.48550/arXiv.2405.13806},
  url = {http://arxiv.org/abs/2405.13806},
  urldate = {2025-02-27},
  abstract = {Spectral graph convolution, an important tool of data filtering on graphs, relies on two essential decisions; selecting spectral bases for signal transformation and parameterizing the kernel for frequency analysis. While recent techniques mainly focus on standard Fourier transform and vector-valued spectral functions, they fall short in flexibility to describe specific signal distribution for each node, and expressivity of spectral function. In this paper, we present a novel wavelet-based graph convolution network, namely WaveGC, which integrates multi-resolution spectral bases and a matrix-valued filter kernel. Theoretically, we establish that WaveGC can effectively capture and decouple short-range and long-range information, providing superior filtering flexibility, surpassing existing graph convolutional networks and graph Transformers (GTs). To instantiate WaveGC, we introduce a novel technique for learning general graph wavelets by separately combining odd and even terms of Chebyshev polynomials. This approach strictly satisfies wavelet admissibility criteria. Our numerical experiments showcase the capabilities of the new network. By replacing the Transformer part in existing architectures with WaveGC, we consistently observe improvements in both short-range and long-range tasks. This underscores the effectiveness of the proposed model in handling different scenarios. Our code is available at https://github.com/liun-online/WaveGC.},
  pubstate = {prepublished},
  keywords = {Computer Science - Machine Learning},
  annotation = {1 citations (Semantic Scholar/arXiv) [2025-02-27]\\
1 citations (Semantic Scholar/DOI) [2025-02-27]},
  file = {/Users/michaelvolk/Zotero/storage/YDKMN5PX/Liu et al_2024_Advancing Graph Convolutional Networks via General Spectral Wavelets.pdf;/Users/michaelvolk/Zotero/storage/SWPRZQ2P/2405.html}
}

@online{liuComplexFractalTrainability2024a,
  title = {Complex Fractal Trainability Boundary Can Arise from Trivial Non-Convexity},
  author = {Liu, Yizhou},
  date = {2024-06-19},
  eprint = {2406.13971},
  eprinttype = {arXiv},
  eprintclass = {nlin},
  doi = {10.48550/arXiv.2406.13971},
  url = {http://arxiv.org/abs/2406.13971},
  urldate = {2024-07-04},
  abstract = {Training neural networks involves optimizing parameters to minimize a loss function, where the nature of the loss function and the optimization strategy are crucial for effective training. Hyperparameter choices, such as the learning rate in gradient descent (GD), significantly affect the success and speed of convergence. Recent studies indicate that the boundary between bounded and divergent hyperparameters can be fractal, complicating reliable hyperparameter selection. However, the nature of this fractal boundary and methods to avoid it remain unclear. In this study, we focus on GD to investigate the loss landscape properties that might lead to fractal trainability boundaries. We discovered that fractal boundaries can emerge from simple non-convex perturbations, i.e., adding or multiplying cosine type perturbations to quadratic functions. The observed fractal dimensions are influenced by factors like parameter dimension, type of non-convexity, perturbation wavelength, and perturbation amplitude. Our analysis identifies "roughness of perturbation", which measures the gradient's sensitivity to parameter changes, as the factor controlling fractal dimensions of trainability boundaries. We observed a clear transition from non-fractal to fractal trainability boundaries as roughness increases, with the critical roughness causing the perturbed loss function non-convex. Thus, we conclude that fractal trainability boundaries can arise from very simple non-convexity. We anticipate that our findings will enhance the understanding of complex behaviors during neural network training, leading to more consistent and predictable training strategies.},
  pubstate = {prepublished},
  keywords = {Computer Science - Machine Learning,Mathematics - Dynamical Systems,Nonlinear Sciences - Chaotic Dynamics},
  annotation = {0 citations (Semantic Scholar/arXiv) [2024-07-04]},
  file = {/Users/michaelvolk/Zotero/storage/58VMIPGU/Liu_2024_Complex fractal trainability boundary can arise from trivial non-convexity.pdf;/Users/michaelvolk/Zotero/storage/XAAGGM2K/2406.html}
}

@article{liuDeepLearningResilience2024,
  title = {Deep Learning Resilience Inference for Complex Networked Systems},
  author = {Liu, Chang and Xu, Fengli and Gao, Chen and Wang, Zhaocheng and Li, Yong and Gao, Jianxi},
  date = {2024-10-24},
  journaltitle = {Nature Communications},
  shortjournal = {Nat Commun},
  volume = {15},
  number = {1},
  pages = {9203},
  publisher = {Nature Publishing Group},
  issn = {2041-1723},
  doi = {10.1038/s41467-024-53303-4},
  url = {https://www.nature.com/articles/s41467-024-53303-4},
  urldate = {2025-02-27},
  abstract = {Resilience, the ability to maintain fundamental functionality amidst failures and errors, is crucial for complex networked systems. Most analytical approaches rely on predefined equations for node activity dynamics and simplifying assumptions on network topology, limiting their applicability to real-world systems. Here, we propose ResInf, a deep learning framework integrating transformers and graph neural networks to infer resilience directly from observational data. ResInf learns representations of node activity dynamics and network topology without simplifying assumptions, enabling accurate resilience inference and low-dimensional visualization. Experimental results show that ResInf significantly outperforms analytical methods, with an F1-score improvement of up to 41.59\% over Gao-Barzel-Barabási framework and 14.32\% over spectral dimension reduction. It also generalizes to unseen topologies and dynamics and maintains robust performance despite observational disturbances. Our findings suggest that ResInf addresses an important gap in resilience inference for real-world systems, offering a fresh perspective on incorporating data-driven approaches to complex network modeling.},
  langid = {english},
  keywords = {Complex networks,Computational science,Computer science,Nonlinear phenomena,Phase transitions and critical phenomena},
  annotation = {2 citations (Semantic Scholar/DOI) [2025-02-27]},
  file = {/Users/michaelvolk/Zotero/storage/PIMX9TLA/Liu et al_2024_Deep learning resilience inference for complex networked systems.pdf}
}

@article{liuEngineeringNovelCelluloseadherent2016,
  title = {Engineering of a Novel Cellulose-Adherent Cellulolytic {{Saccharomyces}} Cerevisiae for Cellulosic Biofuel Production},
  author = {Liu, Zhuo and Ho, Shih-Hsin and Sasaki, Kengo and family=Haan, given=Riaan, prefix=den, useprefix=true and Inokuma, Kentaro and Ogino, Chiaki and family=Zyl, given=Willem H., prefix=van, useprefix=true and Hasunuma, Tomohisa and Kondo, Akihiko},
  date = {2016-04-15},
  journaltitle = {Scientific Reports},
  shortjournal = {Sci Rep},
  volume = {6},
  number = {1},
  pages = {24550},
  publisher = {Nature Publishing Group},
  issn = {2045-2322},
  doi = {10.1038/srep24550},
  url = {https://www.nature.com/articles/srep24550},
  urldate = {2025-02-27},
  abstract = {Cellulosic biofuel is the subject of increasing attention. The main obstacle toward its economic feasibility is the recalcitrance of lignocellulose requiring large amount of enzyme to break. Several engineered yeast strains have been developed with cellulolytic activities to reduce the need for enzyme addition, but exhibiting limited effect. Here, we report the successful engineering of a cellulose-adherent Saccharomyces cerevisiae displaying four different synergistic cellulases on the cell surface. The cellulase-displaying yeast strain exhibited clear cell-to-cellulose adhesion and a “tearing” cellulose degradation pattern; the adhesion ability correlated with enhanced surface area and roughness of the target cellulose fibers, resulting in higher hydrolysis efficiency. The engineered yeast directly produced ethanol from rice straw despite a more than 40\% decrease in the required enzyme dosage for high-density fermentation. Thus, improved cell-to-cellulose interactions provided a novel strategy for increasing cellulose hydrolysis, suggesting a mechanism for promoting the feasibility of cellulosic biofuel production.},
  langid = {english},
  keywords = {Biotechnology,Microbiology},
  annotation = {66 citations (Semantic Scholar/DOI) [2025-02-27]},
  file = {/Users/michaelvolk/Zotero/storage/VUSTGI3T/Liu et al_2016_Engineering of a novel cellulose-adherent cellulolytic Saccharomyces cerevisiae.pdf}
}

@online{liuGraphPoolingGraph2023,
  title = {Graph {{Pooling}} for {{Graph Neural Networks}}: {{Progress}}, {{Challenges}}, and {{Opportunities}}},
  shorttitle = {Graph {{Pooling}} for {{Graph Neural Networks}}},
  author = {Liu, Chuang and Zhan, Yibing and Wu, Jia and Li, Chang and Du, Bo and Hu, Wenbin and Liu, Tongliang and Tao, Dacheng},
  date = {2023-06-22},
  eprint = {2204.07321},
  eprinttype = {arXiv},
  eprintclass = {cs},
  doi = {10.48550/arXiv.2204.07321},
  url = {http://arxiv.org/abs/2204.07321},
  urldate = {2024-09-04},
  abstract = {Graph neural networks have emerged as a leading architecture for many graph-level tasks, such as graph classification and graph generation. As an essential component of the architecture, graph pooling is indispensable for obtaining a holistic graph-level representation of the whole graph. Although a great variety of methods have been proposed in this promising and fast-developing research field, to the best of our knowledge, little effort has been made to systematically summarize these works. To set the stage for the development of future works, in this paper, we attempt to fill this gap by providing a broad review of recent methods for graph pooling. Specifically, 1) we first propose a taxonomy of existing graph pooling methods with a mathematical summary for each category; 2) then, we provide an overview of the libraries related to graph pooling, including the commonly used datasets, model architectures for downstream tasks, and open-source implementations; 3) next, we further outline the applications that incorporate the idea of graph pooling in a variety of domains; 4) finally, we discuss certain critical challenges facing current studies and share our insights on future potential directions for research on the improvement of graph pooling.},
  pubstate = {prepublished},
  keywords = {Computer Science - Machine Learning},
  annotation = {53 citations (Semantic Scholar/arXiv) [2024-09-04]\\
53 citations (Semantic Scholar/DOI) [2024-09-04]},
  file = {/Users/michaelvolk/Zotero/storage/2ZEVUEC9/Liu et al_2023_Graph Pooling for Graph Neural Networks.pdf;/Users/michaelvolk/Zotero/storage/SMB47KDL/2204.html}
}

@online{liuLearningMolecularRepresentation2024,
  title = {Learning {{Molecular Representation}} in a {{Cell}}},
  author = {Liu, Gang and Seal, Srijit and Arevalo, John and Liang, Zhenwen and Carpenter, Anne E. and Jiang, Meng and Singh, Shantanu},
  date = {2024-06-17},
  eprint = {2406.12056},
  eprinttype = {arXiv},
  eprintclass = {cs, q-bio},
  doi = {10.48550/arXiv.2406.12056},
  url = {http://arxiv.org/abs/2406.12056},
  urldate = {2024-06-24},
  abstract = {Predicting drug efficacy and safety in vivo requires information on biological responses (e.g., cell morphology and gene expression) to small molecule perturbations. However, current molecular representation learning methods do not provide a comprehensive view of cell states under these perturbations and struggle to remove noise, hindering model generalization. We introduce the Information Alignment (InfoAlign) approach to learn molecular representations through the information bottleneck method in cells. We integrate molecules and cellular response data as nodes into a context graph, connecting them with weighted edges based on chemical, biological, and computational criteria. For each molecule in a training batch, InfoAlign optimizes the encoder's latent representation with a minimality objective to discard redundant structural information. A sufficiency objective decodes the representation to align with different feature spaces from the molecule's neighborhood in the context graph. We demonstrate that the proposed sufficiency objective for alignment is tighter than existing encoder-based contrastive methods. Empirically, we validate representations from InfoAlign in two downstream tasks: molecular property prediction against up to 19 baseline methods across four datasets, plus zero-shot molecule-morphology matching.},
  pubstate = {prepublished},
  version = {1},
  keywords = {Computer Science - Machine Learning,Quantitative Biology - Quantitative Methods},
  annotation = {0 citations (Semantic Scholar/arXiv) [2024-06-23]},
  file = {/Users/michaelvolk/Zotero/storage/6DIFD3B7/Liu et al_2024_Learning Molecular Representation in a Cell.pdf;/Users/michaelvolk/Zotero/storage/59UX3E49/2406.html}
}

@article{liuVisualizingComplexFeature2019,
  title = {Visualizing Complex Feature Interactions and Feature Sharing in Genomic Deep Neural Networks},
  author = {Liu, Ge and Zeng, Haoyang and Gifford, David K.},
  date = {2019-07-19},
  journaltitle = {BMC Bioinformatics},
  shortjournal = {BMC Bioinformatics},
  volume = {20},
  number = {1},
  pages = {401},
  issn = {1471-2105},
  doi = {10.1186/s12859-019-2957-4},
  url = {https://doi.org/10.1186/s12859-019-2957-4},
  urldate = {2024-09-12},
  abstract = {Visualization tools for deep learning models typically focus on discovering key input features without considering how such low level features are combined in intermediate layers to make decisions. Moreover, many of these methods examine a network’s response to specific input examples that may be insufficient to reveal the complexity of model decision making.},
  keywords = {Combinatorial interactions,Deep neural networks,Visualization},
  annotation = {21 citations (Semantic Scholar/DOI) [2024-09-12]},
  file = {/Users/michaelvolk/Zotero/storage/4XGWX9DQ/Liu et al_2019_Visualizing complex feature interactions and feature sharing in genomic deep.pdf;/Users/michaelvolk/Zotero/storage/PCYCI8EX/s12859-019-2957-4.html}
}

@article{livnatMutationEvolutionConceptual2024,
  title = {Mutation and Evolution: {{Conceptual}} Possibilities},
  shorttitle = {Mutation and Evolution},
  author = {Livnat, Adi and Love, Alan C.},
  date = {2024},
  journaltitle = {BioEssays},
  volume = {46},
  number = {2},
  pages = {2300025},
  issn = {1521-1878},
  doi = {10.1002/bies.202300025},
  url = {https://onlinelibrary.wiley.com/doi/abs/10.1002/bies.202300025},
  urldate = {2024-07-04},
  abstract = {Although random mutation is central to models of evolutionary change, a lack of clarity remains regarding the conceptual possibilities for thinking about the nature and role of mutation in evolution. We distinguish several claims at the intersection of mutation, evolution, and directionality and then characterize a previously unrecognized category: complex conditioned mutation. Empirical evidence in support of this category suggests that the historically famous fluctuation test should be revisited, and new experiments should be undertaken with emerging experimental techniques to facilitate detecting mutation rates within specific loci at an ultra-high, individual base pair resolution.},
  langid = {english},
  keywords = {directed mutation,interaction-based evolution,Lamarckism,modifier theory,random mutation},
  annotation = {0 citations (Semantic Scholar/DOI) [2024-07-04]},
  file = {/Users/michaelvolk/Zotero/storage/HCTLIWA6/Livnat and Love - 2024 - Mutation and evolution Conceptual possibilities.pdf;/Users/michaelvolk/Zotero/storage/RNSFE9ZH/bies.html}
}

@online{lobentanzerDemocratisingKnowledgeRepresentation2023,
  title = {Democratising {{Knowledge Representation}} with {{BioCypher}}},
  author = {Lobentanzer, Sebastian and Aloy, Patrick and Baumbach, Jan and Bohar, Balazs and Charoentong, Pornpimol and Danhauser, Katharina and Doğan, Tunca and Dreo, Johann and Dunham, Ian and Fernandez-Torras, Adrià and Gyori, Benjamin M. and Hartung, Michael and Hoyt, Charles Tapley and Klein, Christoph and Korcsmaros, Tamas and Maier, Andreas and Mann, Matthias and Ochoa, David and Pareja-Lorente, Elena and Popp, Ferdinand and Preusse, Martin and Probul, Niklas and Schwikowski, Benno and Sen, Bünyamin and Strauss, Maximilian T. and Turei, Denes and Ulusoy, Erva and Wodke, Judith Andrea Heidrun and Saez-Rodriguez, Julio},
  date = {2023-01-17},
  eprint = {2212.13543},
  eprinttype = {arXiv},
  eprintclass = {q-bio},
  url = {http://arxiv.org/abs/2212.13543},
  urldate = {2024-03-02},
  abstract = {Standardising the representation of biomedical knowledge among all researchers is an insurmountable task, hindering the effectiveness of many computational methods. To facilitate harmonisation and interoperability despite this fundamental challenge, we propose to standardise the framework of knowledge graph creation instead. We implement this standardisation in BioCypher, a FAIR (findable, accessible, interoperable, reusable) framework to transparently build biomedical knowledge graphs while preserving provenances of the source data. Mapping the knowledge onto biomedical ontologies helps to balance the needs for harmonisation, human and machine readability, and ease of use and accessibility to non-specialist researchers. We demonstrate the usefulness of this framework on a variety of use cases, from maintenance of task-specific knowledge stores, to interoperability between biomedical domains, to on-demand building of task-specific knowledge graphs for federated learning. BioCypher (https://biocypher.org) frees up valuable developer time; we encourage further development and usage by the community.},
  pubstate = {prepublished},
  keywords = {Quantitative Biology - Molecular Networks},
  annotation = {6 citations (Semantic Scholar/arXiv) [2024-03-01]},
  file = {/Users/michaelvolk/Zotero/storage/53MP6Q6U/Lobentanzer et al_2023_Democratising Knowledge Representation with BioCypher.pdf;/Users/michaelvolk/Zotero/storage/PEWVNAMP/2212.html}
}

@article{lobentanzerDemocratizingKnowledgeRepresentation2023,
  title = {Democratizing Knowledge Representation with {{BioCypher}}},
  author = {Lobentanzer, Sebastian and Aloy, Patrick and Baumbach, Jan and Bohar, Balazs and Carey, Vincent J. and Charoentong, Pornpimol and Danhauser, Katharina and Doğan, Tunca and Dreo, Johann and Dunham, Ian and Farr, Elias and Fernandez-Torras, Adrià and Gyori, Benjamin M. and Hartung, Michael and Hoyt, Charles Tapley and Klein, Christoph and Korcsmaros, Tamas and Maier, Andreas and Mann, Matthias and Ochoa, David and Pareja-Lorente, Elena and Popp, Ferdinand and Preusse, Martin and Probul, Niklas and Schwikowski, Benno and Sen, Bünyamin and Strauss, Maximilian T. and Turei, Denes and Ulusoy, Erva and Waltemath, Dagmar and Wodke, Judith A. H. and Saez-Rodriguez, Julio},
  date = {2023-08},
  journaltitle = {Nature Biotechnology},
  shortjournal = {Nat Biotechnol},
  volume = {41},
  number = {8},
  pages = {1056--1059},
  publisher = {Nature Publishing Group},
  issn = {1546-1696},
  doi = {10.1038/s41587-023-01848-y},
  url = {https://www.nature.com/articles/s41587-023-01848-y},
  urldate = {2023-12-13},
  issue = {8},
  langid = {english},
  keywords = {Data integration,Data publication and archiving,Databases,Standards,Translational research},
  annotation = {4 citations (Semantic Scholar/DOI) [2023-12-13]},
  file = {/Users/michaelvolk/Zotero/storage/9W927RFZ/Democratizing knowledge representation with BioCypher.pdf}
}

@article{lobentanzerMolecularCausalityAdvent2024,
  title = {Molecular Causality in the Advent of Foundation Models},
  author = {Lobentanzer, Sebastian and Rodriguez-Mier, Pablo and Bauer, Stefan and Saez-Rodriguez, Julio},
  date = {2024-08-02},
  journaltitle = {Molecular Systems Biology},
  volume = {20},
  number = {8},
  pages = {848--858},
  publisher = {John Wiley \& Sons, Ltd},
  issn = {1744-4292},
  doi = {10.1038/s44320-024-00041-w},
  url = {https://www.embopress.org/doi/full/10.1038/s44320-024-00041-w},
  urldate = {2024-09-13},
  abstract = {Correlation is not causation: this simple and uncontroversial statement has far-reaching implications. Defining and applying causality in biomedical research has posed significant challenges to the scientific community. In this perspective, we attempt to connect the partly disparate fields of systems biology, causal reasoning, and machine learning to inform future approaches in the field of systems biology and molecular medicine.},
  pagetotal = {858},
  keywords = {Causality,Foundation Models,Inductive Bias,Latent Spaces,Systems Biology},
  annotation = {2 citations (Semantic Scholar/DOI) [2024-09-13]},
  file = {/Users/michaelvolk/Zotero/storage/REEGN575/Lobentanzer et al_2024_Molecular causality in the advent of foundation models.pdf}
}

@online{lobentanzerPlatformBiomedicalApplication2023,
  title = {A {{Platform}} for the {{Biomedical Application}} of {{Large Language Models}}},
  author = {Lobentanzer, Sebastian and Saez-Rodriguez, Julio},
  date = {2023-07-21},
  eprint = {2305.06488},
  eprinttype = {arXiv},
  eprintclass = {q-bio},
  doi = {10.48550/arXiv.2305.06488},
  url = {http://arxiv.org/abs/2305.06488},
  urldate = {2024-01-08},
  abstract = {The wealth of knowledge we have amassed in the context of biomedical science has grown exponentially in the last decades. Consequently, understanding and contextualising scientific results has become increasingly difficult for any single individual. In contrast, current Large Language Models (LLMs) can remember an enormous amount of information, but have notable shortcomings, such as a lack of generalised awareness, logical deficits, and a propensity to hallucinate. To improve biomedical analyses, we propose to combine human ingenuity and machine memory by means of an open and modular conversational platform, biochatter (https://github.com/biocypher/biochatter), exemplified in the web application ChatGSE (https://chat.biocypher.org). We safeguard against common LLM shortcomings using general and biomedicine-specific measures and allow automated integration of popular bioinformatics methods. Ultimately, we aim to improve the AI-readiness of biomedicine and make LLMs more useful and trustworthy in research applications.},
  pubstate = {prepublished},
  keywords = {Quantitative Biology - Quantitative Methods},
  annotation = {2 citations (Semantic Scholar/arXiv) [2024-01-08]},
  file = {/Users/michaelvolk/Zotero/storage/8XG6HXQK/Lobentanzer_Saez-Rodriguez_2023_A Platform for the Biomedical Application of Large Language Models.pdf;/Users/michaelvolk/Zotero/storage/PQHTXVR4/2305.html}
}

@article{longRobustYeastChassis2024,
  title = {A Robust Yeast Chassis: Comprehensive Characterization of a Fast-Growing {{Saccharomyces}} Cerevisiae},
  shorttitle = {A Robust Yeast Chassis},
  author = {Long, Yangdanyu and Han, Xiao and Meng, Xuanlin and Xu, Ping and Tao, Fei},
  date = {2024-01-12},
  journaltitle = {mBio},
  volume = {15},
  number = {2},
  pages = {e03196-23},
  publisher = {American Society for Microbiology},
  doi = {10.1128/mbio.03196-23},
  url = {https://journals.asm.org/doi/10.1128/mbio.03196-23},
  urldate = {2024-08-09},
  annotation = {1 citations (Semantic Scholar/DOI) [2024-08-09]},
  file = {/Users/michaelvolk/Zotero/storage/XS3H34XW/Long et al_2024_A robust yeast chassis.pdf}
}

@article{louieCategoricalSystemTheory1983,
  title = {Categorical System Theory},
  author = {Louie, A. H.},
  date = {1983-01-01},
  journaltitle = {Bulletin of Mathematical Biology},
  shortjournal = {Bulletin of Mathematical Biology},
  volume = {45},
  number = {6},
  pages = {1047--1072},
  issn = {0092-8240},
  doi = {10.1016/S0092-8240(83)80077-9},
  url = {https://www.sciencedirect.com/science/article/pii/S0092824083800779},
  urldate = {2024-07-07},
  abstract = {This is an investigation of natural systems from the standpoint of the mathematical theory of categories. It examines the relationships which exist between different descriptions through measurement of observables and dynamical interactions. We begin with a category theory of formal systems with observables, and then proceed to a category theory of dynamical systems. The two categories are then combined to represent natural systems. Topological considerations enter in the study of stability and bifurcation phenomena. Special emphasis is placed on natural systems which model biological processes. The categorical system theory developed is applied to the analysis of several biological problems and biological system theories.},
  annotation = {31 citations (Semantic Scholar/DOI) [2024-07-07]},
  file = {/Users/michaelvolk/Zotero/storage/PNNY6VPP/Louie_1983_Categorical system theory.pdf;/Users/michaelvolk/Zotero/storage/D8M695NS/S0092824083800779.html}
}

@article{luoDeepGraphLevel2022,
  title = {Deep Graph Level Anomaly Detection with Contrastive Learning},
  author = {Luo, Xuexiong and Wu, Jia and Yang, Jian and Xue, Shan and Peng, Hao and Zhou, Chuan and Chen, Hongyang and Li, Zhao and Sheng, Quan Z.},
  date = {2022-11-18},
  journaltitle = {Scientific Reports},
  shortjournal = {Sci Rep},
  volume = {12},
  number = {1},
  pages = {19867},
  publisher = {Nature Publishing Group},
  issn = {2045-2322},
  doi = {10.1038/s41598-022-22086-3},
  url = {https://www.nature.com/articles/s41598-022-22086-3},
  urldate = {2025-02-27},
  abstract = {Graph level anomaly detection (GLAD) aims to spot anomalous graphs that structure pattern and feature information are different from most normal graphs in a graph set, which is rarely studied by other researchers but has significant application value. For instance, GLAD can be used to distinguish some different characteristic molecules in drug discovery and chemical analysis. However, GLAD mainly faces the following three challenges: (1) learning more comprehensive graph level representations to differ normal graphs and abnormal graphs, (2) designing an effective graph anomaly evaluation paradigm to capture graph anomalies from the local and global graph perspectives, (3) overcoming the number imbalance problem of normal and abnormal graphs. In this paper, we combine graph neural networks and contrastive learning to build an end-to-end GLAD framework for solving the three challenges above. We aim to design a new graph level anomaly evaluation way, which first utilizes the contrastive learning strategy to enhance different level representations of normal graphs from node and graph levels by a graph convolution autoencoder with perturbed graph encoder. Then, we evaluate the error of them with corresponding representations of the generated reconstruction graph to detect anomalous graphs. Extensive experiments on ten real-world datasets from three areas, such as molecular, protein and social network anomaly graphs, show that our model can effectively detect graph level anomaly from the majority and outperform existing advanced methods.},
  langid = {english},
  keywords = {Computational science,Computer science,torchcell.contrastive-learning},
  annotation = {28 citations (Semantic Scholar/DOI) [2025-02-27]},
  file = {/Users/michaelvolk/Zotero/storage/M77QB3YZ/Luo et al_2022_Deep graph level anomaly detection with contrastive learning.pdf}
}

@incollection{maGraphAttentionNetworks2021,
  title = {Graph {{Attention Networks}} with {{Positional Embeddings}}},
  booktitle = {Advances in {{Knowledge Discovery}} and {{Data Mining}}},
  author = {Ma, Liheng and Rabbany, Reihaneh and Romero-Soriano, Adriana},
  editor = {Karlapalem, Kamal and Cheng, Hong and Ramakrishnan, Naren and Agrawal, R. K. and Reddy, P. Krishna and Srivastava, Jaideep and Chakraborty, Tanmoy},
  date = {2021},
  volume = {12712},
  pages = {514--527},
  publisher = {Springer International Publishing},
  location = {Cham},
  doi = {10.1007/978-3-030-75762-5_41},
  url = {https://link.springer.com/10.1007/978-3-030-75762-5_41},
  urldate = {2023-10-13},
  abstract = {Graph Neural Networks (GNNs) are deep learning methods which provide the current state of the art performance in node classification tasks. GNNs often assume homophily – neighboring nodes having similar features and labels–, and therefore may not be at their full potential when dealing with non-homophilic graphs. In this work, we focus on addressing this limitation and enable Graph Attention Networks (GAT), a commonly used variant of GNNs, to explore the structural information within each graph locality. Inspired by the positional encoding in the Transformers, we propose a framework, termed Graph Attentional Networks with Positional Embeddings (GAT-POS), to enhance GATs with positional embeddings which capture structural and positional information of the nodes in the graph. In this framework, the positional embeddings are learned by a model predictive of the graph context, plugged into an enhanced GAT architecture, which is able to leverage both the positional and content information of each node. The model is trained jointly to optimize for the task of node classification as well as the task of predicting graph context. Experimental results show that GAT-POS reaches remarkable improvement compared to strong GNN baselines and recent structural embedding enhanced GNNs on non-homophilic graphs.},
  isbn = {978-3-030-75761-8 978-3-030-75762-5},
  langid = {english},
  file = {/Users/michaelvolk/Zotero/storage/XVKXQDPE/Ma et al. - 2021 - Graph Attention Networks with Positional Embedding.pdf}
}

@inproceedings{maGraphlevelAnomalyDetection2023,
  title = {Towards {{Graph-level Anomaly Detection}} via {{Deep Evolutionary Mapping}}},
  booktitle = {Proceedings of the 29th {{ACM SIGKDD Conference}} on {{Knowledge Discovery}} and {{Data Mining}}},
  author = {Ma, Xiaoxiao and Wu, Jia and Yang, Jian and Sheng, Quan Z.},
  date = {2023-08-06},
  pages = {1631--1642},
  publisher = {ACM},
  location = {Long Beach CA USA},
  doi = {10.1145/3580305.3599524},
  url = {https://dl.acm.org/doi/10.1145/3580305.3599524},
  urldate = {2024-06-15},
  eventtitle = {{{KDD}} '23: {{The}} 29th {{ACM SIGKDD Conference}} on {{Knowledge Discovery}} and {{Data Mining}}},
  isbn = {9798400701030},
  langid = {english},
  annotation = {7 citations (Semantic Scholar/DOI) [2024-06-20]},
  file = {/Users/michaelvolk/Zotero/storage/ZKME6TH6/Ma et al_2023_Towards Graph-level Anomaly Detection via Deep Evolutionary Mapping.pdf}
}

@online{maIncorporatingBiologicalKnowledge2019,
  title = {Incorporating {{Biological Knowledge}} with {{Factor Graph Neural Network}} for {{Interpretable Deep Learning}}},
  author = {Ma, Tianle and Zhang, Aidong},
  date = {2019-06-02},
  eprint = {1906.00537},
  eprinttype = {arXiv},
  eprintclass = {cs, q-bio},
  doi = {10.48550/arXiv.1906.00537},
  url = {http://arxiv.org/abs/1906.00537},
  urldate = {2024-03-11},
  abstract = {While deep learning has achieved great success in many fields, one common criticism about deep learning is its lack of interpretability. In most cases, the hidden units in a deep neural network do not have a clear semantic meaning or correspond to any physical entities. However, model interpretability and explainability are crucial in many biomedical applications. To address this challenge, we developed the Factor Graph Neural Network model that is interpretable and predictable by combining probabilistic graphical models with deep learning. We directly encode biological knowledge such as Gene Ontology as a factor graph into the model architecture, making the model transparent and interpretable. Furthermore, we devised an attention mechanism that can capture multi-scale hierarchical interactions among biological entities such as genes and Gene Ontology terms. With parameter sharing mechanism, the unrolled Factor Graph Neural Network model can be trained with stochastic depth and generalize well. We applied our model to two cancer genomic datasets to predict target clinical variables and achieved better results than other traditional machine learning and deep learning models. Our model can also be used for gene set enrichment analysis and selecting Gene Ontology terms that are important to target clinical variables.},
  pubstate = {prepublished},
  keywords = {Computer Science - Machine Learning,Quantitative Biology - Genomics},
  annotation = {11 citations (Semantic Scholar/arXiv) [2024-03-11]},
  file = {/Users/michaelvolk/Zotero/storage/H29F9ZGV/Ma_Zhang_2019_Incorporating Biological Knowledge with Factor Graph Neural Network for.pdf;/Users/michaelvolk/Zotero/storage/PGA7XWPC/1906.html}
}

@article{malfaitEpromotersAreNew2023,
  title = {Epromoters Are New Players in the Regulatory Landscape with Potential Pleiotropic Roles},
  author = {Malfait, Juliette and Wan, Jing and Spicuglia, Salvatore},
  date = {2023},
  journaltitle = {BioEssays},
  volume = {45},
  number = {10},
  pages = {2300012},
  issn = {1521-1878},
  doi = {10.1002/bies.202300012},
  url = {https://onlinelibrary.wiley.com/doi/abs/10.1002/bies.202300012},
  urldate = {2024-07-04},
  abstract = {Precise spatiotemporal control of gene expression during normal development and cell differentiation is achieved by the combined action of proximal (promoters) and distal (enhancers) cis-regulatory elements. Recent studies have reported that a subset of promoters, termed Epromoters, works also as enhancers to regulate distal genes. This new paradigm opened novel questions regarding the complexity of our genome and raises the possibility that genetic variation within Epromoters has pleiotropic effects on various physiological and pathological traits by differentially impacting multiple proximal and distal genes. Here, we discuss the different observations pointing to an important role of Epromoters in the regulatory landscape and summarize the evidence supporting a pleiotropic impact of these elements in disease. We further hypothesize that Epromoter might represent a major contributor to phenotypic variation and disease.},
  langid = {english},
  keywords = {diseases,enhancer,epromoter,gene regulation,pleiotropy,promoter,variants},
  annotation = {0 citations (Semantic Scholar/DOI) [2024-07-04]},
  file = {/Users/michaelvolk/Zotero/storage/9SE5G8MR/Malfait et al. - 2023 - Epromoters are new players in the regulatory lands.pdf;/Users/michaelvolk/Zotero/storage/LT4547VN/bies.html}
}

@article{maliziaReconstructingHigherorderInteractions2024,
  title = {Reconstructing Higher-Order Interactions in Coupled Dynamical Systems},
  author = {Malizia, Federico and Corso, Alessandra and Gambuzza, Lucia Valentina and Russo, Giovanni and Latora, Vito and Frasca, Mattia},
  date = {2024-06-18},
  journaltitle = {Nature Communications},
  shortjournal = {Nat Commun},
  volume = {15},
  number = {1},
  pages = {5184},
  publisher = {Nature Publishing Group},
  issn = {2041-1723},
  doi = {10.1038/s41467-024-49278-x},
  url = {https://www.nature.com/articles/s41467-024-49278-x},
  urldate = {2025-04-16},
  abstract = {Higher-order interactions play a key role for the operation and function of a complex system. However, how to identify them is still an open problem. Here, we propose a method to fully reconstruct the structural connectivity of a system of coupled dynamical units, identifying both pairwise and higher-order interactions from the system time evolution. Our method works for any dynamics, and allows the reconstruction of both hypergraphs and simplicial complexes, either undirected or directed, unweighted or weighted. With two concrete applications, we show how the method can help understanding the complexity of bacterial systems, or the microscopic mechanisms of interaction underlying coupled chaotic oscillators.},
  langid = {english},
  keywords = {Complex networks,Nonlinear phenomena},
  annotation = {18 citations (Semantic Scholar/DOI) [2025-04-15]},
  file = {/Users/michaelvolk/Zotero/storage/GDW9VLS5/Malizia et al_2024_Reconstructing higher-order interactions in coupled dynamical systems.pdf}
}

@article{maloneTenSimpleRules2016,
  title = {Ten {{Simple Rules}} for {{Selecting}} a {{Bio-ontology}}},
  author = {Malone, James and Stevens, Robert and Jupp, Simon and Hancocks, Tom and Parkinson, Helen and Brooksbank, Cath},
  date = {2016-02-11},
  journaltitle = {PLOS Computational Biology},
  shortjournal = {PLOS Computational Biology},
  volume = {12},
  number = {2},
  pages = {e1004743},
  publisher = {Public Library of Science},
  issn = {1553-7358},
  doi = {10.1371/journal.pcbi.1004743},
  url = {https://journals.plos.org/ploscompbiol/article?id=10.1371/journal.pcbi.1004743},
  urldate = {2022-04-23},
  langid = {english},
  keywords = {📚,🦌,ancers and neoplasms,bioinformatics,bioontologies,gene-ontologies},
  annotation = {28 citations (Semantic Scholar/DOI) [2022-11-26]},
  file = {/Users/michaelvolk/Zotero/storage/V2F5YLYL/Malone et al_2016_Ten Simple Rules for Selecting a Bio-ontology.pdf}
}

@article{matentzogluOntologyDevelopmentKit2022,
  title = {Ontology {{Development Kit}}: A Toolkit for Building, Maintaining and Standardizing Biomedical Ontologies},
  shorttitle = {Ontology {{Development Kit}}},
  author = {Matentzoglu, Nicolas and Goutte-Gattat, Damien and Tan, Shawn Zheng Kai and Balhoff, James P and Carbon, Seth and Caron, Anita R and Duncan, William D and Flack, Joe E and Haendel, Melissa and Harris, Nomi L and Hogan, William R and Hoyt, Charles Tapley and Jackson, Rebecca C and Kim, HyeongSik and Kir, Huseyin and Larralde, Martin and McMurry, Julie A and Overton, James A and Peters, Bjoern and Pilgrim, Clare and Stefancsik, Ray and Robb, Sofia Mc and Toro, Sabrina and Vasilevsky, Nicole A and Walls, Ramona and Mungall, Christopher J and Osumi-Sutherland, David},
  date = {2022-10-08},
  journaltitle = {Database},
  volume = {2022},
  pages = {baac087},
  issn = {1758-0463},
  doi = {10.1093/database/baac087},
  url = {https://academic.oup.com/database/article/doi/10.1093/database/baac087/6754192},
  urldate = {2023-11-15},
  abstract = {Similar to managing software packages, managing the ontology life cycle involves multiple complex workflows such as preparing releases, continuous quality control checking and dependency management. To manage these processes, a diverse set of tools is required, from commandline utilities to powerful ontology-engineering environmentsr. Particularly in the biomedical domain, which has developed a set of highly diverse yet inter-dependent ontologies, standardizing release practices and metadata and establishing shared quality standards are crucial to enable interoperability. The Ontology Development Kit (ODK) provides a set of standardized, customizable and automatically executable workflows, and packages all required tooling in a single Docker image. In this paper, we provide an overview of how the ODK works, show how it is used in practice and describe how we envision it driving standardization efforts in our community.},
  langid = {english},
  annotation = {16 citations (Semantic Scholar/DOI) [2023-11-14]},
  file = {/Users/michaelvolk/Zotero/storage/BC9JTLKW/Matentzoglu et al. - 2022 - Ontology Development Kit a toolkit for building, .pdf}
}

@article{mattickKuhnianRevolutionMolecular2023,
  title = {A {{Kuhnian}} Revolution in Molecular Biology: {{Most}} Genes in Complex Organisms Express Regulatory {{RNAs}}},
  shorttitle = {A {{Kuhnian}} Revolution in Molecular Biology},
  author = {Mattick, John S.},
  date = {2023},
  journaltitle = {BioEssays},
  volume = {45},
  number = {9},
  pages = {2300080},
  issn = {1521-1878},
  doi = {10.1002/bies.202300080},
  url = {https://onlinelibrary.wiley.com/doi/abs/10.1002/bies.202300080},
  urldate = {2024-07-04},
  abstract = {Thomas Kuhn described the progress of science as comprising occasional paradigm shifts separated by interludes of ‘normal science’. The paradigm that has held sway since the inception of molecular biology is that genes (mainly) encode proteins. In parallel, theoreticians posited that mutation is random, inferred that most of the genome in complex organisms is non-functional, and asserted that somatic information is not communicated to the germline. However, many anomalies appeared, particularly in plants and animals: the strange genetic phenomena of paramutation and transvection; introns; repetitive sequences; a complex epigenome; lack of scaling of (protein-coding) genes and increase in ‘noncoding’ sequences with developmental complexity; genetic loci termed ‘enhancers’ that control spatiotemporal gene expression patterns during development; and a plethora of ‘intergenic’, overlapping, antisense and intronic transcripts. These observations suggest that the original conception of genetic information was deficient and that most genes in complex organisms specify regulatory RNAs, some of which convey intergenerational information. Also see the video abstract here: https://youtu.be/qxeGwahBANw},
  langid = {english},
  keywords = {enhancers,epigenetics,genome structure,noncoding RNA,transgenerational inheritance},
  annotation = {3 citations (Semantic Scholar/DOI) [2024-07-04]},
  file = {/Users/michaelvolk/Zotero/storage/FQ2PV3EY/Mattick - 2023 - A Kuhnian revolution in molecular biology Most ge.pdf;/Users/michaelvolk/Zotero/storage/RL296WQY/bies.html}
}

@article{maUsingDeepLearning2018,
  title = {Using Deep Learning to Model the Hierarchical Structure and Function of a Cell},
  author = {Ma, Jianzhu and Yu, Michael Ku and Fong, Samson and Ono, Keiichiro and Sage, Eric and Demchak, Barry and Sharan, Roded and Ideker, Trey},
  date = {2018-04-01},
  journaltitle = {Nature Methods},
  shortjournal = {Nat Methods},
  volume = {15},
  number = {4},
  pages = {290--298},
  issn = {1548-7091, 1548-7105},
  doi = {10.1038/nmeth.4627},
  url = {http://www.nature.com/articles/nmeth.4627},
  urldate = {2022-02-08},
  langid = {english},
  keywords = {✅,🦌},
  annotation = {216 citations (Semantic Scholar/DOI) [2022-11-26]\\
180 citations (Crossref) [2022-04-15]},
  file = {/Users/michaelvolk/Zotero/storage/G9NM4UGW/Ma et al. - 2018 - Using deep learning to model the hierarchical stru.pdf;/Users/michaelvolk/Zotero/storage/VMI9LRCA/SI - Ma et al. - 2018 - Using deep learning to model the hierarchical stru.pdf}
}

@article{mazeinGuideDevelopingComprehensive2023,
  title = {A Guide for Developing Comprehensive Systems Biology Maps of Disease Mechanisms: Planning, Construction and Maintenance},
  shorttitle = {A Guide for Developing Comprehensive Systems Biology Maps of Disease Mechanisms},
  author = {Mazein, Alexander and Acencio, Marcio Luis and Balaur, Irina and Rougny, Adrien and Welter, Danielle and Niarakis, Anna and Ramirez Ardila, Diana and Dogrusoz, Ugur and Gawron, Piotr and Satagopam, Venkata and Gu, Wei and Kremer, Andreas and Schneider, Reinhard and Ostaszewski, Marek},
  date = {2023},
  journaltitle = {Frontiers in Bioinformatics},
  volume = {3},
  issn = {2673-7647},
  url = {https://www.frontiersin.org/articles/10.3389/fbinf.2023.1197310},
  urldate = {2023-11-23},
  abstract = {As a conceptual model of disease mechanisms, a disease map integrates available knowledge and is applied for data interpretation, predictions and hypothesis generation. It is possible to model disease mechanisms on different levels of granularity and adjust the approach to the goals of a particular project. This rich environment together with requirements for high-quality network reconstruction makes it challenging for new curators and groups to be quickly introduced to the development methods. In this review, we offer a step-by-step guide for developing a disease map within its mainstream pipeline that involves using the CellDesigner tool for creating and editing diagrams and the MINERVA Platform for online visualisation and exploration. We also describe how the Neo4j graph database environment can be used for managing and querying efficiently such a resource. For assessing the interoperability and reproducibility we apply FAIR principles.},
  file = {/Users/michaelvolk/Zotero/storage/ZPDC4J6Z/Mazein et al_2023_A guide for developing comprehensive systems biology maps of disease mechanisms.pdf}
}

@article{meinhardtPatternFormationLocal2000,
  title = {Pattern Formation by Local Self-Activation and Lateral Inhibition},
  author = {Meinhardt, Hans and Gierer, Alfred},
  date = {2000},
  journaltitle = {BioEssays},
  volume = {22},
  number = {8},
  pages = {753--760},
  issn = {1521-1878},
  doi = {10.1002/1521-1878(200008)22:8<753::AID-BIES9>3.0.CO;2-Z},
  url = {https://onlinelibrary.wiley.com/doi/abs/10.1002/1521-1878%28200008%2922%3A8%3C753%3A%3AAID-BIES9%3E3.0.CO%3B2-Z},
  urldate = {2024-06-21},
  abstract = {In 1972, we proposed a theory of biological pattern formation in which concentration maxima of pattern forming substances are generated through local self-enhancement in conjunction with long range inhibition. Since then, much evidence in various developmental systems has confirmed the importance of autocatalytic feedback loops combined with inhibitory interaction. Examples are found in the formation of embryonal organizing regions, in segmentation, in the polarization of individual cells, and in gene activation. By computer simulations, we have shown that the theory accounts for much of the regulatory phenomena observed, including signalling to regenerate removed parts. These self-regulatory features contribute to making development robust and error-tolerant. Furthermore, the resulting pattern is, to a large extent, independent of the details provided by initial conditions and inducing signals. BioEssays 22:753–760, 2000. © 2000 John Wiley \& Sons, Inc.},
  langid = {english},
  annotation = {629 citations (Semantic Scholar/DOI) [2024-06-21]},
  file = {/Users/michaelvolk/Zotero/storage/AJQ7ZBX7/Meinhardt_Gierer_2000_Pattern formation by local self-activation and lateral inhibition.pdf;/Users/michaelvolk/Zotero/storage/FUTW2HMA/1521-1878(200008)228753AID-BIES93.0.html}
}

@book{menolascinaSyntheticGeneCircuits2021,
  title = {Synthetic {{Gene Circuits}}: {{Methods}} and {{Protocols}}},
  shorttitle = {Synthetic {{Gene Circuits}}},
  editor = {Menolascina, Filippo},
  date = {2021},
  series = {Methods in {{Molecular Biology}}},
  volume = {2229},
  publisher = {Springer US},
  location = {New York, NY},
  doi = {10.1007/978-1-0716-1032-9},
  url = {https://link.springer.com/10.1007/978-1-0716-1032-9},
  urldate = {2024-07-04},
  isbn = {978-1-07-161031-2 978-1-07-161032-9},
  langid = {english},
  keywords = {Boolean Networks,Cello,Evolutionary Algorithm Network Design,Model-Based Biosystems Engineering,SynBADm},
  file = {/Users/michaelvolk/Zotero/storage/IC82TK58/Menolascina - 2021 - Synthetic Gene Circuits Methods and Protocols.pdf}
}

@inproceedings{mesquitaRethinkingPoolingGraph2020,
  title = {Rethinking Pooling in Graph Neural Networks},
  booktitle = {Advances in {{Neural Information Processing Systems}}},
  author = {Mesquita, Diego and Souza, Amauri and Kaski, Samuel},
  date = {2020},
  volume = {33},
  pages = {2220--2231},
  publisher = {Curran Associates, Inc.},
  url = {https://proceedings.neurips.cc/paper/2020/hash/1764183ef03fc7324eb58c3842bd9a57-Abstract.html},
  urldate = {2024-03-11},
  abstract = {Graph pooling is a central component of a myriad of graph neural network (GNN) architectures. As an inheritance from traditional CNNs, most approaches formulate graph pooling as a cluster assignment problem, extending the idea of local patches in regular grids to graphs. Despite the wide adherence to this design choice, no work has rigorously evaluated its influence on the success of GNNs. In this paper, we build upon representative GNNs and introduce variants that challenge the need for locality-preserving representations, either using randomization or clustering on the complement graph. Strikingly, our experiments demonstrate that using these variants does not result in any decrease in performance. To understand this phenomenon, we study the interplay between convolutional layers and the subsequent pooling ones. We show that the convolutions play a leading role in the learned representations. In contrast to the common belief, local pooling is not responsible for the success of GNNs on relevant and widely-used benchmarks.},
  file = {/Users/michaelvolk/Zotero/storage/4QESNDAC/Mesquita et al_2020_Rethinking pooling in graph neural networks.pdf}
}

@article{michaelisSocialStructuralArchitecture2023,
  title = {The Social and Structural Architecture of the Yeast Protein Interactome},
  author = {Michaelis, André C. and Brunner, Andreas-David and Zwiebel, Maximilian and Meier, Florian and Strauss, Maximilian T. and Bludau, Isabell and Mann, Matthias},
  date = {2023-11-15},
  journaltitle = {Nature},
  pages = {1--9},
  publisher = {Nature Publishing Group},
  issn = {1476-4687},
  doi = {10.1038/s41586-023-06739-5},
  url = {https://www.nature.com/articles/s41586-023-06739-5},
  urldate = {2023-11-16},
  abstract = {Cellular functions are mediated by protein–protein interactions, and mapping the interactome provides fundamental insights into biological systems. Affinity purification coupled to mass spectrometry is an ideal tool for such mapping, but it has been difficult to identify low copy number complexes, membrane complexes and complexes that are disrupted by protein tagging. As a result, our current knowledge of the interactome is far from complete, and assessing the reliability of reported interactions is challenging. Here we develop a sensitive high-throughput method using highly reproducible affinity enrichment coupled to mass spectrometry combined with a quantitative two-dimensional analysis strategy to comprehensively map the interactome of Saccharomyces cerevisiae. Thousand-fold reduced volumes in 96-well format enabled replicate analysis of the endogenous GFP-tagged library covering the entire expressed yeast proteome1. The 4,159 pull-downs generated a highly structured network of 3,927 proteins connected by 31,004 interactions, doubling the number of proteins and tripling the number of reliable interactions compared with existing interactome maps2. This includes very-low-abundance epigenetic complexes, organellar membrane complexes and non-taggable complexes inferred by abundance correlation. This nearly saturated interactome reveals that the vast majority of yeast proteins are highly connected, with an average of 16 interactors. Similar to social networks between humans, the average shortest distance between proteins is 4.2 interactions. AlphaFold-Multimer provided novel insights into the functional roles of previously uncharacterized proteins in complexes. Our web portal (www.yeast-interactome.org) enables extensive exploration of the interactome dataset.},
  langid = {english},
  keywords = {Mass spectrometry,Molecular modelling,Protein–protein interaction networks,Systems analysis},
  file = {/Users/michaelvolk/Zotero/storage/HX4X6PYJ/Michaelis et al_2023_The social and structural architecture of the yeast protein interactome.pdf}
}

@article{michaelisSocialStructuralArchitecture2023a,
  title = {The Social and Structural Architecture of the Yeast Protein Interactome},
  author = {Michaelis, André C. and Brunner, Andreas-David and Zwiebel, Maximilian and Meier, Florian and Strauss, Maximilian T. and Bludau, Isabell and Mann, Matthias},
  date = {2023-12},
  journaltitle = {Nature},
  volume = {624},
  number = {7990},
  pages = {192--200},
  publisher = {Nature Publishing Group},
  issn = {1476-4687},
  doi = {10.1038/s41586-023-06739-5},
  url = {https://www.nature.com/articles/s41586-023-06739-5},
  urldate = {2025-04-25},
  abstract = {Cellular functions are mediated by protein–protein interactions, and mapping the interactome provides fundamental insights into biological systems. Affinity purification coupled to mass spectrometry is an ideal tool for such mapping, but it has been difficult to identify low copy number complexes, membrane complexes and complexes that are disrupted by protein tagging. As a result, our current knowledge of the interactome is far from complete, and assessing the reliability of reported interactions is challenging. Here we develop a sensitive high-throughput method using highly reproducible affinity enrichment coupled to mass spectrometry combined with a quantitative two-dimensional analysis strategy to comprehensively map the interactome of Saccharomyces cerevisiae. Thousand-fold reduced volumes in 96-well format enabled replicate analysis of the endogenous GFP-tagged library covering the entire expressed yeast proteome1. The 4,159 pull-downs generated a highly structured network of 3,927 proteins connected by 31,004 interactions, doubling the number of proteins and tripling the number of reliable interactions compared with existing interactome maps2. This includes very-low-abundance epigenetic complexes, organellar membrane complexes and non-taggable complexes inferred by abundance correlation. This nearly saturated interactome reveals that the vast majority of yeast proteins are highly connected, with an average of 16 interactors. Similar to social networks between humans, the average shortest distance between proteins is 4.2 interactions. AlphaFold-Multimer provided novel insights into the functional roles of previously uncharacterized proteins in complexes. Our web portal (www.yeast-interactome.org) enables extensive exploration of the interactome dataset.},
  langid = {english},
  keywords = {Mass spectrometry,Molecular modelling,Protein–protein interaction networks,Systems analysis},
  annotation = {31 citations (Semantic Scholar/DOI) [2025-04-25]},
  file = {/Users/michaelvolk/Zotero/storage/DEXA2I64/Michaelis et al_2023_The social and structural architecture of the yeast protein interactome.pdf}
}

@article{millerLargescaleIdentificationYeast2005,
  title = {Large-Scale Identification of Yeast Integral Membrane Protein Interactions},
  author = {Miller, John P. and Lo, Russell S. and Ben-Hur, Asa and Desmarais, Cynthia and Stagljar, Igor and Noble, William Stafford and Fields, Stanley},
  date = {2005-08-23},
  journaltitle = {Proceedings of the National Academy of Sciences},
  volume = {102},
  number = {34},
  pages = {12123--12128},
  publisher = {Proceedings of the National Academy of Sciences},
  doi = {10.1073/pnas.0505482102},
  url = {https://www.pnas.org/doi/10.1073/pnas.0505482102},
  urldate = {2023-10-20},
  abstract = {We carried out a large-scale screen to identify interactions between integral membrane proteins of Saccharomyces cerevisiae by using a modified split-ubiquitin technique. Among 705 proteins annotated as integral membrane, we identified 1,985 putative interactions involving 536 proteins. To ascribe confidence levels to the interactions, we used a support vector machine algorithm to classify interactions based on the assay results and protein data derived from the literature. Previously identified and computationally supported interactions were used to train the support vector machine, which identified 131 interactions of highest confidence, 209 of the next highest confidence, 468 of the next highest, and the remaining 1,085 of low confidence. This study provides numerous putative interactions among a class of proteins that have been difficult to analyze on a high-throughput basis by other approaches. The results identify potential previously undescribed components of established biological processes and roles for integral membrane proteins of ascribed functions.},
  annotation = {271 citations (Semantic Scholar/DOI) [2023-10-19]},
  file = {/Users/michaelvolk/Zotero/storage/KYYKZNLU/Miller et al_2005_Large-scale identification of yeast integral membrane protein interactions.pdf}
}

@article{miloBioNumbersDatabaseKey2010,
  title = {{{BioNumbers}}—the Database of Key Numbers in Molecular and Cell Biology},
  author = {Milo, Ron and Jorgensen, Paul and Moran, Uri and Weber, Griffin and Springer, Michael},
  date = {2010-01-01},
  journaltitle = {Nucleic Acids Research},
  shortjournal = {Nucleic Acids Research},
  volume = {38},
  pages = {D750-D753},
  issn = {0305-1048},
  doi = {10.1093/nar/gkp889},
  url = {https://doi.org/10.1093/nar/gkp889},
  urldate = {2023-11-23},
  abstract = {BioNumbers (http://www.bionumbers.hms.harvard.edu) is a database of key numbers in molecular and cell biology—the quantitative properties of biological systems of interest to computational, systems and molecular cell biologists. Contents of the database range from cell sizes to metabolite concentrations, from reaction rates to generation times, from genome sizes to the number of mitochondria in a cell. While always of importance to biologists, having numbers in hand is becoming increasingly critical for experimenting, modeling, and analyzing biological systems. BioNumbers was motivated by an appreciation of how long it can take to find even the simplest number in the vast biological literature. All numbers are taken directly from a literature source and that reference is provided with the number. BioNumbers is designed to be highly searchable and queries can be performed by keywords or browsed by menus. BioNumbers is a collaborative community platform where registered users can add content and make comments on existing data. All new entries and commentary are curated to maintain high quality. Here we describe the database characteristics and implementation, demonstrate its use, and discuss future directions for its development.},
  issue = {suppl\_1},
  annotation = {857 citations (Semantic Scholar/DOI) [2023-11-23]},
  file = {/Users/michaelvolk/Zotero/storage/ST5EFC5B/Milo et al_2010_BioNumbers—the database of key numbers in molecular and cell biology.pdf}
}

@book{miloCellBiologyNumbers2016,
  title = {Cell Biology by the Numbers},
  author = {Milo, Ron and Phillips, Rob},
  date = {2016},
  publisher = {Garland Science, Taylor \& Francis Group},
  location = {New York, NY},
  isbn = {978-0-8153-4537-4},
  langid = {english},
  pagetotal = {356},
  keywords = {Cell physiology,Cells,Cellular Structures,Cytology,Data Interpretation Statistical,Data processing,ultrastructure},
  file = {/Users/michaelvolk/Zotero/storage/B8R6XBWX/Ron Milo, Rob Phillips - Cell Biology by the Numbers-Garland Science (2015).pdf}
}

@article{mullederFunctionalMetabolomicsDescribes2016a,
  title = {Functional Metabolomics Describes the Yeast Biosynthetic Regulome},
  author = {Mülleder, Michael and Calvani, Enrica and Alam, Mohammad Tauqeer and Wang, Richard Kangda and Eckerstorfer, Florian and Zelezniak, Aleksej and Ralser, Markus},
  date = {2016},
  journaltitle = {Cell},
  volume = {167},
  number = {2},
  pages = {553--565},
  publisher = {Elsevier},
  url = {https://www.cell.com/cell/pdf/S0092-8674(16)31237-5.pdf},
  urldate = {2023-11-02},
  file = {/Users/michaelvolk/Zotero/storage/JDT6KEIZ/Mülleder et al_2016_Functional metabolomics describes the yeast biosynthetic regulome.pdf}
}

@article{murataPetriNetsProperties1989a,
  title = {Petri Nets: {{Properties}}, Analysis and Applications},
  shorttitle = {Petri Nets},
  author = {Murata, T.},
  date = {1989-04},
  journaltitle = {Proceedings of the IEEE},
  volume = {77},
  number = {4},
  pages = {541--580},
  issn = {1558-2256},
  doi = {10.1109/5.24143},
  abstract = {Starts with a brief review of the history and the application areas considered in the literature. The author then proceeds with introductory modeling examples, behavioral and structural properties, three methods of analysis, subclasses of Petri nets and their analysis. In particular, one section is devoted to marked graphs, the concurrent system model most amenable to analysis. Introductory discussions on stochastic nets with their application to performance modeling, and on high-level nets with their application to logic programming, are provided. Also included are recent results on reachability criteria. Suggestions are provided for further reading on many subject areas of Petri nets.{$<>$}},
  eventtitle = {Proceedings of the {{IEEE}}},
  keywords = {Books,Equations,History,Information processing,Logic programming,Mathematical model,Petri nets,Power system modeling,Stochastic processes,Stochastic systems},
  annotation = {9987 citations (Semantic Scholar/DOI) [2023-04-05]},
  file = {/Users/michaelvolk/Zotero/storage/VTZAY3UV/Murata_1989_Petri nets.pdf;/Users/michaelvolk/Zotero/storage/AXH2J73L/24143.html}
}

@article{muroEmergenceEukaryotesEvolutionary2025,
  title = {The Emergence of Eukaryotes as an Evolutionary Algorithmic Phase Transition},
  author = {Muro, Enrique M. and Ballesteros, Fernando J. and Luque, Bartolo and Bascompte, Jordi},
  date = {2025-04},
  journaltitle = {Proceedings of the National Academy of Sciences},
  volume = {122},
  number = {13},
  pages = {e2422968122},
  publisher = {Proceedings of the National Academy of Sciences},
  doi = {10.1073/pnas.2422968122},
  url = {https://www.pnas.org/doi/abs/10.1073/pnas.2422968122},
  urldate = {2025-05-18},
  abstract = {The origin of eukaryotes represents one of the most significant events in evolution since it allowed the posterior emergence of multicellular organisms. Yet, it remains unclear how existing regulatory mechanisms of gene activity were transformed to allow this increase in complexity. Here, we address this question by analyzing the length distribution of proteins and their corresponding genes for 6,519 species across the tree of life. We find a scale-invariant relationship between gene mean length and variance maintained across the entire evolutionary history. Using a simple model, we show that this scale-invariant relationship naturally originates through a simple multiplicative process of gene growth. During the first phase of this process, corresponding to prokaryotes, protein length follows gene growth. At the onset of the eukaryotic cell, however, mean protein length stabilizes around 500 amino acids. While genes continued growing at the same rate as before, this growth primarily involved noncoding sequences that complemented proteins in regulating gene activity. Our analysis indicates that this shift at the origin of the eukaryotic cell was due to an algorithmic phase transition equivalent to that of certain search algorithms triggered by the constraints in finding increasingly larger proteins.},
  annotation = {3 citations (Semantic Scholar/DOI) [2025-05-18]},
  file = {/Users/michaelvolk/Zotero/storage/YIP96BLC/Muro et al_2025_The emergence of eukaryotes as an evolutionary algorithmic phase transition.pdf}
}

@article{nadal-ribellesRiseSinglecellTranscriptomics2024,
  title = {The Rise of Single-Cell Transcriptomics in Yeast},
  author = {Nadal-Ribelles, Mariona and Solé, Carme and family=Nadal, given=Eulalia, prefix=de, useprefix=true and Posas, Francesc},
  date = {2024},
  journaltitle = {Yeast},
  volume = {41},
  number = {4},
  pages = {158--170},
  issn = {1097-0061},
  doi = {10.1002/yea.3934},
  url = {https://onlinelibrary.wiley.com/doi/abs/10.1002/yea.3934},
  urldate = {2025-02-13},
  abstract = {The field of single-cell omics has transformed our understanding of biological processes and is constantly advancing both experimentally and computationally. One of the most significant developments is the ability to measure the transcriptome of individual cells by single-cell RNA-seq (scRNA-seq), which was pioneered in higher eukaryotes. While yeast has served as a powerful model organism in which to test and develop transcriptomic technologies, the implementation of scRNA-seq has been significantly delayed in this organism, mainly because of technical constraints associated with its intrinsic characteristics, namely the presence of a cell wall, a small cell size and little amounts of RNA. In this review, we examine the current technologies for scRNA-seq in yeast and highlight their strengths and weaknesses. Additionally, we explore opportunities for developing novel technologies and the potential outcomes of implementing single-cell transcriptomics and extension to other modalities. Undoubtedly, scRNA-seq will be invaluable for both basic and applied yeast research, providing unique insights into fundamental biological processes.},
  langid = {english},
  keywords = {🦌✅,methods,single-cell transcriptomics,transcription,yeast},
  annotation = {3 citations (Semantic Scholar/DOI) [2025-02-13]},
  file = {/Users/michaelvolk/Zotero/storage/MVM97EU6/Nadal-Ribelles et al_2024_The rise of single-cell transcriptomics in yeast.pdf;/Users/michaelvolk/Zotero/storage/LL7BDT3X/yea.html}
}

@article{nagalakshmiTranscriptionalLandscapeYeast2008,
  title = {The {{Transcriptional Landscape}} of the {{Yeast Genome Defined}} by {{RNA Sequencing}}},
  author = {Nagalakshmi, Ugrappa and Wang, Zhong and Waern, Karl and Shou, Chong and Raha, Debasish and Gerstein, Mark and Snyder, Michael},
  date = {2008-06-06},
  journaltitle = {Science},
  volume = {320},
  number = {5881},
  pages = {1344--1349},
  publisher = {American Association for the Advancement of Science},
  doi = {10.1126/science.1158441},
  url = {https://www.science.org/doi/10.1126/science.1158441},
  urldate = {2023-10-16},
  abstract = {The identification of untranslated regions, introns, and coding regions within an organism remains challenging. We developed a quantitative sequencing-based method called RNA-Seq for mapping transcribed regions, in which complementary DNA fragments are subjected to high-throughput sequencing and mapped to the genome. We applied RNA-Seq to generate a high-resolution transcriptome map of the yeast genome and demonstrated that most (74.5\%) of the nonrepetitive sequence of the yeast genome is transcribed. We confirmed many known and predicted introns and demonstrated that others are not actively used. Alternative initiation codons and upstream open reading frames also were identified for many yeast genes. We also found unexpected 3′-end heterogeneity and the presence of many overlapping genes. These results indicate that the yeast transcriptome is more complex than previously appreciated.},
  annotation = {2438 citations (Semantic Scholar/DOI) [2023-10-16]},
  file = {/Users/michaelvolk/Zotero/storage/TRKSCMJ5/Nagalakshmi et al_2008_The Transcriptional Landscape of the Yeast Genome Defined by RNA Sequencing.pdf}
}

@article{neuhauserLearningEffectiveOrder2024,
  title = {Learning the Effective Order of a Hypergraph Dynamical System},
  author = {Neuhäuser, Leonie and Scholkemper, Michael and Tudisco, Francesco and Schaub, Michael T.},
  date = {2024-05-08},
  journaltitle = {Science Advances},
  volume = {10},
  number = {19},
  pages = {eadh4053},
  publisher = {American Association for the Advancement of Science},
  doi = {10.1126/sciadv.adh4053},
  url = {https://www.science.org/doi/10.1126/sciadv.adh4053},
  urldate = {2024-07-04},
  abstract = {Dynamical systems on hypergraphs can display a rich set of behaviors not observable for systems with pairwise interactions. Given a distributed dynamical system with a putative hypergraph structure, an interesting question is thus how much of this hypergraph structure is actually necessary to faithfully replicate the observed dynamical behavior. To answer this question, we propose a method to determine the minimum order of a hypergraph necessary to approximate the corresponding dynamics accurately. Specifically, we develop a mathematical framework that allows us to determine this order when the type of dynamics is known. We use these ideas in conjunction with a hypergraph neural network to directly learn the dynamics itself and the resulting order of the hypergraph from both synthetic and real datasets consisting of observed system trajectories.},
  annotation = {6 citations (Semantic Scholar/DOI) [2024-07-04]},
  file = {/Users/michaelvolk/Zotero/storage/6Q5VQSMK/Neuhäuser et al. - 2024 - Learning the effective order of a hypergraph dynam.pdf}
}

@inproceedings{nguyenAlignmentMPNNsGraph2024,
  title = {Alignment of {{MPNNs}} and {{Graph Transformers}}},
  booktitle = {{{ICML}} 2024 {{Workshop}} on {{Geometry-grounded Representation Learning}} and {{Generative Modeling}}},
  author = {Nguyen, Bao and Yodaiken, Anjana and Veličković, Petar},
  date = {2024},
  url = {https://openreview.net/forum?id=MgugfaFubY},
  urldate = {2025-03-01},
  file = {/Users/michaelvolk/Zotero/storage/IG5AR7K5/Nguyen et al_2024_Alignment of MPNNs and Graph Transformers.pdf}
}

@article{nguyenControllingCircuitryDictates2023,
  title = {Controlling Circuitry Dictates the Growth Optimization of {{Saccharomyces}} Cerevisiae},
  author = {Nguyen, Viviana and Xue, Pu and Li, Yifei and Zhao, Huimin and Lu, Ting},
  date = {2023-09-21},
  journaltitle = {Metabolic Engineering},
  shortjournal = {Metabolic Engineering},
  issn = {1096-7176},
  doi = {10.1016/j.ymben.2023.09.013},
  url = {https://www.sciencedirect.com/science/article/pii/S1096717623001398},
  urldate = {2023-10-09},
  abstract = {Microbial growth emerges from coordinated synthesis of various cellular components from limited resources. In Saccharomyces cerevisiae, cyclic AMP (cAMP)-mediated signaling is shown to orchestrate cellular metabolism; however, it remains unclear quantitatively how the controlling circuit drives resource partition and subsequently shapes biomass growth. Here we combined experiment with mathematical modeling to dissect the signaling-mediated growth optimization of S. cerevisiae. We showed that, through cAMP-mediated control, the organism achieves maximal or nearly maximal steady-state growth during the utilization of multiple tested substrates as well as under perturbations impairing glucose uptake. However, the optimal cAMP concentration varies across cases, suggesting that different modes of resource allocation are adopted for varied conditions. Under settings with nutrient alterations, S. cerevisiae tunes its cAMP level to dynamically reprogram itself to realize rapid adaptation. Moreover, to achieve growth maximization, cells employ additional regulatory systems such as the Gcn2-mediated amino acid control. This study establishes a systematic understanding of global resource allocation in S. cerevisiae, providing insights into quantitative yeast physiology as well as metabolic strain engineering for biotechnological applications.},
  keywords = {cAMP,Growth optimality,Mathematical modeling,Resource allocation,Systems biology},
  file = {/Users/michaelvolk/Zotero/storage/6IL7Y8DL/Nguyen et al_2023_Controlling circuitry dictates the growth optimization of Saccharomyces.pdf;/Users/michaelvolk/Zotero/storage/79JKYUBB/S1096717623001398.html}
}

@article{nguyenHyenaDNALongRangeGenomic2023,
  title = {{{HyenaDNA}}: {{Long-Range Genomic Sequence Modeling}} at {{Single Nucleotide Resolution}}},
  shorttitle = {{{HyenaDNA}}},
  author = {Nguyen, Eric and Poli, Michael and Faizi, Marjan and Thomas, Armin and Wornow, Michael and Birch-Sykes, Callum and Massaroli, Stefano and Patel, Aman and Rabideau, Clayton and Bengio, Yoshua and Ermon, Stefano and Ré, Christopher and Baccus, Stephen},
  date = {2023-12-15},
  journaltitle = {Advances in Neural Information Processing Systems},
  volume = {36},
  pages = {43177--43201},
  url = {https://proceedings.neurips.cc/paper_files/paper/2023/hash/86ab6927ee4ae9bde4247793c46797c7-Abstract-Conference.html},
  urldate = {2024-03-31},
  langid = {english},
  file = {/Users/michaelvolk/Zotero/storage/XGYNBJ72/Nguyen et al_2023_HyenaDNA.pdf}
}

@online{nguyenSequenceModelingDesign2024,
  title = {Sequence Modeling and Design from Molecular to Genome Scale with {{Evo}}},
  author = {Nguyen, Eric and Poli, Michael and Durrant, Matthew G. and Thomas, Armin W. and Kang, Brian and Sullivan, Jeremy and Ng, Madelena Y. and Lewis, Ashley and Patel, Aman and Lou, Aaron and Ermon, Stefano and Baccus, Stephen A. and Hernandez-Boussard, Tina and Ré, Christopher and Hsu, Patrick D. and Hie, Brian L.},
  date = {2024-02-27},
  eprinttype = {bioRxiv},
  eprintclass = {New Results},
  pages = {2024.02.27.582234},
  doi = {10.1101/2024.02.27.582234},
  url = {https://www.biorxiv.org/content/10.1101/2024.02.27.582234v1},
  urldate = {2024-03-05},
  abstract = {The genome is a sequence that completely encodes the DNA, RNA, and proteins that orchestrate the function of a whole organism. Advances in machine learning combined with massive datasets of whole genomes could enable a biological foundation model that accelerates the mechanistic understanding and generative design of complex molecular interactions. We report Evo, a genomic foundation model that enables prediction and generation tasks from the molecular to genome scale. Using an architecture based on advances in deep signal processing, we scale Evo to 7 billion parameters with a context length of 131 kilobases (kb) at single-nucleotide, byte resolution. Trained on whole prokaryotic genomes, Evo can generalize across the three fundamental modalities of the central dogma of molecular biology to perform zero-shot function prediction that is competitive with, or outperforms, leading domain-specific language models. Evo also excels at multielement generation tasks, which we demonstrate by generating synthetic CRISPR-Cas molecular complexes and entire transposable systems for the first time. Using information learned over whole genomes, Evo can also predict gene essentiality at nucleotide resolution and can generate coding-rich sequences up to 650 kb in length, orders of magnitude longer than previous methods. Advances in multi-modal and multi-scale learning with Evo provides a promising path toward improving our understanding and control of biology across multiple levels of complexity.},
  langid = {english},
  pubstate = {prepublished},
  file = {/Users/michaelvolk/Zotero/storage/DRU7UPYE/Nguyen et al_2024_Sequence modeling and design from molecular to genome scale with Evo.pdf;/Users/michaelvolk/Zotero/storage/M5TBPEBX/2024.02.27.582234.full.pdf}
}

@article{nguyenSequenceModelingDesign2024a,
  title = {Sequence Modeling and Design from Molecular to Genome Scale with {{Evo}}},
  author = {Nguyen, Eric and Poli, Michael and Durrant, Matthew G. and Kang, Brian and Katrekar, Dhruva and Li, David B. and Bartie, Liam J. and Thomas, Armin W. and King, Samuel H. and Brixi, Garyk and Sullivan, Jeremy and Ng, Madelena Y. and Lewis, Ashley and Lou, Aaron and Ermon, Stefano and Baccus, Stephen A. and Hernandez-Boussard, Tina and Ré, Christopher and Hsu, Patrick D. and Hie, Brian L.},
  date = {2024-11-15},
  journaltitle = {Science},
  volume = {386},
  number = {6723},
  pages = {eado9336},
  publisher = {American Association for the Advancement of Science},
  doi = {10.1126/science.ado9336},
  url = {https://www.science.org/doi/full/10.1126/science.ado9336},
  urldate = {2024-12-02},
  abstract = {The genome is a sequence that encodes the DNA, RNA, and proteins that orchestrate an organism’s function. We present Evo, a long-context genomic foundation model with a frontier architecture trained on millions of prokaryotic and phage genomes, and report scaling laws on DNA to complement observations in language and vision. Evo generalizes across DNA, RNA, and proteins, enabling zero-shot function prediction competitive with domain-specific language models and the generation of functional CRISPR-Cas and transposon systems, representing the first examples of protein-RNA and protein-DNA codesign with a language model. Evo also learns how small mutations affect whole-organism fitness and generates megabase-scale sequences with plausible genomic architecture. These prediction and generation capabilities span molecular to genomic scales of complexity, advancing our understanding and control of biology.},
  annotation = {1 citations (Semantic Scholar/DOI) [2024-12-02]},
  file = {/Users/michaelvolk/Zotero/storage/DGCPB4BJ/Nguyen et al_2024_Sequence modeling and design from molecular to genome scale with Evo.pdf}
}

@online{nieDistLossEnhancing2024,
  title = {Dist {{Loss}}: {{Enhancing Regression}} in {{Few-Shot Region}} through {{Distribution Distance Constraint}}},
  shorttitle = {Dist {{Loss}}},
  author = {Nie, Guangkun and Tang, Gongzheng and Hong, Shenda},
  date = {2024-11-20},
  eprint = {2411.15216},
  eprinttype = {arXiv},
  eprintclass = {cs},
  doi = {10.48550/arXiv.2411.15216},
  url = {http://arxiv.org/abs/2411.15216},
  urldate = {2025-01-08},
  abstract = {Imbalanced data distributions are prevalent in real-world scenarios, posing significant challenges in both imbalanced classification and imbalanced regression tasks. They often cause deep learning models to overfit in areas of high sample density (many-shot regions) while underperforming in areas of low sample density (few-shot regions). This characteristic restricts the utility of deep learning models in various sectors, notably healthcare, where areas with few-shot data hold greater clinical relevance. While recent studies have shown the benefits of incorporating distribution information in imbalanced classification tasks, such strategies are rarely explored in imbalanced regression. In this paper, we address this issue by introducing a novel loss function, termed Dist Loss, designed to minimize the distribution distance between the model's predictions and the target labels in a differentiable manner, effectively integrating distribution information into model training. Dist Loss enables deep learning models to regularize their output distribution during training, effectively enhancing their focus on few-shot regions. We have conducted extensive experiments across three datasets spanning computer vision and healthcare: IMDB-WIKI-DIR, AgeDB-DIR, and ECG-Ka-DIR. The results demonstrate that Dist Loss effectively mitigates the negative impact of imbalanced data distribution on model performance, achieving state-of-the-art results in sparse data regions. Furthermore, Dist Loss is easy to integrate, complementing existing methods.},
  pubstate = {prepublished},
  keywords = {Computer Science - Artificial Intelligence,Computer Science - Machine Learning},
  annotation = {0 citations (Semantic Scholar/arXiv) [2025-01-08]\\
0 citations (Semantic Scholar/DOI) [2025-01-08]},
  file = {/Users/michaelvolk/Zotero/storage/G7BERACF/Nie et al_2024_Dist Loss.pdf;/Users/michaelvolk/Zotero/storage/NSYKRYBB/2411.html}
}

@online{nieDistLossEnhancing2024a,
  title = {Dist {{Loss}}: {{Enhancing Regression}} in {{Few-Shot Region}} through {{Distribution Distance Constraint}}},
  shorttitle = {Dist {{Loss}}},
  author = {Nie, Guangkun and Tang, Gongzheng and Hong, Shenda},
  date = {2024-11-20},
  eprint = {2411.15216},
  eprinttype = {arXiv},
  eprintclass = {cs},
  doi = {10.48550/arXiv.2411.15216},
  url = {http://arxiv.org/abs/2411.15216},
  urldate = {2025-02-27},
  abstract = {Imbalanced data distributions are prevalent in real-world scenarios, posing significant challenges in both imbalanced classification and imbalanced regression tasks. They often cause deep learning models to overfit in areas of high sample density (many-shot regions) while underperforming in areas of low sample density (few-shot regions). This characteristic restricts the utility of deep learning models in various sectors, notably healthcare, where areas with few-shot data hold greater clinical relevance. While recent studies have shown the benefits of incorporating distribution information in imbalanced classification tasks, such strategies are rarely explored in imbalanced regression. In this paper, we address this issue by introducing a novel loss function, termed Dist Loss, designed to minimize the distribution distance between the model's predictions and the target labels in a differentiable manner, effectively integrating distribution information into model training. Dist Loss enables deep learning models to regularize their output distribution during training, effectively enhancing their focus on few-shot regions. We have conducted extensive experiments across three datasets spanning computer vision and healthcare: IMDB-WIKI-DIR, AgeDB-DIR, and ECG-Ka-DIR. The results demonstrate that Dist Loss effectively mitigates the negative impact of imbalanced data distribution on model performance, achieving state-of-the-art results in sparse data regions. Furthermore, Dist Loss is easy to integrate, complementing existing methods.},
  pubstate = {prepublished},
  keywords = {Computer Science - Artificial Intelligence,Computer Science - Machine Learning},
  annotation = {0 citations (Semantic Scholar/arXiv) [2025-02-27]\\
0 citations (Semantic Scholar/DOI) [2025-02-27]},
  file = {/Users/michaelvolk/Zotero/storage/VV4ULX26/Nie et al_2024_Dist Loss.pdf;/Users/michaelvolk/Zotero/storage/CIPHW2M4/2411.html}
}

@article{oduibhirCellCyclePopulation2014,
  title = {Cell Cycle Population Effects in Perturbation Studies},
  author = {O'Duibhir, Eoghan and Lijnzaad, Philip and Benschop, Joris J. and Lenstra, Tineke L. and family=Leenen, given=Dik, prefix=van, useprefix=true and Groot Koerkamp, Marian JA and Margaritis, Thanasis and Brok, Mariel O. and Kemmeren, Patrick and Holstege, Frank CP},
  date = {2014},
  journaltitle = {Molecular systems biology},
  volume = {10},
  number = {6},
  pages = {732},
  abstract = {Growth condition perturbation or gene function disruption are commonly used strategies to study cellular systems. Although it is widely appreciated that such experiments may involve indirect effects, these frequently remain uncharacterized. Here, analysis of functionally unrelated Saccharyomyces cerevisiae deletion strains reveals a common gene expression signature. One property shared by these strains is slower growth, with increased presence of the signature in more slowly growing strains. The slow growth signature is highly similar to the environmental stress response (ESR), an expression response common to diverse environmental perturbations. Both environmental and genetic perturbations result in growth rate changes. These are accompanied by a change in the distribution of cells over different cell cycle phases. Rather than representing a direct expression response in single cells, both the slow growth signature and ESR mainly reflect a redistribution of cells over different cell cycle phases, primarily characterized by an increase in the G1 population. The findings have implications for any study of perturbation that is accompanied by growth rate changes. Strategies to counter these effects are presented and discussed.},
  keywords = {📌,📚,🦌,gene-graph},
  file = {/Users/michaelvolk/Zotero/storage/57NJM4TX/O'Duibhir et al_2014_Cell cycle population effects in perturbation studies.pdf;/Users/michaelvolk/Zotero/storage/FPUF8ZIH/msb.html}
}

@article{oftadehGenomescaleMetabolicModel2021,
  title = {A Genome-Scale Metabolic Model of {{Saccharomyces}} Cerevisiae That Integrates Expression Constraints and Reaction Thermodynamics},
  author = {Oftadeh, Omid and Salvy, Pierre and Masid, Maria and Curvat, Maxime and Miskovic, Ljubisa and Hatzimanikatis, Vassily},
  date = {2021-08-09},
  journaltitle = {Nature Communications},
  shortjournal = {Nat Commun},
  volume = {12},
  number = {1},
  pages = {4790},
  publisher = {Nature Publishing Group},
  issn = {2041-1723},
  doi = {10.1038/s41467-021-25158-6},
  url = {https://www.nature.com/articles/s41467-021-25158-6},
  urldate = {2022-10-16},
  abstract = {Eukaryotic organisms play an important role in industrial biotechnology, from the production of fuels and commodity chemicals to therapeutic proteins. To optimize these industrial systems, a mathematical approach can be used to integrate the description of multiple biological networks into a single model for cell analysis and engineering. One of the most accurate models of biological systems include Expression and Thermodynamics FLux (ETFL), which efficiently integrates RNA and protein synthesis with traditional genome-scale metabolic models. However, ETFL is so far only applicable for E. coli. To adapt this model for Saccharomyces cerevisiae, we developed yETFL, in which we augmented the original formulation with additional considerations for biomass composition, the compartmentalized cellular expression system, and the energetic costs of biological processes. We demonstrated the ability of yETFL to predict maximum growth rate, essential genes, and the phenotype of overflow metabolism. We envision that the presented formulation can be extended to a wide range of eukaryotic organisms to the benefit of academic and industrial research.},
  issue = {1},
  langid = {english},
  keywords = {🦌📚,Biochemical networks,Bioenergetics,Computational models,Computer modelling,Metabolic engineering},
  file = {/Users/michaelvolk/Zotero/storage/7HA2NV4W/Oftadeh et al_2021_A genome-scale metabolic model of Saccharomyces cerevisiae that integrates.pdf;/Users/michaelvolk/Zotero/storage/99DLQN6E/s41467-021-25158-6.html}
}

@article{oftedalSyntheticBiologyGenetic2013,
  title = {Synthetic Biology and Genetic Causation},
  author = {Oftedal, Gry and Parkkinen, Veli-Pekka},
  date = {2013-06-01},
  journaltitle = {Studies in History and Philosophy of Science Part C: Studies in History and Philosophy of Biological and Biomedical Sciences},
  shortjournal = {Studies in History and Philosophy of Science Part C: Studies in History and Philosophy of Biological and Biomedical Sciences},
  series = {Philosophical {{Perspectives}} on {{Synthetic Biology}}},
  volume = {44},
  number = {2},
  pages = {208--216},
  issn = {1369-8486},
  doi = {10.1016/j.shpsc.2013.03.016},
  url = {https://www.sciencedirect.com/science/article/pii/S1369848613000307},
  urldate = {2024-07-04},
  abstract = {Synthetic biology research is often described in terms of programming cells through the introduction of synthetic genes. Genetic material is seemingly attributed with a high level of causal responsibility. We discuss genetic causation in synthetic biology and distinguish three gene concepts differing in their assumptions of genetic control. We argue that synthetic biology generally employs a difference-making approach to establishing genetic causes, and that this approach does not commit to a specific notion of genetic program or genetic control. Still, we suggest that a strong program concept of genetic material can be used as a successful heuristic in certain areas of synthetic biology. Its application requires control of causal context, and may stand in need of a modular decomposition of the target system. We relate different modularity concepts to the discussion of genetic causation and point to possible advantages of and important limitations to seeking modularity in synthetic biology systems.},
  keywords = {Causal selection,Difference-making,Genetic causation,Genetic program,Modularity,Synthetic biology},
  annotation = {6 citations (Semantic Scholar/DOI) [2024-07-04]},
  file = {/Users/michaelvolk/Zotero/storage/QX3XSHIB/Oftedal_Parkkinen_2013_Synthetic biology and genetic causation.pdf;/Users/michaelvolk/Zotero/storage/HMJVMN5G/S1369848613000307.html}
}

@article{ohnukiHighdimensionalSinglecellPhenotyping2018,
  title = {High-Dimensional Single-Cell Phenotyping Reveals Extensive Haploinsufficiency},
  author = {Ohnuki, Shinsuke and Ohya, Yoshikazu},
  date = {2018},
  journaltitle = {PLoS biology},
  volume = {16},
  number = {5},
  pages = {e2005130},
  publisher = {Public Library of Science San Francisco, CA USA},
  url = {https://journals.plos.org/plosbiology/article?id=10.1371/journal.pbio.2005130},
  urldate = {2025-04-30},
  file = {/Users/michaelvolk/Zotero/storage/3E25AL52/Ohnuki_Ohya_2018_High-dimensional single-cell phenotyping reveals extensive haploinsufficiency.pdf}
}

@article{ohnukiHighthroughputPlatformYeast2022,
  title = {High-Throughput Platform for Yeast Morphological Profiling Predicts the Targets of Bioactive Compounds},
  author = {Ohnuki, Shinsuke and Ogawa, Itsuki and Itto-Nakama, Kaori and Lu, Fachuang and Ranjan, Ashish and Kabbage, Mehdi and Gebre, Abraham Abera and Yamashita, Masao and Li, Sheena C. and Yashiroda, Yoko and Yoshida, Satoshi and Usui, Takeo and Piotrowski, Jeff S. and Andrews, Brenda J. and Boone, Charles and Brown, Grant W. and Ralph, John and Ohya, Yoshikazu},
  date = {2022-01-27},
  journaltitle = {npj Systems Biology and Applications},
  shortjournal = {npj Syst Biol Appl},
  volume = {8},
  number = {1},
  pages = {1--16},
  issn = {2056-7189},
  doi = {10.1038/s41540-022-00212-1},
  url = {https://www.nature.com/articles/s41540-022-00212-1},
  urldate = {2024-06-03},
  abstract = {Morphological profiling is an omics-based approach for predicting intracellular targets of chemical compounds in which the dose-dependent morphological changes induced by the compound are systematically compared to the morphological changes in gene-deleted cells. In this study, we developed a reliable high-throughput (HT) platform for yeast morphological profiling using drug-hypersensitive strains to minimize compound use, HT microscopy to speed up data generation and analysis, and a generalized linear model to predict targets with high reliability. We first conducted a proof-of-concept study using six compounds with known targets: bortezomib, hydroxyurea, methyl methanesulfonate, benomyl, tunicamycin, and echinocandin B. Then we applied our platform to predict the mechanism of action of a novel diferulate-derived compound, poacidiene. Morphological profiling of poacidiene implied that it affects the DNA damage response, which genetic analysis confirmed. Furthermore, we found that poacidiene inhibits the growth of phytopathogenic fungi, implying applications as an effective antifungal agent. Thus, our platform is a new whole-cell target prediction tool for drug discovery.},
  langid = {english},
  keywords = {Antimicrobials,Cell biology,Screening,Single-cell imaging,Target identification},
  annotation = {2 citations (Semantic Scholar/DOI) [2024-06-03]},
  file = {/Users/michaelvolk/Zotero/storage/5WRMCY46/Ohnuki et al. - 2022 - High-throughput platform for yeast morphological profiling predicts the targets of bioactive compounds.pdf}
}

@article{ohyaHighdimensionalLargescalePhenotyping2005a,
  title = {High-Dimensional and Large-Scale Phenotyping of Yeast Mutants},
  author = {Ohya, Yoshikazu and Sese, Jun and Yukawa, Masashi and Sano, Fumi and Nakatani, Yoichiro and Saito, Taro L. and Saka, Ayaka and Fukuda, Tomoyuki and Ishihara, Satoru and Oka, Satomi and Suzuki, Genjiro and Watanabe, Machika and Hirata, Aiko and Ohtani, Miwaka and Sawai, Hiroshi and Fraysse, Nicolas and Latgé, Jean-Paul and François, Jean M. and Aebi, Markus and Tanaka, Seiji and Muramatsu, Sachiko and Araki, Hiroyuki and Sonoike, Kintake and Nogami, Satoru and Morishita, Shinichi},
  date = {2005-12-27},
  journaltitle = {Proceedings of the National Academy of Sciences},
  volume = {102},
  number = {52},
  pages = {19015--19020},
  publisher = {Proceedings of the National Academy of Sciences},
  doi = {10.1073/pnas.0509436102},
  url = {https://www.pnas.org/doi/full/10.1073/pnas.0509436102},
  urldate = {2023-11-22},
  abstract = {One of the most powerful techniques for attributing functions to genes in uni- and multicellular organisms is comprehensive analysis of mutant traits. In this study, systematic and quantitative analyses of mutant traits are achieved in the budding yeast Saccharomyces cerevisiae by investigating morphological phenotypes. Analysis of fluorescent microscopic images of triple-stained cells makes it possible to treat morphological variations as quantitative traits. Deletion of nearly half of the yeast genes not essential for growth affects these morphological traits. Similar morphological phenotypes are caused by deletions of functionally related genes, enabling a functional assignment of a locus to a specific cellular pathway. The high-dimensional phenotypic analysis of defined yeast mutant strains provides another step toward attributing gene function to all of the genes in the yeast genome.},
  annotation = {286 citations (Semantic Scholar/DOI) [2023-11-22]},
  file = {/Users/michaelvolk/Zotero/storage/YNBYMHPI/Ohya et al_2005_High-dimensional and large-scale phenotyping of yeast mutants.pdf}
}

@article{oliverPetriPlatesPetri2022,
  title = {From {{Petri Plates}} to {{Petri Nets}}, a Revolution in Yeast Biology},
  author = {Oliver, Stephen G},
  date = {2022-01-01},
  journaltitle = {FEMS Yeast Research},
  shortjournal = {FEMS Yeast Research},
  volume = {22},
  number = {1},
  pages = {foac008},
  issn = {1567-1356},
  doi = {10.1093/femsyr/foac008},
  url = {https://doi.org/10.1093/femsyr/foac008},
  urldate = {2022-04-15},
  abstract = {In the beginning was… the genome.The 30th of January, 1991 found me outside Temple Underground Station on the Thames Embankment in London. John Sgouros of the Martinsried Institute for Protein Sciences, who had flown over from Munich that morning, emerged from the station carrying seven A0 sheets in a roll. They were copies of Figure 1 for the paper ‘The complete DNA sequence of yeast chromosome III’, for which we were determined to get a 1991 submission date. We walked around the corner to the Nature offices in Little Essex Street and handed in these giant Figures together with envelopes containing the manuscript and the other Figures, which I had brought down from Manchester. Nature then lost the copies of Figure 1 but, by 27th March 1992, the paper was accepted and appeared in the journal on the 7th of May 1992 (Oliver et al. 1992). This paper reported the first complete DNA sequence of a chromosome from any organism and, with it, everything changed—certainly for me, for yeast genetics, but also for the wider biomedical research community's view of the value of genome sequencing. The complete sequence of this chromosome taught us some important lessons in two major areas.},
  keywords = {📰-chemical-reviews-review,🦌✅},
  annotation = {0 citations (Semantic Scholar/DOI) [2022-11-26]\\
0 citations (Crossref) [2022-04-15]},
  file = {/Users/michaelvolk/Zotero/storage/7ZUQ77FC/Oliver_2022_From Petri Plates to Petri Nets, a revolution in yeast biology.pdf;/Users/michaelvolk/Zotero/storage/PAWD87HS/6526310.html}
}

@article{orthWhatFluxBalance2010,
  title = {What Is Flux Balance Analysis?},
  author = {Orth, Jeffrey D. and Thiele, Ines and Palsson, Bernhard Ø},
  date = {2010-03},
  journaltitle = {Nature Biotechnology},
  shortjournal = {Nat Biotechnol},
  volume = {28},
  number = {3},
  pages = {245--248},
  publisher = {Nature Publishing Group},
  issn = {1546-1696},
  doi = {10.1038/nbt.1614},
  url = {https://www.nature.com/articles/nbt.1614},
  urldate = {2023-04-05},
  abstract = {Flux balance analysis is a mathematical approach for analyzing the flow of metabolites through a metabolic network. This primer covers the theoretical basis of the approach, several practical examples and a software toolbox for performing the calculations.},
  issue = {3},
  langid = {english},
  keywords = {Biochemical reaction networks,Biotechnology,Metabolism},
  annotation = {3031 citations (Semantic Scholar/DOI) [2023-04-05]},
  file = {/Users/michaelvolk/Zotero/storage/UF4YAWQT/Orth et al_2010_What is flux balance analysis.pdf}
}

@article{ostdiekDeepSetAuto2022,
  title = {Deep {{Set Auto Encoders}} for {{Anomaly Detection}} in {{Particle Physics}}},
  author = {Ostdiek, Bryan},
  date = {2022-01-31},
  journaltitle = {SciPost Physics},
  shortjournal = {SciPost Phys.},
  volume = {12},
  number = {1},
  pages = {045},
  issn = {2542-4653},
  doi = {10.21468/SciPostPhys.12.1.045},
  url = {https://scipost.org/10.21468/SciPostPhys.12.1.045},
  urldate = {2023-10-09},
  abstract = {There is an increased interest in model agnostic search strategies for physics beyond the standard model at the Large Hadron Collider. We introduce a Deep Set Variational Autoencoder and present results on the Dark Machines Anomaly Score Challenge. We find that the method attains the best anomaly detection ability when there is no decoding step for the network, and the anomaly score is based solely on the representation within the encoded latent space. This method was one of the top-performing models in the Dark Machines Challenge, both for the open data sets as well as the blinded data sets.},
  langid = {english},
  annotation = {23 citations (Semantic Scholar/DOI) [2023-10-09]},
  file = {/Users/michaelvolk/Zotero/storage/GGG3AHER/Ostdiek - 2022 - Deep Set Auto Encoders for Anomaly Detection in Pa.pdf}
}

@article{outeiralCodonLanguageEmbeddings2024,
  title = {Codon Language Embeddings Provide Strong Signals for Use in Protein Engineering},
  author = {Outeiral, Carlos and Deane, Charlotte M.},
  date = {2024-02},
  journaltitle = {Nature Machine Intelligence},
  shortjournal = {Nat Mach Intell},
  volume = {6},
  number = {2},
  pages = {170--179},
  publisher = {Nature Publishing Group},
  issn = {2522-5839},
  doi = {10.1038/s42256-024-00791-0},
  url = {https://www.nature.com/articles/s42256-024-00791-0},
  urldate = {2024-03-31},
  abstract = {Protein representations from deep language models have yielded state-of-the-art performance across many tasks in computational protein engineering. In recent years, progress has primarily focused on parameter count, with recent models’ capacities surpassing the size of the very datasets they were trained on. Here we propose an alternative direction. We show that large language models trained on codons, instead of amino acid sequences, provide high-quality representations that outperform comparable state-of-the-art models across a variety of tasks. In some tasks, such as species recognition, prediction of protein and transcript abundance or melting point estimation, we show that a language model trained on codons outperforms every other published protein language model, including some that contain over 50 times more parameters. These results indicate that, in addition to commonly studied scale and model complexity, the information content of biological data provides an orthogonal direction to improve the power of machine learning in biology.},
  langid = {english},
  keywords = {Genomics,Protein folding,Protein function predictions},
  file = {/Users/michaelvolk/Zotero/storage/HLUW27I8/Outeiral_Deane_2024_Codon language embeddings provide strong signals for use in protein engineering.pdf}
}

@book{palssonSystemsBiology2015,
  title = {Systems {{Biology}}: {{Constraint-based Reconstruction}} and {{Analysis}}},
  author = {Palsson, Bernhard},
  date = {2015-01-26},
  eprint = {XvxDBgAAQBAJ},
  eprinttype = {googlebooks},
  publisher = {Cambridge University Press},
  abstract = {Recent technological advances have enabled comprehensive determination of the molecular composition of living cells. The chemical interactions between many of these molecules are known, giving rise to genome-scale reconstructed biochemical reaction networks underlying cellular functions. Mathematical descriptions of the totality of these chemical interactions lead to genome-scale models that allow the computation of physiological functions. Reflecting these recent developments, this textbook explains how such quantitative and computable genotype-phenotype relationships are built using a genome-wide basis of information about the gene portfolio of a target organism. It describes how biological knowledge is assembled to reconstruct biochemical reaction networks, the formulation of computational models of biological functions, and how these models can be used to address key biological questions and enable predictive biology. Developed through extensive classroom use, the book is designed to provide students with a solid conceptual framework and an invaluable set of modeling tools and computational approaches.},
  isbn = {978-1-107-03885-1},
  langid = {english},
  pagetotal = {551},
  keywords = {Medical / General,Science / Biotechnology,Science / Chemistry / Industrial & Technical,Science / Life Sciences / Biochemistry,Science / Life Sciences / Biology,Science / Life Sciences / Genetics & Genomics,Technology & Engineering / Biomedical,Technology & Engineering / Chemical & Biochemical},
  file = {/Users/michaelvolk/Zotero/storage/X5YC6L83/Palsson - 2015 - Systems Biology Constraint-based Reconstruction a.pdf}
}

@article{pandiVersatileActiveLearning2022a,
  title = {A Versatile Active Learning Workflow for Optimization of Genetic and Metabolic Networks},
  author = {Pandi, Amir and Diehl, Christoph and Yazdizadeh Kharrazi, Ali and Scholz, Scott A. and Bobkova, Elizaveta and Faure, Léon and Nattermann, Maren and Adam, David and Chapin, Nils and Foroughijabbari, Yeganeh and Moritz, Charles and Paczia, Nicole and Cortina, Niña Socorro and Faulon, Jean-Loup and Erb, Tobias J.},
  date = {2022-07-05},
  journaltitle = {Nature Communications},
  shortjournal = {Nat Commun},
  volume = {13},
  number = {1},
  pages = {3876},
  publisher = {Nature Publishing Group},
  issn = {2041-1723},
  doi = {10.1038/s41467-022-31245-z},
  url = {https://www.nature.com/articles/s41467-022-31245-z},
  urldate = {2023-09-29},
  abstract = {Optimization of biological networks is often limited by wet lab labor and cost, and the lack of convenient computational tools. Here, we describe METIS, a versatile active machine learning workflow with a simple online interface for the data-driven optimization of biological targets with minimal experiments. We demonstrate our workflow for various applications, including cell-free transcription and translation, genetic circuits, and a 27-variable synthetic CO2-fixation cycle (CETCH cycle), improving these systems between one and two orders of magnitude. For the CETCH cycle, we explore 1025 conditions with only 1,000 experiments to yield the most efficient CO2-fixation cascade described to date. Beyond optimization, our workflow also quantifies the relative importance of individual factors to the performance of a system identifying unknown interactions and bottlenecks. Overall, our workflow opens the way for convenient optimization and prototyping of genetic and metabolic networks with customizable adjustments according to user experience, experimental setup, and laboratory facilities.},
  issue = {1},
  langid = {english},
  keywords = {Biochemical reaction networks,Genetic circuit engineering,Metabolic engineering,Synthetic biology},
  annotation = {13 citations (Semantic Scholar/DOI) [2023-09-29]},
  file = {/Users/michaelvolk/Zotero/storage/I8L4JHA2/Pandi et al_2022_A versatile active learning workflow for optimization of genetic and metabolic.pdf}
}

@inproceedings{pandyLearningGraphSearch2022,
  title = {Learning {{Graph Search Heuristics}}},
  booktitle = {Proceedings of the {{First Learning}} on {{Graphs Conference}}},
  author = {Pándy, Michal and Qiu, Weikang and Corso, Gabriele and Veličković, Petar and Ying, Zhitao and Leskovec, Jure and Lio, Pietro},
  date = {2022-12-21},
  pages = {10:1-10:13},
  publisher = {PMLR},
  issn = {2640-3498},
  url = {https://proceedings.mlr.press/v198/pandy22a.html},
  urldate = {2025-03-01},
  abstract = {Searching for a path between two nodes in a graph is one of the most well-studied and fundamental problems in computer science. In numerous domains such as robotics, AI, or biology, practitioners develop search heuristics to accelerate their pathfinding algorithms. However, it is a laborious and complex process to hand-design heuristics based on the problem and the structure of a given use case. Here we present PHIL (Path Heuristic with Imitation Learning), a novel neural architecture and a training algorithm for discovering graph search and navigation heuristics from data by leveraging recent advances in imitation learning and graph representation learning. At training time, we aggregate datasets of search trajectories and ground-truth shortest path distances, which we use to train a specialized graph neural network-based heuristic function using backpropagation through steps of the pathfinding process. Our heuristic function learns graph embeddings useful for inferring node distances, runs in constant time independent of graph sizes, and can be easily incorporated in an algorithm such as A\textbackslash ast  at test time. Experiments show that PHIL reduces the number of explored nodes compared to state-of-the-art methods on benchmark datasets by 58.5\% on average, can be directly applied in diverse graphs ranging from biological networks to road networks, and allows for fast planning in time-critical robotics domains.},
  eventtitle = {Learning on {{Graphs Conference}}},
  langid = {english},
  file = {/Users/michaelvolk/Zotero/storage/JPLXSVPD/Pándy et al_2022_Learning Graph Search Heuristics.pdf}
}

@article{panHierarchicalCombinationFactors2011,
  title = {A {{Hierarchical Combination}} of {{Factors Shapes}} the {{Genome-wide Topography}} of {{Yeast Meiotic Recombination Initiation}}},
  author = {Pan, Jing and Sasaki, Mariko and Kniewel, Ryan and Murakami, Hajime and Blitzblau, Hannah G. and Tischfield, Sam E. and Zhu, Xuan and Neale, Matthew J. and Jasin, Maria and Socci, Nicholas D. and Hochwagen, Andreas and Keeney, Scott},
  date = {2011-03-04},
  journaltitle = {Cell},
  shortjournal = {Cell},
  volume = {144},
  number = {5},
  eprint = {21376234},
  eprinttype = {pmid},
  pages = {719--731},
  publisher = {Elsevier},
  issn = {0092-8674, 1097-4172},
  doi = {10.1016/j.cell.2011.02.009},
  url = {https://www.cell.com/cell/abstract/S0092-8674(11)00123-1},
  urldate = {2023-08-01},
  langid = {english},
  keywords = {SGD.data},
  annotation = {484 citations (Semantic Scholar/DOI) [2023-08-01]},
  file = {/Users/michaelvolk/Zotero/storage/599W5ZPM/Pan et al_2011_A Hierarchical Combination of Factors Shapes the Genome-wide Topography of.pdf}
}

@unpublished{papamarkouPositionPaperChallenges2024,
  title = {Position Paper: {{Challenges}} and Opportunities in Topological Deep Learning},
  shorttitle = {Position Paper},
  author = {Papamarkou, Theodore and Birdal, Tolga and Bronstein, Michael and Carlsson, Gunnar and Curry, Justin and Gao, Yue and Hajij, Mustafa and Kwitt, Roland and Liò, Pietro and Di Lorenzo, Paolo},
  date = {2024},
  volume = {24},
  eprint = {2402.08871},
  eprinttype = {arXiv},
  pages = {25},
  url = {https://scholar9.com/publication/15b1964641a8fa968b2e1f5d42b5a8bf.pdf},
  urldate = {2025-02-27},
  file = {/Users/michaelvolk/Zotero/storage/AXEK9XWN/Papamarkou et al_2024_Position paper.pdf}
}

@online{papamarkouPositionTopologicalDeep2024,
  title = {Position: {{Topological Deep Learning}} Is the {{New Frontier}} for {{Relational Learning}}},
  shorttitle = {Position},
  author = {Papamarkou, Theodore and Birdal, Tolga and Bronstein, Michael and Carlsson, Gunnar and Curry, Justin and Gao, Yue and Hajij, Mustafa and Kwitt, Roland and Liò, Pietro and Lorenzo, Paolo Di and Maroulas, Vasileios and Miolane, Nina and Nasrin, Farzana and Ramamurthy, Karthikeyan Natesan and Rieck, Bastian and Scardapane, Simone and Schaub, Michael T. and Veličković, Petar and Wang, Bei and Wang, Yusu and Wei, Guo-Wei and Zamzmi, Ghada},
  date = {2024-08-06},
  eprint = {2402.08871},
  eprinttype = {arXiv},
  eprintclass = {cs},
  doi = {10.48550/arXiv.2402.08871},
  url = {http://arxiv.org/abs/2402.08871},
  urldate = {2025-02-27},
  abstract = {Topological deep learning (TDL) is a rapidly evolving field that uses topological features to understand and design deep learning models. This paper posits that TDL is the new frontier for relational learning. TDL may complement graph representation learning and geometric deep learning by incorporating topological concepts, and can thus provide a natural choice for various machine learning settings. To this end, this paper discusses open problems in TDL, ranging from practical benefits to theoretical foundations. For each problem, it outlines potential solutions and future research opportunities. At the same time, this paper serves as an invitation to the scientific community to actively participate in TDL research to unlock the potential of this emerging field.},
  pubstate = {prepublished},
  keywords = {Computer Science - Machine Learning,Statistics - Machine Learning},
  annotation = {18 citations (Semantic Scholar/arXiv) [2025-02-27]},
  file = {/Users/michaelvolk/Zotero/storage/VCDZNVF6/Papamarkou et al_2024_Position.pdf;/Users/michaelvolk/Zotero/storage/GP7GTXV3/2402.html}
}

@online{papamarkouPositionTopologicalDeep2024a,
  title = {Position: {{Topological Deep Learning}} Is the {{New Frontier}} for {{Relational Learning}}},
  shorttitle = {Position},
  author = {Papamarkou, Theodore and Birdal, Tolga and Bronstein, Michael and Carlsson, Gunnar and Curry, Justin and Gao, Yue and Hajij, Mustafa and Kwitt, Roland and Liò, Pietro and Lorenzo, Paolo Di and Maroulas, Vasileios and Miolane, Nina and Nasrin, Farzana and Ramamurthy, Karthikeyan Natesan and Rieck, Bastian and Scardapane, Simone and Schaub, Michael T. and Veličković, Petar and Wang, Bei and Wang, Yusu and Wei, Guo-Wei and Zamzmi, Ghada},
  date = {2024-08-06},
  eprint = {2402.08871},
  eprinttype = {arXiv},
  eprintclass = {cs},
  doi = {10.48550/arXiv.2402.08871},
  url = {http://arxiv.org/abs/2402.08871},
  urldate = {2025-03-01},
  abstract = {Topological deep learning (TDL) is a rapidly evolving field that uses topological features to understand and design deep learning models. This paper posits that TDL is the new frontier for relational learning. TDL may complement graph representation learning and geometric deep learning by incorporating topological concepts, and can thus provide a natural choice for various machine learning settings. To this end, this paper discusses open problems in TDL, ranging from practical benefits to theoretical foundations. For each problem, it outlines potential solutions and future research opportunities. At the same time, this paper serves as an invitation to the scientific community to actively participate in TDL research to unlock the potential of this emerging field.},
  pubstate = {prepublished},
  keywords = {Computer Science - Machine Learning,Statistics - Machine Learning},
  annotation = {18 citations (Semantic Scholar/arXiv) [2025-03-01]},
  file = {/Users/michaelvolk/Zotero/storage/KLV2I6K9/Papamarkou et al_2024_Position.pdf;/Users/michaelvolk/Zotero/storage/VZ5E896A/2402.html}
}

@article{papiligaoSINCERITIESInferringGene2018,
  title = {{{SINCERITIES}}: Inferring Gene Regulatory Networks from Time-Stamped Single Cell Transcriptional Expression Profiles},
  shorttitle = {{{SINCERITIES}}},
  author = {Papili Gao, Nan and Ud-Dean, S M Minhaz and Gandrillon, Olivier and Gunawan, Rudiyanto},
  date = {2018-01-01},
  journaltitle = {Bioinformatics},
  shortjournal = {Bioinformatics},
  volume = {34},
  number = {2},
  pages = {258--266},
  issn = {1367-4803},
  doi = {10.1093/bioinformatics/btx575},
  url = {https://doi.org/10.1093/bioinformatics/btx575},
  urldate = {2023-10-14},
  abstract = {Single cell transcriptional profiling opens up a new avenue in studying the functional role of cell-to-cell variability in physiological processes. The analysis of single cell expression profiles creates new challenges due to the distributive nature of the data and the stochastic dynamics of gene transcription process. The reconstruction of gene regulatory networks (GRNs) using single cell transcriptional profiles is particularly challenging, especially when directed gene-gene relationships are desired.We developed SINCERITIES (SINgle CEll Regularized Inference using TIme-stamped Expression profileS) for the inference of GRNs from single cell transcriptional profiles. We focused on time-stamped cross-sectional expression data, commonly generated from transcriptional profiling of single cells collected at multiple time points after cell stimulation. SINCERITIES recovers directed regulatory relationships among genes by employing regularized linear regression (ridge regression), using temporal changes in the distributions of gene expressions. Meanwhile, the modes of the gene regulations (activation and repression) come from partial correlation analyses between pairs of genes. We demonstrated the efficacy of SINCERITIES in inferring GRNs using in silico time-stamped single cell expression data and single cell transcriptional profiles of THP-1 monocytic human leukemia cells. The case studies showed that SINCERITIES could provide accurate GRN predictions, significantly better than other GRN inference algorithms such as TSNI, GENIE3 and JUMP3. Moreover, SINCERITIES has a low computational complexity and is amenable to problems of extremely large dimensionality. Finally, an application of SINCERITIES to single cell expression data of T2EC chicken erythrocytes pointed to BATF as a candidate novel regulator of erythroid development.MATLAB and R version of SINCERITIES are freely available from the following websites: http://www.cabsel.ethz.ch/tools/sincerities.html and https://github.com/CABSEL/SINCERITIES. The single cell THP-1 and T2EC transcriptional profiles are available from the original publications (Kouno et al., 2013; Richard et al., 2016). The in silico single cell data are available on SINCERITIES websites.Supplementary data are available at Bioinformatics online.},
  annotation = {127 citations (Semantic Scholar/DOI) [2023-10-14]},
  file = {/Users/michaelvolk/Zotero/storage/TSM9FSFG/Papili Gao et al_2018_SINCERITIES.pdf;/Users/michaelvolk/Zotero/storage/MZA9N9UR/4158033.html}
}

@article{pavelComplexityBiologicalControl2022,
  title = {The Complexity of Biological Control Systems: {{An}} Autophagy Case Study},
  shorttitle = {The Complexity of Biological Control Systems},
  author = {Pavel, Mariana and Tanasa, Radu and Park, So Jung and Rubinsztein, David C.},
  date = {2022},
  journaltitle = {BioEssays},
  volume = {44},
  number = {3},
  pages = {2100224},
  issn = {1521-1878},
  doi = {10.1002/bies.202100224},
  url = {https://onlinelibrary.wiley.com/doi/abs/10.1002/bies.202100224},
  urldate = {2024-07-04},
  abstract = {Autophagy and YAP1-WWTR1/TAZ signalling are tightly linked in a complex control system of forward and feedback pathways which determine different cellular outcomes in differing cell types at different time-points after perturbations. Here we extend our previous experimental and modelling approaches to consider two possibilities. First, we have performed additional mathematical modelling to explore how the autophagy-YAP1 crosstalk may be controlled by posttranslational modifications of components of the pathways. Second, since analogous contrasting results have also been reported for autophagy as a regulator of other transduction pathways engaged in tumorigenesis (Wnt/β-catenin, TGF-β/Smads, NF-kB or XIAP/cIAPs), we have considered if such discrepancies may be explicable through situations involving competing pathways and feedback loops in different cell types, analogous to the autophagy-YAP/TAZ situation. Since distinct posttranslational modifications dominate those pathways in distinct cells, these need to be understood to enable appropriate cell type-specific therapeutic strategies for cancers and other diseases.},
  langid = {english},
  keywords = {autophagy,cell heterogeneity,mathematical model,precision medicine,transduction pathways,YAP1 signalling},
  annotation = {3 citations (Semantic Scholar/DOI) [2024-07-04]},
  file = {/Users/michaelvolk/Zotero/storage/RVVHVASH/Pavel et al. - 2022 - The complexity of biological control systems An a.pdf;/Users/michaelvolk/Zotero/storage/35857VRE/bies.html}
}

@article{pavlovicImprovingGeneralizationMachine2024b,
  title = {Improving Generalization of Machine Learning-Identified Biomarkers Using Causal Modelling with Examples from Immune Receptor Diagnostics},
  author = {Pavlović, Milena and Al Hajj, Ghadi S. and Kanduri, Chakravarthi and Pensar, Johan and Wood, Mollie E. and Sollid, Ludvig M. and Greiff, Victor and Sandve, Geir K.},
  date = {2024-01},
  journaltitle = {Nature Machine Intelligence},
  shortjournal = {Nat Mach Intell},
  volume = {6},
  number = {1},
  pages = {15--24},
  publisher = {Nature Publishing Group},
  issn = {2522-5839},
  doi = {10.1038/s42256-023-00781-8},
  url = {https://www.nature.com/articles/s42256-023-00781-8},
  urldate = {2024-07-16},
  abstract = {Machine learning is increasingly used to discover diagnostic and prognostic biomarkers from high-dimensional molecular data. However, a variety of factors related to experimental design may affect the ability to learn generalizable and clinically applicable diagnostics. Here we argue that a causal perspective improves the identification of these challenges and formalizes their relation to the robustness and generalization of machine learning-based diagnostics. To make for a concrete discussion, we focus on a specific, recently established high-dimensional biomarker—adaptive immune receptor repertoires (AIRRs). Through simulations, we illustrate how major biological and experimental factors of the AIRR domain may influence the learned biomarkers. In conclusion, we argue that causal modelling improves machine learning-based biomarker robustness by identifying stable relations between variables and guiding the adjustment of the relations and variables that vary between populations.},
  langid = {english},
  keywords = {Adaptive immunity,Biomarkers,Machine learning,Statistical methods},
  annotation = {3 citations (Semantic Scholar/DOI) [2024-07-15]},
  file = {/Users/michaelvolk/Zotero/storage/5AWFXHTV/Pavlović et al_2024_Improving generalization of machine learning-identified biomarkers using causal.pdf}
}

@article{pengSpatialTemporalIncidence2020,
  title = {Spatial Temporal Incidence Dynamic Graph Neural Networks for Traffic Flow Forecasting},
  author = {Peng, Hao and Wang, Hongfei and Du, Bowen and Bhuiyan, Md Zakirul Alam and Ma, Hongyuan and Liu, Jianwei and Wang, Lihong and Yang, Zeyu and Du, Linfeng and Wang, Senzhang and Yu, Philip S.},
  date = {2020-06-01},
  journaltitle = {Information Sciences},
  shortjournal = {Information Sciences},
  volume = {521},
  pages = {277--290},
  issn = {0020-0255},
  doi = {10.1016/j.ins.2020.01.043},
  url = {https://www.sciencedirect.com/science/article/pii/S0020025520300451},
  urldate = {2023-04-21},
  abstract = {Accurate and real-time traffic passenger flows forecasting at transportation hubs, such as subway/bus stations, is a practical application and of great significance for urban traffic planning, control, guidance, etc. Recently deep learning based methods are promised to learn the spatial-temporal features from high non-linearity and complexity of traffic flows. However, it is still very challenging to handle so much complex factors including the urban transportation network topological structures and the laws of traffic flows with spatial and temporal dependencies. Considering both the static hybrid urban transportation network structures and dynamic spatial-temporal relationships among stations from historical traffic passenger flows, a more effective and fine-grained spatial-temporal features learning framework is necessary. In this paper, we propose a novel spatial-temporal incidence dynamic graph neural networks framework for urban traffic passenger flows prediction. We first model dynamic traffic station relationships over time as spatial-temporal incidence dynamic graph structures based on historically traffic passenger flows. Then we design a novel dynamic graph recurrent convolutional neural network, namely Dynamic-GRCNN, to learn the spatial-temporal features representation for urban transportation network topological structures and transportation hubs. To fully utilize the historical passenger flows, we sample the short-term, medium-term and long-term historical traffic data in training, which can capture the periodicity and trend of the traffic passenger flows at different stations. We conduct extensive experiments on different types of traffic passenger flows datasets including subway, taxi and bus flows in Beijing. The results show that the proposed Dynamic-GRCNN effectively captures comprehensive spatial-temporal correlations significantly and outperforms both traditional and deep learning based urban traffic passenger flows prediction methods.},
  langid = {english},
  keywords = {Graph convolutional neural network,Importance sampling,LSTM,Traffic passenger flows prediction,Urban computing},
  annotation = {126 citations (Semantic Scholar/DOI) [2023-04-21]},
  file = {/Users/michaelvolk/Zotero/storage/JT6NH9BN/Peng et al_2020_Spatial temporal incidence dynamic graph neural networks for traffic flow.pdf;/Users/michaelvolk/Zotero/storage/RP93KZRF/S0020025520300451.html}
}

@article{perssonAdaptationYeastGene2022,
  title = {Adaptation of the Yeast Gene Knockout Collection Is Near-Perfectly Predicted by Fitness and Diminishing Return Epistasis},
  author = {Persson, Karl and Stenberg, Simon and Tamás, Markus J and Warringer, Jonas},
  date = {2022-11-01},
  journaltitle = {G3 Genes|Genomes|Genetics},
  shortjournal = {G3 Genes|Genomes|Genetics},
  volume = {12},
  number = {11},
  pages = {jkac240},
  issn = {2160-1836},
  doi = {10.1093/g3journal/jkac240},
  url = {https://doi.org/10.1093/g3journal/jkac240},
  urldate = {2025-02-27},
  abstract = {Adaptive evolution of clonally dividing cells and microbes is the ultimate cause of cancer and infectious diseases. The possibility of constraining the adaptation of cell populations, by inhibiting proteins enhancing the evolvability, has therefore attracted interest. However, our current understanding of how genes influence adaptation kinetics is limited, partly because accurately measuring adaptation for many cell populations is challenging. We used a high-throughput adaptive laboratory evolution platform to track the adaptation of \&gt;18,000 cell populations corresponding to single-gene deletion strains in the haploid yeast deletion collection. We report that the preadaptation fitness of gene knockouts near-perfectly (R2= 0.91) predicts their adaptation to arsenic, leaving at the most a marginal role for dedicated evolvability gene functions. We tracked the adaptation of another \&gt;23,000 gene knockout populations to a diverse range of selection pressures and generalized the almost perfect (R2=0.72–0.98) capacity of preadaptation fitness to predict adaptation. We also reconstructed mutations in FPS1, ASK10, and ARR3, which together account for almost all arsenic adaptation in wild-type cells, in gene deletions covering a broad fitness range and show that the predictability of arsenic adaptation can be understood as a by global epistasis, where excluding arsenic is more beneficial to arsenic unfit cells. The paucity of genes with a meaningful evolvability effect on adaptation diminishes the prospects of developing adjuvant drugs aiming to slow antimicrobial and chemotherapy resistance.},
  keywords = {torchcell.epistasis,torchcell.epistasis.importance,torchcell.gene-interaction},
  annotation = {7 citations (Semantic Scholar/DOI) [2025-02-27]},
  file = {/Users/michaelvolk/Zotero/storage/TJZGCDTU/Persson et al_2022_Adaptation of the yeast gene knockout collection is near-perfectly predicted by.pdf;/Users/michaelvolk/Zotero/storage/P94U7C9Q/6694849.html}
}

@article{peterGenomeEvolution10112018,
  title = {Genome Evolution across 1,011 {{Saccharomyces}} Cerevisiae Isolates},
  author = {Peter, Jackson and De Chiara, Matteo and Friedrich, Anne and Yue, Jia-Xing and Pflieger, David and Bergström, Anders and Sigwalt, Anastasie and Barre, Benjamin and Freel, Kelle and Llored, Agnès and Cruaud, Corinne and Labadie, Karine and Aury, Jean-Marc and Istace, Benjamin and Lebrigand, Kevin and Barbry, Pascal and Engelen, Stefan and Lemainque, Arnaud and Wincker, Patrick and Liti, Gianni and Schacherer, Joseph},
  date = {2018-04},
  journaltitle = {Nature},
  volume = {556},
  number = {7701},
  pages = {339--344},
  publisher = {Nature Publishing Group},
  issn = {1476-4687},
  doi = {10.1038/s41586-018-0030-5},
  url = {https://www.nature.com/articles/s41586-018-0030-5},
  urldate = {2025-04-24},
  abstract = {Large-scale population genomic surveys are essential to explore the phenotypic diversity of natural populations. Here we report the whole-genome sequencing and phenotyping of 1,011 Saccharomyces cerevisiae isolates, which together provide an accurate evolutionary picture of the genomic variants that shape the species-wide phenotypic landscape of this yeast. Genomic analyses support a single ‘out-of-China’ origin for this species, followed by several independent domestication events. Although domesticated isolates exhibit high variation in ploidy, aneuploidy and genome content, genome evolution in wild isolates is mainly driven by the accumulation of single nucleotide polymorphisms. A common feature is the extensive loss of heterozygosity, which represents an essential source of inter-individual variation in this mainly asexual species. Most of the single nucleotide polymorphisms, including experimentally identified functional polymorphisms, are present at very low frequencies. The largest numbers of variants identified by genome-wide association are copy-number changes, which have a greater phenotypic effect than do single nucleotide polymorphisms. This resource will guide future population genomics and genotype–phenotype studies in this classic model system.},
  langid = {english},
  keywords = {Genome evolution,Rare variants},
  annotation = {815 citations (Semantic Scholar/DOI) [2025-04-23]},
  file = {/Users/michaelvolk/Zotero/storage/6YWLE5VJ/Peter et al_2018_Genome evolution across 1,011 Saccharomyces cerevisiae isolates.pdf}
}

@article{petersonPetriNets1977,
  title = {Petri Nets},
  author = {Peterson, James L.},
  date = {1977},
  journaltitle = {ACM Computing Surveys (CSUR)},
  volume = {9},
  number = {3},
  pages = {223--252},
  publisher = {ACM New York, NY, USA},
  file = {/Users/michaelvolk/Zotero/storage/C9DI8FVS/Peterson_1977_Petri nets.pdf;/Users/michaelvolk/Zotero/storage/JHNW8VXK/356698.html}
}

@article{petriPetriNet2008,
  title = {Petri Net},
  author = {Petri, Carl Adam and Reisig, Wolfgang},
  date = {2008-04-17},
  journaltitle = {Scholarpedia},
  volume = {3},
  number = {4},
  pages = {6477},
  issn = {1941-6016},
  doi = {10.4249/scholarpedia.6477},
  url = {http://www.scholarpedia.org/article/Petri_net},
  urldate = {2023-04-04},
  langid = {english},
  annotation = {57 citations (Semantic Scholar/DOI) [2023-04-04]},
  file = {/Users/michaelvolk/Zotero/storage/3DQSK3BM/Petri_net.html}
}

@online{petrovicTemporalGraphRewiring2024,
  title = {Temporal {{Graph Rewiring}} with {{Expander Graphs}}},
  author = {Petrović, Katarina and Huang, Shenyang and Poursafaei, Farimah and Veličković, Petar},
  date = {2024-10-22},
  eprint = {2406.02362},
  eprinttype = {arXiv},
  eprintclass = {cs},
  doi = {10.48550/arXiv.2406.02362},
  url = {http://arxiv.org/abs/2406.02362},
  urldate = {2025-04-23},
  abstract = {Evolving relations in real-world networks are often modelled by temporal graphs. Temporal Graph Neural Networks (TGNNs) emerged to model evolutionary behaviour of such graphs by leveraging the message passing primitive at the core of Graph Neural Networks (GNNs). It is well-known that GNNs are vulnerable to several issues directly related to the input graph topology, such as under-reaching and over-squashing - we argue that these issues can often get exacerbated in temporal graphs, particularly as the result of stale nodes and edges. While graph rewiring techniques have seen frequent usage in GNNs to make the graph topology more favourable for message passing, they have not seen any mainstream usage on TGNNs. In this work, we propose Temporal Graph Rewiring (TGR), the first approach for graph rewiring on temporal graphs, to the best of our knowledge. TGR constructs message passing highways between temporally distant nodes in a continuous-time dynamic graph by utilizing expander graph propagation, a prominent framework used for graph rewiring on static graphs which makes minimal assumptions on the underlying graph structure. On the challenging TGB benchmark, TGR achieves state-of-the-art results on tgbl-review, tgbl-coin, tgbl-comment and tgbl-flight datasets at the time of writing. For tgbl-review, TGR has 50.5\% improvement in MRR over the base TGN model and 22.2\% improvement over the base TNCN model. The significant improvement over base models demonstrates clear benefits of temporal graph rewiring.},
  pubstate = {prepublished},
  keywords = {Computer Science - Artificial Intelligence,Computer Science - Machine Learning,Computer Science - Social and Information Networks,Statistics - Machine Learning},
  annotation = {4 citations (Semantic Scholar/arXiv) [2025-04-23]\\
4 citations (Semantic Scholar/DOI) [2025-04-23]},
  file = {/Users/michaelvolk/Zotero/storage/TUYFB86F/Petrović et al_2024_Temporal Graph Rewiring with Expander Graphs.pdf;/Users/michaelvolk/Zotero/storage/V8VXTM4H/2406.html}
}

@article{phamHierarchicalPoolingGraph2021,
  title = {Hierarchical {{Pooling}} in {{Graph Neural Networks}} to {{Enhance Classification Performance}} in {{Large Datasets}}},
  author = {Pham, Hai Van and Thanh, Dat Hoang and Moore, Philip},
  date = {2021-09-10},
  journaltitle = {Sensors (Basel, Switzerland)},
  shortjournal = {Sensors (Basel)},
  volume = {21},
  number = {18},
  eprint = {34577277},
  eprinttype = {pmid},
  pages = {6070},
  issn = {1424-8220},
  doi = {10.3390/s21186070},
  url = {https://www.ncbi.nlm.nih.gov/pmc/articles/PMC8472962/},
  urldate = {2025-02-27},
  abstract = {Deep learning methods predicated on convolutional neural networks and graph neural networks have enabled significant improvement in node classification and prediction when applied to graph representation with learning node embedding to effectively represent the hierarchical properties of graphs. An interesting approach (DiffPool) utilises a differentiable graph pooling technique which learns ‘differentiable soft cluster assignment’ for nodes at each layer of a deep graph neural network with nodes mapped on sets of clusters. However, effective control of the learning process is difficult given the inherent complexity in an ‘end-to-end’ model with the potential for a large number parameters (including the potential for redundant parameters). In this paper, we propose an approach termed FPool, which is a development of the basic method adopted in DiffPool (where pooling is applied directly to node representations). Techniques designed to enhance data classification have been created and evaluated using a number of popular and publicly available sensor datasets. Experimental results for FPool demonstrate improved classification and prediction performance when compared to alternative methods considered. Moreover, FPool shows a significant reduction in the training time over the basic DiffPool framework.},
  pmcid = {PMC8472962},
  annotation = {16 citations (Semantic Scholar/DOI) [2025-02-27]},
  file = {/Users/michaelvolk/Zotero/storage/URG55QGZ/Pham et al_2021_Hierarchical Pooling in Graph Neural Networks to Enhance Classification.pdf}
}

@article{pinheiroCellularHeterogeneityYeastside2022,
  title = {Cellular Heterogeneity: Yeast-Side Story},
  shorttitle = {Cellular Heterogeneity},
  author = {Pinheiro, Sandrine and Pandey, Shashank and Pelet, Serge},
  date = {2022-03-01},
  journaltitle = {Fungal Biology Reviews},
  shortjournal = {Fungal Biology Reviews},
  volume = {39},
  pages = {34--45},
  issn = {1749-4613},
  doi = {10.1016/j.fbr.2021.11.005},
  url = {https://www.sciencedirect.com/science/article/pii/S1749461321000579},
  urldate = {2024-07-07},
  abstract = {A major challenge for cells lies in their ability to detect, respond and adapt to changing environments that may threaten their survival. Among the numerous evolutionary strategies, cell-to-cell heterogeneity allows the emergence of different phenotypes within a population. This variability in cellular behaviors can be essential for a small fraction of cells to adapt and survive in various environments. Analyses at the single-cell level have allowed to highlight the great variability that is present between cells within an isogenic population. Numerous molecular mechanisms have been uncovered, allowing to understand the emergence and the role of cellular heterogeneity. These attempts at identifying the source of cellular noise have also provided clues for strategies needed to control heterogeneity. In this review, S. cerevisiae is used as an example to illustrate the different factors leading to cell heterogeneity, ranging from intracellular processes to environmental constraints. In addition, some recent strategies developed to modulate cell-to-cell variability are discussed.},
  keywords = {Bet-hedging,Budding yeast,Feedback control,Intrinsic and extrinsic noise,Single cell analysis},
  annotation = {8 citations (Semantic Scholar/DOI) [2024-07-06]},
  file = {/Users/michaelvolk/Zotero/storage/CDJBKLGX/Pinheiro et al_2022_Cellular heterogeneity.pdf;/Users/michaelvolk/Zotero/storage/V99KCL3A/S1749461321000579.html}
}

@article{pipitoMolecularDynamicsStudies2022,
  title = {Molecular Dynamics Studies Reveal Structural and Functional Features of the {{SARS-CoV-2}} Spike Protein},
  author = {Pipitò, Ludovico and Rujan, Roxana-Maria and Reynolds, Christopher A. and Deganutti, Giuseppe},
  date = {2022},
  journaltitle = {BioEssays},
  volume = {44},
  number = {9},
  pages = {2200060},
  issn = {1521-1878},
  doi = {10.1002/bies.202200060},
  url = {https://onlinelibrary.wiley.com/doi/abs/10.1002/bies.202200060},
  urldate = {2024-07-04},
  abstract = {The SARS-CoV-2 virus is responsible for the COVID-19 pandemic the world experience since 2019. The protein responsible for the first steps of cell invasion, the spike protein, has probably received the most attention in light of its central role during infection. Computational approaches are among the tools employed by the scientific community in the enormous effort to study this new affliction. One of these methods, namely molecular dynamics (MD), has been used to characterize the function of the spike protein at the atomic level and unveil its structural features from a dynamic perspective. In this review, we focus on these main findings, including spike protein flexibility, rare S protein conformational changes, cryptic epitopes, the role of glycans, drug repurposing, and the effect of spike protein variants.},
  langid = {english},
  keywords = {drug repurposing,epitope,glycans,molecular dynamics,SARS-Cov-2,spike protein,variant},
  annotation = {9 citations (Semantic Scholar/DOI) [2024-07-04]},
  file = {/Users/michaelvolk/Zotero/storage/C7DUYGTU/Pipitò et al. - 2022 - Molecular dynamics studies reveal structural and f.pdf;/Users/michaelvolk/Zotero/storage/H59C9JQH/bies.html}
}

@book{poolBioinformaticsConvertingData2000,
  title = {Bioinformatics: {{Converting}} Data to Knowledge: {{A}} Workshop Summary},
  shorttitle = {Bioinformatics},
  author = {Pool, Robert and Esnayra, Joan},
  date = {2000},
  publisher = {National Academies Press},
  url = {http://elibrary.pcu.edu.ph:9000/digi/NA02/2000/9990.pdf},
  urldate = {2023-11-26},
  file = {/Users/michaelvolk/Zotero/storage/UDUEXTRX/Pool_Esnayra_2000_Bioinformatics.pdf}
}

@article{porterFluidProteinFold2023,
  title = {Fluid Protein Fold Space and Its Implications},
  author = {Porter, Lauren L.},
  date = {2023},
  journaltitle = {BioEssays},
  volume = {45},
  number = {9},
  pages = {2300057},
  issn = {1521-1878},
  doi = {10.1002/bies.202300057},
  url = {https://onlinelibrary.wiley.com/doi/abs/10.1002/bies.202300057},
  urldate = {2024-07-04},
  abstract = {Fold-switching proteins, which remodel their secondary and tertiary structures in response to cellular stimuli, suggest a new view of protein fold space. For decades, experimental evidence has indicated that protein fold space is discrete: dissimilar folds are encoded by dissimilar amino acid sequences. Challenging this assumption, fold-switching proteins interconnect discrete groups of dissimilar protein folds, making protein fold space fluid. Three recent observations support the concept of fluid fold space: (1) some amino acid sequences interconvert between folds with distinct secondary structures, (2) some naturally occurring sequences have switched folds by stepwise mutation, and (3) fold switching is evolutionarily selected and likely confers advantage. These observations indicate that minor amino acid sequence modifications can transform protein structure and function. Consequently, proteomic structural and functional diversity may be expanded by alternative splicing, small nucleotide polymorphisms, post-translational modifications, and modified translation rates.},
  langid = {english},
  keywords = {alternative splicing,metamorphic proteins,protein evolution,protein fold switching,protein folding},
  file = {/Users/michaelvolk/Zotero/storage/SQ8AYZCA/bies.html}
}

@article{pudduGenomeArchitectureStability2019,
  title = {Genome Architecture and Stability in the {{Saccharomyces}} Cerevisiae Knockout Collection},
  author = {Puddu, Fabio and Herzog, Mareike and Selivanova, Alexandra and Wang, Siyue and Zhu, Jin and Klein-Lavi, Shir and Gordon, Molly and Meirman, Roi and Millan-Zambrano, Gonzalo and Ayestaran, Iñigo and Salguero, Israel and Sharan, Roded and Li, Rong and Kupiec, Martin and Jackson, Stephen P.},
  date = {2019-09-19},
  journaltitle = {Nature},
  shortjournal = {Nature},
  volume = {573},
  number = {7774},
  pages = {416--420},
  issn = {0028-0836, 1476-4687},
  doi = {10.1038/s41586-019-1549-9},
  url = {http://www.nature.com/articles/s41586-019-1549-9},
  urldate = {2022-02-08},
  langid = {english},
  keywords = {✅,🦌},
  annotation = {30 citations (Semantic Scholar/DOI) [2022-11-26]\\
31 citations (Crossref) [2022-04-15]},
  file = {/Users/michaelvolk/Zotero/storage/VI9U77AS/Puddu et al. - 2019 - Genome architecture and stability in the Saccharom.pdf}
}

@article{qianStoichiometricNetworkTheory2003,
  title = {Stoichiometric Network Theory for Nonequilibrium Biochemical Systems},
  author = {Qian, Hong and Beard, Daniel A. and Liang, Shou-dan},
  date = {2003},
  journaltitle = {European Journal of Biochemistry},
  volume = {270},
  number = {3},
  pages = {415--421},
  issn = {1432-1033},
  doi = {10.1046/j.1432-1033.2003.03357.x},
  url = {https://onlinelibrary.wiley.com/doi/abs/10.1046/j.1432-1033.2003.03357.x},
  urldate = {2023-04-05},
  abstract = {We introduce the basic concepts and develop a theory for nonequilibrium steady-state biochemical systems applicable to analyzing large-scale complex isothermal reaction networks. In terms of the stoichiometric matrix, we demonstrate both Kirchhoff's flux law ΣℓJℓ=0 over a biochemical species, and potential law Σℓμℓ=0 over a reaction loop. They reflect mass and energy conservation, respectively. For each reaction, its steady-state flux J can be decomposed into forward and backward one-way fluxes J = J+ – J, with chemical potential difference Δµ = RT ln(J–/J+). The product –JΔµ gives the isothermal heat dissipation rate, which is necessarily non-negative according to the second law of thermodynamics. The stoichiometric network theory (SNT) embodies all of the relevant fundamental physics. Knowing J and Δµ of a biochemical reaction, a conductance can be computed which directly reflects the level of gene expression for the particular enzyme. For sufficiently small flux a linear relationship between J and Δµ can be established as the linear flux–force relation in irreversible thermodynamics, analogous to Ohm's law in electrical circuits.},
  langid = {english},
  keywords = {biochemical network,chemical potential,flux,nonequilibrium thermodynamics,steady-state},
  annotation = {117 citations (Semantic Scholar/DOI) [2023-04-05]},
  file = {/Users/michaelvolk/Zotero/storage/WF7CQIR8/Qian et al_2003_Stoichiometric network theory for nonequilibrium biochemical systems.pdf}
}

@article{qinMultiscaleMapCell2021a,
  title = {A Multi-Scale Map of Cell Structure Fusing Protein Images and Interactions},
  author = {Qin, Yue and Huttlin, Edward L. and Winsnes, Casper F. and Gosztyla, Maya L. and Wacheul, Ludivine and Kelly, Marcus R. and Blue, Steven M. and Zheng, Fan and Chen, Michael and Schaffer, Leah V. and Licon, Katherine and Bäckström, Anna and Vaites, Laura Pontano and Lee, John J. and Ouyang, Wei and Liu, Sophie N. and Zhang, Tian and Silva, Erica and Park, Jisoo and Pitea, Adriana and Kreisberg, Jason F. and Gygi, Steven P. and Ma, Jianzhu and Harper, J. Wade and Yeo, Gene W. and Lafontaine, Denis L. J. and Lundberg, Emma and Ideker, Trey},
  date = {2021-12},
  journaltitle = {Nature},
  volume = {600},
  number = {7889},
  pages = {536--542},
  publisher = {Nature Publishing Group},
  issn = {1476-4687},
  doi = {10.1038/s41586-021-04115-9},
  url = {https://www.nature.com/articles/s41586-021-04115-9},
  urldate = {2023-08-30},
  abstract = {The cell is a multi-scale structure with modular organization across at least four orders of magnitude1. Two central approaches for mapping this structure—protein fluorescent imaging and protein biophysical association—each generate extensive datasets, but of distinct qualities and resolutions that are typically treated separately2,3. Here we integrate immunofluorescence images in the Human Protein Atlas4 with affinity purifications in BioPlex5 to create a unified hierarchical map of human cell architecture. Integration is achieved by configuring each approach as a general measure of protein distance, then calibrating the two measures using machine learning. The map, known as the multi-scale integrated cell (MuSIC 1.0), resolves 69 subcellular systems, of which approximately half are to our knowledge undocumented. Accordingly, we perform 134 additional affinity purifications and validate subunit associations for the majority of systems. The map reveals a pre-ribosomal RNA processing assembly and accessory factors, which we show govern rRNA maturation, and functional roles for SRRM1 and FAM120C in chromatin and RPS3A in splicing. By integration across scales, MuSIC increases the resolution of imaging while giving protein interactions a spatial dimension, paving the way to incorporate diverse types of data in proteome-wide cell maps.},
  issue = {7889},
  langid = {english},
  keywords = {Computational models,Data integration,Machine learning,Network topology,Proteome informatics},
  annotation = {30 citations (Semantic Scholar/DOI) [2023-08-30]},
  file = {/Users/michaelvolk/Zotero/storage/IS8UNHWQ/Qin et al_2021_A multi-scale map of cell structure fusing protein images and interactions.pdf}
}

@inproceedings{qiPointNetDeepLearning2017,
  title = {{{PointNet}}: {{Deep Learning}} on {{Point Sets}} for {{3D Classification}} and {{Segmentation}}},
  shorttitle = {{{PointNet}}},
  author = {Qi, Charles R. and Su, Hao and Mo, Kaichun and Guibas, Leonidas J.},
  date = {2017},
  pages = {652--660},
  url = {https://openaccess.thecvf.com/content_cvpr_2017/html/Qi_PointNet_Deep_Learning_CVPR_2017_paper.html},
  urldate = {2023-10-09},
  eventtitle = {Proceedings of the {{IEEE Conference}} on {{Computer Vision}} and {{Pattern Recognition}}},
  file = {/Users/michaelvolk/Zotero/storage/LA39NDKR/Qi et al_2017_PointNet.pdf}
}

@article{radivojevicMachineLearningAutomated2020,
  title = {A Machine Learning {{Automated Recommendation Tool}} for Synthetic Biology},
  author = {Radivojević, Tijana and Costello, Zak and Workman, Kenneth and Garcia Martin, Hector},
  date = {2020-12},
  journaltitle = {Nature Communications},
  shortjournal = {Nat Commun},
  volume = {11},
  number = {1},
  pages = {4879},
  issn = {2041-1723},
  doi = {10.1038/s41467-020-18008-4},
  url = {https://www.nature.com/articles/s41467-020-18008-4},
  urldate = {2022-02-08},
  abstract = {Abstract             Synthetic biology allows us to bioengineer cells to synthesize novel valuable molecules such as renewable biofuels or anticancer drugs. However, traditional synthetic biology approaches involve ad-hoc engineering practices, which lead to long development times. Here, we present the Automated Recommendation Tool (ART), a tool that leverages machine learning and probabilistic modeling techniques to guide synthetic biology in a systematic fashion, without the need for a full mechanistic understanding of the biological system. Using sampling-based optimization, ART provides a set of recommended strains to be built in the next engineering cycle, alongside probabilistic predictions of their production levels. We demonstrate the capabilities of ART on simulated data sets, as well as experimental data from real metabolic engineering projects producing renewable biofuels, hoppy flavored beer without hops, fatty acids, and tryptophan. Finally, we discuss the limitations of this approach, and the practical consequences of the underlying assumptions failing.},
  langid = {english},
  keywords = {✅,🦌,machine-learning,quantitative-biology-methods},
  annotation = {78 citations (Semantic Scholar/DOI) [2022-11-26]\\
54 citations (Crossref) [2022-04-15]},
  file = {/Users/michaelvolk/Zotero/storage/LSHFPFQX/SI-Radivojević et al. - 2020 - A machine learning Automated Recommendation Tool f.pdf;/Users/michaelvolk/Zotero/storage/YL3VECT9/Radivojević et al. - 2020 - A machine learning Automated Recommendation Tool f.pdf}
}

@article{raffelExploringLimitsTransfer2020,
  title = {Exploring the Limits of Transfer Learning with a Unified Text-to-Text Transformer},
  author = {Raffel, Colin and Shazeer, Noam and Roberts, Adam and Lee, Katherine and Narang, Sharan and Matena, Michael and Zhou, Yanqi and Li, Wei and Liu, Peter J.},
  date = {2020-01-01},
  journaltitle = {The Journal of Machine Learning Research},
  shortjournal = {J. Mach. Learn. Res.},
  volume = {21},
  number = {1},
  pages = {140:5485--140:5551},
  issn = {1532-4435},
  abstract = {Transfer learning, where a model is first pre-trained on a data-rich task before being fine-tuned on a downstream task, has emerged as a powerful technique in natural language processing (NLP). The effectiveness of transfer learning has given rise to a diversity of approaches, methodology, and practice. In this paper, we explore the landscape of transfer learning techniques for NLP by introducing a unified framework that converts all text-based language problems into a text-to-text format. Our systematic study compares pretraining objectives, architectures, unlabeled data sets, transfer approaches, and other factors on dozens of language understanding tasks. By combining the insights from our exploration with scale and our new "Colossal Clean Crawled Corpus", we achieve state-of-the-art results on many benchmarks covering summarization, question answering, text classification, and more. To facilitate future work on transfer learning for NLP, we release our data set, pre-trained models, and code.},
  keywords = {attention based models,deep learning,multi-task learning,natural language processing,transfer learning},
  file = {/Users/michaelvolk/Zotero/storage/MHEE678A/Raffel et al_2020_Exploring the limits of transfer learning with a unified text-to-text.pdf}
}

@article{rahimikolluSLIDESignificantLatent2024,
  title = {{{SLIDE}}: {{Significant Latent Factor Interaction Discovery}} and {{Exploration}} across Biological Domains},
  shorttitle = {{{SLIDE}}},
  author = {Rahimikollu, Javad and Xiao, Hanxi and Rosengart, AnnaElaine and Rosen, Aaron B. I. and Tabib, Tracy and Zdinak, Paul M. and He, Kun and Bing, Xin and Bunea, Florentina and Wegkamp, Marten and Poholek, Amanda C. and Joglekar, Alok V. and Lafyatis, Robert A. and Das, Jishnu},
  date = {2024-02-19},
  journaltitle = {Nature Methods},
  shortjournal = {Nat Methods},
  pages = {1--11},
  publisher = {Nature Publishing Group},
  issn = {1548-7105},
  doi = {10.1038/s41592-024-02175-z},
  url = {https://www.nature.com/articles/s41592-024-02175-z},
  urldate = {2024-03-15},
  abstract = {Modern multiomic technologies can generate deep multiscale profiles. However, differences in data modalities, multicollinearity of the data, and large numbers of irrelevant features make analyses and integration of high-dimensional omic datasets challenging. Here we present Significant Latent Factor Interaction Discovery and Exploration (SLIDE), a first-in-class interpretable machine learning technique for identifying significant interacting latent factors underlying outcomes of interest from high-dimensional omic datasets. SLIDE makes no assumptions regarding data-generating mechanisms, comes with theoretical guarantees regarding identifiability of the latent factors/corresponding inference, and has rigorous false discovery rate control. Using SLIDE on single-cell and spatial omic datasets, we uncovered significant interacting latent factors underlying a range of molecular, cellular and organismal phenotypes. SLIDE outperforms/performs at least as well as a wide range of state-of-the-art approaches, including other latent factor approaches. More importantly, it provides biological inference beyond prediction that other methods do not afford. Thus, SLIDE is a versatile engine for biological discovery from modern multiomic datasets.},
  langid = {english},
  keywords = {🦌✅,Immunological disorders,Machine learning,Statistical methods},
  file = {/Users/michaelvolk/Zotero/storage/NJ4W6IYY/Rahimikollu et al_2024_SLIDE.pdf}
}

@online{rameshLyraEfficientExpressive2025,
  title = {Lyra: {{An Efficient}} and {{Expressive Subquadratic Architecture}} for {{Modeling Biological Sequences}}},
  shorttitle = {Lyra},
  author = {Ramesh, Krithik and Siddiqui, Sameed M. and Gu, Albert and Mitzenmacher, Michael D. and Sabeti, Pardis C.},
  date = {2025-03-20},
  eprint = {2503.16351},
  eprinttype = {arXiv},
  eprintclass = {cs},
  doi = {10.48550/arXiv.2503.16351},
  url = {http://arxiv.org/abs/2503.16351},
  urldate = {2025-03-28},
  abstract = {Deep learning architectures such as convolutional neural networks and Transformers have revolutionized biological sequence modeling, with recent advances driven by scaling up foundation and task-specific models. The computational resources and large datasets required, however, limit their applicability in biological contexts. We introduce Lyra, a subquadratic architecture for sequence modeling, grounded in the biological framework of epistasis for understanding sequence-to-function relationships. Mathematically, we demonstrate that state space models efficiently capture global epistatic interactions and combine them with projected gated convolutions for modeling local relationships. We demonstrate that Lyra is performant across over 100 wide-ranging biological tasks, achieving state-of-the-art (SOTA) performance in many key areas, including protein fitness landscape prediction, biophysical property prediction (e.g. disordered protein region functions) peptide engineering applications (e.g. antibody binding, cell-penetrating peptide prediction), RNA structure analysis, RNA function prediction, and CRISPR guide design. It achieves this with orders-of-magnitude improvements in inference speed and reduction in parameters (up to 120,000-fold in our tests) compared to recent biology foundation models. Using Lyra, we were able to train and run every task in this study on two or fewer GPUs in under two hours, democratizing access to biological sequence modeling at SOTA performance, with potential applications to many fields.},
  pubstate = {prepublished},
  keywords = {Computer Science - Machine Learning,Quantitative Biology - Genomics},
  annotation = {0 citations (Semantic Scholar/arXiv) [2025-03-27]},
  file = {/Users/michaelvolk/Zotero/storage/MIIDSCFN/Ramesh et al_2025_Lyra.pdf;/Users/michaelvolk/Zotero/storage/XCS8XNBQ/2503.html}
}

@online{rampasekRecipeGeneralPowerful2023,
  title = {Recipe for a {{General}}, {{Powerful}}, {{Scalable Graph Transformer}}},
  author = {Rampášek, Ladislav and Galkin, Mikhail and Dwivedi, Vijay Prakash and Luu, Anh Tuan and Wolf, Guy and Beaini, Dominique},
  date = {2023-01-15},
  eprint = {2205.12454},
  eprinttype = {arXiv},
  eprintclass = {cs},
  doi = {10.48550/arXiv.2205.12454},
  url = {http://arxiv.org/abs/2205.12454},
  urldate = {2025-02-12},
  abstract = {We propose a recipe on how to build a general, powerful, scalable (GPS) graph Transformer with linear complexity and state-of-the-art results on a diverse set of benchmarks. Graph Transformers (GTs) have gained popularity in the field of graph representation learning with a variety of recent publications but they lack a common foundation about what constitutes a good positional or structural encoding, and what differentiates them. In this paper, we summarize the different types of encodings with a clearer definition and categorize them as being \$\textbackslash textit\{local\}\$, \$\textbackslash textit\{global\}\$ or \$\textbackslash textit\{relative\}\$. The prior GTs are constrained to small graphs with a few hundred nodes, here we propose the first architecture with a complexity linear in the number of nodes and edges \$O(N+E)\$ by decoupling the local real-edge aggregation from the fully-connected Transformer. We argue that this decoupling does not negatively affect the expressivity, with our architecture being a universal function approximator on graphs. Our GPS recipe consists of choosing 3 main ingredients: (i) positional/structural encoding, (ii) local message-passing mechanism, and (iii) global attention mechanism. We provide a modular framework \$\textbackslash textit\{GraphGPS\}\$ that supports multiple types of encodings and that provides efficiency and scalability both in small and large graphs. We test our architecture on 16 benchmarks and show highly competitive results in all of them, show-casing the empirical benefits gained by the modularity and the combination of different strategies.},
  pubstate = {prepublished},
  keywords = {Computer Science - Machine Learning},
  annotation = {436 citations (Semantic Scholar/arXiv) [2025-02-12]\\
436 citations (Semantic Scholar/DOI) [2025-02-12]},
  file = {/Users/michaelvolk/Zotero/storage/662YTJFV/Rampášek et al_2023_Recipe for a General, Powerful, Scalable Graph Transformer.pdf;/Users/michaelvolk/Zotero/storage/HCY99X36/2205.html}
}

@article{ranjanASAPAdaptiveStructure2020,
  title = {{{ASAP}}: {{Adaptive Structure Aware Pooling}} for {{Learning Hierarchical Graph Representations}}},
  shorttitle = {{{ASAP}}},
  author = {Ranjan, Ekagra and Sanyal, Soumya and Talukdar, Partha},
  date = {2020-04-03},
  journaltitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  volume = {34},
  number = {04},
  pages = {5470--5477},
  issn = {2374-3468},
  doi = {10.1609/aaai.v34i04.5997},
  url = {https://ojs.aaai.org/index.php/AAAI/article/view/5997},
  urldate = {2024-03-11},
  abstract = {Graph Neural Networks (GNN) have been shown to work effectively for modeling graph structured data to solve tasks such as node classification, link prediction and graph classification. There has been some recent progress in defining the notion of pooling in graphs whereby the model tries to generate a graph level representation by downsampling and summarizing the information present in the nodes. Existing pooling methods either fail to effectively capture the graph substructure or do not easily scale to large graphs. In this work, we propose ASAP (Adaptive Structure Aware Pooling), a sparse and differentiable pooling method that addresses the limitations of previous graph pooling architectures. ASAP utilizes a novel self-attention network along with a modified GNN formulation to capture the importance of each node in a given graph. It also learns a sparse soft cluster assignment for nodes at each layer to effectively pool the subgraphs to form the pooled graph. Through extensive experiments on multiple datasets and theoretical analysis, we motivate our choice of the components used in ASAP. Our experimental results show that combining existing GNN architectures with ASAP leads to state-of-the-art results on multiple graph classification benchmarks. ASAP has an average improvement of 4\%, compared to current sparse hierarchical state-of-the-art method. We make the source code of ASAP available to encourage reproducible research 1.},
  issue = {04},
  langid = {english},
  annotation = {210 citations (Semantic Scholar/DOI) [2024-03-11]},
  file = {/Users/michaelvolk/Zotero/storage/J2D6RC6U/Ranjan et al_2020_ASAP.pdf}
}

@article{razaRecurrentNeuralNetwork2016,
  title = {Recurrent Neural Network Based Hybrid Model for Reconstructing Gene Regulatory Network},
  author = {Raza, Khalid and Alam, Mansaf},
  date = {2016-10-01},
  journaltitle = {Computational Biology and Chemistry},
  shortjournal = {Computational Biology and Chemistry},
  volume = {64},
  pages = {322--334},
  issn = {1476-9271},
  doi = {10.1016/j.compbiolchem.2016.08.002},
  url = {https://www.sciencedirect.com/science/article/pii/S1476927116300147},
  urldate = {2023-10-14},
  abstract = {One of the exciting problems in systems biology research is to decipher how genome controls the development of complex biological system. The gene regulatory networks (GRNs) help in the identification of regulatory interactions between genes and offer fruitful information related to functional role of individual gene in a cellular system. Discovering GRNs lead to a wide range of applications, including identification of disease related pathways providing novel tentative drug targets, helps to predict disease response, and also assists in diagnosing various diseases including cancer. Reconstruction of GRNs from available biological data is still an open problem. This paper proposes a recurrent neural network (RNN) based model of GRN, hybridized with generalized extended Kalman filter for weight update in backpropagation through time training algorithm. The RNN is a complex neural network that gives a better settlement between biological closeness and mathematical flexibility to model GRN; and is also able to capture complex, non-linear and dynamic relationships among variables. Gene expression data are inherently noisy and Kalman filter performs well for estimation problem even in noisy data. Hence, we applied non-linear version of Kalman filter, known as generalized extended Kalman filter, for weight update during RNN training. The developed model has been tested on four benchmark networks such as DNA SOS repair network, IRMA network, and two synthetic networks from DREAM Challenge. We performed a comparison of our results with other state-of-the-art techniques which shows superiority of our proposed model. Further, 5\% Gaussian noise has been induced in the dataset and result of the proposed model shows negligible effect of noise on results, demonstrating the noise tolerance capability of the model.},
  keywords = {Gene expression,Gene regulatory network model,Kalman filter,Recurrent neural network},
  annotation = {42 citations (Semantic Scholar/DOI) [2023-10-14]},
  file = {/Users/michaelvolk/Zotero/storage/GA9VGVDH/Raza_Alam_2016_Recurrent neural network based hybrid model for reconstructing gene regulatory.pdf;/Users/michaelvolk/Zotero/storage/VQASE6XR/S1476927116300147.html}
}

@book{reisigPetriNets1985,
  title = {Petri {{Nets}}},
  author = {Reisig, Wolfgang},
  date = {1985},
  publisher = {Springer Berlin Heidelberg},
  location = {Berlin, Heidelberg},
  doi = {10.1007/978-3-642-69968-9},
  url = {http://link.springer.com/10.1007/978-3-642-69968-9},
  urldate = {2023-04-05},
  isbn = {978-3-642-69970-2 978-3-642-69968-9},
  langid = {english},
  file = {/Users/michaelvolk/Zotero/storage/2HLUHNRL/Reisig - 1985 - Petri Nets.pdf}
}

@article{rhindDNAReplicationTiming2022,
  title = {{{DNA}} Replication Timing: {{Biochemical}} Mechanisms and Biological Significance},
  shorttitle = {{{DNA}} Replication Timing},
  author = {Rhind, Nicholas},
  date = {2022},
  journaltitle = {BioEssays},
  volume = {44},
  number = {11},
  pages = {2200097},
  issn = {1521-1878},
  doi = {10.1002/bies.202200097},
  url = {https://onlinelibrary.wiley.com/doi/abs/10.1002/bies.202200097},
  urldate = {2024-07-04},
  abstract = {The regulation of DNA replication is a fascinating biological problem both from a mechanistic angle—How is replication timing regulated?—and from an evolutionary one—Why is replication timing regulated? Recent work has provided significant insight into the first question. Detailed biochemical understanding of the mechanism and regulation of replication initiation has made possible robust hypotheses for how replication timing is regulated. Moreover, technical progress, including high-throughput, single-molecule mapping of replication initiation and single-cell assays of replication timing, has allowed for direct testing of these hypotheses in mammalian cells. This work has consolidated the conclusion that differential replication timing is a consequence of the varying probability of replication origin initiation. The second question is more difficult to directly address experimentally. Nonetheless, plausible hypotheses can be made and one—that replication timing contributes to the regulation of chromatin structure—has received new experimental support.},
  langid = {english},
  keywords = {DNA replication origin,DNA replication timing,MCM,ORC,Origin activation,S-phase regulation,Stochastic model},
  annotation = {6 citations (Semantic Scholar/DOI) [2024-07-04]},
  file = {/Users/michaelvolk/Zotero/storage/DVBMH3R9/Rhind - 2022 - DNA replication timing Biochemical mechanisms and.pdf;/Users/michaelvolk/Zotero/storage/L3X9SA55/bies.html}
}

@article{richterDelineatingEffectiveUse2025,
  title = {Delineating the Effective Use of Self-Supervised Learning in Single-Cell Genomics},
  author = {Richter, Till and Bahrami, Mojtaba and Xia, Yufan and Fischer, David S. and Theis, Fabian J.},
  date = {2025-01},
  journaltitle = {Nature Machine Intelligence},
  shortjournal = {Nat Mach Intell},
  volume = {7},
  number = {1},
  pages = {68--78},
  publisher = {Nature Publishing Group},
  issn = {2522-5839},
  doi = {10.1038/s42256-024-00934-3},
  url = {https://www.nature.com/articles/s42256-024-00934-3},
  urldate = {2025-02-13},
  abstract = {Self-supervised learning (SSL) has emerged as a powerful method for extracting meaningful representations from vast, unlabelled datasets, transforming computer vision and natural language processing. In single-cell genomics (SCG), representation learning offers insights into the complex biological data, especially with emerging foundation models. However, identifying scenarios in SCG where SSL outperforms traditional learning methods remains a nuanced challenge. Furthermore, selecting the most effective pretext tasks within the SSL framework for SCG is a critical yet unresolved question. Here we address this gap by adapting and benchmarking SSL methods in SCG, including masked autoencoders with multiple masking strategies and contrastive learning methods. Models trained on over 20 million cells were examined across multiple downstream tasks, including cell-type prediction, gene-expression reconstruction, cross-modality prediction and data integration. Our empirical analyses underscore the nuanced role of SSL, namely, in transfer learning scenarios leveraging auxiliary data or analysing unseen datasets. Masked autoencoders excel over contrastive methods in SCG, diverging from computer vision trends. Moreover, our findings reveal the notable capabilities of SSL in zero-shot settings and its potential in cross-modality prediction and data integration. In summary, we study SSL methods in SCG on fully connected networks and benchmark their utility across key representation learning scenarios.},
  langid = {english},
  keywords = {Computational models,Machine learning},
  file = {/Users/michaelvolk/Zotero/storage/W2X95EJW/Richter et al_2025_Delineating the effective use of self-supervised learning in single-cell.pdf}
}

@online{rijalInferringGenotypephenotypeMaps2025,
  title = {Inferring Genotype-Phenotype Maps Using Attention Models},
  author = {Rijal, Krishna and Holmes, Caroline M. and Petti, Samantha and Reddy, Gautam and Desai, Michael M. and Mehta, Pankaj},
  date = {2025-04-11},
  eprinttype = {bioRxiv},
  eprintclass = {New Results},
  pages = {2025.04.11.648465},
  doi = {10.1101/2025.04.11.648465},
  url = {https://www.biorxiv.org/content/10.1101/2025.04.11.648465v1},
  urldate = {2025-05-07},
  abstract = {Predicting phenotype from genotype is a central challenge in genetics. Traditional approaches in quantitative genetics typically analyze this problem using methods based on linear regression. These methods generally assume that the genetic architecture of complex traits can be parameterized in terms of an additive model, where the effects of loci are independent, plus (in some cases) pair-wise epistatic interactions between loci. However, these models struggle to analyze more complex patterns of epistasis or subtle gene-environment interactions. Recent advances in machine learning, particularly attention-based models, offer a promising alternative. Initially developed for natural language processing, attention-based models excel at capturing context-dependent interactions and have shown exceptional performance in predicting protein structure and function. Here, we apply attention-based models to quantitative genetics. We analyze the performance of this attention-based approach in predicting phenotype from genotype using simulated data across a range of models with increasing epistatic complexity, and using experimental data from a recent quantitative trait locus mapping study in budding yeast. We find that our model demonstrates superior out-of-sample predictions in epistatic regimes compared to standard methods. We also explore a more general multi-environment attention-based model to jointly analyze genotype-phenotype maps across multiple environments and show that such architectures can be used for “transfer learning” – predicting phenotypes in novel environments with limited training data.},
  langid = {english},
  pubstate = {prepublished},
  annotation = {0 citations (Semantic Scholar/DOI) [2025-05-07]},
  file = {/Users/michaelvolk/Zotero/storage/Z4G4PV27/Rijal et al_2025_Inferring genotype-phenotype maps using attention models.pdf}
}

@book{robinsonGraphDatabasesNew2015,
  title = {Graph {{Databases}}: {{New Opportunities}} for {{Connected Data}}},
  shorttitle = {Graph {{Databases}}},
  author = {Robinson, Ian and Webber, Jim and Eifrem, Emil},
  date = {2015-08-04},
  edition = {2nd edition},
  publisher = {O'Reilly Media},
  location = {Beijing Boston Farnham},
  abstract = {Discover how graph databases can help you manage and query highly connected data. With this practical book, you’ll learn how to design and implement a graph database that brings the power of graphs to bear on a broad range of problem domains. Whether you want to speed up your response to user queries or build a database that can adapt as your business evolves, this book shows you how to apply the schema-free graph model to real-world problems.  This second edition includes new code samples and diagrams, using the latest Neo4j syntax, as well as information on new functionality. Learn how different organizations are using graph databases to outperform their competitors. With this book’s data modeling, query, and code examples, you’ll quickly be able to implement your own solution. Model data with the Cypher query language and property graph model Learn best practices and common pitfalls when modeling with graphs Plan and implement a graph database solution in test-driven fashion Explore real-world examples to learn how and why organizations use a graph database Understand common patterns and components of graph database architecture Use analytical techniques and algorithms to mine graph database information},
  isbn = {978-1-4919-3089-2},
  langid = {english},
  pagetotal = {236},
  file = {/Users/michaelvolk/Zotero/storage/STQPZX74/Robinson et al. - 2015 - Graph Databases New Opportunities for Connected D.pdf}
}

@article{roodFoundationModelCausal2024,
  title = {Toward a Foundation Model of Causal Cell and Tissue Biology with a {{Perturbation Cell}} and {{Tissue Atlas}}},
  author = {Rood, Jennifer E. and Hupalowska, Anna and Regev, Aviv},
  date = {2024-08-22},
  journaltitle = {Cell},
  shortjournal = {Cell},
  volume = {187},
  number = {17},
  eprint = {39178831},
  eprinttype = {pmid},
  pages = {4520--4545},
  publisher = {Elsevier},
  issn = {0092-8674, 1097-4172},
  doi = {10.1016/j.cell.2024.07.035},
  url = {https://www.cell.com/cell/abstract/S0092-8674(24)00829-8},
  urldate = {2025-04-29},
  langid = {english},
  annotation = {24 citations (Semantic Scholar/DOI) [2025-04-29]},
  file = {/Users/michaelvolk/Zotero/storage/WMIQ3NKG/Rood et al_2024_Toward a foundation model of causal cell and tissue biology with a Perturbation.pdf}
}

@article{roohaniPredictingTranscriptionalOutcomes,
  title = {Predicting Transcriptional Outcomes of Novel Multigene Perturbations with {{GEARS}}},
  author = {Roohani, Yusuf},
  journaltitle = {Nature Biotechnology},
  langid = {english},
  file = {/Users/michaelvolk/Zotero/storage/AKTZKV7W/Roohani - Predicting transcriptional outcomes of novel multi.pdf}
}

@article{roohaniPredictingTranscriptionalOutcomes2023,
  title = {Predicting Transcriptional Outcomes of Novel Multigene Perturbations with {{GEARS}} | {{Nature Biotechnology}}},
  author = {Roohani, Yusuf and Huang, Kexin and Leskovec, Jure},
  date = {2023-08-17},
  journaltitle = {Nature Biotechnology},
  issn = {1546-1696},
  doi = {10.1038/s41587-023-01905-6},
  url = {https://www.nature.com/articles/s41587-023-01905-6},
  urldate = {2023-08-25},
  abstract = {Understanding cellular responses to genetic perturbation is central to numerous biomedical applications, from identifying genetic interactions involved in cancer to developing methods for regenerative medicine. However, the combinatorial explosion in the number of possible multigene perturbations severely limits experimental interrogation. Here, we present graph-enhanced gene activation and repression simulator (GEARS), a method that integrates deep learning with a knowledge graph of gene–gene relationships to predict transcriptional responses to both single and multigene perturbations using single-cell RNA-sequencing data from perturbational screens. GEARS is able to predict outcomes of perturbing combinations consisting of genes that were never experimentally perturbed. GEARS exhibited 40\% higher precision than existing approaches in predicting four distinct genetic interaction subtypes in a combinatorial perturbation screen and identified the strongest interactions twice as well as prior approaches. Overall, GEARS can predict phenotypically distinct effects of multigene perturbations and thus guide the design of perturbational experiments.},
  keywords = {🦌✅},
  annotation = {0 citations (Semantic Scholar/DOI) [2023-08-25]},
  file = {/Users/michaelvolk/Zotero/storage/9ZXD4ZIK/Roohani et al. - 2023 - Predicting transcriptional outcomes of novel multigene perturbations with GEARS  Nature Biotechnology.pdf;/Users/michaelvolk/Zotero/storage/CK8M4Z4P/SI - Roohani et al. - 2023 - Predicting transcriptional outcomes of novel multi.pdf}
}

@online{rosenUniversalCellEmbeddings2023,
  title = {Universal {{Cell Embeddings}}: {{A Foundation Model}} for {{Cell Biology}}},
  shorttitle = {Universal {{Cell Embeddings}}},
  author = {Rosen, Yanay and Roohani, Yusuf and Agarwal, Ayush and Samotorčan, Leon and Consortium, Tabula Sapiens and Quake, Stephen R. and Leskovec, Jure},
  date = {2023-11-29},
  eprinttype = {bioRxiv},
  eprintclass = {New Results},
  pages = {2023.11.28.568918},
  doi = {10.1101/2023.11.28.568918},
  url = {https://www.biorxiv.org/content/10.1101/2023.11.28.568918v1},
  urldate = {2023-12-13},
  abstract = {Developing a universal representation of cells which encompasses the tremendous molecular diversity of cell types within the human body and more generally, across species, would be transformative for cell biology. Recent work using single-cell transcriptomic approaches to create molecular definitions of cell types in the form of cell atlases has provided the necessary data for such an endeavor. Here, we present the Universal Cell Embedding (UCE) foundation model. UCE was trained on a corpus of cell atlas data from human and other species in a completely self-supervised way without any data annotations. UCE offers a unified biological latent space that can represent any cell, regardless of tissue or species. This universal cell embedding captures important biological variation despite the presence of experimental noise across diverse datasets. An important aspect of UCE’s universality is that any new cell from any organism can be mapped to this embedding space with no additional data labeling, model training or fine-tuning. We applied UCE to create the Integrated Mega-scale Atlas, embedding 36 million cells, with more than 1,000 uniquely named cell types, from hundreds of experiments, dozens of tissues and eight species. We uncovered new insights about the organization of cell types and tissues within this universal cell embedding space, and leveraged it to infer function of newly discovered cell types. UCE’s embedding space exhibits emergent behavior, uncovering new biology that it was never explicitly trained for, such as identifying developmental lineages and embedding data from novel species not included in the training set. Overall, by enabling a universal representation for every cell state and type, UCE provides a valuable tool for analysis, annotation and hypothesis generation as the scale and diversity of single cell datasets continues to grow.},
  langid = {english},
  pubstate = {prepublished},
  keywords = {🦌✅},
  annotation = {0 citations (Semantic Scholar/DOI) [2023-12-13]},
  file = {/Users/michaelvolk/Zotero/storage/PUBV7GDL/Rosen et al. - 2023 - Universal Cell Embeddings A Foundation Model for .pdf}
}

@inproceedings{rossiEdgeDirectionalityImproves2024,
  title = {Edge {{Directionality Improves Learning}} on {{Heterophilic Graphs}}},
  booktitle = {Proceedings of the {{Second Learning}} on {{Graphs Conference}}},
  author = {Rossi, Emanuele and Charpentier, Bertrand and Giovanni, Francesco Di and Frasca, Fabrizio and Günnemann, Stephan and Bronstein, Michael M.},
  date = {2024-04-17},
  pages = {25:1-25:27},
  publisher = {PMLR},
  issn = {2640-3498},
  url = {https://proceedings.mlr.press/v231/rossi24a.html},
  urldate = {2025-02-27},
  abstract = {Graph Neural Networks (GNNs) have become the de-facto standard tool for modeling relational data. However, while many real-world graphs are directed, the majority of today’s GNN models discard this information altogether by simply making the graph undirected. The reasons for this are historical: 1) many early variants of spectral GNNs explicitly required undirected graphs, and 2) the first benchmarks on homophilic graphs did not find significant gain from using direction. In this paper, we show that in heterophilic settings, treating the graph as directed increases the effective homophily of the graph, suggesting a potential gain from the correct use of directionality information. To this end, we introduce Directed Graph Neural Network (Dir-GNN), a novel general framework for deep learning on directed graphs. Dir-GNN can be used to extend any Message Passing Neural Network (MPNN) to account for edge directionality information by performing separate aggregations of the incoming and outgoing edges. We prove that Dir-GNN matches the expressivity of the Directed Weisfeiler-Lehman test, exceeding that of conventional MPNNs. In extensive experiments, we validate that while our framework leaves performance unchanged on homophilic datasets, it leads to large gains over base models such as GCN, GAT and GraphSage on heterophilic benchmarks, outperforming much more complex methods and achieving new state-of-the-art results. The code for the paper can be found at https://github.com/emalgorithm/directed-graph-neural-network.},
  eventtitle = {Learning on {{Graphs Conference}}},
  langid = {english},
  keywords = {torchcell.regulatory-edges},
  file = {/Users/michaelvolk/Zotero/storage/MYVV8D7J/Rossi et al_2024_Edge Directionality Improves Learning on Heterophilic Graphs.pdf}
}

@article{rothiCorrelationCausationNew2023,
  title = {From Correlation to Causation: {{The}} New Frontier of Transgenerational Epigenetic Inheritance},
  shorttitle = {From Correlation to Causation},
  author = {Rothi, Mohd Hafiz and Greer, Eric Lieberman},
  date = {2023},
  journaltitle = {BioEssays},
  volume = {45},
  number = {1},
  pages = {2200118},
  issn = {1521-1878},
  doi = {10.1002/bies.202200118},
  url = {https://onlinelibrary.wiley.com/doi/abs/10.1002/bies.202200118},
  urldate = {2024-07-04},
  abstract = {While heredity is predominantly controlled by what deoxyribonucleic acid (DNA) sequences are passed from parents to their offspring, a small but growing number of traits have been shown to be regulated in part by the non-genetic inheritance of information. Transgenerational epigenetic inheritance is defined as heritable information passed from parents to their offspring without changing the DNA sequence. Work of the past seven decades has transitioned what was previously viewed as rare phenomenology, into well-established paradigms by which numerous traits can be modulated. For the most part, studies in model organisms have correlated transgenerational epigenetic inheritance phenotypes with changes in epigenetic modifications. The next steps for this field will entail transitioning from correlative studies to causal ones. Here, we delineate the major molecules that have been implicated in transgenerational epigenetic inheritance in both mammalian and non-mammalian models, speculate on additional molecules that could be involved, and highlight some of the tools which might help transition this field from correlation to causation.},
  langid = {english},
  keywords = {DNA methylation,epigenetic inheritance,histone modifications,lipid methylation,non-coding RNAs,rRNA methylation,transgenerational},
  file = {/Users/michaelvolk/Zotero/storage/YFPRNMQD/Rothi and Greer - 2023 - From correlation to causation The new frontier of.pdf;/Users/michaelvolk/Zotero/storage/XTU4USJL/bies.html}
}

@article{ruizIdentificationDiseaseTreatment2021,
  title = {Identification of Disease Treatment Mechanisms through the Multiscale Interactome},
  author = {Ruiz, Camilo and Zitnik, Marinka and Leskovec, Jure},
  date = {2021-03-19},
  journaltitle = {Nature Communications},
  shortjournal = {Nat Commun},
  volume = {12},
  number = {1},
  pages = {1796},
  publisher = {Nature Publishing Group},
  issn = {2041-1723},
  doi = {10.1038/s41467-021-21770-8},
  url = {https://www.nature.com/articles/s41467-021-21770-8},
  urldate = {2023-04-24},
  abstract = {Most diseases disrupt multiple proteins, and drugs treat such diseases by restoring the functions of the disrupted proteins. How drugs restore these functions, however, is often unknown as a drug’s therapeutic effects are not limited to the proteins that the drug directly targets. Here, we develop the multiscale interactome, a powerful approach to explain disease treatment. We integrate disease-perturbed proteins, drug targets, and biological functions into a multiscale interactome network. We then develop a random walk-based method that captures how drug effects propagate through a hierarchy of biological functions and physical protein-protein interactions. On three key pharmacological tasks, the multiscale interactome predicts drug-disease treatment, identifies proteins and biological functions related to treatment, and predicts genes that alter a treatment’s efficacy and adverse reactions. Our results indicate that physical interactions between proteins alone cannot explain treatment since many drugs treat diseases by affecting the biological functions disrupted by the disease rather than directly targeting disease proteins or their regulators. We provide a general framework for explaining treatment, even when drugs seem unrelated to the diseases they are recommended for.},
  issue = {1},
  langid = {english},
  keywords = {Data integration,Data mining,Machine learning,Network topology},
  annotation = {49 citations (Semantic Scholar/DOI) [2023-04-24]},
  file = {/Users/michaelvolk/Zotero/storage/NDYP7VYI/Ruiz et al_2021_Identification of disease treatment mechanisms through the multiscale.pdf}
}

@article{ruppPartialDifferentialEquations2022a,
  title = {Partial Differential Equations on Hypergraphs and Networks of Surfaces: Derivation and Hybrid Discretizations},
  shorttitle = {Partial Differential Equations on Hypergraphs and Networks of Surfaces},
  author = {Rupp, Andreas and Gahn, Markus and Kanschat, Guido},
  date = {2022},
  journaltitle = {ESAIM: Mathematical Modelling and Numerical Analysis},
  volume = {56},
  number = {2},
  pages = {505--528},
  publisher = {EDP Sciences},
  url = {https://www.esaim-m2an.org/articles/m2an/abs/2022/02/m2an210163/m2an210163.html},
  urldate = {2024-07-04},
  file = {/Users/michaelvolk/Zotero/storage/HBY5Z6DT/Rupp et al_2022_Partial differential equations on hypergraphs and networks of surfaces.pdf}
}

@article{rybnikovModelingEvolutionRecombination2023,
  title = {Modeling the Evolution of Recombination Plasticity: {{A}} Prospective Review},
  shorttitle = {Modeling the Evolution of Recombination Plasticity},
  author = {Rybnikov, Sviatoslav R. and Frenkel, Zeev and Hübner, Sariel and Weissman, Daniel B. and Korol, Abraham B.},
  date = {2023},
  journaltitle = {BioEssays},
  volume = {45},
  number = {8},
  pages = {2200237},
  issn = {1521-1878},
  doi = {10.1002/bies.202200237},
  url = {https://onlinelibrary.wiley.com/doi/abs/10.1002/bies.202200237},
  urldate = {2024-07-04},
  abstract = {Meiotic recombination is one of the main sources of genetic variation, a fundamental factor in the evolutionary adaptation of sexual eukaryotes. Yet, the role of variation in recombination rate and other recombination features remains underexplored. In this review, we focus on the sensitivity of recombination rates to different extrinsic and intrinsic factors. We briefly present the empirical evidence for recombination plasticity in response to environmental perturbations and/or poor genetic background and discuss theoretical models developed to explain how such plasticity could have evolved and how it can affect important population characteristics. We highlight a gap between the evidence, which comes mostly from experiments with diploids, and theory, which typically assumes haploid selection. Finally, we formulate open questions whose solving would help to outline conditions favoring recombination plasticity. This will contribute to answering the long-standing question of why sexual recombination exists despite its costs, since plastic recombination may be evolutionary advantageous even in selection regimes rejecting any non-zero constant recombination.},
  langid = {english},
  keywords = {environmental stressors,evolvability,genetic background,individual fitness,meiotic recombination,modifier models,plasticity},
  annotation = {4 citations (Semantic Scholar/DOI) [2024-07-04]},
  file = {/Users/michaelvolk/Zotero/storage/JJH2WN2Y/Rybnikov et al. - 2023 - Modeling the evolution of recombination plasticity.pdf;/Users/michaelvolk/Zotero/storage/5D75Z9YT/bies.html}
}

@article{saekiOverexpressionProfilingReveals2023,
  title = {Overexpression Profiling Reveals Cellular Requirements in the Context of Genetic Backgrounds and Environments},
  author = {Saeki, Nozomu and Yamamoto, Chie and Eguchi, Yuichi and Sekito, Takayuki and Shigenobu, Shuji and Yoshimura, Mami and Yashiroda, Yoko and Boone, Charles and Moriya, Hisao},
  date = {2023-04-28},
  journaltitle = {PLOS Genetics},
  shortjournal = {PLOS Genetics},
  volume = {19},
  number = {4},
  pages = {e1010732},
  publisher = {Public Library of Science},
  issn = {1553-7404},
  doi = {10.1371/journal.pgen.1010732},
  url = {https://journals.plos.org/plosgenetics/article?id=10.1371/journal.pgen.1010732},
  urldate = {2024-07-04},
  abstract = {Overexpression can help life adapt to stressful environments, making an examination of overexpressed genes valuable for understanding stress tolerance mechanisms. However, a systematic study of genes whose overexpression is functionally adaptive (GOFAs) under stress has yet to be conducted. We developed a new overexpression profiling method and systematically identified GOFAs in Saccharomyces cerevisiae under stress (heat, salt, and oxidative). Our results show that adaptive overexpression compensates for deficiencies and increases fitness under stress, like calcium under salt stress. We also investigated the impact of different genetic backgrounds on GOFAs, which varied among three S. cerevisiae strains reflecting differing calcium and potassium requirements for salt stress tolerance. Our study of a knockout collection also suggested that calcium prevents mitochondrial outbursts under salt stress. Mitochondria-enhancing GOFAs were only adaptive when adequate calcium was available and non-adaptive when calcium was deficient, supporting this idea. Our findings indicate that adaptive overexpression meets the cell’s needs for maximizing the organism’s adaptive capacity in the given environment and genetic context.},
  langid = {english},
  keywords = {Genetics,Genomics,Hyperexpression techniques,Mitochondria,Plasmid construction,Saccharomyces cerevisiae,Thermal stresses,Yeast},
  file = {/Users/michaelvolk/Zotero/storage/YJY5AA2P/Saeki et al_2023_Overexpression profiling reveals cellular requirements in the context of.pdf}
}

@article{saitoDataMiningTools2005,
  title = {Data Mining Tools for the {{Saccharomyces}} Cerevisiae Morphological Database},
  author = {Saito, Taro L. and Sese, Jun and Nakatani, Yoichiro and Sano, Fumi and Yukawa, Masashi and Ohya, Yoshikazu and Morishita, Shinichi},
  date = {2005-07-01},
  journaltitle = {Nucleic Acids Research},
  shortjournal = {Nucleic Acids Research},
  volume = {33},
  pages = {W753-W757},
  issn = {0305-1048},
  doi = {10.1093/nar/gki451},
  url = {https://doi.org/10.1093/nar/gki451},
  urldate = {2025-04-24},
  abstract = {For comprehensive understanding of precise morphological changes resulting from loss-of-function mutagenesis, a large collection of 1 899 247 cell images was assembled from 91 271 micrographs of 4782 budding yeast disruptants of non-lethal genes. All the cell images were processed computationally to measure ∼500 morphological parameters in individual mutants. We have recently made this morphological quantitative data available to the public through the Saccharomyces cerevisiae Morphological Database (SCMD). Inspecting the significance of morphological discrepancies between the wild type and the mutants is expected to provide clues to uncover genes that are relevant to the biological processes producing a particular morphology. To facilitate such intensive data mining, a suite of new software tools for visualizing parameter value distributions was developed to present mutants with significant changes in easily understandable forms. In addition, for a given group of mutants associated with a particular function, the system automatically identifies a combination of multiple morphological parameters that discriminates a mutant group from others significantly, thereby characterizing the function effectively. These data mining functions are available through the World Wide Web at http://scmd.gi.k.u-tokyo.ac.jp/ .},
  issue = {suppl\_2},
  annotation = {21 citations (Semantic Scholar/DOI) [2025-04-23]},
  file = {/Users/michaelvolk/Zotero/storage/GQES6229/Saito et al_2005_Data mining tools for the Saccharomyces cerevisiae morphological database.pdf;/Users/michaelvolk/Zotero/storage/IUVNPT5X/2505633.html}
}

@article{saitoSCMDSaccharomycesCerevisiae2004,
  title = {{{SCMD}}: {{Saccharomyces}} Cerevisiae {{Morphological Database}}},
  shorttitle = {{{SCMD}}},
  author = {Saito, T. L.},
  date = {2004-01-01},
  journaltitle = {Nucleic Acids Research},
  shortjournal = {Nucleic Acids Research},
  volume = {32},
  number = {90001},
  pages = {319D-322},
  issn = {1362-4962},
  doi = {10.1093/nar/gkh113},
  url = {https://academic.oup.com/nar/article-lookup/doi/10.1093/nar/gkh113},
  urldate = {2025-02-07},
  abstract = {To study the global regulation of cell morphology, a number of groups have recently reported genomewide screening data for yeast mutants with abnormal morphology. Despite the relatively simple ellipsoidal shape of yeast cells, in the past, cell morphology researchers have processed information on cells manually. These time-consuming, entirely subjective tasks motivated us to develop image-processing software that automatically extracts yeast cells from micrographs and processes them to measure key morphological characteristics such as cell size, roundness, bud neck position angle, nuclear DNA localization and actin localization. To date, we have retrieved 960 609 cells from 52 988 micrographs of 2531 mutants using our software, and we have published the results in the Saccharomyces cerevisiae Morphological Database (SCMD), which facilitates the analysis of abnormal cells. Our system provides quantitative data for shapes of the daughter and mother cells, localization of the nuclear DNA and morphology of the actin patches. To search for mutants with similar morphological traits, the system outputs a list of mutants ranked by similarity of average morphological parameters. The SCMD is available at http://yeast. gi.k.u-tokyo.ac.jp/.},
  langid = {english},
  annotation = {95 citations (Semantic Scholar/DOI) [2025-02-07]},
  file = {/Users/michaelvolk/Zotero/storage/6HD5CTZR/Saito - 2004 - SCMD Saccharomyces cerevisiae Morphological Datab.pdf}
}

@article{salazar-ciudadEvodevoDevelopmentGeneralizing2023,
  title = {Evo-Devo beyond Development: {{Generalizing}} Evo-Devo to All Levels of the Phenotypic Evolution},
  shorttitle = {Evo-Devo beyond Development},
  author = {Salazar-Ciudad, Isaac and Cano-Fernández, Hugo},
  date = {2023},
  journaltitle = {BioEssays},
  volume = {45},
  number = {3},
  pages = {2200205},
  issn = {1521-1878},
  doi = {10.1002/bies.202200205},
  url = {https://onlinelibrary.wiley.com/doi/abs/10.1002/bies.202200205},
  urldate = {2024-07-04},
  abstract = {A foundational idea of evo-devo is that morphological variation is not isotropic, that is, it does not occur in all directions. Instead, some directions of morphological variation are more likely than others from DNA-level variation and these largely depend on development. We argue that this evo-devo perspective should apply not only to morphology but to evolution at all phenotypic levels. At other phenotypic levels there is no development, but there are processes that can be seen, in analogy to development, as constructing the phenotype (e.g., protein folding, learning for behavior, etc.). We argue that to explain the direction of evolution two types of arguments need to be combined: generative arguments about which phenotypic variation arises in each generation and selective arguments about which of it passes to the next generation. We explain how a full consideration of the two types of arguments improves the explanatory power of evolutionary theory. Also see the video abstract here: https://youtu.be/Egbvma\_uaKc},
  langid = {english},
  keywords = {development,evolution,evolutionary theory,protein evolution},
  annotation = {4 citations (Semantic Scholar/DOI) [2024-07-04]},
  file = {/Users/michaelvolk/Zotero/storage/67FYE9V3/Salazar-Ciudad and Cano-Fernández - 2023 - Evo-devo beyond development Generalizing evo-devo.pdf;/Users/michaelvolk/Zotero/storage/6CN983ZE/bies.html}
}

@article{sales-pardoHyperedgePredictionStatistical2023a,
  title = {Hyperedge Prediction and the Statistical Mechanisms of Higher-Order and Lower-Order Interactions in Complex Networks},
  author = {Sales-Pardo, Marta and Mariné-Tena, Aleix and Guimerà, Roger},
  date = {2023-12-12},
  journaltitle = {Proceedings of the National Academy of Sciences},
  volume = {120},
  number = {50},
  pages = {e2303887120},
  publisher = {Proceedings of the National Academy of Sciences},
  doi = {10.1073/pnas.2303887120},
  url = {https://www.pnas.org/doi/10.1073/pnas.2303887120},
  urldate = {2025-04-16},
  abstract = {Complex networked systems often exhibit higher-order interactions, beyond dyadic interactions, which can dramatically alter their observed behavior. Consequently, understanding hypergraphs from a structural perspective has become increasingly important. Statistical, group-based inference approaches are well suited for unveiling the underlying community structure and predicting unobserved interactions. However, these approaches often rely on two key assumptions: that the same groups can explain hyperedges of any order and that interactions are assortative, meaning that edges are formed by nodes with the same group memberships. To test these assumptions, we propose a group-based generative model for hypergraphs that does not impose an assortative mechanism to explain observed higher-order interactions, unlike current approaches. Our model allows us to explore the validity of the assumptions. Our results indicate that the first assumption appears to hold true for real networks. However, the second assumption is not necessarily accurate; we find that a combination of general statistical mechanisms can explain observed hyperedges. Finally, with our approach, we are also able to determine the importance of lower and high-order interactions for predicting unobserved interactions. Our research challenges the conventional assumptions of group-based inference methodologies and broadens our understanding of the underlying structure of hypergraphs.},
  annotation = {3 citations (Semantic Scholar/DOI) [2025-04-15]},
  file = {/Users/michaelvolk/Zotero/storage/FNL5YFIJ/Sales-Pardo et al_2023_Hyperedge prediction and the statistical mechanisms of higher-order and.pdf}
}

@article{sameithHighresolutionGeneExpression2015a,
  title = {A High-Resolution Gene Expression Atlas of Epistasis between Gene-Specific Transcription Factors Exposes Potential Mechanisms for Genetic Interactions},
  author = {Sameith, Katrin and Amini, Saman and Groot Koerkamp, Marian J. A. and family=Leenen, given=Dik, prefix=van, useprefix=true and Brok, Mariel and Brabers, Nathalie and Lijnzaad, Philip and family=Hooff, given=Sander R., prefix=van, useprefix=true and Benschop, Joris J. and Lenstra, Tineke L. and Apweiler, Eva and family=Wageningen, given=Sake, prefix=van, useprefix=true and Snel, Berend and Holstege, Frank C. P. and Kemmeren, Patrick},
  date = {2015-12-23},
  journaltitle = {BMC Biology},
  shortjournal = {BMC Biology},
  volume = {13},
  number = {1},
  pages = {112},
  issn = {1741-7007},
  doi = {10.1186/s12915-015-0222-5},
  url = {https://doi.org/10.1186/s12915-015-0222-5},
  urldate = {2023-09-14},
  abstract = {Genetic interactions, or non-additive effects between genes, play a crucial role in many cellular processes and disease. Which mechanisms underlie these genetic interactions has hardly been characterized. Understanding the molecular basis of genetic interactions is crucial in deciphering pathway organization and understanding the relationship between genotype, phenotype and disease.},
  keywords = {Gene-specific transcription factors,Genetic interactions,Molecular mechanisms,Saccharomyces cerevisiae},
  annotation = {14 citations (Semantic Scholar/DOI) [2023-09-14]},
  file = {/Users/michaelvolk/Zotero/storage/LGR2R6EC/Sameith et al_2015_A high-resolution gene expression atlas of epistasis between gene-specific.pdf;/Users/michaelvolk/Zotero/storage/N4VGTI6C/s12915-015-0222-5.html}
}

@article{sapovalCurrentProgressOpen2022,
  title = {Current Progress and Open Challenges for Applying Deep Learning across the Biosciences},
  author = {Sapoval, Nicolae and Aghazadeh, Amirali and Nute, Michael G. and Antunes, Dinler A. and Balaji, Advait and Baraniuk, Richard and Barberan, C. J. and Dannenfelser, Ruth and Dun, Chen and Edrisi, Mohammadamin and Elworth, R. A. Leo and Kille, Bryce and Kyrillidis, Anastasios and Nakhleh, Luay and Wolfe, Cameron R. and Yan, Zhi and Yao, Vicky and Treangen, Todd J.},
  date = {2022-04-01},
  journaltitle = {Nature Communications},
  shortjournal = {Nat Commun},
  volume = {13},
  number = {1},
  pages = {1728},
  publisher = {Nature Publishing Group},
  issn = {2041-1723},
  doi = {10.1038/s41467-022-29268-7},
  url = {https://www.nature.com/articles/s41467-022-29268-7},
  urldate = {2022-05-10},
  abstract = {Deep Learning (DL) has recently enabled unprecedented advances in one of the grand challenges in computational biology: the half-century-old problem of protein structure prediction. In this paper we discuss recent advances, limitations, and future perspectives of DL on five~broad areas: protein structure prediction, protein function prediction, genome engineering, systems biology and data integration, and phylogenetic inference. We discuss each application area and cover the main bottlenecks of DL approaches, such as training data, problem scope, and the ability to leverage existing DL architectures in new contexts. To conclude, we provide a summary of the subject-specific and general challenges for DL across the biosciences.},
  issue = {1},
  langid = {english},
  keywords = {✅,🦌,computational-biology-bioinformatics,computer-science,gene-graph,gene-graph-troubleshoot,machine-learning},
  annotation = {11 citations (Semantic Scholar/DOI) [2022-11-26]},
  file = {/Users/michaelvolk/Zotero/storage/VZ3C9MSD/Sapoval et al_2022_Current progress and open challenges for applying deep learning across the.pdf;/Users/michaelvolk/Zotero/storage/JBNVRWDJ/s41467-022-29268-7.html}
}

@article{sausenOvercomingStochasticVariations2021,
  title = {Overcoming Stochastic Variations in Culture Variables to Quantify and Compare Growth Curve Data},
  author = {Sausen, Christopher W. and Bochman, Matthew L.},
  date = {2021},
  journaltitle = {BioEssays},
  volume = {43},
  number = {8},
  pages = {2100108},
  issn = {1521-1878},
  doi = {10.1002/bies.202100108},
  url = {https://onlinelibrary.wiley.com/doi/abs/10.1002/bies.202100108},
  urldate = {2024-07-04},
  abstract = {The comparison of growth, whether it is between different strains or under different growth conditions, is a classic microbiological technique that can provide genetic, epigenetic, cell biological, and chemical biological information depending on how the assay is used. When employing solid growth media, this technique is limited by being largely qualitative and low throughput. Collecting data in the form of growth curves, especially automated data collection in multi-well plates, circumvents these issues. However, the growth curves themselves are subject to stochastic variation in several variables, most notably the length of the lag phase, the doubling rate, and the maximum expansion of the culture. Thus, growth curves are indicative of trends but cannot always be conveniently averaged and statistically compared. Here, we summarize a simple method to compile growth curve data into a quantitative format that is amenable to statistical comparisons and easy to graph and display.},
  langid = {english},
  keywords = {growth curve,microbe,Saccharomyces cerevisiae},
  annotation = {2 citations (Semantic Scholar/DOI) [2024-07-04]},
  file = {/Users/michaelvolk/Zotero/storage/38L7RDQY/Sausen and Bochman - 2021 - Overcoming stochastic variations in culture variab.pdf;/Users/michaelvolk/Zotero/storage/N7FLUPEC/bies.html}
}

@article{schellenbergerQuantitativePredictionCellular2011,
  title = {Quantitative Prediction of Cellular Metabolism with Constraint-Based Models: The {{COBRA Toolbox}} v2.0},
  shorttitle = {Quantitative Prediction of Cellular Metabolism with Constraint-Based Models},
  author = {Schellenberger, Jan and Que, Richard and Fleming, Ronan M. T. and Thiele, Ines and Orth, Jeffrey D. and Feist, Adam M. and Zielinski, Daniel C. and Bordbar, Aarash and Lewis, Nathan E. and Rahmanian, Sorena and Kang, Joseph and Hyduke, Daniel R. and Palsson, Bernhard Ø},
  date = {2011-09},
  journaltitle = {Nature Protocols},
  shortjournal = {Nat Protoc},
  volume = {6},
  number = {9},
  pages = {1290--1307},
  publisher = {Nature Publishing Group},
  issn = {1750-2799},
  doi = {10.1038/nprot.2011.308},
  url = {https://www.nature.com/articles/nprot.2011.308},
  urldate = {2023-10-23},
  abstract = {Over the past decade, a growing community of researchers has emerged around the use of constraint-based reconstruction and analysis (COBRA) methods to simulate, analyze and predict a variety of metabolic phenotypes using genome-scale models. The COBRA Toolbox, a MATLAB package for implementing COBRA methods, was presented earlier. Here we present a substantial update of this in silico toolbox. Version 2.0 of the COBRA Toolbox expands the scope of computations by including in silico analysis methods developed since its original release. New functions include (i) network gap filling, (ii) 13C analysis, (iii) metabolic engineering, (iv) omics-guided analysis and (v) visualization. As with the first version, the COBRA Toolbox reads and writes systems biology markup language–formatted models. In version 2.0, we improved performance, usability and the level of documentation. A suite of test scripts can now be used to learn the core functionality of the toolbox and validate results. This toolbox lowers the barrier of entry to use powerful COBRA methods.},
  issue = {9},
  langid = {english},
  keywords = {Computational biology and bioinformatics,Metabolomics},
  annotation = {1693 citations (Semantic Scholar/DOI) [2023-10-23]},
  file = {/Users/michaelvolk/Zotero/storage/RRWLLSAN/Schellenberger et al_2011_Quantitative prediction of cellular metabolism with constraint-based models.pdf}
}

@article{schmidhuberDeepLearningNeural2015,
  title = {Deep Learning in Neural Networks: {{An}} Overview},
  shorttitle = {Deep Learning in Neural Networks},
  author = {Schmidhuber, Jürgen},
  date = {2015-01-01},
  journaltitle = {Neural Networks},
  shortjournal = {Neural Networks},
  volume = {61},
  pages = {85--117},
  issn = {0893-6080},
  doi = {10.1016/j.neunet.2014.09.003},
  url = {https://www.sciencedirect.com/science/article/pii/S0893608014002135},
  urldate = {2023-12-02},
  abstract = {In recent years, deep artificial neural networks (including recurrent ones) have won numerous contests in pattern recognition and machine learning. This historical survey compactly summarizes relevant work, much of it from the previous millennium. Shallow and Deep Learners are distinguished by the depth of their credit assignment paths, which are chains of possibly learnable, causal links between actions and effects. I review deep supervised learning (also recapitulating the history of backpropagation), unsupervised learning, reinforcement learning \& evolutionary computation, and indirect search for short programs encoding deep and large networks.},
  keywords = {Deep learning,Evolutionary computation,Reinforcement learning,Supervised learning,Unsupervised learning},
  annotation = {9997 citations (Semantic Scholar/DOI) [2023-12-01]},
  file = {/Users/michaelvolk/Zotero/storage/PRU8PF95/Schmidhuber_2015_Deep learning in neural networks.pdf;/Users/michaelvolk/Zotero/storage/DVCEAYWC/S0893608014002135.html}
}

@article{schuldinerExplorationFunctionOrganization2005,
  title = {Exploration of the {{Function}} and {{Organization}} of the {{Yeast Early Secretory Pathway}} through an {{Epistatic Miniarray Profile}}},
  author = {Schuldiner, Maya and Collins, Sean R. and Thompson, Natalie J. and Denic, Vladimir and Bhamidipati, Arunashree and Punna, Thanuja and Ihmels, Jan and Andrews, Brenda and Boone, Charles and Greenblatt, Jack F. and Weissman, Jonathan S. and Krogan, Nevan J.},
  date = {2005-11-04},
  journaltitle = {Cell},
  shortjournal = {Cell},
  volume = {123},
  number = {3},
  eprint = {16269340},
  eprinttype = {pmid},
  pages = {507--519},
  publisher = {Elsevier},
  issn = {0092-8674, 1097-4172},
  doi = {10.1016/j.cell.2005.08.031},
  url = {https://www.cell.com/cell/abstract/S0092-8674(05)00868-8},
  urldate = {2023-12-06},
  langid = {english},
  annotation = {889 citations (Semantic Scholar/DOI) [2023-12-05]},
  file = {/Users/michaelvolk/Zotero/storage/D2VFHLSM/Schuldiner et al_2005_Exploration of the Function and Organization of the Yeast Early Secretory.pdf}
}

@article{segreModularEpistasisYeast2005,
  title = {Modular Epistasis in Yeast Metabolism},
  author = {Segrè, Daniel and DeLuna, Alexander and Church, George M. and Kishony, Roy},
  date = {2005-01},
  journaltitle = {Nature Genetics},
  shortjournal = {Nat Genet},
  volume = {37},
  number = {1},
  pages = {77--83},
  publisher = {Nature Publishing Group},
  issn = {1546-1718},
  doi = {10.1038/ng1489},
  url = {https://www.nature.com/articles/ng1489},
  urldate = {2022-07-01},
  abstract = {Epistatic interactions, manifested in the effects of mutations on the phenotypes caused by other mutations, may help uncover the functional organization of complex biological networks1,2,3. Here, we studied system-level epistatic interactions by computing growth phenotypes of all single and double knockouts of 890 metabolic genes in Saccharomyces cerevisiae, using the framework of flux balance analysis4. A new scale for epistasis identified a distinctive trimodal distribution of these epistatic effects, allowing gene pairs to be classified as buffering, aggravating or noninteracting2,5. We found that the ensuing epistatic interaction network6 could be organized hierarchically into function-enriched modules that interact with each other 'monochromatically' (i.e., with purely aggravating or purely buffering epistatic links). This property extends the concept of epistasis from single genes to functional units and provides a new definition of biological modularity, which emphasizes interactions between, rather than within, functional modules. Our approach can be used to infer functional gene modules from purely phenotypic epistasis measurements.},
  issue = {1},
  langid = {english},
  keywords = {🦌📚,Agriculture,Animal Genetics and Genomics,Biomedicine,Cancer Research,Gene Function,general,Human Genetics},
  annotation = {588 citations (Semantic Scholar/DOI) [2022-11-26]},
  file = {/Users/michaelvolk/Zotero/storage/Z6R7PSAM/Segrè et al_2005_Modular epistasis in yeast metabolism.pdf;/Users/michaelvolk/Zotero/storage/GKJNZ8W5/ng1489.html}
}

@article{seitzInterpretingCisregulatoryMechanisms2024,
  title = {Interpreting Cis-Regulatory Mechanisms from Genomic Deep Neural Networks Using Surrogate Models},
  author = {Seitz, Evan E. and McCandlish, David M. and Kinney, Justin B. and Koo, Peter K.},
  date = {2024-06-21},
  journaltitle = {Nature Machine Intelligence},
  shortjournal = {Nat Mach Intell},
  pages = {1--13},
  publisher = {Nature Publishing Group},
  issn = {2522-5839},
  doi = {10.1038/s42256-024-00851-5},
  url = {https://www.nature.com/articles/s42256-024-00851-5},
  urldate = {2024-06-24},
  abstract = {Deep neural networks (DNNs) have greatly advanced the ability to predict genome function from sequence. However, elucidating underlying biological mechanisms from genomic DNNs remains challenging. Existing interpretability methods, such as attribution maps, have their origins in non-biological machine learning applications and therefore have the potential to be improved by incorporating domain-specific interpretation strategies. Here we introduce SQUID (Surrogate Quantitative Interpretability for Deepnets), a genomic DNN interpretability framework based on domain-specific surrogate modelling. SQUID approximates genomic DNNs in user-specified regions of sequence space using surrogate models—simpler quantitative models that have inherently interpretable mathematical forms. SQUID leverages domain knowledge to model cis-regulatory mechanisms in genomic DNNs, in particular by removing the confounding effects that nonlinearities and heteroscedastic noise in functional genomics data can have on model interpretation. Benchmarking analysis on multiple genomic DNNs shows that SQUID, when compared to established interpretability methods, identifies motifs that are more consistent across genomic loci and yields improved single-nucleotide variant-effect predictions. SQUID also supports surrogate models that quantify epistatic interactions within and between cis-regulatory elements, as well as global explanations of cis-regulatory mechanisms across sequence contexts. SQUID thus advances the ability to mechanistically interpret genomic DNNs.},
  langid = {english},
  keywords = {Computational models,Machine learning},
  file = {/Users/michaelvolk/Zotero/storage/U9PJTF56/Seitz et al_2024_Interpreting cis-regulatory mechanisms from genomic deep neural networks using.pdf}
}

@article{seitzInterpretingCisregulatoryMechanisms2024a,
  title = {Interpreting Cis-Regulatory Mechanisms from Genomic Deep Neural Networks Using Surrogate Models},
  author = {Seitz, Evan E. and McCandlish, David M. and Kinney, Justin B. and Koo, Peter K.},
  date = {2024-06},
  journaltitle = {Nature Machine Intelligence},
  shortjournal = {Nat Mach Intell},
  volume = {6},
  number = {6},
  pages = {701--713},
  publisher = {Nature Publishing Group},
  issn = {2522-5839},
  doi = {10.1038/s42256-024-00851-5},
  url = {https://www.nature.com/articles/s42256-024-00851-5},
  urldate = {2024-07-16},
  abstract = {Deep neural networks (DNNs) have greatly advanced the ability to predict genome function from sequence. However, elucidating underlying biological mechanisms from genomic DNNs remains challenging. Existing interpretability methods, such as attribution maps, have their origins in non-biological machine learning applications and therefore have the potential to be improved by incorporating domain-specific interpretation strategies. Here we introduce SQUID (Surrogate Quantitative Interpretability for Deepnets), a genomic DNN interpretability framework based on domain-specific surrogate modelling. SQUID approximates genomic DNNs in user-specified regions of sequence space using surrogate models—simpler quantitative models that have inherently interpretable mathematical forms. SQUID leverages domain knowledge to model cis-regulatory mechanisms in genomic DNNs, in particular by removing the confounding effects that nonlinearities and heteroscedastic noise in functional genomics data can have on model interpretation. Benchmarking analysis on multiple genomic DNNs shows that SQUID, when compared to established interpretability methods, identifies motifs that are more consistent across genomic loci and yields improved single-nucleotide variant-effect predictions. SQUID also supports surrogate models that quantify epistatic interactions within and between cis-regulatory elements, as well as global explanations of cis-regulatory mechanisms across sequence contexts. SQUID thus advances the ability to mechanistically interpret genomic DNNs.},
  langid = {english},
  keywords = {Computational models,Machine learning},
  file = {/Users/michaelvolk/Zotero/storage/WTIU2JQT/Seitz et al_2024_Interpreting cis-regulatory mechanisms from genomic deep neural networks using.pdf}
}

@book{selvarajooComputationalBiologyMachine2023,
  title = {Computational {{Biology}} and {{Machine Learning}} for {{Metabolic Engineering}} and {{Synthetic Biology}}},
  editor = {Selvarajoo, Kumar},
  date = {2023},
  series = {Methods in {{Molecular Biology}}},
  volume = {2553},
  publisher = {Springer US},
  location = {New York, NY},
  doi = {10.1007/978-1-0716-2617-7},
  url = {https://link.springer.com/10.1007/978-1-0716-2617-7},
  urldate = {2023-02-02},
  isbn = {978-1-07-162616-0 978-1-07-162617-7},
  langid = {english},
  keywords = {Genetic Engineering,high-throughput RNA,Proteomics,Recombinase Logic Gate Circuits Design,Transcription Factors},
  file = {/Users/michaelvolk/Zotero/storage/PE4TBXZ9/Selvarajoo_2023_Computational Biology and Machine Learning for Metabolic Engineering and.pdf}
}

@article{shalemSystematicDissectionSequence2015,
  title = {Systematic {{Dissection}} of the {{Sequence Determinants}} of {{Gene}} 3’ {{End Mediated Expression Control}}},
  author = {Shalem, Ophir and Sharon, Eilon and Lubliner, Shai and Regev, Ifat and Lotan-Pompan, Maya and Yakhini, Zohar and Segal, Eran},
  date = {2015-04-15},
  journaltitle = {PLOS Genetics},
  shortjournal = {PLOS Genetics},
  volume = {11},
  number = {4},
  pages = {e1005147},
  publisher = {Public Library of Science},
  issn = {1553-7404},
  doi = {10.1371/journal.pgen.1005147},
  url = {https://journals.plos.org/plosgenetics/article?id=10.1371/journal.pgen.1005147},
  urldate = {2023-09-13},
  abstract = {The 3’end genomic region encodes a wide range of regulatory process including mRNA stability, 3’ end processing and translation. Here, we systematically investigate the sequence determinants of 3’ end mediated expression control by measuring the effect of 13,000 designed 3’ end sequence variants on constitutive expression levels in yeast. By including a high resolution scanning mutagenesis of more than 200 native 3’ end sequences in this designed set, we found that most mutations had only a mild effect on expression, and that the vast majority (\textasciitilde 90\%) of strongly effecting mutations localized to a single positive TA-rich element, similar to a previously described 3’ end processing efficiency element, and resulted in up to ten-fold decrease in expression. Measurements of 3’ UTR lengths revealed that these mutations result in mRNAs with aberrantly long 3’UTRs, confirming the role for this element in 3’ end processing. Interestingly, we found that other sequence elements that were previously described in the literature to be part of the polyadenylation signal had a minor effect on expression. We further characterize the sequence specificities of the TA-rich element using additional synthetic 3’ end sequences and show that its activity is sensitive to single base pair mutations and strongly depends on the A/T content of the surrounding sequences. Finally, using a computational model, we show that the strength of this element in native 3’ end sequences can explain some of their measured expression variability (R = 0.41). Together, our results emphasize the importance of efficient 3’ end processing for endogenous protein levels and contribute to an improved understanding of the sequence elements involved in this process.},
  langid = {english},
  keywords = {Cloning,Gene expression,Messenger RNA,Mutagenesis,Polyadenylation,Sequence motif analysis,Yeast,Yellow fluorescent protein},
  annotation = {62 citations (Semantic Scholar/DOI) [2023-09-13]},
  file = {/Users/michaelvolk/Zotero/storage/35XH6IA8/Shalem et al_2015_Systematic Dissection of the Sequence Determinants of Gene 3’ End Mediated.pdf}
}

@online{shaoCalculusVariationsHypergraphs2024,
  title = {Calculus of Variations on Hypergraphs},
  author = {Shao, Mengqiu and Tian, Yulu and Zhao, Liang},
  date = {2024-03-29},
  eprint = {2403.12394},
  eprinttype = {arXiv},
  eprintclass = {math},
  url = {http://arxiv.org/abs/2403.12394},
  urldate = {2024-07-04},
  abstract = {We have established a coherent framework for applying variational methods to partial differential equations on hypergraphs, which includes the propositions of calculus and function spaces on hypergraphs. Several results related to the maximum principle on hypergraphs have also been proven. As applications, we demonstrated how these can be used to study partial differential equations on hypergraphs.},
  langid = {english},
  pubstate = {prepublished},
  keywords = {05C65 35A15,Mathematics - Analysis of PDEs,Mathematics - Combinatorics},
  annotation = {0 citations (Semantic Scholar/arXiv) [2024-07-04]},
  file = {/Users/michaelvolk/Zotero/storage/BXT35FL5/Shao et al. - 2024 - Calculus of variations on hypergraphs.pdf}
}

@article{shaReconstructingGrowthDynamic2024a,
  title = {Reconstructing Growth and Dynamic Trajectories from Single-Cell Transcriptomics Data},
  author = {Sha, Yutong and Qiu, Yuchi and Zhou, Peijie and Nie, Qing},
  date = {2024-01},
  journaltitle = {Nature Machine Intelligence},
  shortjournal = {Nat Mach Intell},
  volume = {6},
  number = {1},
  pages = {25--39},
  publisher = {Nature Publishing Group},
  issn = {2522-5839},
  doi = {10.1038/s42256-023-00763-w},
  url = {https://www.nature.com/articles/s42256-023-00763-w},
  urldate = {2024-07-16},
  abstract = {Time-series single-cell RNA sequencing (scRNA-seq) datasets provide unprecedented opportunities to learn dynamic processes of cellular systems. Due to the destructive nature of sequencing, it remains challenging to link the scRNA-seq snapshots sampled at different time points. Here we present TIGON, a dynamic, unbalanced optimal transport algorithm that reconstructs dynamic trajectories and population growth simultaneously as well as the underlying gene regulatory network from multiple snapshots. To tackle the high-dimensional optimal transport problem, we introduce a deep learning method using a dimensionless formulation based on the Wasserstein–Fisher–Rao (WFR) distance. TIGON is evaluated on simulated data and compared with existing methods for its robustness and accuracy in predicting cell state transition and cell population growth. Using three scRNA-seq datasets, we show the importance of growth in the temporal inference, TIGON’s capability in reconstructing gene expression at unmeasured time points and its applications to temporal gene regulatory networks and cell–cell communication inference.},
  langid = {english},
  keywords = {Data integration,Machine learning},
  annotation = {9 citations (Semantic Scholar/DOI) [2024-07-15]},
  file = {/Users/michaelvolk/Zotero/storage/ILSC7SLI/Sha et al_2024_Reconstructing growth and dynamic trajectories from single-cell transcriptomics.pdf}
}

@article{sharmaGraphNeuralNetwork2024,
  title = {Graph {{Neural Network Operators}}: A {{Review}}},
  shorttitle = {Graph {{Neural Network Operators}}},
  author = {Sharma, Anuj and Singh, Sukhdeep and Ratna, S.},
  date = {2024-03-01},
  journaltitle = {Multimedia Tools and Applications},
  shortjournal = {Multimed Tools Appl},
  volume = {83},
  number = {8},
  pages = {23413--23436},
  issn = {1573-7721},
  doi = {10.1007/s11042-023-16440-4},
  url = {https://doi.org/10.1007/s11042-023-16440-4},
  urldate = {2025-02-27},
  abstract = {Graph Neural Networks (GNN) is one of the promising machine learning areas in solving real world problems such as social networks, recommender systems, computer vision and pattern recognition. One of the important component of GNN is GNN operators which are responsible to train GNN graph structured data and forward learning nodes information to other layers. This review focus on recent advancements of GNN operators in detail. The rich Mathematical nature of GNN operators has been discussed for selected GNN operators. The review also highlights different benchmark graph structured datasets and presents results using different GNN operators. We have included thorough discussion for state-of-the-art in this field including limitations and future directions. Overall, the review covers important areas of GNN as GNN operators from future research directions point of view and real world applications perspective.},
  langid = {english},
  keywords = {Deep learning,GNN convolutional operators,Graph neural networks,Graph structural representation},
  annotation = {13 citations (Semantic Scholar/DOI) [2025-02-27]},
  file = {/Users/michaelvolk/Zotero/storage/VHK27G3F/Sharma et al_2024_Graph Neural Network Operators.pdf}
}

@online{shehzadGraphTransformersSurvey2024,
  title = {Graph {{Transformers}}: {{A Survey}}},
  shorttitle = {Graph {{Transformers}}},
  author = {Shehzad, Ahsan and Xia, Feng and Abid, Shagufta and Peng, Ciyuan and Yu, Shuo and Zhang, Dongyu and Verspoor, Karin},
  date = {2024-07-13},
  eprint = {2407.09777},
  eprinttype = {arXiv},
  eprintclass = {cs},
  doi = {10.48550/arXiv.2407.09777},
  url = {http://arxiv.org/abs/2407.09777},
  urldate = {2025-02-12},
  abstract = {Graph transformers are a recent advancement in machine learning, offering a new class of neural network models for graph-structured data. The synergy between transformers and graph learning demonstrates strong performance and versatility across various graph-related tasks. This survey provides an in-depth review of recent progress and challenges in graph transformer research. We begin with foundational concepts of graphs and transformers. We then explore design perspectives of graph transformers, focusing on how they integrate graph inductive biases and graph attention mechanisms into the transformer architecture. Furthermore, we propose a taxonomy classifying graph transformers based on depth, scalability, and pre-training strategies, summarizing key principles for effective development of graph transformer models. Beyond technical analysis, we discuss the applications of graph transformer models for node-level, edge-level, and graph-level tasks, exploring their potential in other application scenarios as well. Finally, we identify remaining challenges in the field, such as scalability and efficiency, generalization and robustness, interpretability and explainability, dynamic and complex graphs, as well as data quality and diversity, charting future directions for graph transformer research.},
  pubstate = {prepublished},
  keywords = {Computer Science - Artificial Intelligence,Computer Science - Machine Learning},
  annotation = {2 citations (Semantic Scholar/arXiv) [2025-02-12]\\
2 citations (Semantic Scholar/DOI) [2025-02-12]},
  file = {/Users/michaelvolk/Zotero/storage/INLQGJGE/Shehzad et al_2024_Graph Transformers.pdf;/Users/michaelvolk/Zotero/storage/6B335PFQ/2407.html}
}

@online{shehzadGraphTransformersSurvey2024a,
  title = {Graph {{Transformers}}: {{A Survey}}},
  shorttitle = {Graph {{Transformers}}},
  author = {Shehzad, Ahsan and Xia, Feng and Abid, Shagufta and Peng, Ciyuan and Yu, Shuo and Zhang, Dongyu and Verspoor, Karin},
  date = {2024-07-13},
  eprint = {2407.09777},
  eprinttype = {arXiv},
  eprintclass = {cs},
  doi = {10.48550/arXiv.2407.09777},
  url = {http://arxiv.org/abs/2407.09777},
  urldate = {2025-02-27},
  abstract = {Graph transformers are a recent advancement in machine learning, offering a new class of neural network models for graph-structured data. The synergy between transformers and graph learning demonstrates strong performance and versatility across various graph-related tasks. This survey provides an in-depth review of recent progress and challenges in graph transformer research. We begin with foundational concepts of graphs and transformers. We then explore design perspectives of graph transformers, focusing on how they integrate graph inductive biases and graph attention mechanisms into the transformer architecture. Furthermore, we propose a taxonomy classifying graph transformers based on depth, scalability, and pre-training strategies, summarizing key principles for effective development of graph transformer models. Beyond technical analysis, we discuss the applications of graph transformer models for node-level, edge-level, and graph-level tasks, exploring their potential in other application scenarios as well. Finally, we identify remaining challenges in the field, such as scalability and efficiency, generalization and robustness, interpretability and explainability, dynamic and complex graphs, as well as data quality and diversity, charting future directions for graph transformer research.},
  pubstate = {prepublished},
  keywords = {Computer Science - Artificial Intelligence,Computer Science - Machine Learning},
  annotation = {4 citations (Semantic Scholar/arXiv) [2025-02-27]\\
4 citations (Semantic Scholar/DOI) [2025-02-27]},
  file = {/Users/michaelvolk/Zotero/storage/B5EBV4ET/Shehzad et al_2024_Graph Transformers.pdf;/Users/michaelvolk/Zotero/storage/A9AP5MLN/2407.html}
}

@online{shiMaskedLabelPrediction2021,
  title = {Masked {{Label Prediction}}: {{Unified Message Passing Model}} for {{Semi-Supervised Classification}}},
  shorttitle = {Masked {{Label Prediction}}},
  author = {Shi, Yunsheng and Huang, Zhengjie and Feng, Shikun and Zhong, Hui and Wang, Wenjin and Sun, Yu},
  date = {2021-05-10},
  eprint = {2009.03509},
  eprinttype = {arXiv},
  eprintclass = {cs},
  doi = {10.48550/arXiv.2009.03509},
  url = {http://arxiv.org/abs/2009.03509},
  urldate = {2025-02-12},
  abstract = {Graph neural network (GNN) and label propagation algorithm (LPA) are both message passing algorithms, which have achieved superior performance in semi-supervised classification. GNN performs feature propagation by a neural network to make predictions, while LPA uses label propagation across graph adjacency matrix to get results. However, there is still no effective way to directly combine these two kinds of algorithms. To address this issue, we propose a novel Unified Message Passaging Model (UniMP) that can incorporate feature and label propagation at both training and inference time. First, UniMP adopts a Graph Transformer network, taking feature embedding and label embedding as input information for propagation. Second, to train the network without overfitting in self-loop input label information, UniMP introduces a masked label prediction strategy, in which some percentage of input label information are masked at random, and then predicted. UniMP conceptually unifies feature propagation and label propagation and is empirically powerful. It obtains new state-of-the-art semi-supervised classification results in Open Graph Benchmark (OGB).},
  pubstate = {prepublished},
  keywords = {Computer Science - Machine Learning,Statistics - Machine Learning},
  annotation = {634 citations (Semantic Scholar/arXiv) [2025-02-12]},
  file = {/Users/michaelvolk/Zotero/storage/5HEIDFLU/Shi et al_2021_Masked Label Prediction.pdf;/Users/michaelvolk/Zotero/storage/N8IX73N4/2009.html}
}

@online{shiMaskedLabelPrediction2021a,
  title = {Masked {{Label Prediction}}: {{Unified Message Passing Model}} for {{Semi-Supervised Classification}}},
  shorttitle = {Masked {{Label Prediction}}},
  author = {Shi, Yunsheng and Huang, Zhengjie and Feng, Shikun and Zhong, Hui and Wang, Wenjin and Sun, Yu},
  date = {2021-05-10},
  eprint = {2009.03509},
  eprinttype = {arXiv},
  eprintclass = {cs},
  doi = {10.48550/arXiv.2009.03509},
  url = {http://arxiv.org/abs/2009.03509},
  urldate = {2025-02-27},
  abstract = {Graph neural network (GNN) and label propagation algorithm (LPA) are both message passing algorithms, which have achieved superior performance in semi-supervised classification. GNN performs feature propagation by a neural network to make predictions, while LPA uses label propagation across graph adjacency matrix to get results. However, there is still no effective way to directly combine these two kinds of algorithms. To address this issue, we propose a novel Unified Message Passaging Model (UniMP) that can incorporate feature and label propagation at both training and inference time. First, UniMP adopts a Graph Transformer network, taking feature embedding and label embedding as input information for propagation. Second, to train the network without overfitting in self-loop input label information, UniMP introduces a masked label prediction strategy, in which some percentage of input label information are masked at random, and then predicted. UniMP conceptually unifies feature propagation and label propagation and is empirically powerful. It obtains new state-of-the-art semi-supervised classification results in Open Graph Benchmark (OGB).},
  pubstate = {prepublished},
  keywords = {Computer Science - Machine Learning,Statistics - Machine Learning},
  annotation = {648 citations (Semantic Scholar/arXiv) [2025-02-27]},
  file = {/Users/michaelvolk/Zotero/storage/92YFKRZ5/Shi et al_2021_Masked Label Prediction.pdf;/Users/michaelvolk/Zotero/storage/5I7WZFVS/2009.html}
}

@article{shiMetabolicEngineeringYeast2025,
  title = {Metabolic {{Engineering}} of {{Yeast}}},
  author = {Shi, Shuobo and Chen, Yu and Nielsen, Jens},
  date = {2025-01-21},
  publisher = {Annual Reviews},
  doi = {10.1146/annurev-biophys-070924-103134},
  url = {https://www.annualreviews.org/content/journals/10.1146/annurev-biophys-070924-103134},
  urldate = {2025-04-30},
  abstract = {Microbial cell factories have been developed to produce various compounds in a sustainable and economically viable manner. The yeast Saccharomyces cerevisiae has been used as a platform cell factory in industrial biotechnology with numerous advantages, including ease of operation, rapid growth, and tolerance for various industrial stressors. Advances in synthetic biology and metabolic models have accelerated the design–build–test–learn cycle in metabolic engineering, significantly facilitating the development of yeast strains with complex phenotypes, including the redirection of metabolic fluxes to desired products, the expansion of the spectrum of usable substrates, and the improvement of the physiological properties of strain. Strains with enhanced titer, rate, and yield are now competing with traditional petroleum-based industrial approaches. This review highlights recent advances and perspectives in the metabolic engineering of yeasts for the production of a variety of compounds, including fuels, chemicals, proteins, and peptides, as well as advancements in synthetic biology tools and mathematical modeling.},
  langid = {english},
  annotation = {2 citations (Semantic Scholar/DOI) [2025-04-30]},
  file = {/Users/michaelvolk/Zotero/storage/E395EB2A/Shi et al_2025_Metabolic Engineering of Yeast.pdf;/Users/michaelvolk/Zotero/storage/VGK2TXL7/annurev-biophys-070924-103134.html}
}

@article{shiMicroRNAsPlayRegulatory2023,
  title = {{{MicroRNAs}} Play Regulatory Roles in Genomic Balance},
  author = {Shi, Xiaowen and Yang, Hua and Birchler, James A.},
  date = {2023},
  journaltitle = {BioEssays},
  volume = {45},
  number = {2},
  pages = {2200187},
  issn = {1521-1878},
  doi = {10.1002/bies.202200187},
  url = {https://onlinelibrary.wiley.com/doi/abs/10.1002/bies.202200187},
  urldate = {2024-07-04},
  abstract = {Classic genetics studies found that genomic imbalance caused by changing the dosage of part of the genome (aneuploidy) has more detrimental effects than altering the dosage of the whole genome (ploidy). Previous analysis revealed global modulation of gene expression triggered by aneuploidy across various species, including maize (Zea mays), Arabidopsis, yeast, mammals, etc. Plant microRNAs (miRNAs) are a class of 20- to 24-nt endogenous small noncoding RNAs that carry out post-transcriptional gene expression regulation. That miRNAs and their putative targets are preferentially retained as duplicates after whole-genome duplication, as are many transcription factors and signaling components, indicates miRNAs are likely to be dosage-sensitive and potentially involved in genomic balance networks. This review addresses the following questions regarding the role of miRNAs in genomic imbalance. (1) How do aneuploidy and polyploidy impact the expression of miRNAs? (2) Do miRNAs play a regulatory role in modulating the expression of their targets under genomic imbalance?},
  langid = {english},
  keywords = {aneuploidy,dosage,genomic imbalance,miRNA,polyploidy},
  annotation = {4 citations (Semantic Scholar/DOI) [2024-07-04]},
  file = {/Users/michaelvolk/Zotero/storage/WZX89GHY/bies.html}
}

@inproceedings{shirzadEvenSparserGraph2024,
  title = {Even {{Sparser Graph Transformers}}},
  author = {Shirzad, Hamed and Lin, Honghao and Venkatachalam, Balaji and Velingker, Ameya and Woodruff, David and Sutherland, Danica J.},
  date = {2024-11-06},
  url = {https://openreview.net/forum?id=K3k4bWuNnk},
  urldate = {2025-02-12},
  abstract = {Graph Transformers excel in long-range dependency modeling, but generally require quadratic memory complexity in the number of nodes in an input graph, and hence have trouble scaling to large graphs. Sparse attention variants such as Exphormer can help, but may require high-degree augmentations to the input graph for good performance, and do not attempt to sparsify an already-dense input graph. As the learned attention mechanisms tend to use few of these edges, however, such high-degree connections may be unnecessary. We show (empirically and with theoretical backing) that attention scores on graphs are usually quite consistent across network widths, and use this observation to propose a two-stage procedure, which we call Spexphormer: first, train a narrow network on the full augmented graph. Next, use only the active connections to train a wider network on a much sparser graph. We establish theoretical conditions when a narrow network's attention scores can match those of a wide network, and show that Spexphormer achieves good performance with drastically reduced memory requirements on various graph datasets.},
  eventtitle = {The {{Thirty-eighth Annual Conference}} on {{Neural Information Processing Systems}}},
  langid = {english},
  file = {/Users/michaelvolk/Zotero/storage/6HWX2CXT/Shirzad et al_2024_Even Sparser Graph Transformers.pdf}
}

@online{shirzadExphormerSparseTransformers2023,
  title = {Exphormer: {{Sparse Transformers}} for {{Graphs}}},
  shorttitle = {Exphormer},
  author = {Shirzad, Hamed and Velingker, Ameya and Venkatachalam, Balaji and Sutherland, Danica J. and Sinop, Ali Kemal},
  date = {2023-07-24},
  eprint = {2303.06147},
  eprinttype = {arXiv},
  eprintclass = {cs},
  doi = {10.48550/arXiv.2303.06147},
  url = {http://arxiv.org/abs/2303.06147},
  urldate = {2025-02-12},
  abstract = {Graph transformers have emerged as a promising architecture for a variety of graph learning and representation tasks. Despite their successes, though, it remains challenging to scale graph transformers to large graphs while maintaining accuracy competitive with message-passing networks. In this paper, we introduce Exphormer, a framework for building powerful and scalable graph transformers. Exphormer consists of a sparse attention mechanism based on two mechanisms: virtual global nodes and expander graphs, whose mathematical characteristics, such as spectral expansion, pseduorandomness, and sparsity, yield graph transformers with complexity only linear in the size of the graph, while allowing us to prove desirable theoretical properties of the resulting transformer models. We show that incorporating Exphormer into the recently-proposed GraphGPS framework produces models with competitive empirical results on a wide variety of graph datasets, including state-of-the-art results on three datasets. We also show that Exphormer can scale to datasets on larger graphs than shown in previous graph transformer architectures. Code can be found at \textbackslash url\{https://github.com/hamed1375/Exphormer\}.},
  pubstate = {prepublished},
  keywords = {Computer Science - Machine Learning},
  annotation = {83 citations (Semantic Scholar/arXiv) [2025-02-12]\\
83 citations (Semantic Scholar/DOI) [2025-02-12]},
  file = {/Users/michaelvolk/Zotero/storage/U2FCYRUE/Shirzad et al_2023_Exphormer.pdf;/Users/michaelvolk/Zotero/storage/KXKPUXZF/2303.html}
}

@article{shuModelingGeneRegulatory2021,
  title = {Modeling Gene Regulatory Networks Using Neural Network Architectures},
  author = {Shu, Hantao and Zhou, Jingtian and Lian, Qiuyu and Li, Han and Zhao, Dan and Zeng, Jianyang and Ma, Jianzhu},
  date = {2021-07},
  journaltitle = {Nature Computational Science},
  shortjournal = {Nat Comput Sci},
  volume = {1},
  number = {7},
  pages = {491--501},
  publisher = {Nature Publishing Group},
  issn = {2662-8457},
  doi = {10.1038/s43588-021-00099-8},
  url = {https://www.nature.com/articles/s43588-021-00099-8},
  urldate = {2023-10-14},
  abstract = {Gene regulatory networks (GRNs) encode the complex molecular interactions that govern cell identity. Here we propose DeepSEM, a deep generative model that can jointly infer GRNs and biologically meaningful representation of single-cell RNA sequencing (scRNA-seq) data. In particular, we developed a neural network version of the structural equation model (SEM) to explicitly model the regulatory relationships among genes. Benchmark results show that DeepSEM achieves comparable or better performance on a variety of single-cell computational tasks, such as GRN inference, scRNA-seq data visualization, clustering and simulation, compared with the state-of-the-art methods. In addition, the gene regulations predicted by DeepSEM on cell-type marker genes in the mouse cortex can be validated by epigenetic data, which further demonstrates the accuracy and efficiency of our method. DeepSEM can provide a useful and powerful tool to analyze scRNA-seq data and infer a GRN.},
  issue = {7},
  langid = {english},
  keywords = {Computational biology and bioinformatics,Gene regulatory networks,Machine learning},
  annotation = {33 citations (Semantic Scholar/DOI) [2023-10-14]},
  file = {/Users/michaelvolk/Zotero/storage/ULKLDBUJ/Shu et al_2021_Modeling gene regulatory networks using neural network architectures.pdf}
}

@article{sigwartWhyThereNo2023,
  title = {Why Is There No Service to Support Taxonomy?},
  author = {Sigwart, Julia D. and Chen, Chong and Tilic, Ekin and Vences, Miguel and Riehl, Torben},
  date = {2023},
  journaltitle = {BioEssays},
  volume = {45},
  number = {9},
  pages = {2300070},
  issn = {1521-1878},
  doi = {10.1002/bies.202300070},
  url = {https://onlinelibrary.wiley.com/doi/abs/10.1002/bies.202300070},
  urldate = {2024-07-04},
  abstract = {Increasing complexity and specialisation of modern sciences has led to increasingly collaborative publications, as well as the involvement of commercial services. Modern integrative taxonomy likewise depends on many lines of evidence and is increasingly complex, but the trend of collaboration lags and various attempts at ‘turbo taxonomy’ have been unsatisfactory. We are developing a taxonomic service in the Senckenberg Ocean Species Alliance to provide fundamental data for new species descriptions. This will also function as a hub to connect a global network of taxonomists, assembling an alliance of scientists working on potential new species to tackle both the extinction and inclusion crises we face today. The current rate of new species descriptions is simply too slow; the discipline is often dismissed as old fashioned, and there is a crisis level need for taxonomic descriptions to come to grips with the scale of Anthropocene biodiversity loss. Here, we envision how the process of describing and naming species would benefit from a service supporting the acquisition of descriptive data. Also see the video abstract here: https://youtu.be/E8q3KJor\_F8},
  langid = {english},
  keywords = {biodiversity,global science,marine inverterbates,species,taxonomy},
  annotation = {2 citations (Semantic Scholar/DOI) [2024-07-04]},
  file = {/Users/michaelvolk/Zotero/storage/EQ69JUH2/Sigwart et al. - 2023 - Why is there no service to support taxonomy.pdf;/Users/michaelvolk/Zotero/storage/URYU7SVR/bies.html}
}

@online{singhAutomatedScientistDesign2023,
  title = {An {{Automated Scientist}} to {{Design}} and {{Optimize Microbial Strains}} for the {{Industrial Production}} of {{Small Molecules}}},
  author = {Singh, Amoolya H. and Kaufmann-Malaga, Benjamin B. and Lerman, Joshua A. and Dougherty, Daniel P. and Zhang, Yang and Kilbo, Alexander L. and Wilson, Erin H. and Ng, Chiam Yu and Erbilgin, Onur and Curran, Kate A. and Reeves, Christopher D. and Hung, John E. and Mantovani, Simone and King, Zachary A. and Ayson, Marites J. and Denery, Judith R. and Lu, Chia-Wei and Norton, Phillip and Tran, Carol and Platt, Darren M. and Cherry, Joel R. and Chandran, Sunil S. and Meadows, Adam L.},
  date = {2023-01-03},
  eprinttype = {bioRxiv},
  eprintclass = {New Results},
  pages = {2023.01.03.521657},
  doi = {10.1101/2023.01.03.521657},
  url = {https://www.biorxiv.org/content/10.1101/2023.01.03.521657v1},
  urldate = {2025-04-06},
  abstract = {Engineering microbes to synthesize molecules of societal value has historically been a time consuming and artisanal process, with the synthesis of each new non-native molecule typically warranting its own separate publication. Because most microbial strain engineering efforts leverage a finite number of common metabolic engineering design tactics, we reasoned that automating these design steps would help create a pipeline that can quickly, cheaply, and reliably generate so-called microbial factories. In this work we describe the design and implementation of a computational system, an Automated Scientist we call Lila, which handles all metabolic engineering design and optimization through the design-build-test-learn (DBTL) paradigm. Lila generates metabolic routes, identifies relevant genetic elements for perturbation, and specifies the design and re-design of microbial strains in a matter of seconds to minutes. Strains specified by Lila are then built and subsequently phenotyped as part of a largely automated in-house pipeline. Humans remain in-the-loop to curate choices made by the system, helping for example to refine the metabolic model or suggest custom protein modifications. Lila attempted to build strains that could produce 454 biochemically diverse molecules with precursors located broadly throughout the metabolism of two microbial hosts, Saccharomyces cerevisiae and Escherichia coli. Notably, we observed the highest published titers for the molecule naringenin, the metabolic precursor to flavonoids. In total we created hundreds of thousands of microbial strains capable of overproducing 242 molecules, of which 180 are not native to S. cerevisiae or E. coli.},
  langid = {english},
  pubstate = {prepublished},
  annotation = {4 citations (Semantic Scholar/DOI) [2025-04-06]},
  file = {/Users/michaelvolk/Zotero/storage/87S3CWPP/Singh et al_2023_An Automated Scientist to Design and Optimize Microbial Strains for the.pdf}
}

@article{singhGmx_qkAutomatedProtein2023,
  title = {Gmx\_qk: {{An Automated Protein}}/{{Protein}}–{{Ligand Complex Simulation Workflow Bridged}} to {{MM}}/{{PBSA}}, {{Based}} on {{Gromacs}} and {{Zenity-Dependent GUI}} for {{Beginners}} in {{MD Simulation Study}}},
  shorttitle = {Gmx\_qk},
  author = {Singh, Harvinder and Raja, Anupam and Prakash, Ajay and Medhi, Bikash},
  date = {2023-05-08},
  journaltitle = {Journal of Chemical Information and Modeling},
  shortjournal = {J. Chem. Inf. Model.},
  volume = {63},
  number = {9},
  pages = {2603--2608},
  publisher = {American Chemical Society},
  issn = {1549-9596},
  doi = {10.1021/acs.jcim.3c00341},
  url = {https://doi.org/10.1021/acs.jcim.3c00341},
  urldate = {2023-09-26},
  abstract = {Open-source MD simulation tools provide academics and low-income countries with the ability to compete in drug discovery advancements. Gromacs is a well-known and established MD simulation tool, among others. Although command-line tools offer full flexibility to users, they require expertise and familiarity with the UNIX operating system. In this context, we have developed an automated bash workflow that enables users with minimal knowledge of UNIX or command-line tools to run protein/protein–ligand complex simulations bridged to MM/PBSA calculations. The workflow provides information to the user using Zenity widgets and requires minimal intervention, such as energy minimization, simulation duration, and output file naming. It initiates MD simulations within a few seconds (energy minimization, NVT, NPT, and MD) after taking input files and parameters, which takes 20–30 min in a command-line-based protocol. The single workflow also helps users to produce reproducible research results with fewer errors. The workflow is available at the GitHub repository: https://github.com/harry-maan/gmx\_qk.},
  annotation = {2 citations (Semantic Scholar/DOI) [2023-09-26]}
}

@article{sinhaKnowEnGKnowledgeEngine2015,
  title = {{{KnowEnG}}: A Knowledge Engine for Genomics},
  shorttitle = {{{KnowEnG}}},
  author = {Sinha, Saurabh and Song, Jun and Weinshilboum, Richard and Jongeneel, Victor and Han, Jiawei},
  date = {2015-11-01},
  journaltitle = {Journal of the American Medical Informatics Association},
  shortjournal = {Journal of the American Medical Informatics Association},
  volume = {22},
  number = {6},
  pages = {1115--1119},
  issn = {1067-5027},
  doi = {10.1093/jamia/ocv090},
  url = {https://doi.org/10.1093/jamia/ocv090},
  urldate = {2023-09-10},
  abstract = {We describe here the vision, motivations, and research plans of the National Institutes of Health Center for Excellence in Big Data Computing at the University of Illinois, Urbana-Champaign. The Center is organized around the construction of “Knowledge Engine for Genomics” (KnowEnG), an E-science framework for genomics where biomedical scientists will have access to powerful methods of data mining, network mining, and machine learning to extract knowledge out of genomics data. The scientist will come to KnowEnG with their own data sets in the form of spreadsheets and ask KnowEnG to analyze those data sets in the light of a massive knowledge base of community data sets called the “Knowledge Network” that will be at the heart of the system. The Center is undertaking discovery projects aimed at testing the utility of KnowEnG for transforming big data to knowledge. These projects span a broad range of biological enquiry, from pharmacogenomics (in collaboration with Mayo Clinic) to transcriptomics of human behavior.},
  annotation = {12 citations (Semantic Scholar/DOI) [2023-09-10]},
  file = {/Users/michaelvolk/Zotero/storage/VM32XB9K/Sinha et al_2015_KnowEnG.pdf;/Users/michaelvolk/Zotero/storage/7S64KPZ2/2357880.html}
}

@inproceedings{skianisRepSetNeural2020,
  title = {Rep the {{Set}}: {{Neural Networks}} for {{Learning Set Representations}}},
  shorttitle = {Rep the {{Set}}},
  booktitle = {Proceedings of the {{Twenty Third International Conference}} on {{Artificial Intelligence}} and {{Statistics}}},
  author = {Skianis, Konstantinos and Nikolentzos, Giannis and Limnios, Stratis and Vazirgiannis, Michalis},
  date = {2020-06-03},
  pages = {1410--1420},
  publisher = {PMLR},
  issn = {2640-3498},
  url = {https://proceedings.mlr.press/v108/skianis20a.html},
  urldate = {2023-10-09},
  abstract = {In several domains, data objects can be decomposed into sets of simpler objects. It is then natural to represent each object as the set of its components or parts. Many conventional machine learning algorithms are unable to process this kind of representations, since sets may vary in cardinality and elements lack a meaningful ordering. In this paper, we present a new neural network architecture, called RepSet, that can handle examples that are represented as sets of vectors. The proposed model computes the correspondences between an input set and some hidden sets by solving a series of network flow problems. This representation is then fed to a standard neural network architecture to produce the output. The architecture allows end-to-end gradient-based learning. We demonstrate RepSet on classification tasks, including text categorization, and graph classification, and we show that the proposed neural network achieves performance better or comparable to state-of-the-art algorithms.},
  eventtitle = {International {{Conference}} on {{Artificial Intelligence}} and {{Statistics}}},
  langid = {english},
  file = {/Users/michaelvolk/Zotero/storage/F9RT7SHH/Skianis et al_2020_Rep the Set.pdf}
}

@incollection{soelchDeepSetLearning2019a,
  title = {On {{Deep Set Learning}} and the {{Choice}} of {{Aggregations}}},
  booktitle = {Artificial {{Neural Networks}} and {{Machine Learning}} – {{ICANN}} 2019: {{Theoretical Neural Computation}}},
  author = {Soelch, Maximilian and Akhundov, Adnan and Van Der Smagt, Patrick and Bayer, Justin},
  editor = {Tetko, Igor V. and Kůrková, Věra and Karpov, Pavel and Theis, Fabian},
  date = {2019},
  volume = {11727},
  pages = {444--457},
  publisher = {Springer International Publishing},
  location = {Cham},
  doi = {10.1007/978-3-030-30487-4_35},
  url = {http://link.springer.com/10.1007/978-3-030-30487-4_35},
  urldate = {2023-10-09},
  isbn = {978-3-030-30486-7 978-3-030-30487-4},
  langid = {english},
  file = {/Users/michaelvolk/Zotero/storage/9WN4Z3FZ/Soelch et al_2019_On Deep Set Learning and the Choice of Aggregations.pdf}
}

@article{SoftwareDesignGuide,
  title = {Software {{Design Guide}}},
  langid = {english},
  file = {/Users/michaelvolk/Zotero/storage/NTVFFR7I/Software Design Guide.pdf}
}

@online{soltaniHyperedgeModelingHypergraph2024,
  title = {Hyperedge {{Modeling}} in {{Hypergraph Neural Networks}} by Using {{Densest Overlapping Subgraphs}}},
  author = {Soltani, Mehrad and Rueda, Luis},
  date = {2024-09-16},
  eprint = {2409.10340},
  eprinttype = {arXiv},
  eprintclass = {cs},
  doi = {10.48550/arXiv.2409.10340},
  url = {http://arxiv.org/abs/2409.10340},
  urldate = {2025-04-23},
  abstract = {Hypergraphs tackle the limitations of traditional graphs by introducing \{\textbackslash em hyperedges\}. While graph edges connect only two nodes, hyperedges connect an arbitrary number of nodes along their edges. Also, the underlying message-passing mechanisms in Hypergraph Neural Networks (HGNNs) are in the form of vertex-hyperedge-vertex, which let HGNNs capture and utilize richer and more complex structural information than traditional Graph Neural Networks (GNNs). More recently, the idea of overlapping subgraphs has emerged. These subgraphs can capture more information about subgroups of vertices without limiting one vertex belonging to just one group, allowing vertices to belong to multiple groups or subgraphs. In addition, one of the most important problems in graph clustering is to find densest overlapping subgraphs (DOS). In this paper, we propose a solution to the DOS problem via Agglomerative Greedy Enumeration (DOSAGE) algorithm as a novel approach to enhance the process of generating the densest overlapping subgraphs and, hence, a robust construction of the hypergraphs. Experiments on standard benchmarks show that the DOSAGE algorithm significantly outperforms the HGNNs and six other methods on the node classification task.},
  pubstate = {prepublished},
  version = {1},
  keywords = {Computer Science - Artificial Intelligence,Computer Science - Machine Learning,Computer Science - Social and Information Networks},
  annotation = {1 citations (Semantic Scholar/arXiv) [2025-04-23]\\
1 citations (Semantic Scholar/DOI) [2025-04-23]},
  file = {/Users/michaelvolk/Zotero/storage/QJCF7UX9/Soltani_Rueda_2024_Hyperedge Modeling in Hypergraph Neural Networks by using Densest Overlapping.pdf;/Users/michaelvolk/Zotero/storage/GDLQ2ABA/2409.html}
}

@article{stahlModellingProteinComplexes2024,
  title = {Modelling Protein Complexes with Crosslinking Mass Spectrometry and Deep Learning},
  author = {Stahl, Kolja and Warneke, Robert and Demann, Lorenz and Bremenkamp, Rica and Hormes, Björn and Brock, Oliver and Stülke, Jörg and Rappsilber, Juri},
  date = {2024-09-09},
  journaltitle = {Nature Communications},
  shortjournal = {Nat Commun},
  volume = {15},
  number = {1},
  pages = {7866},
  publisher = {Nature Publishing Group},
  issn = {2041-1723},
  doi = {10.1038/s41467-024-51771-2},
  url = {https://www.nature.com/articles/s41467-024-51771-2},
  urldate = {2025-02-27},
  abstract = {Scarcity of structural and evolutionary information on protein complexes poses a challenge to deep learning-based structure modelling. We integrate experimental distance restraints obtained by crosslinking mass spectrometry (MS) into AlphaFold-Multimer, by extending AlphaLink to protein complexes. Integrating crosslinking MS data substantially improves modelling performance on challenging targets, by helping to identify interfaces, focusing sampling, and improving model selection. This extends to single crosslinks from whole-cell crosslinking MS, opening the possibility of whole-cell structural investigations driven by experimental data. We demonstrate this by revealing the molecular basis of iron homoeostasis in Bacillus subtilis.},
  langid = {english},
  keywords = {Protein structure predictions,Proteomic analysis,Structural biology},
  file = {/Users/michaelvolk/Zotero/storage/WR3SZ7BC/Stahl et al_2024_Modelling protein complexes with crosslinking mass spectrometry and deep.pdf}
}

@article{stellaAutomatedRapidMethoda,
  title = {Automated, Rapid Method Optimization and Buffer Screening Using the {{Echo}}® {{MS}}+ System with {{ZenoTOF}} 7600 System},
  author = {Stella, Aaron and McCabe, Jacob W. and Bhalkikar, Anuja},
  url = {https://sciex.com/content/dam/SCIEX/pdf/jp/2024/Echo%C2%AE%20MS%2B%E3%82%B7%E3%82%B9%E3%83%86%E3%83%A0%E3%81%A8ZenoTOF%207600%E3%82%B7%E3%82%B9%E3%83%86%E3%83%A0%E3%82%92%E6%B4%BB%E7%94%A8%E3%81%97%E3%81%9F%E3%80%81%E4%BD%8E%E5%88%86%E5%AD%90%E3%80%81%E3%83%9A%E3%83%97%E3%83%81%E3%83%89%E3%80%81%E3%82%BF%E3%83%B3%E3%83%91%E3%82%AF%E8%B3%AA%E6%B8%AC%E5%AE%9A%E7%94%A8%E3%81%AE%E6%9C%80%E9%81%A9%E6%BA%B6%E5%AA%92%E3%81%AE%E8%BF%85%E9%80%9F%E6%AF%94%E8%BC%83.pdf},
  urldate = {2025-04-07},
  file = {/Users/michaelvolk/Zotero/storage/3JAGYA5K/Stella et al_Automated, rapid method optimization and buffer screening using the Echo® MS+.pdf}
}

@inproceedings{stewartTorchGeoDeepLearning2022a,
  title = {{{TorchGeo}}: Deep Learning with Geospatial Data},
  shorttitle = {{{TorchGeo}}},
  booktitle = {Proceedings of the 30th {{International Conference}} on {{Advances}} in {{Geographic Information Systems}}},
  author = {Stewart, Adam J. and Robinson, Caleb and Corley, Isaac A. and Ortiz, Anthony and Ferres, Juan M. Lavista and Banerjee, Arindam},
  date = {2022-11-22},
  series = {{{SIGSPATIAL}} '22},
  pages = {1--12},
  publisher = {Association for Computing Machinery},
  location = {New York, NY, USA},
  doi = {10.1145/3557915.3560953},
  url = {https://dl.acm.org/doi/10.1145/3557915.3560953},
  urldate = {2023-08-18},
  abstract = {Remotely sensed geospatial data are critical for applications including precision agriculture, urban planning, disaster monitoring and response, and climate change research, among others. Deep learning methods are particularly promising for modeling many remote sensing tasks given the success of deep neural networks in similar computer vision tasks and the sheer volume of remotely sensed imagery available. However, the variance in data collection methods and handling of geospatial metadata make the application of deep learning methodology to remotely sensed data nontrivial. For example, satellite imagery often includes additional spectral bands beyond red, green, and blue and must be joined to other geospatial data sources that can have differing coordinate systems, bounds, and resolutions. To help realize the potential of deep learning for remote sensing applications, we introduce TorchGeo, a Python library for integrating geospatial data into the PyTorch deep learning ecosystem. TorchGeo provides data loaders for a variety of benchmark datasets, composable datasets for generic geospatial data sources, samplers for geospatial data, and transforms that work with multispectral imagery. TorchGeo is also the first library to provide pre-trained models for multispectral satellite imagery (e.g., models that use all bands from the Sentinel-2 satellites), allowing for advances in transfer learning on downstream remote sensing tasks with limited labeled data. We use TorchGeo to create reproducible benchmark results on existing datasets and benchmark our proposed method for preprocessing geospatial imagery on the fly. TorchGeo is open source and available on GitHub: https://github.com/microsoft/torchgeo.},
  isbn = {978-1-4503-9529-8},
  keywords = {🦌✅,datasets,deep-learning,earth-observation,geospatial,models,remote-sensing,samplers,transforms},
  annotation = {0 citations (Semantic Scholar/DOI) [2023-08-18]},
  file = {/Users/michaelvolk/Zotero/storage/JN8FQMKR/Stewart et al. - 2022 - TorchGeo deep learning with geospatial data.pdf}
}

@article{stokesDeepLearningApproach2020,
  title = {A {{Deep Learning Approach}} to {{Antibiotic Discovery}}},
  author = {Stokes, Jonathan M. and Yang, Kevin and Swanson, Kyle and Jin, Wengong and Cubillos-Ruiz, Andres and Donghia, Nina M. and MacNair, Craig R. and French, Shawn and Carfrae, Lindsey A. and Bloom-Ackermann, Zohar and Tran, Victoria M. and Chiappino-Pepe, Anush and Badran, Ahmed H. and Andrews, Ian W. and Chory, Emma J. and Church, George M. and Brown, Eric D. and Jaakkola, Tommi S. and Barzilay, Regina and Collins, James J.},
  date = {2020-02},
  journaltitle = {Cell},
  shortjournal = {Cell},
  volume = {180},
  number = {4},
  pages = {688-702.e13},
  issn = {00928674},
  doi = {10.1016/j.cell.2020.01.021},
  url = {https://linkinghub.elsevier.com/retrieve/pii/S0092867420301021},
  urldate = {2022-02-08},
  abstract = {Due to the rapid emergence of antibiotic-resistant bacteria, there is a growing need to discover new antibiotics. To address this challenge, we trained a deep neural network capable of predicting molecules with antibacterial activity. We performed predictions on multiple chemical libraries and discovered a molecule from the Drug Repurposing Hub—halicin—that is structurally divergent from conventional antibiotics and displays bactericidal activity against a wide phylogenetic spectrum of pathogens including Mycobacterium tuberculosis and carbapenem-resistant Enterobacteriaceae. Halicin also effectively treated Clostridioides difficile and pan-resistant Acinetobacter baumannii infections in murine models. Additionally, from a discrete set of 23 empirically tested predictions from {$>$}107 million molecules curated from the ZINC15 database, our model identified eight antibacterial compounds that are structurally distant from known antibiotics. This work highlights the utility of deep learning approaches to expand our antibiotic arsenal through the discovery of structurally distinct antibacterial molecules.},
  langid = {english},
  keywords = {✅,🦌},
  annotation = {689 citations (Semantic Scholar/DOI) [2022-11-26]\\
419 citations (Crossref) [2022-04-15]},
  file = {/Users/michaelvolk/Zotero/storage/8HKUWZRW/Stokes et al. - 2020 - A Deep Learning Approach to Antibiotic Discovery.pdf}
}

@article{svirinaSinglemoleculeApproachesReveal2022,
  title = {Single-Molecule Approaches Reveal Outer Membrane Protein Biogenesis Dynamics},
  author = {Svirina, Anna and Chamachi, Neharika and Schlierf, Michael},
  date = {2022},
  journaltitle = {BioEssays},
  volume = {44},
  number = {12},
  pages = {2200149},
  issn = {1521-1878},
  doi = {10.1002/bies.202200149},
  url = {https://onlinelibrary.wiley.com/doi/abs/10.1002/bies.202200149},
  urldate = {2024-07-04},
  abstract = {Outer membrane proteins (OMPs) maintain the viability of Gram-negative bacteria by functioning as receptors, transporters, ion channels, lipases, and porins. Folding and assembly of OMPs involves synchronized action of chaperones and multi-protein machineries which escort the highly hydrophobic polypeptides to their target outer membrane in a folding competent state. Previous studies have identified proteins and their involvement along the OMP biogenesis pathway. Yet, the mechanisms of action and the intriguing ability of all these molecular machines to work without the typical cellular energy source of ATP, but solely based on thermodynamic principles, are still not well understood. Here, we highlight how different single-molecule studies can shed additional light on the mechanisms and kinetics of OMP biogenesis.},
  langid = {english},
  keywords = {AFM,BAM,dynamics,FCS,OMP biogenesis,SecYEG,single-molecule FRET,Skp,SurA},
  annotation = {4 citations (Semantic Scholar/DOI) [2024-07-04]},
  file = {/Users/michaelvolk/Zotero/storage/5FBIV5JW/Svirina et al. - 2022 - Single-molecule approaches reveal outer membrane p.pdf;/Users/michaelvolk/Zotero/storage/USJHXVZQ/bies.html}
}

@article{takahashiEnvironmentalFactorReversibly2024,
  title = {Environmental Factor Reversibly Determines Cellular Identity through Opposing {{Integrators}} That Unify Epigenetic and Transcriptional Pathways},
  author = {Takahashi, Hiroki and Ito, Ryo and Matsumura, Yoshihiro and Sakai, Juro},
  date = {2024},
  journaltitle = {BioEssays},
  volume = {46},
  number = {2},
  pages = {2300084},
  issn = {1521-1878},
  doi = {10.1002/bies.202300084},
  url = {https://onlinelibrary.wiley.com/doi/abs/10.1002/bies.202300084},
  urldate = {2024-07-04},
  abstract = {Organisms must adapt to environmental stresses to ensure their survival and prosperity. Different types of stresses, including thermal, mechanical, and hypoxic stresses, can alter the cellular state that accompanies changes in gene expression but not the cellular identity determined by a chromatin state that remains stable throughout life. Some tissues, such as adipose tissue, demonstrate remarkable plasticity and adaptability in response to environmental cues, enabling reversible cellular identity changes; however, the mechanisms underlying these changes are not well understood. We hypothesized that positive and/or negative “Integrators” sense environmental cues and coordinate the epigenetic and transcriptional pathways required for changes in cellular identity. Adverse environmental factors such as pollution disrupt the coordinated control contributing to disease development. Further research based on this hypothesis will reveal how organisms adapt to fluctuating environmental conditions, such as temperature, extracellular matrix stiffness, oxygen, cytokines, and hormonal cues by changing their cellular identities.},
  langid = {english},
  keywords = {beige adipocytes,cellular identity,chromatin state,pollution,protein kinase,protein phosphatase,transdifferentiation},
  annotation = {0 citations (Semantic Scholar/DOI) [2024-07-04]},
  file = {/Users/michaelvolk/Zotero/storage/CDCXNIFM/Takahashi et al. - 2024 - Environmental factor reversibly determines cellula.pdf;/Users/michaelvolk/Zotero/storage/U7K9EV4Z/bies.html}
}

@online{tangEvaluatingRepresentationalPower2024,
  title = {Evaluating the Representational Power of Pre-Trained {{DNA}} Language Models for Regulatory Genomics},
  author = {Tang, Ziqi and Koo, Peter K.},
  date = {2024-03-04},
  eprinttype = {bioRxiv},
  eprintclass = {New Results},
  pages = {2024.02.29.582810},
  doi = {10.1101/2024.02.29.582810},
  url = {https://www.biorxiv.org/content/10.1101/2024.02.29.582810v1},
  urldate = {2024-03-31},
  abstract = {The emergence of genomic language models (gLMs) offers an unsupervised approach to learn a wide diversity of cis-regulatory patterns in the non-coding genome without requiring labels of functional activity generated by wet-lab experiments. Previous evaluations have shown pre-trained gLMs can be leveraged to improve prediction performance across a broad range of regulatory genomics tasks, albeit using relatively simple benchmark datasets and baseline models. Since the gLMs in these studies were tested upon fine-tuning their weights for each downstream task, determining whether gLM representations embody a foundational understanding of cis-regulatory biology remains an open question. Here we evaluate the representational power of pre-trained gLMs to predict and interpret cell-type-specific functional genomics data that span DNA and RNA regulation. Our findings suggest that current gLMs do not offer substantial advantages over conventional machine learning approaches that use one-hot encoded sequences. This work highlights a major limitation with current gLMs, raising potential issues in conventional pre-training strategies for the non-coding genome.},
  langid = {english},
  pubstate = {prepublished},
  annotation = {1 citations (Semantic Scholar/DOI) [2024-03-30]},
  file = {/Users/michaelvolk/Zotero/storage/3GZKUKAE/Tang_Koo_2024_Evaluating the representational power of pre-trained DNA language models for.pdf}
}

@article{tangExplainableMultitaskLearning2023,
  title = {Explainable Multi-Task Learning for Multi-Modality Biological Data Analysis},
  author = {Tang, Xin and Zhang, Jiawei and He, Yichun and Zhang, Xinhe and Lin, Zuwan and Partarrieu, Sebastian and Hanna, Emma Bou and Ren, Zhaolin and Shen, Hao and Yang, Yuhong and Wang, Xiao and Li, Na and Ding, Jie and Liu, Jia},
  date = {2023-05-03},
  journaltitle = {Nature Communications},
  shortjournal = {Nat Commun},
  volume = {14},
  number = {1},
  pages = {2546},
  issn = {2041-1723},
  doi = {10.1038/s41467-023-37477-x},
  url = {https://www.nature.com/articles/s41467-023-37477-x},
  urldate = {2024-06-12},
  abstract = {Current biotechnologies can simultaneously measure multiple high-dimensional modalities (e.g., RNA, DNA accessibility, and protein) from the same cells. A combination of different analytical tasks (e.g., multi-modal integration and cross-modal analysis) is required to comprehensively understand such data, inferring how gene regulation drives biological diversity and functions. However, current analytical methods are designed to perform a single task, only providing a partial picture of the multi-modal data. Here, we present UnitedNet, an explainable multi-task deep neural network capable of integrating different tasks to analyze single-cell multi-modality data. Applied to various multi-modality datasets (e.g., Patch-seq, multiome ATAC\,+\,gene expression, and spatial transcriptomics), UnitedNet demonstrates similar or better accuracy in multi-modal integration and cross-modal prediction compared with state-of-the-art methods. Moreover, by dissecting the trained UnitedNet with the explainable machine learning algorithm, we can directly quantify the relationship between gene expression and other modalities with cell-type specificity. UnitedNet is a comprehensive end-to-end framework that could be broadly applicable to single-cell multi-modality biology. This framework has the potential to facilitate the discovery of cell-type-specific regulation kinetics across transcriptomics and other modalities.},
  langid = {english},
  keywords = {✅🦌,Bioinformatics,Computational science,Data integration,Data processing,Machine learning},
  file = {/Users/michaelvolk/Zotero/storage/SHLJ4NH6/Tang et al. - 2023 - Explainable multi-task learning for multi-modality biological data analysis.pdf}
}

@inproceedings{tangGraphGPTGraphInstruction2024,
  title = {{{GraphGPT}}: {{Graph Instruction Tuning}} for {{Large Language Models}}},
  shorttitle = {{{GraphGPT}}},
  booktitle = {Proceedings of the 47th {{International ACM SIGIR Conference}} on {{Research}} and {{Development}} in {{Information Retrieval}}},
  author = {Tang, Jiabin and Yang, Yuhao and Wei, Wei and Shi, Lei and Su, Lixin and Cheng, Suqi and Yin, Dawei and Huang, Chao},
  date = {2024-07-10},
  pages = {491--500},
  publisher = {ACM},
  location = {Washington DC USA},
  doi = {10.1145/3626772.3657775},
  url = {https://dl.acm.org/doi/10.1145/3626772.3657775},
  urldate = {2025-02-27},
  eventtitle = {{{SIGIR}} 2024: {{The}} 47th {{International ACM SIGIR Conference}} on {{Research}} and {{Development}} in {{Information Retrieval}}},
  isbn = {9798400704314},
  langid = {english}
}

@article{taymaz-nikerelGenomeWideTranscriptionalResponse2016,
  title = {Genome-{{Wide Transcriptional Response}} of {{Saccharomyces}} Cerevisiae to {{Stress-Induced Perturbations}}},
  author = {Taymaz-Nikerel, Hilal and Cankorur-Cetinkaya, Ayca and Kirdar, Betul},
  date = {2016-02-18},
  journaltitle = {Frontiers in Bioengineering and Biotechnology},
  shortjournal = {Front. Bioeng. Biotechnol.},
  volume = {4},
  publisher = {Frontiers},
  issn = {2296-4185},
  doi = {10.3389/fbioe.2016.00017},
  url = {https://www.frontiersin.org/journals/bioengineering-and-biotechnology/articles/10.3389/fbioe.2016.00017/full},
  urldate = {2024-09-09},
  abstract = {{$<$}p{$>$}Cells respond to environmental and/or genetic perturbations in order to survive and proliferate. Characterization of the changes after various stimuli at different -omics levels is crucial to comprehend the adaptation of cells to the changing conditions. Genome-wide quantification and analysis of transcript levels, the genes affected by perturbations, extends our understanding of cellular metabolism by pointing out the mechanisms that play role in sensing the stress caused by those perturbations and related signaling pathways, and in this way guides us to achieve endeavors, such as rational engineering of cells or interpretation of disease mechanisms. {$<$}italic{$>$}Saccharomyces cerevisiae{$<$}/italic{$>$} as a model system has been studied in response to different perturbations and corresponding transcriptional profiles were followed either statically or/and dynamically, short and long term. This review focuses on response of yeast cells to diverse stress inducing perturbations, including nutritional changes, ionic stress, salt stress, oxidative stress, osmotic shock, and to genetic interventions such as deletion and overexpression of genes. It is aimed to conclude on common regulatory phenomena that allow yeast to organize its transcriptomic response after any perturbation under different external conditions.{$<$}/p{$>$}},
  langid = {english},
  keywords = {perturbation,regulation,stress,Transcriptome,yeast},
  annotation = {63 citations (Semantic Scholar/DOI) [2024-09-08]},
  file = {/Users/michaelvolk/Zotero/storage/2WQ8P24C/Taymaz-Nikerel et al_2016_Genome-Wide Transcriptional Response of Saccharomyces cerevisiae to.pdf}
}

@article{teixeiraYEASTRACTPortalExploitation2023,
  title = {{{YEASTRACT}}+: A Portal for the Exploitation of Global Transcription Regulation and Metabolic Model Data in Yeast Biotechnology and Pathogenesis},
  shorttitle = {{{YEASTRACT}}+},
  author = {Teixeira, Miguel Cacho and Viana, Romeu and Palma, Margarida and Oliveira, Jorge and Galocha, Mónica and Mota, Marta Neves and Couceiro, Diogo and Pereira, Maria Galhardas and Antunes, Miguel and Costa, Inês V and Pais, Pedro and Parada, Carolina and Chaouiya, Claudine and Sá-Correia, Isabel and Monteiro, Pedro Tiago},
  date = {2023-01-06},
  journaltitle = {Nucleic Acids Research},
  shortjournal = {Nucleic Acids Research},
  volume = {51},
  number = {D1},
  pages = {D785-D791},
  issn = {0305-1048},
  doi = {10.1093/nar/gkac1041},
  url = {https://doi.org/10.1093/nar/gkac1041},
  urldate = {2023-07-24},
  abstract = {YEASTRACT+ (http://yeastract-plus.org/) is a tool for the analysis, prediction and modelling of transcription regulatory data at the gene and genomic levels in yeasts. It incorporates three integrated databases: YEASTRACT (http://yeastract-plus.org/yeastract/), PathoYeastract (http://yeastract-plus.org/pathoyeastract/) and NCYeastract (http://yeastract-plus.org/ncyeastract/), focused on Saccharomyces cerevisiae, pathogenic yeasts of the Candida genus, and non-conventional yeasts of biotechnological relevance. In this release, YEASTRACT+ offers upgraded information on transcription regulation for the ten previously incorporated yeast species, while extending the database to another pathogenic yeast, Candida auris. Since the last release of YEASTRACT+ (January 2020), a fourth database has been integrated. CommunityYeastract (http://yeastract-plus.org/community/) offers a platform for the creation, use, and future update of YEASTRACT-like databases for any yeast of the users’ choice. CommunityYeastract currently provides information for two Saccharomyces boulardii strains, Rhodotorula toruloides NP11 oleaginous yeast, and Schizosaccharomyces pombe 972h-. In addition, YEASTRACT+ portal currently gathers 304 547 documented regulatory associations between transcription factors (TF) and target genes and 480 DNA binding sites, considering 2771 TFs from 11 yeast species. A new set of tools, currently implemented for S. cerevisiae and C. albicans, is further offered, combining regulatory information with genome-scale metabolic models to provide predictions on the most promising transcription factors to be exploited in cell factory optimisation or to be used as novel drug targets. The expansion of these new tools to the remaining YEASTRACT+ species is ongoing.},
  file = {/Users/michaelvolk/Zotero/storage/2RAF6EDS/Teixeira et al. - 2023 - YEASTRACT+ a portal for the exploitation of globa.pdf;/Users/michaelvolk/Zotero/storage/QSTYCSQS/6814442.html}
}

@article{tengGenomewideConsequencesDeleting2013,
  title = {Genome-Wide {{Consequences}} of {{Deleting Any Single Gene}}},
  author = {Teng, Xinchen and Dayhoff-Brannigan, Margaret and Cheng, Wen-Chih and Gilbert, Catherine E. and Sing, Cierra N. and Diny, Nicola L. and Wheelan, Sarah J. and Dunham, Maitreya J. and Boeke, Jef D. and Pineda, Fernando J. and Hardwick, J. Marie},
  date = {2013-11-21},
  journaltitle = {Molecular Cell},
  shortjournal = {Molecular Cell},
  volume = {52},
  number = {4},
  pages = {485--494},
  issn = {1097-2765},
  doi = {10.1016/j.molcel.2013.09.026},
  url = {https://www.sciencedirect.com/science/article/pii/S109727651300748X},
  urldate = {2025-02-27},
  abstract = {Loss or duplication of chromosome segments can lead to further genomic changes associated with cancer. However, it is not known whether only a select subset of genes is responsible for driving further changes. To determine whether perturbation of any given gene in a genome suffices to drive subsequent genetic changes, we analyzed the yeast knockout collection for secondary mutations of functional consequence. Unlike wild-type, most gene knockout strains were found to have one additional mutant gene affecting nutrient responses and/or heat-stress-induced cell death. Moreover, independent knockouts of the same gene often evolved mutations in the same secondary gene. Genome sequencing identified acquired mutations in several human tumor suppressor homologs. Thus, mutation of any single gene may cause a genomic imbalance, with consequences sufficient to drive adaptive genetic changes. This complicates genetic analyses but is a logical consequence of losing a functional unit originally acquired under pressure during evolution.},
  keywords = {torchcell.deep-learning.genome-wide},
  annotation = {172 citations (Semantic Scholar/DOI) [2025-02-27]},
  file = {/Users/michaelvolk/Zotero/storage/LIIUVZUF/Teng et al_2013_Genome-wide Consequences of Deleting Any Single Gene.pdf;/Users/michaelvolk/Zotero/storage/K2WQFK3T/S109727651300748X.html}
}

@article{thomasWhatEnhancer2023,
  title = {What Is an Enhancer?},
  author = {Thomas, Henry Fabian and Buecker, Christa},
  date = {2023},
  journaltitle = {BioEssays},
  volume = {45},
  number = {10},
  pages = {2300044},
  issn = {1521-1878},
  doi = {10.1002/bies.202300044},
  url = {https://onlinelibrary.wiley.com/doi/abs/10.1002/bies.202300044},
  urldate = {2024-07-04},
  abstract = {Tight control of the transcription process is essential for the correct spatial and temporal gene expression pattern during development and in homeostasis. Enhancers are at the core of correct transcriptional activation. The original definition of an enhancer is straightforward: a DNA sequence that activates transcription independent of orientation and direction. Dissection of numerous enhancer loci has shown that many enhancer-like elements might not conform to the original definition, suggesting that enhancers and enhancer-like elements might use multiple different mechanisms to contribute to transcriptional activation. Here, we review methodologies to identify enhancers and enhancer-like elements and discuss pitfalls and consequences for our understanding of transcriptional regulation.},
  langid = {english},
  keywords = {enhancer,enhancer-like element,facilitator element,polymerase II,transcriptional regulation},
  annotation = {2 citations (Semantic Scholar/DOI) [2024-07-04]},
  file = {/Users/michaelvolk/Zotero/storage/FNC9R4SY/Thomas and Buecker - 2023 - What is an enhancer.pdf;/Users/michaelvolk/Zotero/storage/VHGDADAT/bies.html}
}

@online{toppingUnderstandingOversquashingBottlenecks2022,
  title = {Understanding Over-Squashing and Bottlenecks on Graphs via Curvature},
  author = {Topping, Jake and Giovanni, Francesco Di and Chamberlain, Benjamin Paul and Dong, Xiaowen and Bronstein, Michael M.},
  date = {2022-11-12},
  eprint = {2111.14522},
  eprinttype = {arXiv},
  eprintclass = {stat},
  doi = {10.48550/arXiv.2111.14522},
  url = {http://arxiv.org/abs/2111.14522},
  urldate = {2025-02-27},
  abstract = {Most graph neural networks (GNNs) use the message passing paradigm, in which node features are propagated on the input graph. Recent works pointed to the distortion of information flowing from distant nodes as a factor limiting the efficiency of message passing for tasks relying on long-distance interactions. This phenomenon, referred to as 'over-squashing', has been heuristically attributed to graph bottlenecks where the number of \$k\$-hop neighbors grows rapidly with \$k\$. We provide a precise description of the over-squashing phenomenon in GNNs and analyze how it arises from bottlenecks in the graph. For this purpose, we introduce a new edge-based combinatorial curvature and prove that negatively curved edges are responsible for the over-squashing issue. We also propose and experimentally test a curvature-based graph rewiring method to alleviate the over-squashing.},
  pubstate = {prepublished},
  keywords = {Computer Science - Machine Learning,Statistics - Machine Learning},
  annotation = {400 citations (Semantic Scholar/arXiv) [2025-02-27]},
  file = {/Users/michaelvolk/Zotero/storage/WVJR8WCL/Topping et al_2022_Understanding over-squashing and bottlenecks on graphs via curvature.pdf;/Users/michaelvolk/Zotero/storage/WVP3DGWP/2111.html}
}

@article{tranSurveyProteinSequence2023,
  title = {Survey of {{Protein Sequence Embedding Models}}},
  author = {Tran, Chau and Khadkikar, Siddharth and Porollo, Aleksey},
  date = {2023-01},
  journaltitle = {International Journal of Molecular Sciences},
  volume = {24},
  number = {4},
  pages = {3775},
  publisher = {Multidisciplinary Digital Publishing Institute},
  issn = {1422-0067},
  doi = {10.3390/ijms24043775},
  url = {https://www.mdpi.com/1422-0067/24/4/3775},
  urldate = {2023-10-17},
  abstract = {Derived from the natural language processing (NLP) algorithms, protein language models enable the encoding of protein sequences, which are widely diverse in length and amino acid composition, in fixed-size numerical vectors (embeddings). We surveyed representative embedding models such as Esm, Esm1b, ProtT5, and SeqVec, along with their derivatives (GoPredSim and PLAST), to conduct the following tasks in computational biology: embedding the Saccharomyces cerevisiae proteome, gene ontology (GO) annotation of the uncharacterized proteins of this organism, relating variants of human proteins to disease status, correlating mutants of beta-lactamase TEM-1 from Escherichia coli with experimentally measured antimicrobial resistance, and analyzing diverse fungal mating factors. We discuss the advances and shortcomings, differences, and concordance of the models. Of note, all of the models revealed that the uncharacterized proteins in yeast tend to be less than 200 amino acids long, contain fewer aspartates and glutamates, and are enriched for cysteine. Less than half of these proteins can be annotated with GO terms with high confidence. The distribution of the cosine similarity scores of benign and pathogenic mutations to the reference human proteins shows a statistically significant difference. The differences in embeddings of the reference TEM-1 and mutants have low to no correlation with minimal inhibitory concentrations (MIC).},
  issue = {4},
  langid = {english},
  keywords = {deep learning,natural language processing,protein annotation,protein language model,protein sequence embedding,survey of embedding models},
  annotation = {3 citations (Semantic Scholar/DOI) [2023-10-16]},
  file = {/Users/michaelvolk/Zotero/storage/GWWE9LLP/Tran et al_2023_Survey of Protein Sequence Embedding Models.pdf}
}

@article{trespNeuralnetworkModelsBlood1999a,
  title = {Neural-Network Models for the Blood Glucose Metabolism of a Diabetic},
  author = {Tresp, V. and Briegel, T. and Moody, J.},
  date = {1999-09},
  journaltitle = {IEEE Transactions on Neural Networks},
  volume = {10},
  number = {5},
  pages = {1204--1213},
  issn = {1941-0093},
  doi = {10.1109/72.788659},
  abstract = {We study the application of neural networks to modeling the blood glucose metabolism of a diabetic. In particular we consider recurrent neural networks and time series convolution neural networks which we compare to linear models and to nonlinear compartment models. We include a linear error model to take into account the uncertainty in the system and for handling missing blood glucose observations. Our results indicate that best performance can be achieved by the combination of the recurrent neural network and the linear error model.},
  eventtitle = {{{IEEE Transactions}} on {{Neural Networks}}},
  keywords = {Biochemistry,Blood,Computer displays,Convolution,Diabetes,Insulin,Medical treatment,Neural networks,Recurrent neural networks,Sugar},
  annotation = {86 citations (Semantic Scholar/DOI) [2023-04-04]},
  file = {/Users/michaelvolk/Zotero/storage/4NCX7UWB/Tresp et al_1999_Neural-network models for the blood glucose metabolism of a diabetic.pdf;/Users/michaelvolk/Zotero/storage/CDWJMG7H/stamp.html}
}

@article{tsitsulinGraphClusteringGraph2023,
  title = {Graph {{Clustering}} with {{Graph Neural Networks}}},
  author = {Tsitsulin, Anton and Palowitch, John and Perozzi, Bryan and Müller, Emmanuel},
  date = {2023},
  journaltitle = {Journal of Machine Learning Research},
  volume = {24},
  number = {127},
  pages = {1--21},
  issn = {1533-7928},
  url = {http://jmlr.org/papers/v24/20-998.html},
  urldate = {2024-03-11},
  abstract = {Graph Neural Networks (GNNs) have achieved state-of-the-art results on many graph analysis tasks such as node classification and link prediction. However, important unsupervised problems on graphs, such as graph clustering, have proved more resistant to advances in GNNs. Graph clustering has the same overall goal as node pooling in GNNs—does this mean that GNN pooling methods do a good job at clustering graphs? Surprisingly, the answer is no—current GNN pooling methods often fail to recover the cluster structure in cases where simple baselines, such as k-means applied on learned representations, work well. We investigate further by carefully designing a set of experiments to study different signal-to-noise scenarios both in graph structure and attribute data. To address these methods' poor performance in clustering, we introduce Deep Modularity Networks (DMoN), an unsupervised pooling method inspired by the modularity measure of clustering quality, and show how it tackles recovery of the challenging clustering structure of real-world graphs. Similarly, on real-world data, we show that DMoN produces high quality clusters which correlate strongly with ground truth labels, achieving state-of-the-art results with over 40\% improvement over other pooling methods across different metrics.},
  file = {/Users/michaelvolk/Zotero/storage/JC83YXSN/Tsitsulin et al_2023_Graph Clustering with Graph Neural Networks.pdf;/Users/michaelvolk/Zotero/storage/LIJD64QG/dmon.html}
}

@article{turcoGlobalAnalysisYeast2023,
  title = {Global Analysis of the Yeast Knockout Phenome},
  author = {Turco, Gina and Chang, Christie and Wang, Rebecca Y. and Kim, Griffin and Stoops, Emily H. and Richardson, Brianna and Sochat, Vanessa and Rust, Jennifer and Oughtred, Rose and Thayer, Nathaniel and Kang, Fan and Livstone, Michael S. and Heinicke, Sven and Schroeder, Mark and Dolinski, Kara J. and Botstein, David and Baryshnikova, Anastasia},
  date = {2023-05-26},
  journaltitle = {Science Advances},
  volume = {9},
  number = {21},
  pages = {eadg5702},
  publisher = {American Association for the Advancement of Science},
  doi = {10.1126/sciadv.adg5702},
  url = {https://www.science.org/doi/10.1126/sciadv.adg5702},
  urldate = {2023-06-13},
  abstract = {Genome-wide phenotypic screens in the budding yeast Saccharomyces cerevisiae, enabled by its knockout collection, have produced the largest, richest, and most systematic phenotypic description of any organism. However, integrative analyses of this rich data source have been virtually impossible because of the lack of a central data repository and consistent metadata annotations. Here, we describe the aggregation, harmonization, and analysis of \textasciitilde 14,500 yeast knockout screens, which we call Yeast Phenome. Using this unique dataset, we characterized two unknown genes (YHR045W and YGL117W) and showed that tryptophan starvation is a by-product of many chemical treatments. Furthermore, we uncovered an exponential relationship between phenotypic similarity and intergenic distance, which suggests that gene positions in both yeast and human genomes are optimized for function.},
  file = {/Users/michaelvolk/Zotero/storage/4M97RBDI/Turco et al. - 2023 - Global analysis of the yeast knockout phenome.pdf}
}

@article{turcoGlobalAnalysisYeast2023a,
  title = {Global Analysis of the Yeast Knockout Phenome},
  author = {Turco, Gina and Chang, Christie and Wang, Rebecca Y. and Kim, Griffin and Stoops, Emily H. and Richardson, Brianna and Sochat, Vanessa and Rust, Jennifer and Oughtred, Rose and Thayer, Nathaniel and Kang, Fan and Livstone, Michael S. and Heinicke, Sven and Schroeder, Mark and Dolinski, Kara J. and Botstein, David and Baryshnikova, Anastasia},
  date = {2023-05-26},
  journaltitle = {Science Advances},
  volume = {9},
  number = {21},
  pages = {eadg5702},
  publisher = {American Association for the Advancement of Science},
  doi = {10.1126/sciadv.adg5702},
  url = {https://www.science.org/doi/full/10.1126/sciadv.adg5702},
  urldate = {2025-04-24},
  abstract = {Genome-wide phenotypic screens in the budding yeast Saccharomyces cerevisiae, enabled by its knockout collection, have produced the largest, richest, and most systematic phenotypic description of any organism. However, integrative analyses of this rich data source have been virtually impossible because of the lack of a central data repository and consistent metadata annotations. Here, we describe the aggregation, harmonization, and analysis of \textasciitilde 14,500 yeast knockout screens, which we call Yeast Phenome. Using this unique dataset, we characterized two unknown genes (YHR045W and YGL117W) and showed that tryptophan starvation is a by-product of many chemical treatments. Furthermore, we uncovered an exponential relationship between phenotypic similarity and intergenic distance, which suggests that gene positions in both yeast and human genomes are optimized for function.},
  annotation = {17 citations (Semantic Scholar/DOI) [2025-04-24]},
  file = {/Users/michaelvolk/Zotero/storage/55L5VHSK/Turco et al_2023_Global analysis of the yeast knockout phenome.pdf}
}

@article{unniBiolinkModelUniversal2022,
  title = {Biolink {{Model}}: {{A}} Universal Schema for Knowledge Graphs in Clinical, Biomedical, and Translational Science},
  shorttitle = {Biolink {{Model}}},
  author = {Unni, Deepak R. and Moxon, Sierra A. T. and Bada, Michael and Brush, Matthew and Bruskiewich, Richard and Caufield, J. Harry and Clemons, Paul A. and Dancik, Vlado and Dumontier, Michel and Fecho, Karamarie and Glusman, Gustavo and Hadlock, Jennifer J. and Harris, Nomi L. and Joshi, Arpita and Putman, Tim and Qin, Guangrong and Ramsey, Stephen A. and Shefchek, Kent A. and Solbrig, Harold and Soman, Karthik and Thessen, Anne E. and Haendel, Melissa A. and Bizon, Chris and Mungall, Christopher J. and Consortium, The Biomedical Data Translator},
  date = {2022},
  journaltitle = {Clinical and Translational Science},
  volume = {15},
  number = {8},
  pages = {1848--1855},
  issn = {1752-8062},
  doi = {10.1111/cts.13302},
  url = {https://onlinelibrary.wiley.com/doi/abs/10.1111/cts.13302},
  urldate = {2024-07-24},
  abstract = {Within clinical, biomedical, and translational science, an increasing number of projects are adopting graphs for knowledge representation. Graph-based data models elucidate the interconnectedness among core biomedical concepts, enable data structures to be easily updated, and support intuitive queries, visualizations, and inference algorithms. However, knowledge discovery across these “knowledge graphs” (KGs) has remained difficult. Data set heterogeneity and complexity; the proliferation of ad hoc data formats; poor compliance with guidelines on findability, accessibility, interoperability, and reusability; and, in particular, the lack of a universally accepted, open-access model for standardization across biomedical KGs has left the task of reconciling data sources to downstream consumers. Biolink Model is an open-source data model that can be used to formalize the relationships between data structures in translational science. It incorporates object-oriented classification and graph-oriented features. The core of the model is a set of hierarchical, interconnected classes (or categories) and relationships between them (or predicates) representing biomedical entities such as gene, disease, chemical, anatomic structure, and phenotype. The model provides class and edge attributes and associations that guide how entities should relate to one another. Here, we highlight the need for a standardized data model for KGs, describe Biolink Model, and compare it with other models. We demonstrate the utility of Biolink Model in various initiatives, including the Biomedical Data Translator Consortium and the Monarch Initiative, and show how it has supported easier integration and interoperability of biomedical KGs, bringing together knowledge from multiple sources and helping to realize the goals of translational science.},
  langid = {english},
  annotation = {42 citations (Semantic Scholar/DOI) [2024-07-24]},
  file = {/Users/michaelvolk/Zotero/storage/AJU2M8PA/Unni et al_2022_Biolink Model.pdf;/Users/michaelvolk/Zotero/storage/HL5WMEHV/cts.html}
}

@article{vaishnavEvolutionEvolvabilityEngineering2022a,
  title = {The Evolution, Evolvability and Engineering of Gene Regulatory {{DNA}}},
  author = {Vaishnav, Eeshit Dhaval and family=Boer, given=Carl G., prefix=de, useprefix=true and Molinet, Jennifer and Yassour, Moran and Fan, Lin and Adiconis, Xian and Thompson, Dawn A. and Levin, Joshua Z. and Cubillos, Francisco A. and Regev, Aviv},
  date = {2022-03},
  journaltitle = {Nature},
  volume = {603},
  number = {7901},
  pages = {455--463},
  publisher = {Nature Publishing Group},
  issn = {1476-4687},
  doi = {10.1038/s41586-022-04506-6},
  url = {https://www.nature.com/articles/s41586-022-04506-6},
  urldate = {2023-06-28},
  abstract = {Mutations in non-coding regulatory DNA sequences can alter gene expression, organismal phenotype and fitness1–3. Constructing complete fitness landscapes, in which DNA sequences are mapped to fitness, is a long-standing goal in biology, but has remained elusive because it is challenging to generalize reliably to vast sequence spaces4–6. Here we build sequence-to-expression models that capture fitness landscapes and use them to decipher principles of regulatory evolution. Using millions of randomly sampled promoter DNA sequences and their measured expression levels in the yeast Saccharomyces cerevisiae, we learn deep neural network models that generalize with excellent prediction performance, and enable sequence design for expression engineering. Using our models, we study expression divergence under genetic drift and strong-selection weak-mutation regimes to find that regulatory evolution is rapid and subject to diminishing returns epistasis; that conflicting expression objectives in different environments constrain expression adaptation; and that stabilizing selection on gene expression leads to the moderation of regulatory complexity. We present an approach for using such~models to detect signatures of selection on expression from natural variation in regulatory sequences and use it to discover an instance of convergent regulatory evolution. We assess mutational robustness, finding that regulatory mutation effect sizes follow a power law, characterize regulatory evolvability, visualize promoter fitness landscapes, discover evolvability archetypes and illustrate the mutational robustness of natural regulatory sequence populations. Our work provides a general framework for designing regulatory~sequences and~addressing fundamental questions in regulatory evolution.},
  issue = {7901},
  langid = {english},
  keywords = {Computational models,Genomics,Machine learning,Molecular evolution,Synthetic biology},
  annotation = {66 citations (Semantic Scholar/DOI) [2023-06-28]},
  file = {/Users/michaelvolk/Zotero/storage/P7LDDXKM/Vaishnav et al_2022_The evolution, evolvability and engineering of gene regulatory DNA.pdf}
}

@book{vanbruggenLearningNeo4jRun2014,
  title = {Learning {{Neo4j}}: Run Blazingly Fast Queries on Complex Graph Datasets with the Power of the {{Neo4j}} Graph Database},
  shorttitle = {Learning {{Neo4j}}},
  author = {Van Bruggen, Rik},
  date = {2014},
  series = {Community Experience Distilled},
  edition = {1. publ},
  publisher = {Packt Publ},
  location = {Birmingham, UK},
  isbn = {978-1-84951-716-4},
  langid = {english},
  pagetotal = {201},
  file = {/Users/michaelvolk/Zotero/storage/DWE7HI5K/Van Bruggen - 2014 - Learning Neo4j run blazingly fast queries on comp.pdf}
}

@article{vandergulikContoursEvolutionDefence2024,
  title = {The Contours of Evolution: {{In}} Defence of {{Darwin}}'s Tree of Life Paradigm},
  shorttitle = {The Contours of Evolution},
  author = {family=Gulik, given=Peter T. S., prefix=van der, useprefix=true and Hoff, Wouter D. and Speijer, Dave},
  date = {2024},
  journaltitle = {BioEssays},
  volume = {46},
  number = {5},
  pages = {2400012},
  issn = {1521-1878},
  doi = {10.1002/bies.202400012},
  url = {https://onlinelibrary.wiley.com/doi/abs/10.1002/bies.202400012},
  urldate = {2024-07-04},
  abstract = {Both the concept of a Darwinian tree of life (TOL) and the possibility of its accurate reconstruction have been much criticized. Criticisms mostly revolve around the extensive occurrence of lateral gene transfer (LGT), instances of uptake of complete organisms to become organelles (with the associated subsequent gene transfer to the nucleus), as well as the implications of more subtle aspects of the biological species concept. Here we argue that none of these criticisms are sufficient to abandon the valuable TOL concept and the biological realities it captures. Especially important is the need to conceptually distinguish between organismal trees and gene trees, which necessitates incorporating insights of widely occurring LGT into modern evolutionary theory. We demonstrate that all criticisms, while based on important new findings, do not invalidate the TOL. After considering the implications of these new insights, we find that the contours of evolution are best represented by a TOL.},
  langid = {english},
  keywords = {endosymbiosis,Eukaryogenesis,evolution,LGT,species concept,tree of life},
  annotation = {0 citations (Semantic Scholar/DOI) [2024-07-04]},
  file = {/Users/michaelvolk/Zotero/storage/NZDHJXNQ/van der Gulik et al. - 2024 - The contours of evolution In defence of Darwin's .pdf;/Users/michaelvolk/Zotero/storage/PIGYYBT4/bies.html}
}

@article{vandijkXUTsAreClass2011,
  title = {{{XUTs}} Are a Class of {{Xrn1-sensitive}} Antisense Regulatory Non-Coding {{RNA}} in Yeast},
  author = {family=Dijk, given=E. L., prefix=van, useprefix=true and Chen, C. L. and family=Carafa, given=Y., prefix=d’Aubenton-, useprefix=true and Gourvennec, S. and Kwapisz, M. and Roche, V. and Bertrand, C. and Silvain, M. and Legoix-Né, P. and Loeillet, S. and Nicolas, A. and Thermes, C. and Morillon, A.},
  date = {2011-07},
  journaltitle = {Nature},
  volume = {475},
  number = {7354},
  pages = {114--117},
  publisher = {Nature Publishing Group},
  issn = {1476-4687},
  doi = {10.1038/nature10118},
  url = {https://www.nature.com/articles/nature10118},
  urldate = {2023-08-01},
  abstract = {Several lines of evidence suggest that non-coding RNAs (ncRNAs) have a significant role in gene regulation in eukaryotes. Genome-wide deep sequencing in the yeast Saccharomyces cerevisiae has now identified antisense ncRNAs that are destabilized by the Xrn1 RNA exonuclease in the 5′ RNA-decay pathway. These Xrn1-sensitive unstable transcripts, or XUTs, seem to function in gene repression and can be antagonized by histone H3K4 trimethylation.},
  issue = {7354},
  langid = {english},
  keywords = {Epigenetics,Gene regulation,Non-coding RNAs,SGD.data},
  annotation = {376 citations (Semantic Scholar/DOI) [2023-08-01]},
  file = {/Users/michaelvolk/Zotero/storage/GV52HNLM/van Dijk et al_2011_XUTs are a class of Xrn1-sensitive antisense regulatory non-coding RNA in yeast.pdf}
}

@online{velickovicEverythingConnectedGraph2023,
  title = {Everything Is {{Connected}}: {{Graph Neural Networks}}},
  shorttitle = {Everything Is {{Connected}}},
  author = {Veličković, Petar},
  date = {2023-01-19},
  eprint = {2301.08210},
  eprinttype = {arXiv},
  eprintclass = {cs, stat},
  doi = {10.48550/arXiv.2301.08210},
  url = {http://arxiv.org/abs/2301.08210},
  urldate = {2023-02-03},
  abstract = {In many ways, graphs are the main modality of data we receive from nature. This is due to the fact that most of the patterns we see, both in natural and artificial systems, are elegantly representable using the language of graph structures. Prominent examples include molecules (represented as graphs of atoms and bonds), social networks and transportation networks. This potential has already been seen by key scientific and industrial groups, with already-impacted application areas including traffic forecasting, drug discovery, social network analysis and recommender systems. Further, some of the most successful domains of application for machine learning in previous years -- images, text and speech processing -- can be seen as special cases of graph representation learning, and consequently there has been significant exchange of information between these areas. The main aim of this short survey is to enable the reader to assimilate the key concepts in the area, and position graph representation learning in a proper context with related fields.},
  pubstate = {prepublished},
  keywords = {Computer Science - Artificial Intelligence,Computer Science - Machine Learning,Computer Science - Social and Information Networks,Statistics - Machine Learning},
  file = {/Users/michaelvolk/Zotero/storage/AJZWR67A/Veličković_2023_Everything is Connected.pdf;/Users/michaelvolk/Zotero/storage/6YUYL7J7/2301.html}
}

@article{velickovicEverythingConnectedGraph2023a,
  title = {Everything Is {{Connected}}: {{Graph Neural Networks}}},
  shorttitle = {Everything Is {{Connected}}},
  author = {Veličković, Petar},
  date = {2023-04},
  journaltitle = {Current Opinion in Structural Biology},
  shortjournal = {Current Opinion in Structural Biology},
  volume = {79},
  eprint = {2301.08210},
  eprinttype = {arXiv},
  eprintclass = {cs},
  pages = {102538},
  issn = {0959440X},
  doi = {10.1016/j.sbi.2023.102538},
  url = {http://arxiv.org/abs/2301.08210},
  urldate = {2025-03-01},
  abstract = {In many ways, graphs are the main modality of data we receive from nature. This is due to the fact that most of the patterns we see, both in natural and artificial systems, are elegantly representable using the language of graph structures. Prominent examples include molecules (represented as graphs of atoms and bonds), social networks and transportation networks. This potential has already been seen by key scientific and industrial groups, with already-impacted application areas including traffic forecasting, drug discovery, social network analysis and recommender systems. Further, some of the most successful domains of application for machine learning in previous years -- images, text and speech processing -- can be seen as special cases of graph representation learning, and consequently there has been significant exchange of information between these areas. The main aim of this short survey is to enable the reader to assimilate the key concepts in the area, and position graph representation learning in a proper context with related fields.},
  keywords = {Computer Science - Artificial Intelligence,Computer Science - Machine Learning,Computer Science - Social and Information Networks,Statistics - Machine Learning},
  annotation = {159 citations (Semantic Scholar/arXiv) [2025-03-01]\\
159 citations (Semantic Scholar/DOI) [2025-03-01]},
  file = {/Users/michaelvolk/Zotero/storage/Y53UHJLH/Veličković_2023_Everything is Connected.pdf;/Users/michaelvolk/Zotero/storage/58W2RFXT/2301.html}
}

@unpublished{vermaCounterfactualExplanationsMachine2020,
  title = {Counterfactual Explanations for Machine Learning: {{A}} Review},
  shorttitle = {Counterfactual Explanations for Machine Learning},
  author = {Verma, Sahil and Dickerson, John and Hines, Keegan},
  date = {2020},
  volume = {2},
  number = {1},
  eprint = {2010.10596},
  eprinttype = {arXiv},
  pages = {1},
  url = {https://ml-retrospectives.github.io/neurips2020/camera_ready/5.pdf},
  urldate = {2025-02-27},
  file = {/Users/michaelvolk/Zotero/storage/ANVKZCCT/Verma et al_2020_Counterfactual explanations for machine learning.pdf}
}

@article{vieitezHighthroughputFunctionalCharacterization2022,
  title = {High-Throughput Functional Characterization of Protein Phosphorylation Sites in Yeast},
  author = {Viéitez, Cristina and Busby, Bede P. and Ochoa, David and Mateus, André and Memon, Danish and Galardini, Marco and Yildiz, Umut and Trovato, Matteo and Jawed, Areeb and Geiger, Alexander G. and Oborská-Oplová, Michaela and Potel, Clement M. and Vonesch, Sibylle C. and Szu Tu, Chelsea and Shahraz, Mohammed and Stein, Frank and Steinmetz, Lars M. and Panse, Vikram G. and Noh, Kyung-Min and Savitski, Mikhail M. and Typas, Athanasios and Beltrao, Pedro},
  date = {2022-03},
  journaltitle = {Nature Biotechnology},
  shortjournal = {Nat Biotechnol},
  volume = {40},
  number = {3},
  pages = {382--390},
  publisher = {Nature Publishing Group},
  issn = {1546-1696},
  doi = {10.1038/s41587-021-01051-x},
  url = {https://www.nature.com/articles/s41587-021-01051-x},
  urldate = {2022-06-14},
  abstract = {Phosphorylation is a critical post-translational modification involved in the regulation of almost all cellular processes. However, fewer than 5\% of thousands of recently discovered phosphosites have been functionally annotated. In this study, we devised a chemical genetic approach to study the functional relevance of phosphosites in Saccharomyces cerevisiae. We generated 474 yeast strains with mutations in specific phosphosites that were screened for fitness in 102 conditions, along with a gene deletion library. Of these phosphosites, 42\% exhibited growth phenotypes, suggesting that these are more likely functional. We inferred their function based on the similarity of their growth profiles with that of gene deletions and validated a subset by thermal proteome profiling and lipidomics. A high fraction exhibited phenotypes not seen in the corresponding gene deletion, suggestive of a gain-of-function effect. For phosphosites conserved in humans, the severity of the yeast phenotypes is indicative of their human functional relevance. This high-throughput approach allows for functionally characterizing individual phosphosites at scale.},
  issue = {3},
  langid = {english},
  keywords = {☁️,🦌,¼📖,Phosphorylation,Regulatory networks},
  annotation = {7 citations (Semantic Scholar/DOI) [2022-11-26]},
  file = {/Users/michaelvolk/Zotero/storage/GBSCW5G4/Viéitez et al. - 2022 - High-throughput functional characterization of pro.pdf;/Users/michaelvolk/Zotero/storage/4PUPEIPT/s41587-021-01051-x.html}
}

@article{vinasHypergraphFactorizationMultitissue2023,
  title = {Hypergraph Factorization for Multi-Tissue Gene Expression Imputation},
  author = {Viñas, Ramon and Joshi, Chaitanya K. and Georgiev, Dobrik and Lin, Phillip and Dumitrascu, Bianca and Gamazon, Eric R. and Liò, Pietro},
  date = {2023-07},
  journaltitle = {Nature Machine Intelligence},
  shortjournal = {Nat Mach Intell},
  volume = {5},
  number = {7},
  pages = {739--753},
  publisher = {Nature Publishing Group},
  issn = {2522-5839},
  doi = {10.1038/s42256-023-00684-8},
  url = {https://www.nature.com/articles/s42256-023-00684-8},
  urldate = {2024-07-16},
  abstract = {Integrating gene expression across tissues and cell types is crucial for understanding the coordinated biological mechanisms that drive disease and characterize homoeostasis. However, traditional multi-tissue integration methods either cannot handle uncollected tissues or rely on genotype information, which is often unavailable and subject to privacy concerns. Here we present HYFA (hypergraph factorization), a parameter-efficient graph representation learning approach for joint imputation of multi-tissue and cell-type gene expression. HYFA is genotype agnostic, supports a variable number of collected tissues per individual, and imposes strong inductive biases to leverage the shared regulatory architecture of tissues and genes. In performance comparison on Genotype–Tissue Expression project data, HYFA achieves superior performance over existing methods, especially when multiple reference tissues are available. The HYFA-imputed dataset can be used to identify replicable regulatory genetic variations (expression quantitative trait loci), with substantial gains over the original incomplete dataset. HYFA can accelerate the effective and scalable integration of tissue and cell-type transcriptome biorepositories.},
  langid = {english},
  keywords = {Machine learning,Transcriptomics},
  annotation = {12 citations (Semantic Scholar/DOI) [2024-07-15]},
  file = {/Users/michaelvolk/Zotero/storage/4JD5GECX/Viñas et al_2023_Hypergraph factorization for multi-tissue gene expression imputation.pdf}
}

@article{voitBestModelsMetabolism2017a,
  title = {The Best Models of Metabolism},
  author = {Voit, Eberhard O.},
  date = {2017},
  journaltitle = {WIREs Systems Biology and Medicine},
  volume = {9},
  number = {6},
  pages = {e1391},
  issn = {1939-005X},
  doi = {10.1002/wsbm.1391},
  url = {https://onlinelibrary.wiley.com/doi/abs/10.1002/wsbm.1391},
  urldate = {2023-04-04},
  abstract = {Biochemical systems are among of the oldest application areas of mathematical modeling. Spanning a time period of over one hundred years, the repertoire of options for structuring a model and for formulating reactions has been constantly growing, and yet, it is still unclear whether or to what degree some models are better than others and how the modeler is to choose among them. In fact, the variety of options has become overwhelming and difficult to maneuver for novices and experts alike. This review outlines the metabolic model design process and discusses the numerous choices for modeling frameworks and mathematical representations. It tries to be inclusive, even though it cannot be complete, and introduces the various modeling options in a manner that is as unbiased as that is feasible. However, the review does end with personal recommendations for the choices of default models. WIREs Syst Biol Med 2017, 9:e1391. doi: 10.1002/wsbm.1391 This article is categorized under: Analytical and Computational Methods {$>$} Dynamical Methods Models of Systems Properties and Processes {$>$} Mechanistic Models Biological Mechanisms {$>$} Metabolism},
  langid = {english},
  annotation = {32 citations (Semantic Scholar/DOI) [2023-04-04]},
  file = {/Users/michaelvolk/Zotero/storage/S9IFF2DZ/Voit_2017_The best models of metabolism.pdf;/Users/michaelvolk/Zotero/storage/293DZ2UM/wsbm.html}
}

@article{vossSteadyStateAnalysis2003,
  title = {Steady State Analysis of Metabolic Pathways Using {{Petri}} Nets},
  author = {Voss, Klaus and Heiner, Monika and Koch, Ina},
  date = {2003},
  journaltitle = {In silico biology},
  volume = {3},
  number = {3},
  pages = {367--387},
  publisher = {IOS Press},
  file = {/Users/michaelvolk/Zotero/storage/YSW4G6K4/Voss et al_2003_Steady state analysis of metabolic pathways using Petri nets.pdf}
}

@article{vujovicCellularSelforganizationOverdrive2022,
  title = {Cellular Self-Organization: {{An}} Overdrive in {{Cambrian}} Diversity?},
  shorttitle = {Cellular Self-Organization},
  author = {Vujovic, Filip and Hunter, Neil and Farahani, Ramin M.},
  date = {2022},
  journaltitle = {BioEssays},
  volume = {44},
  number = {10},
  pages = {2200033},
  issn = {1521-1878},
  doi = {10.1002/bies.202200033},
  url = {https://onlinelibrary.wiley.com/doi/abs/10.1002/bies.202200033},
  urldate = {2024-07-04},
  abstract = {During the early Cambrian period metazoan life forms diverged at an accelerated rate to occupy multiple ecological niches on earth. A variety of explanations have been proposed to address this major evolutionary phenomenon termed the “Cambrian explosion.” While most hypotheses address environmental, developmental, and ecological factors that facilitated evolutionary innovations, the biological basis for accelerated emergence of species diversity in the Cambrian period remains largely conjectural. Herein, we posit that morphogenesis by self-organization enables the uncoupling of genomic mutational landscape from phenotypic diversification. Evidence is provided for a two-tiered interpretation of genomic changes in metazoan animals wherein mutations not only impact upon function of individual cells, but also alter the self-organization outcome during developmental morphogenesis. We provide evidence that the morphological impacts of mutations on self-organization could remain repressed if associated with an unmet negative energetic cost. We posit that accelerated morphological diversification in transition to the Cambrian period has occurred by emergence of dormant (i.e., reserved) morphological novelties whose molecular underpinnings were seeded in the Precambrian period.},
  langid = {english},
  keywords = {Cambrian explosion,cell cycle,cellular self-organisation,dormant phenotypes},
  annotation = {1 citations (Semantic Scholar/DOI) [2024-07-04]},
  file = {/Users/michaelvolk/Zotero/storage/D67IW8QV/Vujovic et al. - 2022 - Cellular self-organization An overdrive in Cambri.pdf;/Users/michaelvolk/Zotero/storage/7YFJELNM/bies.html}
}

@article{wacholderVastEvolutionarilyTransient2023,
  title = {A Vast Evolutionarily Transient Translatome Contributes to Phenotype and Fitness},
  author = {Wacholder, Aaron and Parikh, Saurin Bipin and Coelho, Nelson Castilho and Acar, Omer and Houghton, Carly and Chou, Lin and Carvunis, Anne-Ruxandra},
  date = {2023-05-17},
  journaltitle = {Cell Systems},
  shortjournal = {cels},
  volume = {14},
  number = {5},
  eprint = {37164009},
  eprinttype = {pmid},
  pages = {363-381.e8},
  issn = {2405-4712},
  doi = {10.1016/j.cels.2023.04.002},
  url = {https://www.cell.com/cell-systems/abstract/S2405-4712(23)00086-8},
  urldate = {2023-08-11},
  langid = {english},
  keywords = {🦌✅,de novo gene birth,evolutionary genomics,genome annotation,microproteins,noncanonical translation,protein evolution,ribosome profiling,smORFs},
  file = {/Users/michaelvolk/Zotero/storage/MIPY7XNY/Wacholder et al. - 2023 - A vast evolutionarily transient translatome contributes to phenotype and fitness.pdf}
}

@article{waernExtensiveTranscriptDiversity2013,
  title = {Extensive {{Transcript Diversity}} and {{Novel Upstream Open Reading Frame Regulation}} in {{Yeast}}},
  author = {Waern, Karl and Snyder, Michael},
  date = {2013-02-01},
  journaltitle = {G3 Genes|Genomes|Genetics},
  shortjournal = {G3 Genes|Genomes|Genetics},
  volume = {3},
  number = {2},
  pages = {343--352},
  issn = {2160-1836},
  doi = {10.1534/g3.112.003640},
  url = {https://doi.org/10.1534/g3.112.003640},
  urldate = {2023-08-01},
  abstract = {To understand the diversity of transcripts in yeast (Saccharomyces cerevisiae) we analyzed the transcriptional landscapes for cells grown under 18 different environmental conditions. Each sample was analyzed using RNA-sequencing, and a total of 670,446,084 uniquely mapped reads and 377,263 poly-adenylated end tags were produced. Consistent with previous studies, we find that the majority of yeast genes are expressed under one or more different conditions. By directly comparing the 5′ and 3′ ends of the transcribed regions, we find extensive differences in transcript ends across many conditions, especially those of stationary phase, growth in grape juice, and salt stimulation, suggesting differential choice of transcription start and stop sites is pervasive in yeast. Relative to the exponential growth condition (i.e., YPAD), transcripts differing at the 5′ ends and 3′ ends are predicted to differ in their annotated start codon in 21 genes and their annotated stop codon in 63 genes. Many (431) upstream open reading frames (uORFs) are found in alternate 5′ ends and are significantly enriched in transcripts produced during the salt response. Mutational analysis of five genes with uORFs revealed that two sets of uORFs increase the expression of a reporter construct, indicating a role in activation which had not been reported previously, whereas two other uORFs decreased expression. In addition, RNA binding protein motifs are statistically enriched for alternate ends under many conditions. Overall, these results demonstrate enormous diversity of transcript ends, and that this heterogeneity is regulated under different environmental conditions. Moreover, transcript end diversity has important biological implications for the regulation of gene expression. In addition, our data also serve as a valuable resource for the scientific community.},
  keywords = {SGD.data},
  annotation = {59 citations (Semantic Scholar/DOI) [2023-08-01]},
  file = {/Users/michaelvolk/Zotero/storage/E46KS7GM/Waern_Snyder_2013_Extensive Transcript Diversity and Novel Upstream Open Reading Frame Regulation.pdf;/Users/michaelvolk/Zotero/storage/YDAGI2KB/6025709.html}
}

@inproceedings{wagstaffLimitationsRepresentingFunctions2019a,
  title = {On the Limitations of Representing Functions on Sets},
  booktitle = {International {{Conference}} on {{Machine Learning}}},
  author = {Wagstaff, Edward and Fuchs, Fabian and Engelcke, Martin and Posner, Ingmar and Osborne, Michael A.},
  date = {2019},
  pages = {6487--6494},
  publisher = {PMLR},
  url = {https://proceedings.mlr.press/v97/wagstaff19a.html},
  urldate = {2023-10-09},
  file = {/Users/michaelvolk/Zotero/storage/Q577G5B9/Wagstaff et al_2019_On the limitations of representing functions on sets.pdf}
}

@article{wanAmbiguitiesNeuralnetworkbasedHyperedge2024a,
  title = {Ambiguities in Neural-Network-Based Hyperedge Prediction},
  author = {Wan, Changlin and Zhang, Muhan and Dang, Pengtao and Hao, Wei and Cao, Sha and Li, Pan and Zhang, Chi},
  date = {2024-10-01},
  journaltitle = {Journal of Applied and Computational Topology},
  shortjournal = {J Appl. and Comput. Topology},
  volume = {8},
  number = {5},
  pages = {1333--1361},
  issn = {2367-1734},
  doi = {10.1007/s41468-024-00172-x},
  url = {https://doi.org/10.1007/s41468-024-00172-x},
  urldate = {2025-04-23},
  abstract = {A hypergraph is a generalization of a graph that depicts higher-order relations. Predicting higher-order relations, i.e. hyperedges, is a fundamental problem in hypergraph studies, and has immense applications in multiple domains. Recent development of graph neural network (GNN) advanced the prediction of pair-wise relations in graphs. However, existing methods can hardly be extended to hypergraphs due to the lack of higher-order dependency in their graph embedding. In this paper, we mathematically formulate the ambiguity challenges of GNN-based representation of higher-order relations, namely node-level and hyperedge-level ambiguities. We further present HIGNN (Hyperedge Isomorphism Graph Neural Network) that utilizes bipartite graph neural network with hyperedge structural features to collectively tackle the two ambiguity issues in the hyperedge prediction problem. HIGNN achieves constant performance improvement compared with recent GNN-based models. In addition, we apply HIGNN to a new task, predicting genetic higher-order interactions on 3D genome organization data. HIGNN shows consistently higher prediction accuracy across different chromosomes, and generates novel findings on 4-way gene interactions, which is further validated by existing literature.},
  langid = {english},
  keywords = {05C60,Ambiguity,Edge prediction,Graph neural network,Hypergraph},
  annotation = {0 citations (Semantic Scholar/DOI) [2025-04-23]},
  file = {/Users/michaelvolk/Zotero/storage/YLVJ4Z5D/Wan et al_2024_Ambiguities in neural-network-based hyperedge prediction.pdf}
}

@article{wanAmbiguitiesNeuralnetworkbasedHyperedge2024b,
  title = {Ambiguities in Neural-Network-Based Hyperedge Prediction},
  author = {Wan, Changlin and Zhang, Muhan and Dang, Pengtao and Hao, Wei and Cao, Sha and Li, Pan and Zhang, Chi},
  date = {2024-10-01},
  journaltitle = {Journal of Applied and Computational Topology},
  shortjournal = {J Appl. and Comput. Topology},
  volume = {8},
  number = {5},
  pages = {1333--1361},
  issn = {2367-1734},
  doi = {10.1007/s41468-024-00172-x},
  url = {https://doi.org/10.1007/s41468-024-00172-x},
  urldate = {2025-05-01},
  abstract = {A hypergraph is a generalization of a graph that depicts higher-order relations. Predicting higher-order relations, i.e. hyperedges, is a fundamental problem in hypergraph studies, and has immense applications in multiple domains. Recent development of graph neural network (GNN) advanced the prediction of pair-wise relations in graphs. However, existing methods can hardly be extended to hypergraphs due to the lack of higher-order dependency in their graph embedding. In this paper, we mathematically formulate the ambiguity challenges of GNN-based representation of higher-order relations, namely node-level and hyperedge-level ambiguities. We further present HIGNN (Hyperedge Isomorphism Graph Neural Network) that utilizes bipartite graph neural network with hyperedge structural features to collectively tackle the two ambiguity issues in the hyperedge prediction problem. HIGNN achieves constant performance improvement compared with recent GNN-based models. In addition, we apply HIGNN to a new task, predicting genetic higher-order interactions on 3D genome organization data. HIGNN shows consistently higher prediction accuracy across different chromosomes, and generates novel findings on 4-way gene interactions, which is further validated by existing literature.},
  langid = {english},
  keywords = {05C60,Ambiguity,Edge prediction,Graph neural network,Hypergraph},
  annotation = {0 citations (Semantic Scholar/DOI) [2025-04-30]},
  file = {/Users/michaelvolk/Zotero/storage/HVH55IBS/Wan et al_2024_Ambiguities in neural-network-based hyperedge prediction.pdf}
}

@article{wangComputationalMethodsDatabases2022,
  title = {Computational Methods, Databases and Tools for Synthetic Lethality Prediction},
  author = {Wang, Jing and Zhang, Qinglong and Han, Junshan and Zhao, Yanpeng and Zhao, Caiyun and Yan, Bowei and Dai, Chong and Wu, Lianlian and Wen, Yuqi and Zhang, Yixin and Leng, Dongjin and Wang, Zhongming and Yang, Xiaoxi and He, Song and Bo, Xiaochen},
  date = {2022-05-01},
  journaltitle = {Briefings in Bioinformatics},
  shortjournal = {Briefings in Bioinformatics},
  volume = {23},
  number = {3},
  pages = {bbac106},
  issn = {1477-4054},
  doi = {10.1093/bib/bbac106},
  url = {https://doi.org/10.1093/bib/bbac106},
  urldate = {2023-07-25},
  abstract = {Synthetic lethality (SL) occurs between two genes when the inactivation of either gene alone has no effect on cell survival but the inactivation of both genes results in cell death. SL-based therapy has become one of the most promising targeted cancer therapies in the last decade as PARP inhibitors achieve great success in the clinic. The key point to exploiting SL-based cancer therapy is the identification of robust SL pairs. Although many wet-lab-based methods have been developed to screen SL pairs, known SL pairs are less than 0.1\% of all potential pairs due to large number of human gene combinations. Computational prediction methods complement wet-lab-based methods to effectively reduce the search space of SL pairs. In this paper, we review the recent applications of computational methods and commonly used databases for SL prediction. First, we introduce the concept of SL and its screening methods. Second, various SL-related data resources are summarized. Then, computational methods including statistical-based methods, network-based methods, classical machine learning methods and deep learning methods for SL prediction are summarized. In particular, we elaborate on the negative sampling methods applied in these models. Next, representative tools for SL prediction are introduced. Finally, the challenges and future work for SL prediction are discussed.},
  annotation = {4 citations (Semantic Scholar/DOI) [2023-07-25]},
  file = {/Users/michaelvolk/Zotero/storage/76PBVFVJ/Wang et al_2022_Computational methods, databases and tools for synthetic lethality prediction.pdf;/Users/michaelvolk/Zotero/storage/F7QX6NKH/6555403.html}
}

@article{wangLeveragingCellOntology2021,
  title = {Leveraging the {{Cell Ontology}} to Classify Unseen Cell Types},
  author = {Wang, Sheng and Pisco, Angela Oliveira and McGeever, Aaron and Brbic, Maria and Zitnik, Marinka and Darmanis, Spyros and Leskovec, Jure and Karkanias, Jim and Altman, Russ B.},
  date = {2021-09-21},
  journaltitle = {Nature Communications},
  shortjournal = {Nat Commun},
  volume = {12},
  number = {1},
  pages = {5556},
  publisher = {Nature Publishing Group},
  issn = {2041-1723},
  doi = {10.1038/s41467-021-25725-x},
  url = {https://www.nature.com/articles/s41467-021-25725-x},
  urldate = {2023-12-06},
  abstract = {Single cell technologies are rapidly generating large amounts of data that enables us to understand biological systems at single-cell resolution. However, joint analysis of datasets generated by independent labs remains challenging due to a lack of consistent terminology to describe cell types. Here, we present OnClass, an algorithm and accompanying software for automatically classifying cells into cell types that are part of the controlled vocabulary that forms the Cell Ontology. A key advantage of OnClass is its capability to classify cells into cell types not present in the training data because it uses the Cell Ontology graph to infer cell type relationships. Furthermore, OnClass can be used to identify marker genes for all the cell ontology categories, regardless of whether the cell types are present or absent in the training data, suggesting that OnClass goes beyond a simple annotation tool for single cell datasets, being the first algorithm capable to identify marker genes specific to all terms of the Cell Ontology and offering the possibility of refining the Cell Ontology using a data-centric approach.},
  issue = {1},
  langid = {english},
  keywords = {Machine learning,Network topology},
  annotation = {20 citations (Semantic Scholar/DOI) [2023-12-06]},
  file = {/Users/michaelvolk/Zotero/storage/CSWLYIYM/Wang et al_2021_Leveraging the Cell Ontology to classify unseen cell types.pdf}
}

@article{wangPredictingPlasmidPersistence2021,
  title = {Predicting Plasmid Persistence in Microbial Communities by Coarse-Grained Modeling},
  author = {Wang, Teng and Weiss, Andrea and Ha, Yuanchi and You, Lingchong},
  date = {2021},
  journaltitle = {BioEssays},
  volume = {43},
  number = {9},
  pages = {2100084},
  issn = {1521-1878},
  doi = {10.1002/bies.202100084},
  url = {https://onlinelibrary.wiley.com/doi/abs/10.1002/bies.202100084},
  urldate = {2024-07-04},
  abstract = {Plasmids are a major type of mobile genetic elements (MGEs) that mediate horizontal gene transfer. The stable maintenance of plasmids plays a critical role in the functions and survival for microbial populations. However, predicting and controlling plasmid persistence and abundance in complex microbial communities remain challenging. Computationally, this challenge arises from the combinatorial explosion associated with the conventional modeling framework. Recently, a plasmid-centric framework (PCF) has been developed to overcome this computational bottleneck. This framework enables the derivation of a simple metric, the persistence potential, to predict plasmid persistence and abundance. Here, we discuss how PCF can be extended to account for plasmid interactions. We also discuss how such model-guided predictions of plasmid fates can benefit from the development of new experimental tools and data-driven computational methods.},
  langid = {english},
  keywords = {coarse-grained model,horizontal gene transfer,machine learning,microbial communities,mobile genetic elements,next generation sequencing,plasmid persistence},
  annotation = {3 citations (Semantic Scholar/DOI) [2024-07-04]},
  file = {/Users/michaelvolk/Zotero/storage/GQUIN6Y6/Wang et al. - 2021 - Predicting plasmid persistence in microbial commun.pdf;/Users/michaelvolk/Zotero/storage/X59HR9S9/bies.html}
}

@article{wangScientificDiscoveryAge2023,
  title = {Scientific Discovery in the Age of Artificial Intelligence},
  author = {Wang, Hanchen and Fu, Tianfan and Du, Yuanqi and Gao, Wenhao and Huang, Kexin and Liu, Ziming and Chandak, Payal and Liu, Shengchao and Van Katwyk, Peter and Deac, Andreea and Anandkumar, Anima and Bergen, Karianne and Gomes, Carla P. and Ho, Shirley and Kohli, Pushmeet and Lasenby, Joan and Leskovec, Jure and Liu, Tie-Yan and Manrai, Arjun and Marks, Debora and Ramsundar, Bharath and Song, Le and Sun, Jimeng and Tang, Jian and Veličković, Petar and Welling, Max and Zhang, Linfeng and Coley, Connor W. and Bengio, Yoshua and Zitnik, Marinka},
  date = {2023-08},
  journaltitle = {Nature},
  volume = {620},
  number = {7972},
  pages = {47--60},
  publisher = {Nature Publishing Group},
  issn = {1476-4687},
  doi = {10.1038/s41586-023-06221-2},
  url = {https://www.nature.com/articles/s41586-023-06221-2},
  urldate = {2025-03-01},
  abstract = {Artificial intelligence (AI) is being increasingly integrated into scientific discovery to augment and accelerate research, helping scientists to generate hypotheses, design experiments, collect and interpret large datasets, and gain insights that might not have been possible using traditional scientific methods alone. Here we examine breakthroughs over the past decade that include self-supervised learning, which allows models to be trained on vast amounts of unlabelled data, and geometric deep learning, which leverages knowledge about the structure of scientific data to enhance model accuracy and efficiency. Generative AI methods can create designs, such as small-molecule drugs and proteins, by analysing diverse data modalities, including images and sequences. We discuss how these methods can help scientists throughout the scientific process and the central issues that remain despite such advances. Both developers and users of AI tools need a better understanding of when such approaches need improvement, and challenges posed by poor data quality and stewardship remain. These issues cut across scientific disciplines and require developing foundational algorithmic approaches that can contribute to scientific understanding or acquire it autonomously, making them critical areas of focus for AI innovation.},
  langid = {english},
  keywords = {Computer science,Machine learning,Scientific community,Statistics},
  annotation = {629 citations (Semantic Scholar/DOI) [2025-03-01]},
  file = {/Users/michaelvolk/Zotero/storage/CQKF4UQV/Wang et al_2023_Scientific discovery in the age of artificial intelligence.pdf}
}

@article{wangSynLethDBWebbasedKnowledge2022,
  title = {{{SynLethDB}} 2.0: A Web-Based Knowledge Graph Database on Synthetic Lethality for Novel Anticancer Drug Discovery},
  shorttitle = {{{SynLethDB}} 2.0},
  author = {Wang, Jie and Wu, Min and Huang, Xuhui and Wang, Li and Zhang, Sophia and Liu, Hui and Zheng, Jie},
  date = {2022-01-01},
  journaltitle = {Database},
  shortjournal = {Database},
  volume = {2022},
  pages = {baac030},
  issn = {1758-0463},
  doi = {10.1093/database/baac030},
  url = {https://doi.org/10.1093/database/baac030},
  urldate = {2023-09-15},
  abstract = {Two genes are synthetic lethal if mutations in both genes result in impaired cell viability, while mutation of either gene does not affect the cell survival. The potential usage of synthetic lethality (SL) in anticancer therapeutics has attracted many researchers to identify synthetic lethal gene pairs. To include newly identified SLs and more related knowledge, we present a new version of the SynLethDB database to facilitate the discovery of clinically relevant SLs. We extended the first version of SynLethDB database significantly by including new SLs identified through Clustered Regularly Interspaced Short Palindromic Repeats (CRISPR) screening, a knowledge graph about human SLs, a new web interface, etc. Over 16\,000 new SLs and 26 types of other relationships have been added, encompassing relationships among 14\,100 genes, 53 cancers, 1898 drugs, etc. Moreover, a brand-new web interface has been developed to include modules such as SL query by disease or compound, SL partner gene set enrichment analysis and knowledge graph browsing through a dynamic graph viewer. The data can be downloaded directly from the website or through the RESTful Application Programming Interfaces (APIs). Database URL: ~https://synlethdb.sist.shanghaitech.edu.cn/v2.},
  annotation = {0 citations (Semantic Scholar/DOI) [2023-09-15]},
  file = {/Users/michaelvolk/Zotero/storage/384VKU84/Wang et al_2022_SynLethDB 2.pdf;/Users/michaelvolk/Zotero/storage/2FZ52NED/6585691.html}
}

@online{wanPrincipledHyperedgePrediction2021,
  title = {Principled {{Hyperedge Prediction}} with {{Structural Spectral Features}} and {{Neural Networks}}},
  author = {Wan, Changlin and Zhang, Muhan and Hao, Wei and Cao, Sha and Li, Pan and Zhang, Chi},
  date = {2021-06-13},
  eprint = {2106.04292},
  eprinttype = {arXiv},
  eprintclass = {cs},
  doi = {10.48550/arXiv.2106.04292},
  url = {http://arxiv.org/abs/2106.04292},
  urldate = {2025-04-23},
  abstract = {Hypergraph offers a framework to depict the multilateral relationships in real-world complex data. Predicting higher-order relationships, i.e hyperedge, becomes a fundamental problem for the full understanding of complicated interactions. The development of graph neural network (GNN) has greatly advanced the analysis of ordinary graphs with pair-wise relations. However, these methods could not be easily extended to the case of hypergraph. In this paper, we generalize the challenges of GNN in representing higher-order data in principle, which are edge- and node-level ambiguities. To overcome the challenges, we present SNALS that utilizes bipartite graph neural network with structural features to collectively tackle the two ambiguity issues. SNALS captures the joint interactions of a hyperedge by its local environment, which is retrieved by collecting the spectrum information of their connections. As a result, SNALS achieves nearly 30\% performance increase compared with most recent GNN-based models. In addition, we applied SNALS to predict genetic higher-order interactions on 3D genome organization data. SNALS showed consistently high prediction accuracy across different chromosomes, and generated novel findings on 4-way gene interaction, which is further validated by existing literature.},
  pubstate = {prepublished},
  keywords = {Computer Science - Machine Learning,Computer Science - Social and Information Networks},
  annotation = {15 citations (Semantic Scholar/arXiv) [2025-04-23]},
  file = {/Users/michaelvolk/Zotero/storage/962FX2I3/Wan et al_2021_Principled Hyperedge Prediction with Structural Spectral Features and Neural.pdf;/Users/michaelvolk/Zotero/storage/4GJL6KAB/2106.html}
}

@article{weimerMoleculesInteractHow2023,
  title = {Molecules Interact. {{But}} How Strong and How Much?},
  author = {Weimer, Kathleen and Zambo, Boglarka and Gogl, Gergo},
  date = {2023},
  journaltitle = {BioEssays},
  volume = {45},
  number = {6},
  pages = {2300007},
  issn = {1521-1878},
  doi = {10.1002/bies.202300007},
  url = {https://onlinelibrary.wiley.com/doi/abs/10.1002/bies.202300007},
  urldate = {2024-07-04},
  abstract = {Interactomics aims to characterize all interactions formed between molecules that comprise our body. Although it emerged from quantitative biophysics, it has devolved into a predominantly qualitative field of science over the past decades. Due to technical limitations at its onset, almost all tools in interactomics are qualitative, which persists in defining the discipline. Here, we argue that interactomics needs to return to a quantitative direction because the technical achievements of the last decade have overcome the original limitations that forced its current path. In contrast to qualitative interactomics which is constrained to charting lists of observed interactions, quantitative interactomics can also uncover answers to key questions such as the strength of interactions or how many of certain complexes can form in cells, thus providing researchers with more immediate proxies for understanding and predicting biological processes.},
  langid = {english},
  keywords = {interactomics,protein–protein interactions,quantitative biology},
  annotation = {2 citations (Semantic Scholar/DOI) [2024-07-04]},
  file = {/Users/michaelvolk/Zotero/storage/2DKPPHSL/Weimer et al. - 2023 - Molecules interact. But how strong and how much.pdf;/Users/michaelvolk/Zotero/storage/U6LMMFPD/bies.html}
}

@inproceedings{wijesingheGraphSelfSupervisedLearning2025,
  title = {Graph {{Self-Supervised Learning}} with {{Learnable Structural}} and {{Positional Encodings}}},
  author = {Wijesinghe, Asiri and Zhu, Hao and Koniusz, Piotr},
  date = {2025-01-29},
  url = {https://openreview.net/forum?id=fX3UjnmtTt#discussion},
  urldate = {2025-02-27},
  abstract = {We propose a novel framework that addresses a critical limitation in Graph Self-Supervised Learning (GSSL) for graph classification: the underestimation of topological information. Traditional GSSL, despite its success in various benchmarks, often fails to fully leverage the expressive power of Graph Neural Networks (GNNs), particularly in capturing complex structural properties. This limitation stems from two main factors: (1) the inadequacy of conventional GNNs in representing sophisticated topological features, and (2) the focus of self-supervised learning solely on final graph representations. To address these issues, we introduce GenHopNet, a GNN framework that integrates a k-hop message-passing scheme, enhancing its ability to capture local structural information without explicit substructure extraction. We theoretically demonstrate that GenHopNet surpasses the expressiveness of the classical Weisfeiler-Lehman (WL) test for graph isomorphism. Furthermore, we propose a structural- and positional-aware GSSL framework that incorporates topological information throughout the learning process. This approach enables the learning of representations that are both sensitive to graph topology and invariant to specific structural and feature augmentations. Comprehensive experiments on graph classification datasets, including those designed to test structural sensitivity, show that our methods consistently outperform most of the existing approaches in accuracy while maintaining computational efficiency. Our work significantly advances GSSL's capability in distinguishing graphs with similar local structures but different global topologies.},
  eventtitle = {{{THE WEB CONFERENCE}} 2025},
  langid = {english},
  file = {/Users/michaelvolk/Zotero/storage/QTK393JC/Wijesinghe et al_2025_Graph Self-Supervised Learning with Learnable Structural and Positional.pdf}
}

@article{wildenhainPredictionSynergismChemicalGenetic2015,
  title = {Prediction of {{Synergism}} from {{Chemical-Genetic Interactions}} by {{Machine Learning}}},
  author = {Wildenhain, Jan and Spitzer, Michaela and Dolma, Sonam and Jarvik, Nick and White, Rachel and Roy, Marcia and Griffiths, Emma and Bellows, David~S. and Wright, Gerard~D. and Tyers, Mike},
  date = {2015-12},
  journaltitle = {Cell Systems},
  shortjournal = {Cell Systems},
  volume = {1},
  number = {6},
  pages = {383--395},
  issn = {24054712},
  doi = {10.1016/j.cels.2015.12.003},
  url = {https://linkinghub.elsevier.com/retrieve/pii/S2405471215002173},
  urldate = {2022-02-08},
  abstract = {The structure of genetic interaction networks predicts that, analogous to synthetic lethal interactions between non-essential genes, combinations of compounds with latent activities may exhibit potent synergism. To test this hypothesis, we generated a chemical-genetic matrix of 195 diverse yeast deletion strains treated with 4,915 compounds. This approach uncovered 1,221 genotype-specific inhibitors, which we termed cryptagens. Synergism between 8,128 structurally disparate cryptagen pairs was assessed experimentally and used to benchmark predictive algorithms. A model based on the chemical-genetic matrix and the genetic interaction network failed to accurately predict synergism. However, a combined random forest and Naive Bayesian learner that associated chemical structural features with genotype-specific growth inhibition had strong predictive power. This approach identified previously unknown compound combinations that exhibited species-selective toxicity toward human fungal pathogens. This work demonstrates that machine learning methods trained on unbiased chemical-genetic interaction data may be widely applicable for the discovery of synergistic combinations in different species.},
  langid = {english},
  keywords = {✅,🦌},
  annotation = {67 citations (Semantic Scholar/DOI) [2022-11-26]\\
59 citations (Crossref) [2022-04-15]},
  file = {/Users/michaelvolk/Zotero/storage/4D7FW8LE/Wildenhain et al. - 2015 - Prediction of Synergism from Chemical-Genetic Inte.pdf}
}

@article{wilhelmRNASeqQuantitativeMeasurement2009a,
  title = {{{RNA-Seq}}—Quantitative Measurement of Expression through Massively Parallel {{RNA-sequencing}}},
  author = {Wilhelm, Brian T. and Landry, Josette-Renée},
  date = {2009-07},
  journaltitle = {Methods},
  shortjournal = {Methods},
  volume = {48},
  number = {3},
  pages = {249--257},
  issn = {10462023},
  doi = {10.1016/j.ymeth.2009.03.016},
  url = {https://linkinghub.elsevier.com/retrieve/pii/S1046202309000632},
  urldate = {2023-08-01},
  abstract = {The ability to quantitatively survey the global behavior of transcriptomes has been a key milestone in the field of systems biology, enabled by the advent of DNA microarrays. While this approach has literally transformed our vision and approach to cellular physiology, microarray technology has always been limited by the requirement to decide, a priori, what regions of the genome to examine. While very high density tiling arrays have reduced this limitation for simpler organisms, it remains an obstacle for larger, more complex, eukaryotic genomes.},
  langid = {english},
  keywords = {SGD.data},
  annotation = {499 citations (Semantic Scholar/DOI) [2023-08-01]},
  file = {/Users/michaelvolk/Zotero/storage/VXGZ9P6X/main.pdf}
}

@article{wuGenomewideLandscapePosition2017,
  title = {Genome-Wide Landscape of Position Effects on Heterogeneous Gene Expression in {{Saccharomyces}} Cerevisiae},
  author = {Wu, Xiao-Le and Li, Bing-Zhi and Zhang, Wen-Zheng and Song, Kai and Qi, Hao and Dai, Jun-biao and Yuan, Ying-Jin},
  date = {2017-07-18},
  journaltitle = {Biotechnology for Biofuels},
  shortjournal = {Biotechnology for Biofuels},
  volume = {10},
  number = {1},
  pages = {189},
  issn = {1754-6834},
  doi = {10.1186/s13068-017-0872-3},
  url = {https://doi.org/10.1186/s13068-017-0872-3},
  urldate = {2023-06-28},
  abstract = {Integration of heterogeneous genes is widely applied in synthetic biology and metabolic engineering. However, knowledge about the effect of integrative position on gene expression remains limited.},
  keywords = {Gene expression,Genome,Position effect,Synthetic biology,Yeast},
  annotation = {45 citations (Semantic Scholar/DOI) [2023-06-28]},
  file = {/Users/michaelvolk/Zotero/storage/JR2ZNZJU/Wu et al_2017_Genome-wide landscape of position effects on heterogeneous gene expression in.pdf}
}

@inproceedings{wuGroupNormalization2018,
  title = {Group {{Normalization}}},
  author = {Wu, Yuxin and He, Kaiming},
  date = {2018},
  pages = {3--19},
  url = {https://openaccess.thecvf.com/content_ECCV_2018/html/Yuxin_Wu_Group_Normalization_ECCV_2018_paper.html},
  urldate = {2023-10-03},
  eventtitle = {Proceedings of the {{European Conference}} on {{Computer Vision}} ({{ECCV}})},
  file = {/Users/michaelvolk/Zotero/storage/ZG8UVK4E/Wu_He_2018_Group Normalization.pdf}
}

@online{wuNonAsymptoticAnalysisOversmoothing2023,
  title = {A {{Non-Asymptotic Analysis}} of {{Oversmoothing}} in {{Graph Neural Networks}}},
  author = {Wu, Xinyi and Chen, Zhengdao and Wang, William and Jadbabaie, Ali},
  date = {2023-03-01},
  eprint = {2212.10701},
  eprinttype = {arXiv},
  eprintclass = {cs},
  doi = {10.48550/arXiv.2212.10701},
  url = {http://arxiv.org/abs/2212.10701},
  urldate = {2025-02-27},
  abstract = {Oversmoothing is a central challenge of building more powerful Graph Neural Networks (GNNs). While previous works have only demonstrated that oversmoothing is inevitable when the number of graph convolutions tends to infinity, in this paper, we precisely characterize the mechanism behind the phenomenon via a non-asymptotic analysis. Specifically, we distinguish between two different effects when applying graph convolutions -- an undesirable mixing effect that homogenizes node representations in different classes, and a desirable denoising effect that homogenizes node representations in the same class. By quantifying these two effects on random graphs sampled from the Contextual Stochastic Block Model (CSBM), we show that oversmoothing happens once the mixing effect starts to dominate the denoising effect, and the number of layers required for this transition is \$O(\textbackslash log N/\textbackslash log (\textbackslash log N))\$ for sufficiently dense graphs with \$N\$ nodes. We also extend our analysis to study the effects of Personalized PageRank (PPR), or equivalently, the effects of initial residual connections on oversmoothing. Our results suggest that while PPR mitigates oversmoothing at deeper layers, PPR-based architectures still achieve their best performance at a shallow depth and are outperformed by the graph convolution approach on certain graphs. Finally, we support our theoretical results with numerical experiments, which further suggest that the oversmoothing phenomenon observed in practice can be magnified by the difficulty of optimizing deep GNN models.},
  pubstate = {prepublished},
  keywords = {Computer Science - Machine Learning,Computer Science - Social and Information Networks,Statistics - Machine Learning},
  annotation = {37 citations (Semantic Scholar/arXiv) [2025-02-27]\\
37 citations (Semantic Scholar/DOI) [2025-02-27]},
  file = {/Users/michaelvolk/Zotero/storage/FPWSC3UZ/Wu et al_2023_A Non-Asymptotic Analysis of Oversmoothing in Graph Neural Networks.pdf;/Users/michaelvolk/Zotero/storage/P2KFG2RB/2212.html}
}

@inproceedings{wuRepresentingLongRangeContext2021,
  title = {Representing {{Long-Range Context}} for {{Graph Neural Networks}} with {{Global Attention}}},
  booktitle = {Advances in {{Neural Information Processing Systems}}},
  author = {Wu, Zhanghao and Jain, Paras and Wright, Matthew and Mirhoseini, Azalia and Gonzalez, Joseph E and Stoica, Ion},
  date = {2021},
  volume = {34},
  pages = {13266--13279},
  publisher = {Curran Associates, Inc.},
  url = {https://proceedings.neurips.cc/paper/2021/hash/6e67691b60ed3e4a55935261314dd534-Abstract.html},
  urldate = {2024-03-11},
  abstract = {Graph neural networks are powerful architectures for structured datasets. However, current methods struggle to represent long-range dependencies. Scaling the depth or width of GNNs is insufficient to broaden receptive fields as larger GNNs encounter optimization instabilities such as vanishing gradients and representation oversmoothing, while pooling-based approaches have yet to become as universally useful as in computer vision. In this work, we propose the use of Transformer-based self-attention to learn long-range pairwise relationships, with a novel “readout” mechanism to obtain a global graph embedding. Inspired by recent computer vision results that find position-invariant attention performant in learning long-range relationships, our method, which we call GraphTrans, applies a permutation-invariant Transformer module after a standard GNN module. This simple architecture leads to state-of-the-art results on several graph classification tasks, outperforming methods that explicitly encode graph structure. Our results suggest that purely-learning-based approaches without graph structure may be suitable for learning high-level, long-range relationships on graphs. Code for GraphTrans is available at https://github.com/ucbrise/graphtrans.},
  file = {/Users/michaelvolk/Zotero/storage/3CGLJYSM/Wu et al_2021_Representing Long-Range Context for Graph Neural Networks with Global Attention.pdf}
}

@online{xianGenerativeGraphNeural2022,
  title = {Generative {{Graph Neural Networks}} for {{Link Prediction}}},
  author = {Xian, Xingping and Wu, Tao and Ma, Xiaoke and Qiao, Shaojie and Shao, Yabin and Wang, Chao and Yuan, Lin and Wu, Yu},
  date = {2022-12-31},
  eprint = {2301.00169},
  eprinttype = {arXiv},
  eprintclass = {cs},
  doi = {10.48550/arXiv.2301.00169},
  url = {http://arxiv.org/abs/2301.00169},
  urldate = {2023-04-25},
  abstract = {Inferring missing links or detecting spurious ones based on observed graphs, known as link prediction, is a long-standing challenge in graph data analysis. With the recent advances in deep learning, graph neural networks have been used for link prediction and have achieved state-of-the-art performance. Nevertheless, existing methods developed for this purpose are typically discriminative, computing features of local subgraphs around two neighboring nodes and predicting potential links between them from the perspective of subgraph classification. In this formalism, the selection of enclosing subgraphs and heuristic structural features for subgraph classification significantly affects the performance of the methods. To overcome this limitation, this paper proposes a novel and radically different link prediction algorithm based on the network reconstruction theory, called GraphLP. Instead of sampling positive and negative links and heuristically computing the features of their enclosing subgraphs, GraphLP utilizes the feature learning ability of deep-learning models to automatically extract the structural patterns of graphs for link prediction under the assumption that real-world graphs are not locally isolated. Moreover, GraphLP explores high-order connectivity patterns to utilize the hierarchical organizational structures of graphs for link prediction. Our experimental results on all common benchmark datasets from different applications demonstrate that the proposed method consistently outperforms other state-of-the-art methods. Unlike the discriminative neural network models used for link prediction, GraphLP is generative, which provides a new paradigm for neural-network-based link prediction.},
  pubstate = {prepublished},
  keywords = {Computer Science - Artificial Intelligence,Computer Science - Social and Information Networks,I.2.4,I.2.8,J.2},
  annotation = {1 citations (Semantic Scholar/arXiv) [2023-04-25]\\
1 citations (Semantic Scholar/DOI) [2023-04-25]},
  file = {/Users/michaelvolk/Zotero/storage/486MUXQT/Xian et al_2022_Generative Graph Neural Networks for Link Prediction.pdf;/Users/michaelvolk/Zotero/storage/V57DPUM4/2301.html}
}

@online{xieSelfSupervisedLearningGraph2022,
  title = {Self-{{Supervised Learning}} of {{Graph Neural Networks}}: {{A Unified Review}}},
  shorttitle = {Self-{{Supervised Learning}} of {{Graph Neural Networks}}},
  author = {Xie, Yaochen and Xu, Zhao and Zhang, Jingtun and Wang, Zhengyang and Ji, Shuiwang},
  date = {2022-04-25},
  eprint = {2102.10757},
  eprinttype = {arXiv},
  eprintclass = {cs},
  doi = {10.48550/arXiv.2102.10757},
  url = {http://arxiv.org/abs/2102.10757},
  urldate = {2023-03-31},
  abstract = {Deep models trained in supervised mode have achieved remarkable success on a variety of tasks. When labeled samples are limited, self-supervised learning (SSL) is emerging as a new paradigm for making use of large amounts of unlabeled samples. SSL has achieved promising performance on natural language and image learning tasks. Recently, there is a trend to extend such success to graph data using graph neural networks (GNNs). In this survey, we provide a unified review of different ways of training GNNs using SSL. Specifically, we categorize SSL methods into contrastive and predictive models. In either category, we provide a unified framework for methods as well as how these methods differ in each component under the framework. Our unified treatment of SSL methods for GNNs sheds light on the similarities and differences of various methods, setting the stage for developing new methods and algorithms. We also summarize different SSL settings and the corresponding datasets used in each setting. To facilitate methodological development and empirical comparison, we develop a standardized testbed for SSL in GNNs, including implementations of common baseline methods, datasets, and evaluation metrics.},
  pubstate = {prepublished},
  keywords = {Computer Science - Machine Learning},
  annotation = {115 citations (Semantic Scholar/arXiv) [2023-03-31]},
  file = {/Users/michaelvolk/Zotero/storage/Y8ZZABCK/Xie et al_2022_Self-Supervised Learning of Graph Neural Networks.pdf;/Users/michaelvolk/Zotero/storage/IFL8W7YD/2102.html}
}

@article{xieSelfSupervisedLearningGraph2023,
  title = {Self-{{Supervised Learning}} of {{Graph Neural Networks}}: {{A Unified Review}}},
  shorttitle = {Self-{{Supervised Learning}} of {{Graph Neural Networks}}},
  author = {Xie, Yaochen and Xu, Zhao and Zhang, Jingtun and Wang, Zhengyang and Ji, Shuiwang},
  date = {2023-02},
  journaltitle = {IEEE Transactions on Pattern Analysis and Machine Intelligence},
  volume = {45},
  number = {2},
  pages = {2412--2429},
  issn = {1939-3539},
  doi = {10.1109/TPAMI.2022.3170559},
  url = {https://ieeexplore.ieee.org/document/9764632},
  urldate = {2025-02-27},
  abstract = {Deep models trained in supervised mode have achieved remarkable success on a variety of tasks. When labeled samples are limited, self-supervised learning (SSL) is emerging as a new paradigm for making use of large amounts of unlabeled samples. SSL has achieved promising performance on natural language and image learning tasks. Recently, there is a trend to extend such success to graph data using graph neural networks (GNNs). In this survey, we provide a unified review of different ways of training GNNs using SSL. Specifically, we categorize SSL methods into contrastive and predictive models. In either category, we provide a unified framework for methods as well as how these methods differ in each component under the framework. Our unified treatment of SSL methods for GNNs sheds light on the similarities and differences of various methods, setting the stage for developing new methods and algorithms. We also summarize different SSL settings and the corresponding datasets used in each setting. To facilitate methodological development and empirical comparison, we develop a standardized testbed for SSL in GNNs, including implementations of common baseline methods, datasets, and evaluation metrics.},
  eventtitle = {{{IEEE Transactions}} on {{Pattern Analysis}} and {{Machine Intelligence}}},
  keywords = {Data models,Deep learning,graph analysis,graph neural networks,Graph neural networks,Head,Mutual information,Predictive models,review,self-supervised learning,survey,Task analysis,Training,unsupervised learning},
  annotation = {298 citations (Semantic Scholar/DOI) [2025-02-27]},
  file = {/Users/michaelvolk/Zotero/storage/BULZ2T39/Xie et al_2023_Self-Supervised Learning of Graph Neural Networks.pdf;/Users/michaelvolk/Zotero/storage/9HFZN5CP/9764632.html}
}

@article{xiongPushingBoundariesMolecular2020,
  title = {Pushing the {{Boundaries}} of {{Molecular Representation}} for {{Drug Discovery}} with the {{Graph Attention Mechanism}}},
  author = {Xiong, Zhaoping and Wang, Dingyan and Liu, Xiaohong and Zhong, Feisheng and Wan, Xiaozhe and Li, Xutong and Li, Zhaojun and Luo, Xiaomin and Chen, Kaixian and Jiang, Hualiang and Zheng, Mingyue},
  date = {2020-08-27},
  journaltitle = {Journal of Medicinal Chemistry},
  shortjournal = {J. Med. Chem.},
  volume = {63},
  number = {16},
  pages = {8749--8760},
  issn = {0022-2623, 1520-4804},
  doi = {10.1021/acs.jmedchem.9b00959},
  url = {https://pubs.acs.org/doi/10.1021/acs.jmedchem.9b00959},
  urldate = {2022-02-08},
  abstract = {Hunting for chemicals with favorable pharmacological, toxicological, and pharmacokinetic properties remains a formidable challenge for drug discovery. Deep learning provides us with powerful tools to build predictive models that are appropriate for the rising amounts of data, but the gap between what these neural networks learn and what human beings can comprehend is growing. Moreover, this gap may induce distrust and restrict deep learning applications in practice. Here, we introduce a new graph neural network architecture called Attentive FP for molecular representation that uses a graph attention mechanism to learn from relevant drug discovery data sets. We demonstrate that Attentive FP achieves state-of-the-art predictive performances on a variety of data sets and that what it learns is interpretable. The feature visualization for Attentive FP suggests that it automatically learns nonlocal intramolecular interactions from specified tasks, which can help us gain chemical insights directly from data beyond human perception.},
  langid = {english},
  keywords = {✅,🦌},
  annotation = {207 citations (Semantic Scholar/DOI) [2022-11-26]\\
84 citations (Crossref) [2022-04-15]},
  file = {/Users/michaelvolk/Zotero/storage/YHGAQZ87/Xiong et al. - 2020 - Pushing the Boundaries of Molecular Representation.pdf}
}

@article{xuCompositeQuantileRegression2017,
  title = {Composite Quantile Regression Neural Network with Applications},
  author = {Xu, Qifa and Deng, Kai and Jiang, Cuixia and Sun, Fang and Huang, Xue},
  date = {2017-06-15},
  journaltitle = {Expert Systems with Applications},
  shortjournal = {Expert Systems with Applications},
  volume = {76},
  pages = {129--139},
  issn = {0957-4174},
  doi = {10.1016/j.eswa.2017.01.054},
  url = {https://www.sciencedirect.com/science/article/pii/S0957417417300726},
  urldate = {2025-02-27},
  abstract = {In recent years, there has been growing interest in neural network to explore complex patterns. We consider an extension of this framework in composite quantile regression setup and propose a novel composite quantile regression neural network (CQRNN) model. We further construct a differential approximation to the quantile regression loss function, and develop an estimation procedure using standard gradient-based optimization algorithms. The CQRNN model is flexible and efficient to explore potential nonlinear relationships among variables, which we demonstrate both in Monte Carlo simulation studies and three real-world applications. It enhances the nonlinear processing capacity of ANN and enables us to achieve desired results for handling different types of data. In addition, our method also provides an idea to bridge the gap between composite quantile regression and intelligent methods such as ANNs, SVM, etc., which is helpful to improve their robustness, goodness-of-fit and predictive ability.},
  keywords = {Composite quantile regression,CQRNN,Neural network,Quantile regression,Quantile regression neural network},
  annotation = {83 citations (Semantic Scholar/DOI) [2025-02-27]},
  file = {/Users/michaelvolk/Zotero/storage/BG5TEQCY/Xu et al_2017_Composite quantile regression neural network with applications.pdf;/Users/michaelvolk/Zotero/storage/AK86B42Q/S0957417417300726.html}
}

@online{yangBreakingExpressiveBottlenecks2020,
  title = {Breaking the {{Expressive Bottlenecks}} of {{Graph Neural Networks}}},
  author = {Yang, Mingqi and Shen, Yanming and Qi, Heng and Yin, Baocai},
  date = {2020-12-13},
  eprint = {2012.07219},
  eprinttype = {arXiv},
  eprintclass = {cs},
  doi = {10.48550/arXiv.2012.07219},
  url = {http://arxiv.org/abs/2012.07219},
  urldate = {2024-03-11},
  abstract = {Recently, the Weisfeiler-Lehman (WL) graph isomorphism test was used to measure the expressiveness of graph neural networks (GNNs), showing that the neighborhood aggregation GNNs were at most as powerful as 1-WL test in distinguishing graph structures. There were also improvements proposed in analogy to \$k\$-WL test (\$k{$>$}1\$). However, the aggregators in these GNNs are far from injective as required by the WL test, and suffer from weak distinguishing strength, making it become expressive bottlenecks. In this paper, we improve the expressiveness by exploring powerful aggregators. We reformulate aggregation with the corresponding aggregation coefficient matrix, and then systematically analyze the requirements of the aggregation coefficient matrix for building more powerful aggregators and even injective aggregators. It can also be viewed as the strategy for preserving the rank of hidden features, and implies that basic aggregators correspond to a special case of low-rank transformations. We also show the necessity of applying nonlinear units ahead of aggregation, which is different from most aggregation-based GNNs. Based on our theoretical analysis, we develop two GNN layers, ExpandingConv and CombConv. Experimental results show that our models significantly boost performance, especially for large and densely connected graphs.},
  pubstate = {prepublished},
  keywords = {Computer Science - Artificial Intelligence,Computer Science - Machine Learning},
  annotation = {10 citations (Semantic Scholar/arXiv) [2024-03-11]},
  file = {/Users/michaelvolk/Zotero/storage/G6UBPEKP/Yang et al_2020_Breaking the Expressive Bottlenecks of Graph Neural Networks.pdf;/Users/michaelvolk/Zotero/storage/SXZGUT96/2012.html}
}

@online{yangRecentAdvancesHypergraph2025,
  title = {Recent {{Advances}} in {{Hypergraph Neural Networks}}},
  author = {Yang, Murong and Xu, Xin-Jian},
  date = {2025-03-11},
  eprint = {2503.07959},
  eprinttype = {arXiv},
  eprintclass = {cs},
  doi = {10.48550/arXiv.2503.07959},
  url = {http://arxiv.org/abs/2503.07959},
  urldate = {2025-04-23},
  abstract = {The growing interest in hypergraph neural networks (HGNNs) is driven by their capacity to capture the complex relationships and patterns within hypergraph structured data across various domains, including computer vision, complex networks, and natural language processing. This paper comprehensively reviews recent advances in HGNNs and presents a taxonomy of mainstream models based on their architectures: hypergraph convolutional networks (HGCNs), hypergraph attention networks (HGATs), hypergraph autoencoders (HGAEs), hypergraph recurrent networks (HGRNs), and deep hypergraph generative models (DHGGMs). For each category, we delve into its practical applications, mathematical mechanisms, literature contributions, and open problems. Finally, we discuss some common challenges and promising research directions.This paper aspires to be a helpful resource that provides guidance for future research and applications of HGNNs.},
  pubstate = {prepublished},
  version = {1},
  keywords = {Computer Science - Machine Learning,Computer Science - Social and Information Networks},
  annotation = {0 citations (Semantic Scholar/arXiv) [2025-04-23]\\
0 citations (Semantic Scholar/DOI) [2025-04-23]},
  file = {/Users/michaelvolk/Zotero/storage/H2GJWEHW/Yang_Xu_2025_Recent Advances in Hypergraph Neural Networks.pdf;/Users/michaelvolk/Zotero/storage/MAPK984L/2503.html}
}

@inproceedings{yanHypergraphDynamicSystem2023,
  title = {Hypergraph {{Dynamic System}}},
  author = {Yan, Jielong and Feng, Yifan and Ying, Shihui and Gao, Yue},
  date = {2023-10-13},
  url = {https://openreview.net/forum?id=NLbRvr840Q},
  urldate = {2024-07-04},
  abstract = {Recently, hypergraph neural networks (HGNNs) exhibit the potential to tackle tasks with high-order correlations and have achieved success in many tasks. However, existing evolution on the hypergraph has poor controllability and lacks sufficient theoretical support (like dynamic systems), thus yielding sub-optimal performance. One typical scenario is that only one or two layers of HGNNs can achieve good results and more layers lead to degeneration of performance. Under such circumstances, it is important to increase the controllability of HGNNs. In this paper, we first introduce hypergraph dynamic systems (HDS), which bridge hypergraphs and dynamic systems and characterize the continuous dynamics of representations. We then propose a control-diffusion hypergraph dynamic system by an ordinary differential equation (ODE). We design a multi-layer HDS\$\textasciicircum\{ode\}\$ as a neural implementation, which contains control steps and diffusion steps. HDS\$\textasciicircum\{ode\}\$ has the properties of controllability and stabilization and is allowed to capture long-range correlations among vertices. Experiments on \$9\$ datasets demonstrate HDS\$\textasciicircum\{ode\}\$ beat all compared methods. HDS\$\textasciicircum\{ode\}\$ achieves stable performance with increased layers and solves the poor controllability of HGNNs. We also provide the feature visualization of the evolutionary process to demonstrate the controllability and stabilization of HDS\$\textasciicircum\{ode\}\$.},
  eventtitle = {The {{Twelfth International Conference}} on {{Learning Representations}}},
  langid = {english},
  file = {/Users/michaelvolk/Zotero/storage/5JUS42VR/Yan et al_2023_Hypergraph Dynamic System.pdf}
}

@incollection{yantongSyntheticGeneticArray2006,
  title = {Synthetic {{Genetic Array Analysis}} in {{Saccharomyces}} Cerevisiae},
  booktitle = {Yeast {{Protocol}}},
  author = {Yan Tong, Amy Hin and Boone, Charles},
  editor = {Xiao, Wei},
  date = {2006},
  series = {Methods in {{Molecular Biology}}},
  pages = {171--191},
  publisher = {Humana Press},
  location = {Totowa, NJ},
  doi = {10.1385/1-59259-958-3:171},
  url = {https://doi.org/10.1385/1-59259-958-3:171},
  urldate = {2023-08-04},
  abstract = {Synthetic lethality occurs when the combination of two mutations leads to an inviable organism. Screens for synthetic lethal genetic interactions have been used extensively to identify genes whose products buffer one another or impinge on the same essential pathway. For the yeast Saccharomyces cerevisiae, we developed a method termed Synthetic Genetic Array (SGA) analysis, which offers an efficient approach for the systematic construction of double mutants and enables a global analysis of synthetic lethal genetic interactions. In a typical SGA screen, a query mutation is crossed to an ordered array of approx 5000 viable gene deletion mutants (representing ∼80\% of all yeast genes) such that meiotic progeny harboring both mutations can be scored for fitness defects. This array-based approach automates yeast genetic analysis in general and can be easily adapted for a number of different screens, including genetic suppression, plasmid shuffling, dosage lethality, or suppression.},
  isbn = {978-1-59259-958-5},
  langid = {english},
  keywords = {Bacto Agar,Fitness Defect,Synthetic Genetic Array,Tetrad Analysis,Yeast Nitrogen Base},
  file = {/Users/michaelvolk/Zotero/storage/4YYAIYCQ/Yan Tong_Boone_2006_Synthetic Genetic Array Analysis in Saccharomyces cerevisiae.pdf}
}

@article{yaoScalableGeneticScreening2024,
  title = {Scalable Genetic Screening for Regulatory Circuits Using Compressed {{Perturb-seq}}},
  author = {Yao, Douglas and Binan, Loic and Bezney, Jon and Simonton, Brooke and Freedman, Jahanara and Frangieh, Chris J. and Dey, Kushal and Geiger-Schuller, Kathryn and Eraslan, Basak and Gusev, Alexander and Regev, Aviv and Cleary, Brian},
  date = {2024-08},
  journaltitle = {Nature Biotechnology},
  shortjournal = {Nat Biotechnol},
  volume = {42},
  number = {8},
  pages = {1282--1295},
  publisher = {Nature Publishing Group},
  issn = {1546-1696},
  doi = {10.1038/s41587-023-01964-9},
  url = {https://www.nature.com/articles/s41587-023-01964-9},
  urldate = {2025-03-14},
  abstract = {Pooled CRISPR screens with single-cell RNA sequencing readout (Perturb-seq) have emerged as a key technique in functional genomics, but they are limited in scale by cost and combinatorial complexity. In this study, we modified the design of Perturb-seq by incorporating algorithms applied to random, low-dimensional observations. Compressed Perturb-seq measures multiple random perturbations per cell or multiple cells per droplet and computationally decompresses these measurements by leveraging the sparse structure of regulatory circuits. Applied to 598 genes in the immune response to bacterial lipopolysaccharide, compressed Perturb-seq achieves the same accuracy as conventional Perturb-seq with an order of magnitude cost reduction and greater power to learn genetic interactions. We identified known and novel regulators of immune responses and uncovered evolutionarily constrained genes with downstream targets enriched for immune disease heritability, including many missed by existing genome-wide association studies. Our framework enables new scales of interrogation for a foundational method in functional genomics.},
  langid = {english},
  keywords = {🦌✅,Gene expression profiling,High-throughput screening},
  file = {/Users/michaelvolk/Zotero/storage/JXZJ6JGU/SI - Yao et al. - 2024 - Scalable genetic screening for regulatory circuits.pdf;/Users/michaelvolk/Zotero/storage/YJ8CL3PP/Yao et al_2024_Scalable genetic screening for regulatory circuits using compressed Perturb-seq.pdf}
}

@article{yasemiModellingCellMetabolism2021,
  title = {Modelling {{Cell Metabolism}}: {{A Review}} on {{Constraint-Based Steady-State}} and {{Kinetic Approaches}}},
  shorttitle = {Modelling {{Cell Metabolism}}},
  author = {Yasemi, Mohammadreza and Jolicoeur, Mario},
  date = {2021-02},
  journaltitle = {Processes},
  volume = {9},
  number = {2},
  pages = {322},
  publisher = {Multidisciplinary Digital Publishing Institute},
  issn = {2227-9717},
  doi = {10.3390/pr9020322},
  url = {https://www.mdpi.com/2227-9717/9/2/322},
  urldate = {2023-07-25},
  abstract = {Studying cell metabolism serves a plethora of objectives such as the enhancement of bioprocess performance, and advancement in the understanding of cell biology, of drug target discovery, and in metabolic therapy. Remarkable successes in these fields emerged from heuristics approaches, for instance, with the introduction of effective strategies for genetic modifications, drug developments and optimization of bioprocess management. However, heuristics approaches have showed significant shortcomings, such as to describe regulation of metabolic pathways and to extrapolate experimental conditions. In the specific case of bioprocess management, such shortcomings limit their capacity to increase product quality, while maintaining desirable productivity and reproducibility levels. For instance, since heuristics approaches are not capable of prediction of the cellular functions under varying experimental conditions, they may lead to sub-optimal processes. Also, such approaches used for bioprocess control often fail in regulating a process under unexpected variations of external conditions. Therefore, methodologies inspired by the systematic mathematical formulation of cell metabolism have been used to address such drawbacks and achieve robust reproducible results. Mathematical modelling approaches are effective for both the characterization of the cell physiology, and the estimation of metabolic pathways utilization, thus allowing to characterize a cell population metabolic behavior. In this article, we present a review on methodology used and promising mathematical modelling approaches, focusing primarily to investigate metabolic events and regulation. Proceeding from a topological representation of the metabolic networks, we first present the metabolic modelling approaches that investigate cell metabolism at steady state, complying to the constraints imposed by mass conservation law and thermodynamics of reactions reversibility. Constraint-based models (CBMs) are reviewed highlighting the set of assumed optimality functions for reaction pathways. We explore models simulating cell growth dynamics, by expanding flux balance models developed at steady state. Then, discussing a change of metabolic modelling paradigm, we describe dynamic kinetic models that are based on the mathematical representation of the mechanistic description of nonlinear enzyme activities. In such approaches metabolic pathway regulations are considered explicitly as a function of the activity of other components of metabolic networks and possibly far from the metabolic steady state. We have also assessed the significance of metabolic model parameterization in kinetic models, summarizing a standard parameter estimation procedure frequently employed in kinetic metabolic modelling literature. Finally, some optimization practices used for the parameter estimation are reviewed.},
  issue = {2},
  langid = {english},
  keywords = {constraint-based modelling approach,dynamic metabolic flux analysis,Gibbs free energy,kinetic modelling,metabolic control analysis,metabolic flux regulation,metabolic model parameterization,metabolic network,metabolic network structure,thermodynamic constraints},
  annotation = {26 citations (Semantic Scholar/DOI) [2023-07-25]},
  file = {/Users/michaelvolk/Zotero/storage/8RMH2IRJ/Yasemi_Jolicoeur_2021_Modelling Cell Metabolism.pdf}
}

@article{yeCurrentStatusTrends2023,
  title = {The Current Status and Trends of {{DNA}} Extraction},
  author = {Ye, Xiaojun and Lei, Bo},
  date = {2023},
  journaltitle = {BioEssays},
  volume = {45},
  number = {8},
  pages = {2200242},
  issn = {1521-1878},
  doi = {10.1002/bies.202200242},
  url = {https://onlinelibrary.wiley.com/doi/abs/10.1002/bies.202200242},
  urldate = {2024-07-04},
  abstract = {DNA extraction, playing an irreplaceable role in molecular biology as it is an essential step prior to various downstream biological analyses. Thus, the accuracy and reliability of downstream research outcomes depend largely on upstream DNA extraction methodology. However, with the advancement of downstream DNA detection techniques, the development of corresponding DNA extraction methods is lagging behind. The most innovative DNA extraction techniques are silica- or magnetic-based. Recent studies have demonstrated that plant fiber-based adsorbents (PF-BAs) have stronger DNA capturing ability than classic materials. Moreover, magnetic ionic liquid (MIL)-based DNA extraction has gathered attention lately, and extrachromosomal circular DNA (eccDNA), cell-free DNA (cfDNA), and microbial community DNA are current research hotspots. These require specific extraction methods, along with constant improvements in the way they are used. This review discusses the significance as well as the direction of innovation of DNA extraction methods to try to provide valuable references including current status and trends for DNA extraction.},
  langid = {english},
  keywords = {cell-free DNA,extrachromosomal circular DNA,magnetic ionic liquid,microbial community,plant fiber-based adsorbent},
  annotation = {5 citations (Semantic Scholar/DOI) [2024-07-04]},
  file = {/Users/michaelvolk/Zotero/storage/ZML8ULED/bies.html}
}

@online{yingTransformersReallyPerform2021,
  title = {Do {{Transformers Really Perform Bad}} for {{Graph Representation}}?},
  author = {Ying, Chengxuan and Cai, Tianle and Luo, Shengjie and Zheng, Shuxin and Ke, Guolin and He, Di and Shen, Yanming and Liu, Tie-Yan},
  date = {2021-11-24},
  eprint = {2106.05234},
  eprinttype = {arXiv},
  eprintclass = {cs},
  doi = {10.48550/arXiv.2106.05234},
  url = {http://arxiv.org/abs/2106.05234},
  urldate = {2025-02-20},
  abstract = {The Transformer architecture has become a dominant choice in many domains, such as natural language processing and computer vision. Yet, it has not achieved competitive performance on popular leaderboards of graph-level prediction compared to mainstream GNN variants. Therefore, it remains a mystery how Transformers could perform well for graph representation learning. In this paper, we solve this mystery by presenting Graphormer, which is built upon the standard Transformer architecture, and could attain excellent results on a broad range of graph representation learning tasks, especially on the recent OGB Large-Scale Challenge. Our key insight to utilizing Transformer in the graph is the necessity of effectively encoding the structural information of a graph into the model. To this end, we propose several simple yet effective structural encoding methods to help Graphormer better model graph-structured data. Besides, we mathematically characterize the expressive power of Graphormer and exhibit that with our ways of encoding the structural information of graphs, many popular GNN variants could be covered as the special cases of Graphormer.},
  pubstate = {prepublished},
  keywords = {Computer Science - Artificial Intelligence,Computer Science - Machine Learning},
  annotation = {425 citations (Semantic Scholar/arXiv) [2025-02-20]},
  file = {/Users/michaelvolk/Zotero/storage/CLZ58BGL/Ying et al_2021_Do Transformers Really Perform Bad for Graph Representation.pdf;/Users/michaelvolk/Zotero/storage/YR5GVGJH/2106.html}
}

@article{yoshidaDistanceMetricLearning2021,
  title = {Distance Metric Learning for Graph Structured Data},
  author = {Yoshida, Tomoki and Takeuchi, Ichiro and Karasuyama, Masayuki},
  date = {2021-07-01},
  journaltitle = {Machine Learning},
  shortjournal = {Mach Learn},
  volume = {110},
  number = {7},
  pages = {1765--1811},
  issn = {1573-0565},
  doi = {10.1007/s10994-021-06009-3},
  url = {https://doi.org/10.1007/s10994-021-06009-3},
  urldate = {2025-02-27},
  abstract = {Graphs are versatile tools for representing structured data. As a result, a variety of machine learning methods have been studied for graph data analysis. Although many such learning methods depend on the measurement of differences between input graphs, defining an appropriate distance metric for graphs remains a controversial issue. Hence, we propose a supervised distance metric learning method for the graph classification problem. Our method, named interpretable graph metric learning (IGML), learns discriminative metrics in a subgraph-based feature space, which has a strong graph representation capability. By introducing a sparsity-inducing penalty on the weight of each subgraph, IGML can identify a small number of important subgraphs that can provide insight into the given classification task. Because our formulation has a large number of optimization variables, an efficient algorithm that uses pruning techniques based on safe screening and working set selection methods is also proposed. An important property of IGML is that solution optimality is guaranteed because the problem is formulated as a convex problem and our pruning strategies only discard unnecessary subgraphs. Furthermore, we show that IGML is also applicable to other structured data such as itemset and sequence data, and that it can incorporate vertex-label similarity by using a transportation-based subgraph feature. We empirically evaluate the computational efficiency and classification performance of IGML on several benchmark datasets and provide some illustrative examples of how IGML identifies important subgraphs from a given graph dataset.},
  langid = {english},
  keywords = {Artificial Intelligence,Convex optimization,Graph mining,Interpretability,Metric learning,Structured data},
  annotation = {12 citations (Semantic Scholar/DOI) [2025-02-27]},
  file = {/Users/michaelvolk/Zotero/storage/TXJQ4GAC/Yoshida et al_2021_Distance metric learning for graph structured data.pdf}
}

@article{yuanCellBoxInterpretableMachine2021,
  title = {{{CellBox}}: {{Interpretable Machine Learning}} for {{Perturbation Biology}} with {{Application}} to the {{Design}} of {{Cancer Combination Therapy}}},
  shorttitle = {{{CellBox}}},
  author = {Yuan, Bo and Shen, Ciyue and Luna, Augustin and Korkut, Anil and Marks, Debora S. and Ingraham, John and Sander, Chris},
  date = {2021-02},
  journaltitle = {Cell Systems},
  shortjournal = {Cell Systems},
  volume = {12},
  number = {2},
  pages = {128-140.e4},
  issn = {24054712},
  doi = {10.1016/j.cels.2020.11.013},
  url = {https://linkinghub.elsevier.com/retrieve/pii/S2405471220304646},
  urldate = {2023-10-19},
  abstract = {Systematic perturbation of cells followed by comprehensive measurements of molecular and phenotypic responses provides informative data resources for constructing computational models of cell biology. Models that generalize well beyond training data can be used to identify combinatorial perturbations of potential therapeutic interest. Major challenges for machine learning on large biological datasets are to find global optima in a complex multidimensional space and mechanistically interpret the solutions. To address these challenges, we introduce a hybrid approach that combines explicit mathematical models of cell dynamics with a machine-learning framework, implemented in TensorFlow. We tested the modeling framework on a perturbation-response dataset of a melanoma cell line after drug treatments. The models can be efficiently trained to describe cellular behavior accurately. Even though completely data driven and independent of prior knowledge, the resulting de novo network models recapitulate some known interactions. The approach is readily applicable to various kinetic models of cell biology. A record of this paper’s Transparent Peer Review process is included in the Supplemental Information.},
  langid = {english},
  annotation = {59 citations (Semantic Scholar/DOI) [2023-10-19]},
  file = {/Users/michaelvolk/Zotero/storage/VR7VSBBF/Yuan et al. - 2021 - CellBox Interpretable Machine Learning for Pertur.pdf}
}

@article{yuanSTRUCTPOOLSTRUCTUREDGRAPH2020,
  title = {{{STRUCTPOOL}}: {{STRUCTURED GRAPH POOLING VIA CONDITIONAL RANDOM FIELDS}}},
  author = {Yuan, Hao and Ji, Shuiwang},
  date = {2020},
  abstract = {Learning high-level representations for graphs is of great importance for graph analysis tasks. In addition to graph convolution, graph pooling is an important but less explored research area. In particular, most of existing graph pooling techniques do not consider the graph structural information explicitly. We argue that such information is important and develop a novel graph pooling technique, know as the STRUCTPOOL, in this work. We consider the graph pooling as a node clustering problem, which requires the learning of a cluster assignment matrix. We propose to formulate it as a structured prediction problem and employ conditional random fields to capture the relationships among the assignments of different nodes. We also generalize our method to incorporate graph topological information in designing the Gibbs energy function. Experimental results on multiple datasets demonstrate the effectiveness of our proposed STRUCTPOOL.},
  langid = {english},
  file = {/Users/michaelvolk/Zotero/storage/M9FVMGAV/Yuan and Ji - 2020 - STRUCTPOOL STRUCTURED GRAPH POOLING VIA CONDITION.pdf}
}

@article{yuEnzymeFunctionPrediction2023,
  title = {Enzyme Function Prediction Using Contrastive Learning},
  author = {Yu, Tianhao and Cui, Haiyang and Li, Jianan Canal and Luo, Yunan and Jiang, Guangde and Zhao, Huimin},
  date = {2023-03-31},
  journaltitle = {Science},
  volume = {379},
  number = {6639},
  pages = {1358--1363},
  publisher = {American Association for the Advancement of Science},
  doi = {10.1126/science.adf2465},
  url = {https://www.science.org/doi/10.1126/science.adf2465},
  urldate = {2023-09-10},
  abstract = {Enzyme function annotation is a fundamental challenge, and numerous computational tools have been developed. However, most of these tools cannot accurately predict functional annotations, such as enzyme commission (EC) number, for less-studied proteins or those with previously uncharacterized functions or multiple activities. We present a machine learning algorithm named CLEAN (contrastive learning–enabled enzyme annotation) to assign EC numbers to enzymes with better accuracy, reliability, and sensitivity compared with the state-of-the-art tool BLASTp. The contrastive learning framework empowers CLEAN to confidently (i) annotate understudied enzymes, (ii) correct mislabeled enzymes, and (iii) identify promiscuous enzymes with two or more EC numbers—functions that we demonstrate by systematic in silico and in vitro experiments. We anticipate that this tool will be widely used for predicting the functions of uncharacterized enzymes, thereby advancing many fields, such as genomics, synthetic biology, and biocatalysis.},
  annotation = {16 citations (Semantic Scholar/DOI) [2023-09-10]},
  file = {/Users/michaelvolk/Zotero/storage/WELUVTDI/Yu et al. - 2023 - Enzyme function prediction using contrastive learn.pdf}
}

@online{yun$On$ConnectionsAre2020,
  title = {\${{O}}(n)\$ {{Connections}} Are {{Expressive Enough}}: {{Universal Approximability}} of {{Sparse Transformers}}},
  shorttitle = {\${{O}}(n)\$ {{Connections}} Are {{Expressive Enough}}},
  author = {Yun, Chulhee and Chang, Yin-Wen and Bhojanapalli, Srinadh and Rawat, Ankit Singh and Reddi, Sashank J. and Kumar, Sanjiv},
  date = {2020-12-19},
  eprint = {2006.04862},
  eprinttype = {arXiv},
  eprintclass = {cs},
  doi = {10.48550/arXiv.2006.04862},
  url = {http://arxiv.org/abs/2006.04862},
  urldate = {2025-02-27},
  abstract = {Recently, Transformer networks have redefined the state of the art in many NLP tasks. However, these models suffer from quadratic computational cost in the input sequence length \$n\$ to compute pairwise attention in each layer. This has prompted recent research into sparse Transformers that sparsify the connections in the attention layers. While empirically promising for long sequences, fundamental questions remain unanswered: Can sparse Transformers approximate any arbitrary sequence-to-sequence function, similar to their dense counterparts? How does the sparsity pattern and the sparsity level affect their performance? In this paper, we address these questions and provide a unifying framework that captures existing sparse attention models. We propose sufficient conditions under which we prove that a sparse attention model can universally approximate any sequence-to-sequence function. Surprisingly, our results show that sparse Transformers with only \$O(n)\$ connections per attention layer can approximate the same function class as the dense model with \$n\textasciicircum 2\$ connections. Lastly, we present experiments comparing different patterns/levels of sparsity on standard NLP tasks.},
  pubstate = {prepublished},
  keywords = {Computer Science - Machine Learning,Statistics - Machine Learning},
  file = {/Users/michaelvolk/Zotero/storage/LGK85BTE/Yun et al_2020_$O(n)$ Connections are Expressive Enough.pdf;/Users/michaelvolk/Zotero/storage/E39Z2TV3/2006.html}
}

@online{yunAreTransformersUniversal2020,
  title = {Are {{Transformers}} Universal Approximators of Sequence-to-Sequence Functions?},
  author = {Yun, Chulhee and Bhojanapalli, Srinadh and Rawat, Ankit Singh and Reddi, Sashank J. and Kumar, Sanjiv},
  date = {2020-02-25},
  eprint = {1912.10077},
  eprinttype = {arXiv},
  eprintclass = {cs},
  doi = {10.48550/arXiv.1912.10077},
  url = {http://arxiv.org/abs/1912.10077},
  urldate = {2025-02-27},
  abstract = {Despite the widespread adoption of Transformer models for NLP tasks, the expressive power of these models is not well-understood. In this paper, we establish that Transformer models are universal approximators of continuous permutation equivariant sequence-to-sequence functions with compact support, which is quite surprising given the amount of shared parameters in these models. Furthermore, using positional encodings, we circumvent the restriction of permutation equivariance, and show that Transformer models can universally approximate arbitrary continuous sequence-to-sequence functions on a compact domain. Interestingly, our proof techniques clearly highlight the different roles of the self-attention and the feed-forward layers in Transformers. In particular, we prove that fixed width self-attention layers can compute contextual mappings of the input sequences, playing a key role in the universal approximation property of Transformers. Based on this insight from our analysis, we consider other simpler alternatives to self-attention layers and empirically evaluate them.},
  pubstate = {prepublished},
  keywords = {Computer Science - Machine Learning,Statistics - Machine Learning},
  annotation = {307 citations (Semantic Scholar/arXiv) [2025-02-27]},
  file = {/Users/michaelvolk/Zotero/storage/VAXGBNLX/Yun et al_2020_Are Transformers universal approximators of sequence-to-sequence functions.pdf;/Users/michaelvolk/Zotero/storage/ZNJIJXTY/1912.html}
}

@inproceedings{yunGraphTransformerNetworks2019,
  title = {Graph {{Transformer Networks}}},
  booktitle = {Advances in {{Neural Information Processing Systems}}},
  author = {Yun, Seongjun and Jeong, Minbyul and Kim, Raehyun and Kang, Jaewoo and Kim, Hyunwoo J},
  date = {2019},
  volume = {32},
  publisher = {Curran Associates, Inc.},
  url = {https://proceedings.neurips.cc/paper/2019/hash/9d63484abb477c97640154d40595a3bb-Abstract.html},
  urldate = {2025-02-19},
  abstract = {Graph neural networks (GNNs) have been widely used in representation learning on graphs and achieved state-of-the-art performance in tasks such as node classification and link prediction. However, most existing GNNs are designed to learn node representations on the fixed and homogeneous graphs. The limitations especially become problematic when learning representations on a misspecified graph or a heterogeneous graph that consists of various types of nodes and edges. In this paper, we propose Graph Transformer Networks (GTNs) that are capable of generating new graph structures, which involve identifying useful connections between unconnected nodes on the original graph, while learning effective node representation on the new graphs in an end-to-end fashion. Graph Transformer layer, a core layer of GTNs, learns a soft selection of edge types and composite relations for generating useful multi-hop connections so-call meta-paths. Our experiments show that GTNs learn new graph structures, based on data and tasks without domain knowledge, and yield powerful node representation via convolution on the new graphs. Without domain-specific graph preprocessing, GTNs achieved the best performance in all three benchmark node classification tasks against the state-of-the-art methods that require pre-defined meta-paths from domain knowledge.},
  file = {/Users/michaelvolk/Zotero/storage/48HKQX4N/Yun et al_2019_Graph Transformer Networks.pdf}
}

@inproceedings{yunGraphTransformerNetworks2019a,
  title = {Graph {{Transformer Networks}}},
  booktitle = {Advances in {{Neural Information Processing Systems}}},
  author = {Yun, Seongjun and Jeong, Minbyul and Kim, Raehyun and Kang, Jaewoo and Kim, Hyunwoo J},
  date = {2019},
  volume = {32},
  publisher = {Curran Associates, Inc.},
  url = {https://proceedings.neurips.cc/paper_files/paper/2019/hash/9d63484abb477c97640154d40595a3bb-Abstract.html},
  urldate = {2025-02-27},
  abstract = {Graph neural networks (GNNs) have been widely used in representation learning on graphs and achieved state-of-the-art performance in tasks such as node classification and link prediction. However, most existing GNNs are designed to learn node representations on the fixed and homogeneous graphs. The limitations especially become problematic when learning representations on a misspecified graph or a heterogeneous graph that consists of various types of nodes and edges. In this paper, we propose Graph Transformer Networks (GTNs) that are capable of generating new graph structures, which involve identifying useful connections between unconnected nodes on the original graph, while learning effective node representation on the new graphs in an end-to-end fashion. Graph Transformer layer, a core layer of GTNs, learns a soft selection of edge types and composite relations for generating useful multi-hop connections so-call meta-paths. Our experiments show that GTNs learn new graph structures, based on data and tasks without domain knowledge, and yield powerful node representation via convolution on the new graphs. Without domain-specific graph preprocessing, GTNs achieved the best performance in all three benchmark node classification tasks against the state-of-the-art methods that require pre-defined meta-paths from domain knowledge.},
  file = {/Users/michaelvolk/Zotero/storage/KC6WFGSH/Yun et al_2019_Graph Transformer Networks.pdf}
}

@article{yuTranslationGenotypePhenotype2016,
  title = {Translation of {{Genotype}} to {{Phenotype}} by a {{Hierarchy}} of {{Cell Subsystems}}},
  author = {Yu, Michael Ku and Kramer, Michael and Dutkowski, Janusz and Srivas, Rohith and Licon, Katherine and Kreisberg, Jason F. and Ng, Cherie T. and Krogan, Nevan and Sharan, Roded and Ideker, Trey},
  date = {2016-02},
  journaltitle = {Cell Systems},
  shortjournal = {Cell Systems},
  volume = {2},
  number = {2},
  pages = {77--88},
  issn = {24054712},
  doi = {10.1016/j.cels.2016.02.003},
  url = {https://linkinghub.elsevier.com/retrieve/pii/S2405471216300333},
  urldate = {2022-02-08},
  abstract = {Accurately translating genotype to phenotype requires accounting for the functional impact of genetic variation at many biological scales. Here, we present a strategy for genotype-phenotype reasoning based on existing knowledge of cellular subsystems. These subsystems and their hierarchical organization are defined by the Gene Ontology or a complementary ontology inferred directly from previously published datasets. Guided by the ontology’s hierarchical structure, we organize genotype data into an ‘‘ontotype,’’ that is, a hierarchy of perturbations representing the effects of genetic variation at multiple cellular scales. The ontotype is then interpreted using logical rules generated by machine learning to predict phenotype. This approach substantially outperforms previous non-hierarchical methods for translating yeast genotype to cell growth phenotype, and it accurately predicts the growth outcomes of two new screens of 2,503 double gene knockouts affecting DNA repair or nuclear lumen. Ontotypes also generalize to larger knockout combinations, setting the stage for interpreting the complex genetics of disease.},
  langid = {english},
  keywords = {✅,🦌},
  annotation = {60 citations (Semantic Scholar/DOI) [2022-11-26]\\
56 citations (Crossref) [2022-04-15]},
  file = {/Users/michaelvolk/Zotero/storage/I7QLGPCL/Yu et al. - 2016 - Translation of Genotype to Phenotype by a Hierarch.pdf}
}

@article{yuVisibleMachineLearning2018,
  title = {Visible {{Machine Learning}} for {{Biomedicine}}},
  author = {Yu, Michael K. and Ma, Jianzhu and Fisher, Jasmin and Kreisberg, Jason F. and Raphael, Benjamin J. and Ideker, Trey},
  date = {2018-06-14},
  journaltitle = {Cell},
  shortjournal = {Cell},
  volume = {173},
  number = {7},
  pages = {1562--1565},
  issn = {0092-8674},
  doi = {10.1016/j.cell.2018.05.056},
  url = {https://www.sciencedirect.com/science/article/pii/S0092867418307190},
  urldate = {2025-05-08},
  abstract = {A major ambition of artificial intelligence lies in translating patient data to successful therapies. Machine learning models face particular challenges in biomedicine, however, including handling of extreme data heterogeneity and lack of mechanistic insight into predictions. Here, we argue for “visible” approaches that guide model structure with experimental biology.},
  annotation = {132 citations (Semantic Scholar/DOI) [2025-05-08]},
  file = {/Users/michaelvolk/Zotero/storage/NFZUQBJ6/Yu et al_2018_Visible Machine Learning for Biomedicine.pdf;/Users/michaelvolk/Zotero/storage/6VGVKAFH/S0092867418307190.html}
}

@online{zaheerDeepSets2018,
  title = {Deep {{Sets}}},
  author = {Zaheer, Manzil and Kottur, Satwik and Ravanbakhsh, Siamak and Poczos, Barnabas and Salakhutdinov, Ruslan and Smola, Alexander},
  date = {2018-04-14},
  eprint = {1703.06114},
  eprinttype = {arXiv},
  eprintclass = {cs, stat},
  doi = {10.48550/arXiv.1703.06114},
  url = {http://arxiv.org/abs/1703.06114},
  urldate = {2023-08-04},
  abstract = {We study the problem of designing models for machine learning tasks defined on \textbackslash emph\{sets\}. In contrast to traditional approach of operating on fixed dimensional vectors, we consider objective functions defined on sets that are invariant to permutations. Such problems are widespread, ranging from estimation of population statistics \textbackslash cite\{poczos13aistats\}, to anomaly detection in piezometer data of embankment dams \textbackslash cite\{Jung15Exploration\}, to cosmology \textbackslash cite\{Ntampaka16Dynamical,Ravanbakhsh16ICML1\}. Our main theorem characterizes the permutation invariant functions and provides a family of functions to which any permutation invariant objective function must belong. This family of functions has a special structure which enables us to design a deep network architecture that can operate on sets and which can be deployed on a variety of scenarios including both unsupervised and supervised learning tasks. We also derive the necessary and sufficient conditions for permutation equivariance in deep models. We demonstrate the applicability of our method on population statistic estimation, point cloud classification, set expansion, and outlier detection.},
  pubstate = {prepublished},
  keywords = {🦌½✅,Computer-Science-Machine-Learning,Deep-Sets,equivariance,invariance,Statistics-Machine-Learning},
  annotation = {1530 citations (Semantic Scholar/arXiv) [2023-08-04]},
  file = {/Users/michaelvolk/Zotero/storage/8RP6SM59/Zaheer et al_2018_Deep Sets.pdf;/Users/michaelvolk/Zotero/storage/X33W7H3S/1703.html}
}

@article{zelezniakContributionNetworkConnectivity2014,
  title = {Contribution of {{Network Connectivity}} in {{Determining}} the {{Relationship}} between {{Gene Expression}} and {{Metabolite Concentration Changes}}},
  author = {Zelezniak, Aleksej and Sheridan, Steven and Patil, Kiran Raosaheb},
  date = {2014-04-24},
  journaltitle = {PLOS Computational Biology},
  shortjournal = {PLOS Computational Biology},
  volume = {10},
  number = {4},
  pages = {e1003572},
  publisher = {Public Library of Science},
  issn = {1553-7358},
  doi = {10.1371/journal.pcbi.1003572},
  url = {https://journals.plos.org/ploscompbiol/article?id=10.1371/journal.pcbi.1003572},
  urldate = {2023-11-02},
  abstract = {One of the primary mechanisms through which a cell exerts control over its metabolic state is by modulating expression levels of its enzyme-coding genes. However, the changes at the level of enzyme expression allow only indirect control over metabolite levels, for two main reasons. First, at the level of individual reactions, metabolite levels are non-linearly dependent on enzyme abundances as per the reaction kinetics mechanisms. Secondly, specific metabolite pools are tightly interlinked with the rest of the metabolic network through their production and consumption reactions. While the role of reaction kinetics in metabolite concentration control is well studied at the level of individual reactions, the contribution of network connectivity has remained relatively unclear. Here we report a modeling framework that integrates both reaction kinetics and network connectivity constraints for describing the interplay between metabolite concentrations and mRNA levels. We used this framework to investigate correlations between the gene expression and the metabolite concentration changes in Saccharomyces cerevisiae during its metabolic cycle, as well as in response to three fundamentally different biological perturbations, namely gene knockout, nutrient shock and nutrient change. While the kinetic constraints applied at the level of individual reactions were found to be poor descriptors of the mRNA-metabolite relationship, their use in the context of the network enabled us to correlate changes in the expression of enzyme-coding genes to the alterations in metabolite levels. Our results highlight the key contribution of metabolic network connectivity in mediating cellular control over metabolite levels, and have implications towards bridging the gap between genotype and metabolic phenotype.},
  langid = {english},
  keywords = {Enzyme metabolism,Enzyme regulation,Enzymes,Gene expression,Metabolic networks,Metabolites,Protein folding,Protein metabolism},
  annotation = {62 citations (Semantic Scholar/DOI) [2023-11-02]},
  file = {/Users/michaelvolk/Zotero/storage/KG78X9L6/Zelezniak et al_2014_Contribution of Network Connectivity in Determining the Relationship between.pdf}
}

@article{zelezniakMachineLearningPredicts2018,
  title = {Machine {{Learning Predicts}} the {{Yeast Metabolome}} from the {{Quantitative Proteome}} of {{Kinase Knockouts}}},
  author = {Zelezniak, Aleksej and Vowinckel, Jakob and Capuano, Floriana and Messner, Christoph B. and Demichev, Vadim and Polowsky, Nicole and Mülleder, Michael and Kamrad, Stephan and Klaus, Bernd and Keller, Markus A. and Ralser, Markus},
  date = {2018-09},
  journaltitle = {Cell Systems},
  shortjournal = {Cell Systems},
  volume = {7},
  number = {3},
  pages = {269-283.e6},
  issn = {24054712},
  doi = {10.1016/j.cels.2018.08.001},
  url = {https://linkinghub.elsevier.com/retrieve/pii/S2405471218303168},
  urldate = {2022-02-08},
  abstract = {A challenge in solving the genotype-to-phenotype relationship is to predict a cell’s metabolome, believed to correlate poorly with gene expression. Using comparative quantitative proteomics, we found that differential protein expression in 97 Saccharomyces cerevisiae kinase deletion strains is non-redundant and dominated by abundance changes in metabolic enzymes. Associating differential enzyme expression landscapes to corresponding metabolomes using network models provided reasoning for poor proteome-metabolome correlations; differential protein expression redistributes flux control between many enzymes acting in concert, a mechanism not captured by one-to-one correlation statistics. Mapping these regulatory patterns using machine learning enabled the prediction of metabolite concentrations, as well as identification of candidate genes important for the regulation of metabolism. Overall, our study reveals that a large part of metabolism regulation is explained through coordinated enzyme expression changes. Our quantitative data indicate that this mechanism explains more than half of metabolism regulation and underlies the interdependency between enzyme levels and metabolism, which renders the metabolome a predictable phenotype.},
  langid = {english},
  keywords = {✅,📰-chemical-reviews-review,🦌,machine-learning,metabolomics,saccharomyces-cerevisiae,systems-biology,systems-metabolic-engineering},
  annotation = {58 citations (Semantic Scholar/DOI) [2022-11-26]\\
45 citations (Crossref) [2022-04-15]},
  file = {/Users/michaelvolk/Zotero/storage/XZ534RYF/Zelezniak et al. - 2018 - Machine Learning Predicts the Yeast Metabolome fro.pdf}
}

@online{zeniMatterGenGenerativeModel2024,
  title = {{{MatterGen}}: A Generative Model for Inorganic Materials Design},
  shorttitle = {{{MatterGen}}},
  author = {Zeni, Claudio and Pinsler, Robert and Zügner, Daniel and Fowler, Andrew and Horton, Matthew and Fu, Xiang and Shysheya, Sasha and Crabbé, Jonathan and Sun, Lixin and Smith, Jake and Nguyen, Bichlien and Schulz, Hannes and Lewis, Sarah and Huang, Chin-Wei and Lu, Ziheng and Zhou, Yichi and Yang, Han and Hao, Hongxia and Li, Jielan and Tomioka, Ryota and Xie, Tian},
  date = {2024-01-29},
  eprint = {2312.03687},
  eprinttype = {arXiv},
  eprintclass = {cond-mat},
  doi = {10.48550/arXiv.2312.03687},
  url = {http://arxiv.org/abs/2312.03687},
  urldate = {2025-02-27},
  abstract = {The design of functional materials with desired properties is essential in driving technological advances in areas like energy storage, catalysis, and carbon capture. Generative models provide a new paradigm for materials design by directly generating entirely novel materials given desired property constraints. Despite recent progress, current generative models have low success rate in proposing stable crystals, or can only satisfy a very limited set of property constraints. Here, we present MatterGen, a model that generates stable, diverse inorganic materials across the periodic table and can further be fine-tuned to steer the generation towards a broad range of property constraints. To enable this, we introduce a new diffusion-based generative process that produces crystalline structures by gradually refining atom types, coordinates, and the periodic lattice. We further introduce adapter modules to enable fine-tuning towards any given property constraints with a labeled dataset. Compared to prior generative models, structures produced by MatterGen are more than twice as likely to be novel and stable, and more than 15 times closer to the local energy minimum. After fine-tuning, MatterGen successfully generates stable, novel materials with desired chemistry, symmetry, as well as mechanical, electronic and magnetic properties. Finally, we demonstrate multi-property materials design capabilities by proposing structures that have both high magnetic density and a chemical composition with low supply-chain risk. We believe that the quality of generated materials and the breadth of MatterGen's capabilities represent a major advancement towards creating a universal generative model for materials design.},
  pubstate = {prepublished},
  keywords = {Computer Science - Artificial Intelligence,Condensed Matter - Materials Science},
  annotation = {74 citations (Semantic Scholar/arXiv) [2025-02-27]\\
74 citations (Semantic Scholar/DOI) [2025-02-27]},
  file = {/Users/michaelvolk/Zotero/storage/H2CC2BAA/Zeni et al_2024_MatterGen.pdf;/Users/michaelvolk/Zotero/storage/XEB7QXVT/2312.html}
}

@article{zevedei-oanceaTopologicalAnalysisMetabolic2003,
  title = {Topological Analysis of Metabolic Networks Based on {{Petri}} Net Theory},
  author = {Zevedei-Oancea, Ionela and Schuster, Stefan},
  date = {2003},
  journaltitle = {In silico biology},
  volume = {3},
  number = {3},
  pages = {323--345},
  publisher = {IOS Press},
  file = {/Users/michaelvolk/Zotero/storage/G94J322M/retrieve.pdf}
}

@article{zhangAlgorithmOptimizedMRNA2023,
  title = {Algorithm for Optimized {{mRNA}} Design Improves Stability and Immunogenicity},
  author = {Zhang, He and Zhang, Liang and Lin, Ang and Xu, Congcong and Li, Ziyu and Liu, Kaibo and Liu, Boxiang and Ma, Xiaopin and Zhao, Fanfan and Jiang, Huiling and Chen, Chunxiu and Shen, Haifa and Li, Hangwen and Mathews, David H. and Zhang, Yujian and Huang, Liang},
  date = {2023-09},
  journaltitle = {Nature},
  volume = {621},
  number = {7978},
  pages = {396--403},
  publisher = {Nature Publishing Group},
  issn = {1476-4687},
  doi = {10.1038/s41586-023-06127-z},
  url = {https://www.nature.com/articles/s41586-023-06127-z},
  urldate = {2023-10-09},
  abstract = {Messenger RNA (mRNA) vaccines are being used to combat the spread of COVID-19 (refs. 1–3), but they still exhibit critical limitations caused by mRNA instability and degradation, which are major obstacles for the storage, distribution and efficacy of the vaccine products4. Increasing secondary structure lengthens mRNA half-life, which, together with optimal codons, improves protein expression5. Therefore, a principled mRNA design algorithm must optimize both structural stability and codon usage. However, owing to synonymous codons, the mRNA design space is prohibitively large—for example, there are around 2.4\,×\,10632 candidate mRNA sequences for the SARS-CoV-2 spike protein. This poses insurmountable computational challenges. Here we provide a simple and unexpected solution using the classical concept of lattice parsing~in computational linguistics, where finding the optimal mRNA sequence is analogous to identifying the most likely sentence among similar-sounding alternatives6. Our algorithm LinearDesign finds an optimal mRNA design for the spike protein in just 11 minutes, and can concurrently optimize stability and codon usage. LinearDesign substantially improves mRNA half-life and protein expression, and~profoundly increases antibody titre by up to 128 times in mice compared to the codon-optimization benchmark on~mRNA vaccines for~COVID-19 and varicella-zoster virus. This result reveals the great potential of principled mRNA design and enables the exploration of previously unreachable but highly stable and efficient designs. Our work is a timely tool for vaccines and other mRNA-based medicines encoding therapeutic proteins such as monoclonal antibodies and anti-cancer drugs7,8.},
  issue = {7978},
  langid = {english},
  keywords = {Computational biology and bioinformatics,Computer science,RNA vaccines},
  annotation = {16 citations (Semantic Scholar/DOI) [2023-10-09]},
  file = {/Users/michaelvolk/Zotero/storage/P7JVABLL/Zhang et al_2023_Algorithm for optimized mRNA design improves stability and immunogenicity.pdf}
}

@online{zhangArtificialIntelligenceScience2025,
  title = {Artificial {{Intelligence}} for {{Science}} in {{Quantum}}, {{Atomistic}}, and {{Continuum Systems}}},
  author = {Zhang, Xuan and Wang, Limei and Helwig, Jacob and Luo, Youzhi and Fu, Cong and Xie, Yaochen and Liu, Meng and Lin, Yuchao and Xu, Zhao and Yan, Keqiang and Adams, Keir and Weiler, Maurice and Li, Xiner and Fu, Tianfan and Wang, Yucheng and Strasser, Alex and Yu, Haiyang and Xie, YuQing and Fu, Xiang and Xu, Shenglong and Liu, Yi and Du, Yuanqi and Saxton, Alexandra and Ling, Hongyi and Lawrence, Hannah and Stärk, Hannes and Gui, Shurui and Edwards, Carl and Gao, Nicholas and Ladera, Adriana and Wu, Tailin and Hofgard, Elyssa F. and Tehrani, Aria Mansouri and Wang, Rui and Daigavane, Ameya and Bohde, Montgomery and Kurtin, Jerry and Huang, Qian and Phung, Tuong and Xu, Minkai and Joshi, Chaitanya K. and Mathis, Simon V. and Azizzadenesheli, Kamyar and Fang, Ada and Aspuru-Guzik, Alán and Bekkers, Erik and Bronstein, Michael and Zitnik, Marinka and Anandkumar, Anima and Ermon, Stefano and Liò, Pietro and Yu, Rose and Günnemann, Stephan and Leskovec, Jure and Ji, Heng and Sun, Jimeng and Barzilay, Regina and Jaakkola, Tommi and Coley, Connor W. and Qian, Xiaoning and Qian, Xiaofeng and Smidt, Tess and Ji, Shuiwang},
  date = {2025-02-26},
  eprint = {2307.08423},
  eprinttype = {arXiv},
  eprintclass = {cs},
  doi = {10.48550/arXiv.2307.08423},
  url = {http://arxiv.org/abs/2307.08423},
  urldate = {2025-02-27},
  abstract = {Advances in artificial intelligence (AI) are fueling a new paradigm of discoveries in natural sciences. Today, AI has started to advance natural sciences by improving, accelerating, and enabling our understanding of natural phenomena at a wide range of spatial and temporal scales, giving rise to a new area of research known as AI for science (AI4Science). Being an emerging research paradigm, AI4Science is unique in that it is an enormous and highly interdisciplinary area. Thus, a unified and technical treatment of this field is needed yet challenging. This work aims to provide a technically thorough account of a subarea of AI4Science; namely, AI for quantum, atomistic, and continuum systems. These areas aim at understanding the physical world from the subatomic (wavefunctions and electron density), atomic (molecules, proteins, materials, and interactions), to macro (fluids, climate, and subsurface) scales and form an important subarea of AI4Science. A unique advantage of focusing on these areas is that they largely share a common set of challenges, thereby allowing a unified and foundational treatment. A key common challenge is how to capture physics first principles, especially symmetries, in natural systems by deep learning methods. We provide an in-depth yet intuitive account of techniques to achieve equivariance to symmetry transformations. We also discuss other common technical challenges, including explainability, out-of-distribution generalization, knowledge transfer with foundation and large language models, and uncertainty quantification. To facilitate learning and education, we provide categorized lists of resources that we found to be useful. We strive to be thorough and unified and hope this initial effort may trigger more community interests and efforts to further advance AI4Science.},
  pubstate = {prepublished},
  keywords = {Computer Science - Machine Learning,Physics - Computational Physics},
  annotation = {86 citations (Semantic Scholar/arXiv) [2025-02-27]\\
86 citations (Semantic Scholar/DOI) [2025-02-27]},
  file = {/Users/michaelvolk/Zotero/storage/IEIAUGST/Zhang et al_2025_Artificial Intelligence for Science in Quantum, Atomistic, and Continuum Systems.pdf;/Users/michaelvolk/Zotero/storage/HYP9YV6Y/2307.html}
}

@article{zhangCombiningMechanisticMachine2020a,
  title = {Combining Mechanistic and Machine Learning Models for Predictive Engineering and Optimization of Tryptophan Metabolism},
  author = {Zhang, Jie and Petersen, Søren D. and Radivojevic, Tijana and Ramirez, Andrés and Pérez-Manríquez, Andrés and Abeliuk, Eduardo and Sánchez, Benjamín J. and Costello, Zak and Chen, Yu and Fero, Michael J. and Martin, Hector Garcia and Nielsen, Jens and Keasling, Jay D. and Jensen, Michael K.},
  date = {2020-09-25},
  journaltitle = {Nature Communications},
  shortjournal = {Nat Commun},
  volume = {11},
  number = {1},
  pages = {4880},
  publisher = {Nature Publishing Group},
  issn = {2041-1723},
  doi = {10.1038/s41467-020-17910-1},
  url = {https://www.nature.com/articles/s41467-020-17910-1},
  urldate = {2025-04-21},
  abstract = {Through advanced mechanistic modeling and the generation of large high-quality datasets, machine learning is becoming an integral part of understanding and engineering living systems. Here we show that mechanistic and machine learning models can be combined to enable accurate genotype-to-phenotype predictions. We use a genome-scale model to pinpoint engineering targets, efficient library construction of metabolic pathway designs, and high-throughput biosensor-enabled screening for training diverse machine learning algorithms. From a single data-generation cycle, this enables successful forward engineering of complex aromatic amino acid metabolism in yeast, with the best machine learning-guided design recommendations improving tryptophan titer and productivity by up to 74 and 43\%, respectively, compared to the best designs used for algorithm training. Thus, this study highlights the power of combining mechanistic and machine learning models to effectively direct metabolic engineering efforts.},
  langid = {english},
  keywords = {🦌✅,Applied microbiology,Metabolic engineering,Synthetic biology},
  annotation = {191 citations (Semantic Scholar/DOI) [2025-04-21]},
  file = {/Users/michaelvolk/Zotero/storage/FNMBZZHR/SI - Zhang et al. - 2020 - Combining meanistic and machine learning models .pdf;/Users/michaelvolk/Zotero/storage/RNZY48PB/Zhang et al_2020_Combining mechanistic and machine learning models for predictive engineering.pdf}
}

@online{zhangDANGOPredictingHigherorder2020,
  title = {{{DANGO}}: {{Predicting}} Higher-Order Genetic Interactions},
  shorttitle = {{{DANGO}}},
  author = {Zhang, Ruochi and Ma, Jianzhu and Ma, Jian},
  date = {2020-11-27},
  eprinttype = {bioRxiv},
  eprintclass = {New Results},
  pages = {2020.11.26.400739},
  doi = {10.1101/2020.11.26.400739},
  url = {https://www.biorxiv.org/content/10.1101/2020.11.26.400739v1},
  urldate = {2023-05-12},
  abstract = {Higher-order genetic interactions, which have profound impact on phenotypic variations, remain poorly characterized. Almost all studies to date have primarily reported pairwise interactions because it is dauntingly difficult to design high-throughput genetic screenings of the large combinatorial search space for higher-order interactions. Here, we develop an algorithm named Dango, based on a self-attention hypergraph neural network, to effectively predict the higher-order genetic interaction for a group of genes. As a proof-of-concept, we make comprehensive prediction of {$>$}400 million trigenic interactions in the yeast S. cerevisiae, significantly expanding the quantitative characterization of trigenic interactions. We find that Dango can accurately predict trigenic interactions that reveal both known and new biological functions related to cell growth. The predicted trigenic interactions can also serve as powerful genetic markers to predict growth response to many distinct conditions. Dango enables unveiling a more complete map of complex genetic interactions that impinge upon phenotypic diversity.},
  langid = {english},
  pubstate = {prepublished},
  annotation = {1 citations (Semantic Scholar/DOI) [2023-05-12]},
  file = {/Users/michaelvolk/Zotero/storage/AFBC5E89/Zhang et al. - 2020 - DANGO Predicting higher-order genetic interaction.pdf}
}

@online{zhangGraphNeuralDistance2020,
  title = {Graph {{Neural Distance Metric Learning}} with {{Graph-Bert}}},
  author = {Zhang, Jiawei},
  date = {2020-02-09},
  eprint = {2002.03427},
  eprinttype = {arXiv},
  eprintclass = {cs},
  doi = {10.48550/arXiv.2002.03427},
  url = {http://arxiv.org/abs/2002.03427},
  urldate = {2025-02-27},
  abstract = {Graph distance metric learning serves as the foundation for many graph learning problems, e.g., graph clustering, graph classification and graph matching. Existing research works on graph distance metric (or graph kernels) learning fail to maintain the basic properties of such metrics, e.g., non-negative, identity of indiscernibles, symmetry and triangle inequality, respectively. In this paper, we will introduce a new graph neural network based distance metric learning approaches, namely GB-DISTANCE (GRAPH-BERT based Neural Distance). Solely based on the attention mechanism, GB-DISTANCE can learn graph instance representations effectively based on a pre-trained GRAPH-BERT model. Different from the existing supervised/unsupervised metrics, GB-DISTANCE can be learned effectively in a semi-supervised manner. In addition, GB-DISTANCE can also maintain the distance metric basic properties mentioned above. Extensive experiments have been done on several benchmark graph datasets, and the results demonstrate that GB-DISTANCE can out-perform the existing baseline methods, especially the recent graph neural network model based graph metrics, with a significant gap in computing the graph distance.},
  pubstate = {prepublished},
  keywords = {Computer Science - Machine Learning,Computer Science - Neural and Evolutionary Computing,Statistics - Machine Learning},
  annotation = {5 citations (Semantic Scholar/arXiv) [2025-02-27]},
  file = {/Users/michaelvolk/Zotero/storage/J47MPEC3/Zhang_2020_Graph Neural Distance Metric Learning with Graph-Bert.pdf;/Users/michaelvolk/Zotero/storage/S2W5PETX/2002.html}
}

@online{zhangHierarchicalGraphPooling2019,
  title = {Hierarchical {{Graph Pooling}} with {{Structure Learning}}},
  author = {Zhang, Zhen and Bu, Jiajun and Ester, Martin and Zhang, Jianfeng and Yao, Chengwei and Yu, Zhi and Wang, Can},
  date = {2019-12-25},
  eprint = {1911.05954},
  eprinttype = {arXiv},
  eprintclass = {cs, stat},
  doi = {10.48550/arXiv.1911.05954},
  url = {http://arxiv.org/abs/1911.05954},
  urldate = {2024-03-11},
  abstract = {Graph Neural Networks (GNNs), which generalize deep neural networks to graph-structured data, have drawn considerable attention and achieved state-of-the-art performance in numerous graph related tasks. However, existing GNN models mainly focus on designing graph convolution operations. The graph pooling (or downsampling) operations, that play an important role in learning hierarchical representations, are usually overlooked. In this paper, we propose a novel graph pooling operator, called Hierarchical Graph Pooling with Structure Learning (HGP-SL), which can be integrated into various graph neural network architectures. HGP-SL incorporates graph pooling and structure learning into a unified module to generate hierarchical representations of graphs. More specifically, the graph pooling operation adaptively selects a subset of nodes to form an induced subgraph for the subsequent layers. To preserve the integrity of graph's topological information, we further introduce a structure learning mechanism to learn a refined graph structure for the pooled graph at each layer. By combining HGP-SL operator with graph neural networks, we perform graph level representation learning with focus on graph classification task. Experimental results on six widely used benchmarks demonstrate the effectiveness of our proposed model.},
  pubstate = {prepublished},
  keywords = {Computer Science - Machine Learning,Statistics - Machine Learning},
  annotation = {128 citations (Semantic Scholar/arXiv) [2024-03-11]},
  file = {/Users/michaelvolk/Zotero/storage/PU8N5BS4/Zhang et al_2019_Hierarchical Graph Pooling with Structure Learning.pdf;/Users/michaelvolk/Zotero/storage/Q73UMQSR/1911.html}
}

@article{zhangHigherorderInteractionsShape2023,
  title = {Higher-Order Interactions Shape Collective Dynamics Differently in Hypergraphs and Simplicial Complexes},
  author = {Zhang, Yuanzhao and Lucas, Maxime and Battiston, Federico},
  date = {2023-03-23},
  journaltitle = {Nature Communications},
  shortjournal = {Nat Commun},
  volume = {14},
  number = {1},
  pages = {1605},
  publisher = {Nature Publishing Group},
  issn = {2041-1723},
  doi = {10.1038/s41467-023-37190-9},
  url = {https://www.nature.com/articles/s41467-023-37190-9},
  urldate = {2024-07-04},
  abstract = {Higher-order networks have emerged as a powerful framework to model complex systems and their collective behavior. Going beyond pairwise interactions, they encode structured relations among arbitrary numbers of units through representations such as simplicial complexes and hypergraphs. So far, the choice between simplicial complexes and hypergraphs has often been motivated by technical convenience. Here, using synchronization as an example, we demonstrate that the effects of higher-order interactions are highly representation-dependent. In particular, higher-order interactions typically enhance synchronization in hypergraphs but have the opposite effect in simplicial complexes. We provide theoretical insight by linking the synchronizability of different hypergraph structures to (generalized) degree heterogeneity and cross-order degree correlation, which in turn influence a wide range of dynamical processes from contagion to diffusion. Our findings reveal the hidden impact of higher-order representations on collective dynamics, highlighting the importance of choosing appropriate representations when studying systems with nonpairwise interactions.},
  langid = {english},
  keywords = {Complex networks,Nonlinear phenomena},
  annotation = {55 citations (Semantic Scholar/DOI) [2024-07-04]},
  file = {/Users/michaelvolk/Zotero/storage/SHYYH8Z6/Zhang et al. - 2023 - Higher-order interactions shape collective dynamic.pdf}
}

@online{zhangHyperSAGNNSelfattentionBased2019,
  title = {Hyper-{{SAGNN}}: A Self-Attention Based Graph Neural Network for Hypergraphs},
  shorttitle = {Hyper-{{SAGNN}}},
  author = {Zhang, Ruochi and Zou, Yuesong and Ma, Jian},
  date = {2019-11-06},
  eprint = {1911.02613},
  eprinttype = {arXiv},
  eprintclass = {cs},
  doi = {10.48550/arXiv.1911.02613},
  url = {http://arxiv.org/abs/1911.02613},
  urldate = {2025-04-23},
  abstract = {Graph representation learning for hypergraphs can be used to extract patterns among higher-order interactions that are critically important in many real world problems. Current approaches designed for hypergraphs, however, are unable to handle different types of hypergraphs and are typically not generic for various learning tasks. Indeed, models that can predict variable-sized heterogeneous hyperedges have not been available. Here we develop a new self-attention based graph neural network called Hyper-SAGNN applicable to homogeneous and heterogeneous hypergraphs with variable hyperedge sizes. We perform extensive evaluations on multiple datasets, including four benchmark network datasets and two single-cell Hi-C datasets in genomics. We demonstrate that Hyper-SAGNN significantly outperforms the state-of-the-art methods on traditional tasks while also achieving great performance on a new task called outsider identification. Hyper-SAGNN will be useful for graph representation learning to uncover complex higher-order interactions in different applications.},
  pubstate = {prepublished},
  keywords = {Computer Science - Machine Learning,Statistics - Machine Learning},
  annotation = {187 citations (Semantic Scholar/arXiv) [2025-04-23]},
  file = {/Users/michaelvolk/Zotero/storage/CQMCUEBC/Zhang et al_2019_Hyper-SAGNN.pdf;/Users/michaelvolk/Zotero/storage/CAU89PEZ/1911.html}
}

@online{zhangImprovingDeepRegression2023,
  title = {Improving {{Deep Regression}} with {{Ordinal Entropy}}},
  author = {Zhang, Shihao and Yang, Linlin and Mi, Michael Bi and Zheng, Xiaoxu and Yao, Angela},
  date = {2023-02-28},
  eprint = {2301.08915},
  eprinttype = {arXiv},
  eprintclass = {cs},
  doi = {10.48550/arXiv.2301.08915},
  url = {http://arxiv.org/abs/2301.08915},
  urldate = {2024-12-12},
  abstract = {In computer vision, it is often observed that formulating regression problems as a classification task often yields better performance. We investigate this curious phenomenon and provide a derivation to show that classification, with the cross-entropy loss, outperforms regression with a mean squared error loss in its ability to learn high-entropy feature representations. Based on the analysis, we propose an ordinal entropy loss to encourage higher-entropy feature spaces while maintaining ordinal relationships to improve the performance of regression tasks. Experiments on synthetic and real-world regression tasks demonstrate the importance and benefits of increasing entropy for regression.},
  pubstate = {prepublished},
  keywords = {Computer Science - Artificial Intelligence,Computer Science - Computer Vision and Pattern Recognition,Computer Science - Machine Learning},
  annotation = {27 citations (Semantic Scholar/arXiv) [2024-12-11]\\
27 citations (Semantic Scholar/DOI) [2024-12-11]},
  file = {/Users/michaelvolk/Zotero/storage/68LHUECX/Zhang et al_2023_Improving Deep Regression with Ordinal Entropy.pdf;/Users/michaelvolk/Zotero/storage/WJUAWGHF/2301.html}
}

@article{zhaoEnhancingGraphSelfSupervised2024,
  title = {Enhancing {{Graph Self-Supervised Learning}} with {{Graph Interplay}}},
  author = {Zhao, Xinjian and Pang, Wei and Jian, Xiangru and Xu, Yaoyao and Ying, Chaolong and Yu, Tianshu},
  date = {2024-10-04},
  url = {https://openreview.net/forum?id=YWTpBisnwd},
  urldate = {2025-02-27},
  abstract = {Graph self-supervised learning (GSSL) has emerged as a compelling framework for extracting informative representations from graph-structured data without extensive reliance on labeled inputs. In this study, we introduce Graph Interplay (GIP), an innovative and versatile approach that significantly enhances the performance equipped with various existing GSSL methods. To this end, GIP advocates direct graph-level communications by introducing random inter-graph edges within standard batches. Against GIP's simplicity, we further theoretically show that GIP essentially performs a principled manifold separation via combining inter-graph message passing and GSSL, bringing about more structured embedding manifolds and thus benefits a series of downstream tasks. Our empirical study demonstrates that GIP surpasses the performance of prevailing GSSL methods across multiple benchmarks by significant margins, highlighting its potential as a breakthrough approach. Besides, GIP can be readily integrated into a series of GSSL methods and consistently offers additional performance gain. This advancement not only amplifies the capability of GSSL but also potentially sets the stage for a novel graph learning paradigm in a broader sense.},
  langid = {english},
  file = {/Users/michaelvolk/Zotero/storage/2YP9IAAE/Zhao et al_2024_Enhancing Graph Self-Supervised Learning with Graph Interplay.pdf}
}

@online{zhaoLearningMetricsPersistencebased2019,
  title = {Learning Metrics for Persistence-Based Summaries and Applications for Graph Classification},
  author = {Zhao, Qi and Wang, Yusu},
  date = {2019-12-11},
  eprint = {1904.12189},
  eprinttype = {arXiv},
  eprintclass = {cs},
  url = {http://arxiv.org/abs/1904.12189},
  urldate = {2024-03-11},
  abstract = {Recently a new feature representation and data analysis methodology based on a topological tool called persistent homology (and its corresponding persistence diagram summary) has started to attract momentum. A series of methods have been developed to map a persistence diagram to a vector representation so as to facilitate the downstream use of machine learning tools, and in these approaches, the importance (weight) of different persistence features are often preset. However often in practice, the choice of the weight function should depend on the nature of the specific type of data one considers, and it is thus highly desirable to learn a best weight function (and thus metric for persistence diagrams) from labelled data. We study this problem and develop a new weighted kernel, called WKPI, for persistence summaries, as well as an optimization framework to learn a good metric for persistence summaries. Both our kernel and optimization problem have nice properties. We further apply the learned kernel to the challenging task of graph classification, and show that our WKPI-based classification framework obtains similar or (sometimes significantly) better results than the best results from a range of previous graph classification frameworks on a collection of benchmark datasets.},
  pubstate = {prepublished},
  keywords = {Computer Science - Computational Geometry},
  annotation = {85 citations (Semantic Scholar/arXiv) [2024-03-11]},
  file = {/Users/michaelvolk/Zotero/storage/K83UYUFC/Zhao_Wang_2019_Learning metrics for persistence-based summaries and applications for graph.pdf;/Users/michaelvolk/Zotero/storage/QSJGVH58/1904.html}
}

@article{zhaSupervisedContrastiveRegression2022,
  title = {Supervised {{Contrastive Regression}}},
  author = {Zha, Kaiwen and Cao, Peng and Yang, Yuzhe and Katabi, Dina},
  date = {2022-09-29},
  url = {https://openreview.net/forum?id=_QZlje4dZPu&noteId=gIk7t-ZrCG),[3](https://openreview.net/forum?id=_QZlje4dZPu&noteId=MegNyb1HHa),[4](https://openreview.net/forum?id=_QZlje4dZPu&noteId=ZmAPyjdzA-},
  urldate = {2025-02-27},
  abstract = {Deep regression models typically learn in an end-to-end fashion and do not explicitly try to learn a regression-aware representation. Their representations tend to be fragmented and fail to capture the continuous nature of regression tasks. In this paper, we propose Supervised Contrastive Regression (SupCR), a framework that learns a regression-aware representation by contrasting samples against each other based on their target distance. SupCR is orthogonal to existing regression models, and can be used in combination with such models to improve performance. Extensive experiments using five real-world regression datasets that span computer vision, human-computer interaction, and healthcare show that using SupCR achieves the state-of-the-art performance and consistently improves prior regression baselines on all datasets, tasks, and input modalities. SupCR also improves robustness to data corruptions, resilience to reduced training data, performance on transfer learning, and generalization to unseen targets.},
  langid = {english},
  file = {/Users/michaelvolk/Zotero/storage/IBV5FK96/Zha et al_2022_Supervised Contrastive Regression.pdf}
}

@article{zhengInterpretationCancerMutations2021a,
  title = {Interpretation of Cancer Mutations Using a Multiscale Map of Protein Systems},
  author = {Zheng, Fan and Kelly, Marcus R. and Ramms, Dana J. and Heintschel, Marissa L. and Tao, Kai and Tutuncuoglu, Beril and Lee, John J. and Ono, Keiichiro and Foussard, Helene and Chen, Michael and Herrington, Kari A. and Silva, Erica and Liu, Sophie N. and Chen, Jing and Churas, Christopher and Wilson, Nicholas and Kratz, Anton and Pillich, Rudolf T. and Patel, Devin N. and Park, Jisoo and Kuenzi, Brent and Yu, Michael K. and Licon, Katherine and Pratt, Dexter and Kreisberg, Jason F. and Kim, Minkyu and Swaney, Danielle L. and Nan, Xiaolin and Fraley, Stephanie I. and Gutkind, J. Silvio and Krogan, Nevan J. and Ideker, Trey},
  date = {2021-10},
  journaltitle = {Science},
  volume = {374},
  number = {6563},
  pages = {eabf3067},
  publisher = {American Association for the Advancement of Science},
  doi = {10.1126/science.abf3067},
  url = {https://www.science.org/doi/10.1126/science.abf3067},
  urldate = {2023-08-30},
  abstract = {A major goal of cancer research is to understand how mutations distributed across diverse genes affect common cellular systems, including multiprotein complexes and assemblies. Two challenges—how to comprehensively map such systems and how to identify which are under mutational selection—have hindered this understanding. Accordingly, we created a comprehensive map of cancer protein systems integrating both new and published multi-omic interaction data at multiple scales of analysis. We then developed a unified statistical model that pinpoints 395 specific systems under mutational selection across 13 cancer types. This map, called NeST (Nested Systems in Tumors), incorporates canonical processes and notable discoveries, including a PIK3CA-actomyosin complex that inhibits phosphatidylinositol 3-kinase signaling and recurrent mutations in collagen complexes that promote tumor proliferation. These systems can be used as clinical biomarkers and implicate a total of 548 genes in cancer evolution and progression. This work shows how disparate tumor mutations converge on protein assemblies at different scales.},
  annotation = {16 citations (Semantic Scholar/DOI) [2023-08-30]},
  file = {/Users/michaelvolk/Zotero/storage/XY8H897U/Zheng et al_2021_Interpretation of cancer mutations using a multiscale map of protein systems.pdf}
}

@online{zhengPyGSSLGraphSelfSupervised2024,
  title = {{{PyG-SSL}}: {{A Graph Self-Supervised Learning Toolkit}}},
  shorttitle = {{{PyG-SSL}}},
  author = {Zheng, Lecheng and Jing, Baoyu and Li, Zihao and Zeng, Zhichen and Wei, Tianxin and Ai, Mengting and He, Xinrui and Liu, Lihui and Fu, Dongqi and You, Jiaxuan and Tong, Hanghang and He, Jingrui},
  date = {2024-12-30},
  eprint = {2412.21151},
  eprinttype = {arXiv},
  eprintclass = {cs},
  doi = {10.48550/arXiv.2412.21151},
  url = {http://arxiv.org/abs/2412.21151},
  urldate = {2025-02-27},
  abstract = {Graph Self-Supervised Learning (SSL) has emerged as a pivotal area of research in recent years. By engaging in pretext tasks to learn the intricate topological structures and properties of graphs using unlabeled data, these graph SSL models achieve enhanced performance, improved generalization, and heightened robustness. Despite the remarkable achievements of these graph SSL methods, their current implementation poses significant challenges for beginners and practitioners due to the complex nature of graph structures, inconsistent evaluation metrics, and concerns regarding reproducibility hinder further progress in this field. Recognizing the growing interest within the research community, there is an urgent need for a comprehensive, beginner-friendly, and accessible toolkit consisting of the most representative graph SSL algorithms. To address these challenges, we present a Graph SSL toolkit named PyG-SSL, which is built upon PyTorch and is compatible with various deep learning and scientific computing backends. Within the toolkit, we offer a unified framework encompassing dataset loading, hyper-parameter configuration, model training, and comprehensive performance evaluation for diverse downstream tasks. Moreover, we provide beginner-friendly tutorials and the best hyper-parameters of each graph SSL algorithm on different graph datasets, facilitating the reproduction of results. The GitHub repository of the library is https://github.com/iDEA-iSAIL-Lab-UIUC/pyg-ssl.},
  pubstate = {prepublished},
  keywords = {Computer Science - Artificial Intelligence,Computer Science - Machine Learning},
  annotation = {1 citations (Semantic Scholar/arXiv) [2025-02-27]\\
1 citations (Semantic Scholar/DOI) [2025-02-27]},
  file = {/Users/michaelvolk/Zotero/storage/QR9LRWTE/Zheng et al_2024_PyG-SSL.pdf;/Users/michaelvolk/Zotero/storage/CXKLKUEU/2412.html}
}

@inproceedings{zhenyuEfficientInferenceSchema2023,
  title = {An {{Efficient Inference Schema}} for {{Gene Regulatory Networks}} Using {{Directed Graph Neural Networks}}},
  booktitle = {2023 42nd {{Chinese Control Conference}} ({{CCC}})},
  author = {Zhenyu, Guo and Wanhong, Zhang},
  date = {2023-07-24},
  pages = {6829--6834},
  publisher = {IEEE},
  location = {Tianjin, China},
  doi = {10.23919/CCC58697.2023.10240472},
  url = {https://ieeexplore.ieee.org/document/10240472/},
  urldate = {2023-10-14},
  abstract = {Inferring gene regulatory networks (GRNs) from gene expression data has remained the computational challenge due to the large-scale number of genes and the complexity of expression data in systems biology, which may often formulate a reconstruction problem among nodes for a topology graph. Graph neural network (GNN) is one of the most promising approaches to reconstructing a GRN by integrating topological neighbor propagation throughout a gene network. This paper proposes an end-to-end gene regulatory directed graph neural network (GRDGNN) schema to infer GRN from scratch using gene expression data in a supervised framework. Specifically, the regulatory relationship of the GRN can be first described as a graph multi-classification problem to distinguish the connection kinds between two nodes for subgraphs. Then, using gene dominant expression features and graph embedding node features, subgraphs consisting of gene node pairs and their neighbor are classified into four classes by a directed GNN model. In addition, a starting network structure constructed with noise from partial information can guide GRN inference through an appropriate integration approach. Finally, we demonstrate the ability of this method using the test data from DREAM5 challenge and the human embryonic stem cells (hESC) and human mature hepatocytes (hHep) datasets. Computational results show that the proposed method displays greater inference performance.},
  eventtitle = {2023 42nd {{Chinese Control Conference}} ({{CCC}})},
  isbn = {978-988-758-154-3},
  langid = {english},
  annotation = {0 citations (Semantic Scholar/DOI) [2023-10-14]},
  file = {/Users/michaelvolk/Zotero/storage/9DNI6YEY/Zhenyu and Wanhong - 2023 - An Efficient Inference Schema for Gene Regulatory .pdf}
}

@article{zhongGO2VecTransformingGO2020,
  title = {{{GO2Vec}}: Transforming {{GO}} Terms and Proteins to Vector Representations via Graph Embeddings},
  shorttitle = {{{GO2Vec}}},
  author = {Zhong, Xiaoshi and Kaalia, Rama and Rajapakse, Jagath C.},
  date = {2020-02-18},
  journaltitle = {BMC Genomics},
  shortjournal = {BMC Genomics},
  volume = {20},
  number = {9},
  pages = {918},
  issn = {1471-2164},
  doi = {10.1186/s12864-019-6272-2},
  url = {https://doi.org/10.1186/s12864-019-6272-2},
  urldate = {2023-10-17},
  abstract = {Semantic similarity between Gene Ontology (GO) terms is a fundamental measure for many bioinformatics applications, such as determining functional similarity between genes or proteins. Most previous research exploited information content to estimate the semantic similarity between GO terms; recently some research exploited word embeddings to learn vector representations for GO terms from a large-scale corpus. In this paper, we proposed a novel method, named GO2Vec, that exploits graph embeddings to learn vector representations for GO terms from GO graph. GO2Vec combines the information from both GO graph and GO annotations, and its learned vectors can be applied to a variety of bioinformatics applications, such as calculating functional similarity between proteins and predicting protein-protein interactions.},
  keywords = {CESSM evaluation,Gene ontology,Graph embeddings,Protein-protein interaction prediction,Vector representations},
  annotation = {23 citations (Semantic Scholar/DOI) [2023-10-16]},
  file = {/Users/michaelvolk/Zotero/storage/4ETED282/Zhong et al_2020_GO2Vec.pdf;/Users/michaelvolk/Zotero/storage/EZRQ4698/s12864-019-6272-2.html}
}

@article{zhongGraphEmbeddingsGene2020a,
  title = {Graph Embeddings on Gene Ontology Annotations for Protein–Protein Interaction Prediction},
  author = {Zhong, Xiaoshi and Rajapakse, Jagath C.},
  date = {2020-12-16},
  journaltitle = {BMC Bioinformatics},
  shortjournal = {BMC Bioinformatics},
  volume = {21},
  number = {16},
  pages = {560},
  issn = {1471-2105},
  doi = {10.1186/s12859-020-03816-8},
  url = {https://doi.org/10.1186/s12859-020-03816-8},
  urldate = {2023-10-17},
  abstract = {Protein–protein interaction (PPI) prediction is an important task towards the understanding of many bioinformatics functions and applications, such as predicting protein functions, gene-disease associations and disease-drug associations. However, many previous PPI prediction researches do not consider missing and spurious interactions inherent in PPI networks. To address these two issues, we define two corresponding tasks, namely missing PPI prediction and spurious PPI prediction, and propose a method that employs graph embeddings that learn vector representations from constructed Gene Ontology Annotation (GOA) graphs and then use embedded vectors to achieve the two tasks. Our method leverages on information from both term–term relations among GO terms and term-protein annotations between GO terms and proteins, and preserves properties of both local and global structural information of the GO annotation graph.},
  langid = {english},
  keywords = {Gene Ontology annotations,Graph embeddings,Missing PPIs,Protein–protein interactions,Spurious PPIs,Vector representations},
  annotation = {12 citations (Semantic Scholar/DOI) [2023-10-16]},
  file = {/Users/michaelvolk/Zotero/storage/YANRM7G7/Zhong_Rajapakse_2020_Graph embeddings on gene ontology annotations for protein–protein interaction.pdf}
}

@online{zhouDNABERTSLearningSpeciesAware2024,
  title = {{{DNABERT-S}}: {{Learning Species-Aware DNA Embedding}} with {{Genome Foundation Models}}},
  shorttitle = {{{DNABERT-S}}},
  author = {Zhou, Zhihan and Wu, Weimin and Ho, Harrison and Wang, Jiayi and Shi, Lizhen and Davuluri, Ramana V. and Wang, Zhong and Liu, Han},
  date = {2024-02-14},
  eprint = {2402.08777},
  eprinttype = {arXiv},
  eprintclass = {cs, q-bio},
  doi = {10.48550/arXiv.2402.08777},
  url = {http://arxiv.org/abs/2402.08777},
  urldate = {2024-03-31},
  abstract = {Effective DNA embedding remains crucial in genomic analysis, particularly in scenarios lacking labeled data for model fine-tuning, despite the significant advancements in genome foundation models. A prime example is metagenomics binning, a critical process in microbiome research that aims to group DNA sequences by their species from a complex mixture of DNA sequences derived from potentially thousands of distinct, often uncharacterized species. To fill the lack of effective DNA embedding models, we introduce DNABERT-S, a genome foundation model that specializes in creating species-aware DNA embeddings. To encourage effective embeddings to error-prone long-read DNA sequences, we introduce Manifold Instance Mixup (MI-Mix), a contrastive objective that mixes the hidden representations of DNA sequences at randomly selected layers and trains the model to recognize and differentiate these mixed proportions at the output layer. We further enhance it with the proposed Curriculum Contrastive Learning (C\$\textasciicircum 2\$LR) strategy. Empirical results on 18 diverse datasets showed DNABERT-S's remarkable performance. It outperforms the top baseline's performance in 10-shot species classification with just a 2-shot training while doubling the Adjusted Rand Index (ARI) in species clustering and substantially increasing the number of correctly identified species in metagenomics binning. The code, data, and pre-trained model are publicly available at https://github.com/Zhihan1996/DNABERT\_S.},
  pubstate = {prepublished},
  keywords = {Computer Science - Artificial Intelligence,Computer Science - Computation and Language,Computer Science - Computational Engineering Finance and Science,Quantitative Biology - Genomics},
  annotation = {0 citations (Semantic Scholar/arXiv) [2024-03-30]\\
0 citations (Semantic Scholar/DOI) [2024-03-30]},
  file = {/Users/michaelvolk/Zotero/storage/TVXBBBNC/Zhou et al_2024_DNABERT-S.pdf;/Users/michaelvolk/Zotero/storage/GUB9X4MQ/2402.html}
}

@online{zhouIntegratingProteinDynamics2025,
  title = {Integrating {{Protein Dynamics}} into {{Structure-Based Drug Design}} via {{Full-Atom Stochastic Flows}}},
  author = {Zhou, Xiangxin and Xiao, Yi and Lin, Haowei and He, Xinheng and Guan, Jiaqi and Wang, Yang and Liu, Qiang and Zhou, Feng and Wang, Liang and Ma, Jianzhu},
  date = {2025-03-06},
  eprint = {2503.03989},
  eprinttype = {arXiv},
  eprintclass = {q-bio},
  doi = {10.48550/arXiv.2503.03989},
  url = {http://arxiv.org/abs/2503.03989},
  urldate = {2025-05-08},
  abstract = {The dynamic nature of proteins, influenced by ligand interactions, is essential for comprehending protein function and progressing drug discovery. Traditional structure-based drug design (SBDD) approaches typically target binding sites with rigid structures, limiting their practical application in drug development. While molecular dynamics simulation can theoretically capture all the biologically relevant conformations, the transition rate is dictated by the intrinsic energy barrier between them, making the sampling process computationally expensive. To overcome the aforementioned challenges, we propose to use generative modeling for SBDD considering conformational changes of protein pockets. We curate a dataset of apo and multiple holo states of protein-ligand complexes, simulated by molecular dynamics, and propose a full-atom flow model (and a stochastic version), named DynamicFlow, that learns to transform apo pockets and noisy ligands into holo pockets and corresponding 3D ligand molecules. Our method uncovers promising ligand molecules and corresponding holo conformations of pockets. Additionally, the resultant holo-like states provide superior inputs for traditional SBDD approaches, playing a significant role in practical drug discovery.},
  pubstate = {prepublished},
  keywords = {Computer Science - Machine Learning,Quantitative Biology - Biomolecules},
  annotation = {0 citations (Semantic Scholar/arXiv) [2025-05-08]\\
0 citations (Semantic Scholar/DOI) [2025-05-08]},
  file = {/Users/michaelvolk/Zotero/storage/VDJTJT2D/Zhou et al_2025_Integrating Protein Dynamics into Structure-Based Drug Design via Full-Atom.pdf;/Users/michaelvolk/Zotero/storage/4CB5W5J2/2503.html}
}

@online{zhouOpenGSLComprehensiveBenchmark2023,
  title = {{{OpenGSL}}: {{A Comprehensive Benchmark}} for {{Graph Structure Learning}}},
  shorttitle = {{{OpenGSL}}},
  author = {Zhou, Zhiyao and Zhou, Sheng and Mao, Bochao and Zhou, Xuanyi and Chen, Jiawei and Tan, Qiaoyu and Zha, Daochen and Wang, Can and Feng, Yan and Chen, Chun},
  date = {2023-06-17},
  eprint = {2306.10280},
  eprinttype = {arXiv},
  eprintclass = {cs},
  doi = {10.48550/arXiv.2306.10280},
  url = {http://arxiv.org/abs/2306.10280},
  urldate = {2023-10-16},
  abstract = {Graph Neural Networks (GNNs) have emerged as the de facto standard for representation learning on graphs, owing to their ability to effectively integrate graph topology and node attributes. However, the inherent suboptimal nature of node connections, resulting from the complex and contingent formation process of graphs, presents significant challenges in modeling them effectively. To tackle this issue, Graph Structure Learning (GSL), a family of data-centric learning approaches, has garnered substantial attention in recent years. The core concept behind GSL is to jointly optimize the graph structure and the corresponding GNN models. Despite the proposal of numerous GSL methods, the progress in this field remains unclear due to inconsistent experimental protocols, including variations in datasets, data processing techniques, and splitting strategies. In this paper, we introduce OpenGSL, the first comprehensive benchmark for GSL, aimed at addressing this gap. OpenGSL enables a fair comparison among state-of-the-art GSL methods by evaluating them across various popular datasets using uniform data processing and splitting strategies. Through extensive experiments, we observe that existing GSL methods do not consistently outperform vanilla GNN counterparts. However, we do observe that the learned graph structure demonstrates a strong generalization ability across different GNN backbones, despite its high computational and space requirements. We hope that our open-sourced library will facilitate rapid and equitable evaluation and inspire further innovative research in the field of GSL. The code of the benchmark can be found in https://github.com/OpenGSL/OpenGSL.},
  pubstate = {prepublished},
  keywords = {Computer Science - Machine Learning,Computer Science - Social and Information Networks},
  annotation = {2 citations (Semantic Scholar/arXiv) [2023-10-16]\\
2 citations (Semantic Scholar/DOI) [2023-10-16]},
  file = {/Users/michaelvolk/Zotero/storage/4KGWHREP/Zhou et al_2023_OpenGSL.pdf;/Users/michaelvolk/Zotero/storage/AFUPAU36/2306.html}
}

@online{zhuSurveyGraphStructure2022,
  title = {A {{Survey}} on {{Graph Structure Learning}}: {{Progress}} and {{Opportunities}}},
  shorttitle = {A {{Survey}} on {{Graph Structure Learning}}},
  author = {Zhu, Yanqiao and Xu, Weizhi and Zhang, Jinghao and Du, Yuanqi and Zhang, Jieyu and Liu, Qiang and Yang, Carl and Wu, Shu},
  date = {2022-02-14},
  eprint = {2103.03036},
  eprinttype = {arXiv},
  eprintclass = {cs},
  doi = {10.48550/arXiv.2103.03036},
  url = {http://arxiv.org/abs/2103.03036},
  urldate = {2023-10-16},
  abstract = {Graphs are widely used to describe real-world objects and their interactions. Graph Neural Networks (GNNs) as a de facto model for analyzing graphstructured data, are highly sensitive to the quality of the given graph structures. Therefore, noisy or incomplete graphs often lead to unsatisfactory representations and prevent us from fully understanding the mechanism underlying the system. In pursuit of an optimal graph structure for downstream tasks, recent studies have sparked an effort around the central theme of Graph Structure Learning (GSL), which aims to jointly learn an optimized graph structure and corresponding graph representations. In the presented survey, we broadly review recent progress in GSL methods. Specifically, we first formulate a general pipeline of GSL and review state-of-the-art methods classified by the way of modeling graph structures, followed by applications of GSL across domains. Finally, we point out some issues in current studies and discuss future directions.},
  pubstate = {prepublished},
  keywords = {Computer Science - Machine Learning,Computer Science - Social and Information Networks},
  annotation = {35 citations (Semantic Scholar/arXiv) [2023-10-16]},
  file = {/Users/michaelvolk/Zotero/storage/NW2WCKJ6/Zhu et al_2022_A Survey on Graph Structure Learning.pdf;/Users/michaelvolk/Zotero/storage/7HV465WK/2103.html}
}

@unpublished{ziaTopologicalDeepLearning2023b,
  title = {Topological {{Deep Learning}}: {{A Review}} of an {{Emerging Paradigm}}},
  shorttitle = {Topological {{Deep Learning}}},
  author = {Zia, Ali and Khamis, Abdelwahed and Nichols, James and Hayder, Zeeshan and Rolland, Vivien and Petersson, Lars},
  date = {2023},
  eprint = {2302.03836},
  eprinttype = {arXiv},
  url = {https://arxiv.org/abs/2302.03836},
  urldate = {2023-10-09},
  annotation = {2 citations (Semantic Scholar/arXiv) [2023-10-09]},
  file = {/Users/michaelvolk/Zotero/storage/3AIGVS9P/Zia et al_2023_Topological Deep Learning.pdf}
}

@online{ziaTopologicalDeepLearning2023c,
  title = {Topological {{Deep Learning}}: {{A Review}} of an {{Emerging Paradigm}}},
  shorttitle = {Topological {{Deep Learning}}},
  author = {Zia, Ali and Khamis, Abdelwahed and Nichols, James and Hayder, Zeeshan and Rolland, Vivien and Petersson, Lars},
  date = {2023-02-07},
  eprint = {2302.03836},
  eprinttype = {arXiv},
  eprintclass = {cs},
  url = {http://arxiv.org/abs/2302.03836},
  urldate = {2023-10-09},
  abstract = {Topological data analysis (TDA) provides insight into data shape. The summaries obtained by these methods are principled global descriptions of multi-dimensional data whilst exhibiting stable properties such as robustness to deformation and noise. Such properties are desirable in deep learning pipelines but they are typically obtained using non-TDA strategies. This is partly caused by the difficulty of combining TDA constructs (e.g. barcode and persistence diagrams) with current deep learning algorithms. Fortunately, we are now witnessing a growth of deep learning applications embracing topologically-guided components. In this survey, we review the nascent field of topological deep learning by first revisiting core concepts of TDA. We then explore how the use of TDA techniques has evolved over time to support deep learning frameworks, and how they can be integrated into different aspects of deep learning. Furthermore, we touch on TDA usage for analyzing existing deep models; deep topological analytics. Finally, we discuss the challenges and future prospects of topological deep learning.},
  langid = {english},
  pubstate = {prepublished},
  keywords = {Computer Science - Artificial Intelligence,Computer Science - Machine Learning},
  annotation = {2 citations (Semantic Scholar/arXiv) [2023-10-09]}
}

@online{ziaTopologicalDeepLearning2023d,
  title = {Topological {{Deep Learning}}: {{A Review}} of an {{Emerging Paradigm}}},
  shorttitle = {Topological {{Deep Learning}}},
  author = {Zia, Ali and Khamis, Abdelwahed and Nichols, James and Hayder, Zeeshan and Rolland, Vivien and Petersson, Lars},
  date = {2023-02-07},
  eprint = {2302.03836},
  eprinttype = {arXiv},
  eprintclass = {cs},
  url = {http://arxiv.org/abs/2302.03836},
  urldate = {2023-10-09},
  abstract = {Topological data analysis (TDA) provides insight into data shape. The summaries obtained by these methods are principled global descriptions of multi-dimensional data whilst exhibiting stable properties such as robustness to deformation and noise. Such properties are desirable in deep learning pipelines but they are typically obtained using non-TDA strategies. This is partly caused by the difficulty of combining TDA constructs (e.g. barcode and persistence diagrams) with current deep learning algorithms. Fortunately, we are now witnessing a growth of deep learning applications embracing topologically-guided components. In this survey, we review the nascent field of topological deep learning by first revisiting core concepts of TDA. We then explore how the use of TDA techniques has evolved over time to support deep learning frameworks, and how they can be integrated into different aspects of deep learning. Furthermore, we touch on TDA usage for analyzing existing deep models; deep topological analytics. Finally, we discuss the challenges and future prospects of topological deep learning.},
  langid = {english},
  pubstate = {prepublished},
  keywords = {Computer Science - Artificial Intelligence,Computer Science - Machine Learning},
  annotation = {2 citations (Semantic Scholar/arXiv) [2023-10-09]}
}

@article{zouRegularizationVariableSelection2005,
  title = {Regularization and {{Variable Selection Via}} the {{Elastic Net}}},
  author = {Zou, Hui and Hastie, Trevor},
  date = {2005-04-01},
  journaltitle = {Journal of the Royal Statistical Society Series B: Statistical Methodology},
  shortjournal = {Journal of the Royal Statistical Society Series B: Statistical Methodology},
  volume = {67},
  number = {2},
  pages = {301--320},
  issn = {1369-7412},
  doi = {10.1111/j.1467-9868.2005.00503.x},
  url = {https://doi.org/10.1111/j.1467-9868.2005.00503.x},
  urldate = {2024-05-04},
  abstract = {We propose the elastic net, a new regularization and variable selection method. Real world data and a simulation study show that the elastic net often outperforms the lasso, while enjoying a similar sparsity of representation. In addition, the elastic net encourages a grouping effect, where strongly correlated predictors tend to be in or out of the model together. The elastic net is particularly useful when the number of predictors (p) is much bigger than the number of observations (n). By contrast, the lasso is not a very satisfactory variable selection method in the p≫n case. An algorithm called LARS-EN is proposed for computing elastic net regularization paths efficiently, much like algorithm LARS does for the lasso.},
  file = {/Users/michaelvolk/Zotero/storage/83ZIYHR4/Zou_Hastie_2005_Regularization and Variable Selection Via the Elastic Net.pdf;/Users/michaelvolk/Zotero/storage/C368X6B2/7109482.html}
}

@article{zrimecDeepLearningSuggests2020,
  title = {Deep Learning Suggests That Gene Expression Is Encoded in All Parts of a Co-Evolving Interacting Gene Regulatory Structure},
  author = {Zrimec, Jan and Börlin, Christoph S. and Buric, Filip and Muhammad, Azam Sheikh and Chen, Rhongzen and Siewers, Verena and Verendel, Vilhelm and Nielsen, Jens and Töpel, Mats and Zelezniak, Aleksej},
  date = {2020-12-01},
  journaltitle = {Nature Communications},
  shortjournal = {Nat Commun},
  volume = {11},
  number = {1},
  pages = {6141},
  publisher = {Nature Publishing Group},
  issn = {2041-1723},
  doi = {10.1038/s41467-020-19921-4},
  url = {https://www.nature.com/articles/s41467-020-19921-4},
  urldate = {2023-09-15},
  abstract = {Understanding the genetic regulatory code governing gene expression is an important challenge in molecular biology. However, how individual coding and non-coding regions of the gene regulatory structure interact and contribute to mRNA expression levels remains unclear. Here we apply deep learning on over 20,000 mRNA datasets to examine the genetic regulatory code controlling mRNA abundance in 7 model organisms ranging from bacteria to Human. In all organisms, we can predict mRNA abundance directly from DNA sequence, with up to 82\% of the variation of transcript levels encoded in the gene regulatory structure. By searching for DNA regulatory motifs across the gene regulatory structure, we discover that motif interactions could explain the whole dynamic range of mRNA levels.~Co-evolution across coding and non-coding regions suggests that it is not single motifs or regions, but the entire gene regulatory structure and specific combination of regulatory elements that define gene expression levels.},
  issue = {1},
  langid = {english},
  keywords = {Gene regulatory networks,Machine learning,Synthetic biology},
  annotation = {70 citations (Semantic Scholar/DOI) [2023-09-15]},
  file = {/Users/michaelvolk/Zotero/storage/URXNDSGZ/Zrimec et al_2020_Deep learning suggests that gene expression is encoded in all parts of a.pdf}
}
