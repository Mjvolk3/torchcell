# torchcell/models/dcell_new
# [[torchcell.models.dcell_new]]
# https://github.com/Mjvolk3/torchcell/tree/main/torchcell/models/dcell_new
# Test file: tests/torchcell/models/test_dcell_new.py

import torch
import torch.nn as nn
import torch.nn.functional as F
from typing import Dict, List, Tuple, Union, Optional
from torch_geometric.data import HeteroData, Batch
import networkx as nx
import hydra
import os
import os.path as osp
import numpy as np
import time
import matplotlib.pyplot as plt
from omegaconf import DictConfig
from dotenv import load_dotenv
from torchcell.timestamp import timestamp
from torchcell.losses.dcell_new import DCellNewLoss

# Load environment variables to get ASSET_IMAGES_DIR
load_dotenv()


class SubsystemModel(nn.Module):
    """
    Neural network model representing a subsystem in the GO hierarchy.

    This module processes the inputs for each GO term, which consists of:
    1. The mutant state for genes directly annotated to this term
    2. Outputs from child subsystems in the GO hierarchy

    Args:
        input_size: Total input size (mutant states + child outputs)
        output_size: Size of the output vector for this subsystem
        norm_type: Type of normalization to use ('batch', 'layer', or 'none')
    """

    def __init__(self, input_size: int, output_size: int, norm_type: str = "batch"):
        super().__init__()
        self.output_size = output_size  # Store output size as an attribute
        self.linear = nn.Linear(input_size, output_size)
        # Original DCell doesn't have special initialization - use PyTorch default
        # which is uniform(-sqrt(k), sqrt(k)), where k = 1/in_features
        self.tanh = nn.Tanh()
        self.norm_type = norm_type

        # Create normalization layer based on specified type
        if norm_type == "batch":
            # Use standard BatchNorm with running stats to match original DCell
            self.norm = nn.BatchNorm1d(output_size)
        elif norm_type == "layer":
            # Use LayerNorm as an alternative
            self.norm = nn.LayerNorm(output_size)
        elif norm_type == "none":
            self.norm = None
        else:
            raise ValueError(
                f"Unknown norm_type: {norm_type}. Expected 'batch', 'layer', or 'none'."
            )

    def forward(self, x: torch.Tensor) -> torch.Tensor:
        """
        Forward pass for the subsystem.

        Args:
            x: Input tensor containing mutant states and child outputs [batch_size, input_size]

        Returns:
            Processed subsystem output [batch_size, output_size]
        """
        x = self.linear(x)
        x = self.tanh(x)

        # Apply normalization if specified
        if self.norm_type == "batch":
            # Handle single batch case safely
            if x.size(0) == 1:
                # Skip BatchNorm for single samples to avoid the error
                pass
            else:
                x = self.norm(x)
        elif self.norm_type == "layer":
            # LayerNorm works with any batch size, including 1
            x = self.norm(x)
        # No normalization for 'none' case

        return x


class DCellNew(nn.Module):
    """
    Reimplementation of DCell model that works directly with PyTorch Geometric HeteroData.

    This implementation:
    1. Uses the gene_ontology structure from cell_graph
    2. Processes mutant state tensors generated by DCellGraphProcessor
    3. Handles batches of multiple samples efficiently using vectorized operations

    Args:
        gene_num: Total number of genes (used for tensor allocations)
        subsystem_output_min: Minimum output size for any subsystem
        subsystem_output_max_mult: Multiplier for scaling subsystem output sizes
        verbose_debug: Enable verbose debug output
        norm_type: Type of normalization to use ('batch', 'layer', or 'none')
    """

    def __init__(
        self,
        gene_num: int,
        subsystem_output_min: int = 20,
        subsystem_output_max_mult: float = 0.3,
        verbose_debug: bool = False,
        norm_type: str = "batch",
    ):
        super().__init__()
        self.gene_num = gene_num
        self.subsystem_output_min = subsystem_output_min
        self.subsystem_output_max_mult = subsystem_output_max_mult
        self.subsystems = nn.ModuleDict()
        self.go_graph = None
        self.verbose_debug = verbose_debug  # Control debug output
        self.norm_type = norm_type

        # Initialize with a simple default subsystem to ensure the model has parameters
        # This will be replaced when actual data is provided
        self.subsystems["default"] = SubsystemModel(
            input_size=1, output_size=subsystem_output_min, norm_type=norm_type
        )

        # Flag to track if we've initialized from real data
        self.initialized = False

        # Cache for topological order
        self.sorted_subsystems = None

    def _initialize_from_cell_graph(self, cell_graph: HeteroData) -> None:
        """
        Initialize subsystems from the cell_graph structure.
        Must be called before the first forward pass.

        Args:
            cell_graph: The cell graph containing gene ontology structure
        """
        # Verify we have gene ontology data
        if "gene_ontology" not in cell_graph.node_types:
            raise ValueError("Cell graph must contain gene_ontology nodes")

        # Build the NetworkX graph from the HeteroData structure for traversal
        go_graph = nx.DiGraph()

        # Add GO terms as nodes with full data
        for i, term_id in enumerate(cell_graph["gene_ontology"].node_ids):
            # Extract gene indices for this term
            gene_indices = []
            if hasattr(cell_graph["gene_ontology"], "term_to_gene_dict"):
                gene_indices = cell_graph["gene_ontology"].term_to_gene_dict.get(i, [])

            # Add gene names if available
            gene_names = []
            if hasattr(cell_graph["gene"], "node_ids"):
                gene_names = [
                    cell_graph["gene"].node_ids[idx]
                    for idx in gene_indices
                    if idx < len(cell_graph["gene"].node_ids)
                ]

            # Add node with all required attributes
            go_graph.add_node(
                term_id,
                id=i,
                gene_set=gene_names if gene_names else gene_indices,
                namespace="biological_process",  # Default, might be updated later if info is available
                # Initialize empty mutant state
                mutant_state=torch.ones(len(gene_indices), dtype=torch.float32),
            )

        # Add hierarchical edges (child -> parent)
        if ("gene_ontology", "is_child_of", "gene_ontology") in cell_graph.edge_types:
            edge_index = cell_graph[
                "gene_ontology", "is_child_of", "gene_ontology"
            ].edge_index
            for i in range(edge_index.size(1)):
                child_idx = edge_index[0, i].item()
                parent_idx = edge_index[1, i].item()
                child_id = cell_graph["gene_ontology"].node_ids[child_idx]
                parent_id = cell_graph["gene_ontology"].node_ids[parent_idx]
                go_graph.add_edge(child_id, parent_id)

        # Add root node if not already present
        if "GO:ROOT" not in go_graph.nodes:
            # Find all nodes without parents (current roots)
            root_nodes = [
                node for node in go_graph.nodes if go_graph.in_degree(node) == 0
            ]

            # Add super-root node
            go_graph.add_node(
                "GO:ROOT",
                name="GO Super Node",
                namespace="super_root",
                level=-1,
                gene_set=[],
                mutant_state=torch.tensor([], dtype=torch.float32),
            )

            # Connect all current roots to the super-root
            for node in root_nodes:
                go_graph.add_edge("GO:ROOT", node)

        # Reverse the graph to make traversal easier (parent -> child)
        go_graph = nx.reverse(go_graph, copy=True)
        self.go_graph = go_graph

        # Clear default subsystem
        self.subsystems.clear()

        # Build the subsystems in topological order
        self._build_subsystems(go_graph)
        self.initialized = True

        # Cache sorted subsystems for faster forward pass
        self.sorted_subsystems = list(
            reversed(list(nx.topological_sort(self.go_graph)))
        )

        # Log the number of subsystems created
        print(
            f"Created {len(self.subsystems)} subsystems from GO graph with {len(go_graph.nodes)} nodes"
        )

    def _build_subsystems(self, go_graph: nx.DiGraph) -> None:
        """
        Build the subsystem modules based on the GO graph structure.

        Args:
            go_graph: NetworkX DiGraph representing the GO hierarchy
        """
        # Sort nodes topologically to ensure we process all nodes systematically
        nodes_sorted = list(nx.topological_sort(go_graph))

        # Create a mapping to track input and output sizes for validation
        self.input_sizes = {}

        # First pass: count children and identify leaf nodes
        node_children = {}
        leaf_nodes = []
        for node_id in nodes_sorted:
            successors = list(go_graph.successors(node_id))
            node_children[node_id] = successors
            if not successors:  # No children = leaf node
                leaf_nodes.append(node_id)

        # Debug information
        print(
            f"Found {len(leaf_nodes)} leaf nodes out of {len(nodes_sorted)} total nodes"
        )

        # First process leaf nodes (no children)
        for node_id in leaf_nodes:
            # Get gene set for this term
            genes = go_graph.nodes[node_id].get("gene_set", [])
            # Ensure input size is at least 1
            input_size = max(1, len(genes))

            # Store input size for validation later
            self.input_sizes[node_id] = input_size

            # Calculate output size with minimum threshold
            output_size = max(
                self.subsystem_output_min,
                int(self.subsystem_output_max_mult * len(genes)),
            )

            # Create subsystem
            self.subsystems[node_id] = SubsystemModel(
                input_size=input_size, output_size=output_size, norm_type=self.norm_type
            )

        # Second pass: process non-leaf nodes in reverse topological order
        # Process nodes from leaves toward the root
        for node_id in reversed(nodes_sorted):
            # Skip if already processed
            if node_id in self.subsystems:
                continue

            # Get children of this node
            children = node_children.get(node_id, [])

            # Make sure all children have been processed
            all_children_processed = all(child in self.subsystems for child in children)
            if not all_children_processed:
                print(f"Warning: Not all children processed for {node_id}")
                # Add any missing children as simple pass-through
                for child in children:
                    if child not in self.subsystems:
                        genes_child = go_graph.nodes[child].get("gene_set", [])
                        self.subsystems[child] = SubsystemModel(
                            input_size=max(1, len(genes_child)),
                            output_size=self.subsystem_output_min,
                            norm_type=self.norm_type,
                        )
                        self.input_sizes[child] = max(1, len(genes_child))

            # Calculate total input size: sum of child outputs + genes for this term
            children_output_size = sum(
                self.subsystems[child].output_size
                for child in children
                if child in self.subsystems
            )

            # Get genes for this term
            genes = go_graph.nodes[node_id].get("gene_set", [])

            # Calculate total input size (child outputs + gene states)
            total_input_size = children_output_size + len(genes)
            # Ensure at least size 1 to avoid errors with empty terms
            total_input_size = max(1, total_input_size)

            # Store for validation
            self.input_sizes[node_id] = total_input_size

            # Calculate output size with minimum threshold
            output_size = max(
                self.subsystem_output_min,
                int(self.subsystem_output_max_mult * len(genes)),
            )

            # Initialize subsystem with proper sizes
            self.subsystems[node_id] = SubsystemModel(
                input_size=total_input_size,
                output_size=output_size,
                norm_type=self.norm_type,
            )

        # Add special handling for root node if present
        if "GO:ROOT" in go_graph.nodes and "GO:ROOT" not in self.subsystems:
            # Get children of root
            root_children = list(go_graph.successors("GO:ROOT"))
            # Sum output sizes of all root's children
            root_input_size = sum(
                self.subsystems[child].output_size
                for child in root_children
                if child in self.subsystems
            )

            # Add 1 for the gene state - this is critical for the ROOT node
            root_input_size += 1

            # Ensure at least size 1
            root_input_size = max(1, root_input_size)
            # Store for validation
            self.input_sizes["GO:ROOT"] = root_input_size

            # Create root subsystem
            self.subsystems["GO:ROOT"] = SubsystemModel(
                input_size=root_input_size,
                output_size=self.subsystem_output_min,
                norm_type=self.norm_type,
            )

        # Verify subsystem creation
        num_created = len(self.subsystems)
        print(f"Created {num_created} subsystems out of {len(nodes_sorted)} nodes")

        # Print parameter count
        param_count = sum(
            sum(p.numel() for p in s.parameters() if p.requires_grad)
            for s in self.subsystems.values()
        )
        print(f"Total parameters in subsystems: {param_count:,}")

        # If we somehow ended up with no subsystems (very unlikely but possible),
        # add a default one to ensure we have parameters
        if len(self.subsystems) == 0:
            print("Warning: No subsystems created, adding default subsystem")
            self.subsystems["default"] = SubsystemModel(
                input_size=1,
                output_size=self.subsystem_output_min,
                norm_type=self.norm_type,
            )

    def forward(
        self, cell_graph: HeteroData, batch: HeteroData
    ) -> Tuple[torch.Tensor, Dict[str, torch.Tensor]]:
        """
        Vectorized forward pass for the DCellNew model.
        This implementation avoids loops over individual samples in a batch.

        Args:
            cell_graph: The cell graph containing gene ontology structure
            batch: HeteroDataBatch containing perturbation information and mutant states

        Returns:
            Tuple of (root_output, outputs_dictionary)
        """
        # Initialize subsystems from cell_graph if not done yet
        if not self.initialized:
            self._initialize_from_cell_graph(cell_graph)

        # Set device
        device = batch["gene"].phenotype_values.device
        num_graphs = batch.num_graphs

        # Get mutant state tensor - COO format containing [term_idx, gene_idx, state]
        if not hasattr(batch["gene_ontology"], "mutant_state"):
            raise ValueError(
                "Batch must contain gene_ontology.mutant_state for DCell model"
            )

        mutant_state = batch["gene_ontology"].mutant_state

        # Extract batch information
        if hasattr(batch["gene_ontology"], "mutant_state_batch"):
            # Use provided batch indices for the mutant states
            batch_indices = batch["gene_ontology"].mutant_state_batch
        else:
            # If no batch index, assume single graph
            batch_indices = torch.zeros(
                mutant_state.size(0), dtype=torch.long, device=device
            )

        # Map from term IDs to indices in the cell_graph
        term_id_to_idx = {
            term_id: idx
            for idx, term_id in enumerate(cell_graph["gene_ontology"].node_ids)
        }

        # Dictionary to store all subsystem outputs
        subsystem_outputs = {}

        # Handle the special case of the default subsystem for empty GO graphs
        if "default" in self.subsystems and len(self.subsystems) == 1:
            # Create a dummy output for the default subsystem
            default_output = torch.zeros(
                (num_graphs, self.subsystems["default"].output_size), device=device
            )
            subsystem_outputs["default"] = default_output
            root_output = default_output
            return root_output, {"subsystem_outputs": subsystem_outputs}

        # Create a dictionary to hold gene states for each term and batch item
        term_gene_states = {}

        # Pre-process mutant states for all terms and batch items
        # Group by term_idx to avoid duplication in the loop
        term_indices = mutant_state[:, 0].long()
        term_indices_set = torch.unique(term_indices).tolist()

        # For each term, create a tensor of gene states for all batch items
        for term_idx in term_indices_set:
            term_idx = (
                term_idx.item() if isinstance(term_idx, torch.Tensor) else term_idx
            )

            # Get genes for this term
            genes = cell_graph["gene_ontology"].term_to_gene_dict.get(term_idx, [])
            num_genes = max(1, len(genes))  # Ensure at least 1 gene

            # Initialize gene states tensor for this term: [batch_size, num_genes]
            # Default state is 1.0 (not perturbed)
            term_gene_states[term_idx] = torch.ones(
                (num_graphs, num_genes), dtype=torch.float, device=device
            )

            # Get all mutant states for this term
            term_mask = term_indices == term_idx
            term_mutant_states = mutant_state[term_mask]

            if term_mutant_states.size(0) > 0:
                # Get batch indices for these states
                if hasattr(batch["gene_ontology"], "mutant_state_batch"):
                    states_batch_indices = batch_indices[term_mask]
                else:
                    # If no batch info, assume all from batch 0
                    states_batch_indices = torch.zeros(
                        term_mutant_states.size(0), dtype=torch.long, device=device
                    )

                # Apply perturbations to gene states
                for i in range(term_mutant_states.size(0)):
                    batch_idx = states_batch_indices[i].item()
                    gene_idx = term_mutant_states[i, 1].long().item()
                    state_value = term_mutant_states[i, 2].item()

                    # Only process valid gene indices
                    if gene_idx < len(genes):
                        # Find local index within the term's genes
                        gene_local_idx = (
                            genes.index(gene_idx) if gene_idx in genes else -1
                        )
                        if gene_local_idx >= 0:
                            # If state is not 1.0, set to 0.0 (perturbed)
                            if state_value != 1.0:
                                term_gene_states[term_idx][
                                    batch_idx, gene_local_idx
                                ] = 0.0

        # Special case for root node
        if "GO:ROOT" in self.subsystems:
            # For ROOT, use a single gene state tensor (all 1s)
            term_gene_states[-1] = torch.ones(
                (num_graphs, 1), dtype=torch.float, device=device
            )

        # Now process nodes in reverse topological order (leaves to root)
        # using the cached sorted order for efficiency
        for subsystem_name in self.sorted_subsystems:
            # Skip subsystems that weren't initialized
            if subsystem_name not in self.subsystems:
                continue

            # Get the model for this subsystem
            subsystem_model = self.subsystems[subsystem_name]

            # Get the index for this term in the cell_graph
            if subsystem_name == "GO:ROOT":
                # Handle root node specially
                term_idx = -1  # Special value for root
            else:
                # Get the index from the term_id
                term_idx = term_id_to_idx.get(subsystem_name, -1)
                if term_idx == -1:
                    # Skip if term is not in the cell graph
                    continue

            # Get or create gene states tensor for this term
            if term_idx in term_gene_states:
                gene_states = term_gene_states[term_idx]
            else:
                # For terms not encountered in mutant_state, use default all-1s
                genes = cell_graph["gene_ontology"].term_to_gene_dict.get(term_idx, [])
                gene_states = torch.ones(
                    (num_graphs, max(1, len(genes))), dtype=torch.float, device=device
                )

            # Get children outputs and concatenate them
            child_outputs = []
            for child in self.go_graph.successors(subsystem_name):
                if child in subsystem_outputs:
                    child_outputs.append(subsystem_outputs[child])

            # Combine gene states with child outputs
            if child_outputs:
                # Concatenate all child outputs along feature dimension
                child_tensor = torch.cat(child_outputs, dim=1)
                # For each batch sample, combine its gene states with child outputs
                combined_input = torch.cat([gene_states, child_tensor], dim=1)
            else:
                # Use only gene states if no children
                combined_input = gene_states

            # Check for size mismatch and fix if needed
            expected_size = subsystem_model.linear.weight.size(1)
            actual_size = combined_input.size(1)

            if actual_size != expected_size:
                if self.verbose_debug and (
                    not hasattr(self, "_reported_mismatch")
                    or subsystem_name not in self._reported_mismatch
                ):
                    # Track reported mismatches
                    if not hasattr(self, "_reported_mismatch"):
                        self._reported_mismatch = set()
                    self._reported_mismatch.add(subsystem_name)

                    # Print mismatch info
                    print(
                        f"Size mismatch for {subsystem_name}: expected {expected_size}, got {actual_size}"
                    )

                # Fix by padding or truncating
                if actual_size < expected_size:
                    # Pad with zeros
                    padding = torch.zeros(
                        (num_graphs, expected_size - actual_size),
                        dtype=combined_input.dtype,
                        device=device,
                    )
                    combined_input = torch.cat([combined_input, padding], dim=1)
                else:
                    # Truncate to expected size
                    combined_input = combined_input[:, :expected_size]

            # Forward through subsystem model
            output = subsystem_model(combined_input)
            subsystem_outputs[subsystem_name] = output

        # Find the root output
        if "GO:ROOT" in subsystem_outputs:
            root_output = subsystem_outputs["GO:ROOT"]
        else:
            # Find any node without predecessors
            root_candidates = [
                node_id
                for node_id in self.sorted_subsystems
                if node_id in subsystem_outputs
                and not list(self.go_graph.predecessors(node_id))
            ]

            if root_candidates:
                root_output = subsystem_outputs[root_candidates[0]]
            elif subsystem_outputs:
                # Use any output as a fallback
                root_node_id = next(iter(subsystem_outputs))
                root_output = subsystem_outputs[root_node_id]
                print(
                    f"Warning: Could not find root node, using {root_node_id} as root"
                )
            else:
                # Create empty output as a last resort
                root_output = torch.zeros(
                    (num_graphs, self.subsystem_output_min), device=device
                )
                print("Warning: No subsystem outputs generated")

        # Return root output and all subsystem outputs
        return root_output, {"subsystem_outputs": subsystem_outputs}


class DCellLinear(nn.Module):
    """
    Linear prediction head for DCell that takes subsystem outputs and makes final predictions.

    Args:
        subsystems: ModuleDict of subsystems from DCell model
        output_size: Size of the final output (usually 1 for fitness prediction)
    """

    def __init__(self, subsystems: nn.ModuleDict, output_size: int = 1):
        super().__init__()
        self.output_size = output_size
        self.subsystem_linears = nn.ModuleDict()

        # Create a linear layer for each subsystem
        for subsystem_name, subsystem in subsystems.items():
            in_features = subsystem.output_size
            linear = nn.Linear(in_features, self.output_size)

            # Use default initialization to match original DCell behavior
            # Default PyTorch initialization should provide sufficient randomness

            self.subsystem_linears[subsystem_name] = linear

    def forward(
        self, subsystem_outputs: Dict[str, torch.Tensor]
    ) -> Dict[str, torch.Tensor]:
        """
        Forward pass applying linear transformation to each subsystem output.

        Args:
            subsystem_outputs: Dictionary mapping subsystem names to their outputs

        Returns:
            Dictionary mapping subsystem names to transformed outputs
        """
        linear_outputs = {}

        for subsystem_name, subsystem_output in subsystem_outputs.items():
            if subsystem_name in self.subsystem_linears:
                transformed_output = self.subsystem_linears[subsystem_name](
                    subsystem_output
                )
                linear_outputs[subsystem_name] = transformed_output

        return linear_outputs


class DCellModel(nn.Module):
    """
    Complete DCell model that integrates DCellNew with prediction head.

    This model:
    1. Processes gene perturbations through the GO hierarchy
    2. Makes phenotype predictions based on the subsystem outputs

    Args:
        gene_num: Total number of genes
        subsystem_output_min: Minimum output size for any subsystem
        subsystem_output_max_mult: Multiplier for scaling subsystem output sizes
        output_size: Size of the final output (usually 1 for fitness prediction)
        norm_type: Type of normalization to use ('batch', 'layer', or 'none')
    """

    def __init__(
        self,
        gene_num: int,
        subsystem_output_min: int = 20,
        subsystem_output_max_mult: float = 0.3,
        output_size: int = 1,
        norm_type: str = "batch",
    ):
        super().__init__()

        # DCell component for processing GO hierarchy
        self.dcell = DCellNew(
            gene_num=gene_num,
            subsystem_output_min=subsystem_output_min,
            subsystem_output_max_mult=subsystem_output_max_mult,
            norm_type=norm_type,
        )

        # Defer initializing DCellLinear until we have the fully initialized DCell component
        # This avoids initializing twice (once with default subsystem, once with actual subsystems)
        self.dcell_linear = None

        self.output_size = output_size
        self._initialized = False

    def forward(
        self, cell_graph: HeteroData, batch: HeteroData
    ) -> Tuple[torch.Tensor, Dict[str, torch.Tensor]]:
        """
        Forward pass for the complete DCellModel.

        Args:
            cell_graph: The cell graph containing gene ontology structure
            batch: HeteroDataBatch containing perturbation information

        Returns:
            Tuple of (predictions, outputs dictionary)
        """
        # Process through DCell
        root_output, outputs = self.dcell(cell_graph, batch)
        subsystem_outputs = outputs["subsystem_outputs"]

        # Initialize DCellLinear if we haven't yet or if the DCell component's subsystems have changed
        if self.dcell_linear is None or not self._initialized:
            self.dcell_linear = DCellLinear(
                subsystems=self.dcell.subsystems, output_size=self.output_size
            )
            self._initialized = True

        # Apply linear transformation to all subsystem outputs
        linear_outputs = self.dcell_linear(subsystem_outputs)
        outputs["linear_outputs"] = linear_outputs

        # Find the root prediction
        predictions = None

        # First try to get prediction for "GO:ROOT"
        if "GO:ROOT" in linear_outputs:
            predictions = linear_outputs["GO:ROOT"]
        # Otherwise find any node without predecessors
        else:
            root_candidates = []
            for node_id in self.dcell.go_graph.nodes() if self.dcell.go_graph else []:
                if (
                    node_id in linear_outputs
                    and self.dcell.go_graph is not None
                    and not list(self.dcell.go_graph.predecessors(node_id))
                ):
                    root_candidates.append(node_id)

            if root_candidates:
                predictions = linear_outputs[root_candidates[0]]
            # If we couldn't find a root, use the first available output
            elif linear_outputs:
                first_key = next(iter(linear_outputs))
                predictions = linear_outputs[first_key]
                print(f"Warning: Using {first_key} as root for predictions")
            else:
                # Return zeros if no outputs (shouldn't happen, but just in case)
                predictions = torch.zeros(
                    batch.num_graphs,
                    self.output_size,
                    device=batch["gene"].phenotype_values.device,
                )

        return predictions, outputs

    @property
    def num_parameters(self) -> Dict[str, int]:
        """
        Count the number of trainable parameters in the model
        """

        def count_params(module: nn.Module) -> int:
            return sum(p.numel() for p in module.parameters() if p.requires_grad)

        counts = {"dcell": count_params(self.dcell)}

        # Count parameters in each subsystem
        subsystem_counts = {}
        for name, subsystem in self.dcell.subsystems.items():
            subsystem_counts[name] = count_params(subsystem)

        counts["subsystems"] = sum(subsystem_counts.values())

        if self.dcell_linear is not None:
            counts["dcell_linear"] = count_params(self.dcell_linear)

        # Calculate overall total
        counts["total"] = sum(v for k, v in counts.items() if k not in ["subsystems"])

        # Additional useful information
        if hasattr(self.dcell, "go_graph") and self.dcell.go_graph is not None:
            counts["num_go_terms"] = len(self.dcell.go_graph.nodes())
            counts["num_subsystems"] = len(self.dcell.subsystems)

        return counts


@hydra.main(
    version_base=None,
    config_path=osp.join(os.getcwd(), "experiments/005-kuzmin2018-tmi/conf"),
    config_name="dcell_kuzmin2018_tmi",
)
def main(cfg: DictConfig):
    """
    Main function to test the DCellModel on a batch of data.
    Overfits the model on a single batch and produces loss component plots.
    """
    import torch.optim as optim
    import matplotlib.pyplot as plt
    from torchcell.scratch.load_batch_005 import load_sample_data_batch
    import time
    from tqdm.auto import tqdm

    print("Loading sample data with DCellGraphProcessor...")
    # Load sample data with DCellGraphProcessor
    dataset, batch, input_channels, max_num_nodes = load_sample_data_batch(
        batch_size=32, num_workers=4, config="dcell", is_dense=False
    )

    # Set device
    device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
    print(f"Using device: {device}")

    # Print minimal dataset information
    print(f"Dataset: {len(dataset)} samples, Batch: {batch.num_graphs} graphs")

    # Move data to device
    cell_graph = dataset.cell_graph.to(device)
    batch = batch.to(device)

    # Initialize model
    print("Initializing model with LayerNorm...")
    model = DCellModel(
        gene_num=max_num_nodes,
        subsystem_output_min=20,
        subsystem_output_max_mult=0.3,
        output_size=1,
        norm_type="layer",  # Use LayerNorm instead of BatchNorm
    ).to(device)

    # Disable verbose debug output for cleaner console
    model.dcell.verbose_debug = False

    # Run a forward pass to initialize the model
    with torch.no_grad():
        predictions, _ = model(cell_graph, batch)

        # Briefly check prediction diversity
        diversity = predictions.std().item()
        print(f"Initial predictions diversity: {diversity:.6f}")

        if diversity < 1e-6:
            print("WARNING: Predictions lack diversity!")
        else:
            print("✓ Predictions are diverse")

    # Print basic parameter information
    param_info = model.num_parameters
    total_params = param_info.get("total", 0)
    print(f"Model parameters: {total_params:,}")
    print(f"Subsystems: {param_info.get('num_subsystems', 0):,}")

    # Create optimizer
    optimizer = optim.Adam(model.parameters(), lr=0.001)
    criterion = DCellNewLoss(alpha=0.3)

    # Get target
    target = batch["gene"].phenotype_values.view_as(
        torch.zeros(batch.num_graphs, 1, device=device)
    )

    # Overfit the model on a single batch
    print("\nOverfitting model on a single batch...")
    num_epochs = 3
    plot_every = 1  # Plot the loss curve every 10 epochs

    # Initialize history for loss tracking
    history = {
        "total_loss": [],
        "primary_loss": [],
        "auxiliary_loss": [],
        "weighted_auxiliary_loss": [],
        "epochs": [],
        "time_per_epoch": [],
    }

    # Training loop with tqdm progress bar
    start_time = time.time()
    progress_bar = tqdm(range(num_epochs), desc="Training")
    for epoch in progress_bar:
        epoch_start = time.time()

        # Forward pass
        predictions, outputs = model(cell_graph, batch)

        # Extract actual prediction and target values for tracking
        pred_values = predictions.detach().cpu().numpy().flatten()
        target_values = target.detach().cpu().numpy().flatten()

        # Compute loss
        loss, loss_components = criterion(predictions, outputs, target)

        # Store loss components
        history["total_loss"].append(loss.item())
        history["primary_loss"].append(loss_components["primary_loss"].item())
        history["auxiliary_loss"].append(loss_components["auxiliary_loss"].item())
        history["weighted_auxiliary_loss"].append(
            loss_components["weighted_auxiliary_loss"].item()
        )
        history["epochs"].append(epoch)

        # Record time taken for this epoch
        epoch_time = time.time() - epoch_start
        history["time_per_epoch"].append(epoch_time)

        # Backward pass and optimizer step
        optimizer.zero_grad()
        loss.backward()
        optimizer.step()

        # Update progress bar with current statistics
        if len(pred_values) > 1:  # Only if we have more than one sample
            try:
                correlation = np.corrcoef(pred_values, target_values)[0, 1]
                corr_str = f", Corr: {correlation:.4f}"
            except:
                corr_str = ""
        else:
            corr_str = ""

        # Update progress bar description
        progress_bar.set_description(
            f"Loss: {loss.item():.6f}{corr_str}, Time: {epoch_time:.3f}s/epoch"
        )

        # Plot loss curves at regular intervals
        if (epoch + 1) % plot_every == 0:
            # Create output directory if needed
            os.makedirs("outputs", exist_ok=True)

            # Plot loss components
            plt.figure(figsize=(10, 6))
            plt.plot(
                history["epochs"], history["total_loss"], "b-", label="Total Loss"
            )
            plt.plot(
                history["epochs"],
                history["primary_loss"],
                "r-",
                label="Primary Loss",
            )
            plt.plot(
                history["epochs"],
                history["weighted_auxiliary_loss"],
                "g-",
                label="Weighted Aux Loss",
            )

            plt.xlabel("Epoch")
            plt.ylabel("Loss")
            plt.title(f"DCellNew Loss Components - Epoch {epoch+1} (LayerNorm)")
            plt.legend()
            plt.grid(True)

            # Save figure properly using ASSET_IMAGES_DIR and timestamp
            title = f"dcell_layernorm_loss_components_epoch_{epoch+1}"
            save_path = osp.join(
                os.environ["ASSET_IMAGES_DIR"], f"{title}_{timestamp()}.png"
            )
            plt.savefig(save_path)
            print(f"Saved loss components plot to {save_path}")
            plt.close()

            # Plot time per epoch
            plt.figure(figsize=(10, 4))
            plt.plot(history["epochs"], history["time_per_epoch"], "k-")
            plt.xlabel("Epoch")
            plt.ylabel("Time (seconds)")
            plt.title("Time per Epoch")
            plt.grid(True)

            # Save figure properly using ASSET_IMAGES_DIR and timestamp
            title = f"dcell_layernorm_time_per_epoch_{epoch+1}"
            save_path = osp.join(
                os.environ["ASSET_IMAGES_DIR"], f"{title}_{timestamp()}.png"
            )
            plt.savefig(save_path)
            print(f"Saved time per epoch plot to {save_path}")
            plt.close()

    # Create output directory for plots
    os.makedirs("outputs", exist_ok=True)

    # Create a more detailed loss components plot
    fig, (ax1, ax2) = plt.subplots(2, 1, figsize=(12, 10), sharex=True)

    # Primary plot: Main loss components
    ax1.plot(history["total_loss"], "b-", linewidth=2, label="Total Loss")
    ax1.plot(history["primary_loss"], "r-", linewidth=2, label="Primary Loss")
    ax1.plot(
        history["weighted_auxiliary_loss"],
        "g-",
        linewidth=2,
        label="Weighted Auxiliary Loss",
    )
    ax1.set_ylabel("Loss Value", fontsize=12)
    ax1.set_title("DCell Loss Components During Training (LayerNorm)", fontsize=14)
    ax1.legend(loc="upper right", fontsize=10)
    ax1.grid(True, linestyle="--", alpha=0.7)

    # Add epoch markers
    for epoch in range(0, num_epochs, 50):
        if epoch > 0:  # Skip the first epoch for clarity
            ax1.axvline(x=epoch, color="gray", linestyle="--", alpha=0.3)

    # Secondary plot: Auxiliary loss (different scale)
    ax2.plot(
        history["auxiliary_loss"],
        "orange",
        linewidth=2,
        label="Auxiliary Loss (Unweighted)",
    )
    ax2.set_xlabel("Epoch", fontsize=12)
    ax2.set_ylabel("Auxiliary Loss Value", fontsize=12)
    ax2.grid(True, linestyle="--", alpha=0.7)
    ax2.legend(loc="upper right", fontsize=10)

    # Clear existing legends
    ax1.get_legend().remove()
    ax2.get_legend().remove()

    # Add final values to the legend instead of using annotations
    ax1.legend(
        [
            f"Total Loss: {history['total_loss'][-1]:.6f}",
            f"Primary Loss: {history['primary_loss'][-1]:.6f}",
            f"Weighted Aux Loss: {history['weighted_auxiliary_loss'][-1]:.6f}",
        ],
        loc="upper right",
        fontsize=10,
    )

    ax2.legend(
        [f"Auxiliary Loss: {history['auxiliary_loss'][-1]:.6f}"],
        loc="upper right",
        fontsize=10,
    )

    plt.tight_layout()

    # Save figure properly using ASSET_IMAGES_DIR and timestamp
    title = "dcell_layernorm_loss_components_final"
    save_path = osp.join(os.environ["ASSET_IMAGES_DIR"], f"{title}_{timestamp()}.png")
    plt.savefig(save_path, dpi=300)
    print(f"\nDetailed loss components plot saved to '{save_path}'")

    # Plot time per epoch
    plt.figure(figsize=(10, 6))
    plt.plot(history["epochs"], history["time_per_epoch"], "k-", linewidth=2)
    plt.xlabel("Epoch")
    plt.ylabel("Time per Epoch (seconds)")
    plt.title("Training Time per Epoch")
    plt.grid(True, linestyle="--", alpha=0.7)

    # Add average line
    avg_time = sum(history["time_per_epoch"]) / len(history["time_per_epoch"])
    plt.axhline(
        y=avg_time, color="r", linestyle="--", label=f"Average: {avg_time:.3f}s"
    )
    plt.legend()

    # Save figure properly using ASSET_IMAGES_DIR and timestamp
    title = "dcell_layernorm_time_per_epoch_final"
    save_path = osp.join(os.environ["ASSET_IMAGES_DIR"], f"{title}_{timestamp()}.png")
    plt.savefig(save_path, dpi=300)
    print(f"Time per epoch plot saved to '{save_path}'")

    # Check if predictions are converging to targets
    # If we have multiple samples, create a predictions vs targets plot
    if len(pred_values) > 1:
        plt.figure(figsize=(10, 6))

        # Create a colormap for samples based on their indices
        cmap = plt.cm.viridis
        normalize = plt.Normalize(vmin=0, vmax=len(target_values) - 1)
        colors = [cmap(normalize(i)) for i in range(len(target_values))]

        # Plot points with color indicating sample index
        scatter = plt.scatter(
            target_values,
            pred_values,
            c=colors,
            alpha=0.8,
            s=80,  # Larger point size
            label="Predictions",
        )

        # Add a colorbar to show sample indices
        cbar = plt.colorbar(plt.cm.ScalarMappable(normalize=normalize, cmap=cmap))
        cbar.set_label("Sample Index")

        # Add perfect prediction line
        min_val = min(min(target_values), min(pred_values))
        max_val = max(max(target_values), max(pred_values))
        plt.plot(
            [min_val, max_val], [min_val, max_val], "r--", label="Perfect Prediction"
        )

        # Calculate and display correlation
        correlation = np.corrcoef(pred_values, target_values)[0, 1]
        plt.title(
            f"DCell Predictions vs Targets - LayerNorm (Correlation: {correlation:.4f})",
            fontsize=14,
        )
        plt.xlabel("Target Values", fontsize=12)
        plt.ylabel("Predicted Values", fontsize=12)
        plt.legend()
        plt.grid(True, linestyle="--", alpha=0.7)

        plt.tight_layout()

        # Save figure properly using ASSET_IMAGES_DIR and timestamp
        title = "dcell_layernorm_predictions_vs_targets"
        save_path = osp.join(
            os.environ["ASSET_IMAGES_DIR"], f"{title}_{timestamp()}.png"
        )
        plt.savefig(save_path, dpi=300)
        print(f"Predictions vs targets plot saved to '{save_path}'")

    # Print final loss values
    print("\nFinal loss values:")
    print(f"  Total Loss: {history['total_loss'][-1]:.6f}")
    print(f"  Primary Loss: {history['primary_loss'][-1]:.6f}")
    print(f"  Auxiliary Loss: {history['auxiliary_loss'][-1]:.6f}")
    print(f"  Weighted Auxiliary Loss: {history['weighted_auxiliary_loss'][-1]:.6f}")

    # Print time statistics
    avg_time = sum(history["time_per_epoch"]) / len(history["time_per_epoch"])
    print(f"\nTime statistics:")
    print(f"  Average time per epoch: {avg_time:.3f}s")
    print(f"  First epoch time: {history['time_per_epoch'][0]:.3f}s")
    print(f"  Last epoch time: {history['time_per_epoch'][-1]:.3f}s")
    print(f"  Min epoch time: {min(history['time_per_epoch']):.3f}s")
    print(f"  Max epoch time: {max(history['time_per_epoch']):.3f}s")

    # Verify BatchNorm behavior with small batch
    print("\nVerifying BatchNorm with small batch...")
    if batch.num_graphs > 1:
        single_batch = batch[0]
        single_batch.num_graphs = 1
        try:
            predictions_single, _ = model(cell_graph, single_batch)
            print(
                f"Single batch forward pass succeeded, shape: {predictions_single.shape}"
            )
        except Exception as e:
            print(f"Single batch forward pass failed: {e}")

    return model, history


if __name__ == "__main__":
    main()
