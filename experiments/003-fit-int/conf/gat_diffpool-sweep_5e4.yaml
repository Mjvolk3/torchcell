program: experiments/003-fit-int/scripts/gat_diffpool.py
project: torchcell_003-fit-int_gat_diffpool_5e4
method: grid

# method: bayes
# metric:
#   goal: minimize
#   name: val/loss
# early_terminate:
#   type: hyperband
#   min_iter: 16
#   eta: 1.3

parameters:
  cell_dataset:
    parameters:
      graphs:
        values: [[physical, regulatory]]
      node_embeddings:
        values:
          - [codon_frequency]
          # - [one_hot_gene]
          # - [calm]
          # - [fudt_downstream]
          # - [fudt_upstream]
          # - [prot_T5_all]
          # - [prot_T5_no_dubious]
          # - [nt_window_5979]
          # - [nt_window_three_prime_300]
          # - [nt_window_five_prime_1003]
          # - [esm2_t33_650M_UR50D_all]
          # - [esm2_t33_650M_UR50D_no_dubious]
          # - [normalized_chrom_pathways]
          # - [random_1000]
          # - [random_100]
          # - [random_10]
          # - [random_1]

  data_module:
    parameters:
      is_perturbation_subset:
        values: [true]
      perturbation_subset_size:
        values: [5e4]
      batch_size:
        values: [12] # 16 OOM, could probably do 12 (will be at edge)
      num_workers:
        values: [12]
      pin_memory:
        values: [true]
      prefetch:
        values: [true]

  trainer:
    parameters:
      max_epochs:
        values: [30]
      strategy:
        values: [auto]
      accelerator:
        values: [gpu]

  models:
    parameters:
      graph:
        parameters:
          num_initial_gat_layers:
            values: [8]
          initial_gat_hidden_channels:
            values: [8]
          initial_gat_out_channels:
            values: [8]
          gat_dropout_prob:
            values: [0.0]
          gat_skip_connection:
            values: [true]
          num_diffpool_layers:
            values: [3]
          cluster_size_decay_factor:
            values: [10.0]
          num_post_pool_gat_layers:
            values: [1]
          diffpool_hidden_channels:
            values: [8]
          diffpool_out_channels:
            values: [8]
          last_layer_dropout_prob:
            values: [0.0]
          norm:
            values: [null] # [instance, layer, batch, graph]
          activation:
            values: [gelu]
          pruned_max_average_node_degree:
            values: [3]
          weight_init:
            values: [xavier_uniform]

      pred_head:
        parameters:
          hidden_channels:
            values: [0]
          out_channels:
            values: [2]
          num_layers:
            values: [1]
          dropout_prob:
            values: [0.0]
          norm:
            values: [null]
          activation:
            values: [null]
          output_activation:
            values: [null]

  regression_task:
    parameters:
      boxplot_every_n_epochs:
        values: [1]
      learning_rate:
        values: [1e-6, 1e-5, 1e-4, 1e-3] #[1e-5, 1e-4]
      weight_decay:
        values: [1e-1] #[1e-4, 1e-3]
      clip_grad_norm:
        values: [true]
      clip_grad_norm_max_norm:
        values: [0.1]
      link_pred_loss_weight:
        values: [0.01] #[0.01, 0.1]
      entropy_loss_weight:
        values: [0.01] #[0.01, 0.1]

command:
  - ${env}
  - python
  - ${program}
