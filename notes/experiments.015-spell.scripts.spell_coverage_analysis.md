---
id: qm4e6ym576n8d5tma6kcit2
title: Spell_coverage_analysis
desc: ''
updated: 1768498094333
created: 1768427123070
---

## Overview

Analyzes the enhanced SPELL condition metadata to generate comprehensive coverage reports, identify data extraction patterns, and prioritize Environment subclass implementation. This Phase 1.2 analysis is the second component of the SPELL pipeline, consuming the enhanced metadata CSV generated by the extraction step.

## Functionality

### 1. Frequency Distribution Analysis

Generates frequency counts for all condition categories:

- Primary category counts with percentages
- Top 20 most common experimental condition types
- Identifies dominant experimental paradigms in SPELL database

**Key Output**: Understanding which experimental conditions are most prevalent guides which Environment subclasses will have the most training data.

### 2. Co-occurrence Analysis

Creates co-occurrence matrices showing which condition categories appear together:

- Identifies multi-factor experiments (e.g., heat_shock + time_series)
- Top 20 category pairs that frequently co-occur
- Reveals common experimental patterns (e.g., temperature + chemical stress)

**Key Output**: Informs whether Environment subclasses should support composition or if we need hybrid classes.

### 3. Parameter Range Analysis

Extracts statistical distributions for numerical and categorical parameters:

**Numerical Parameters:**

- **Temperature**: min/max/mean/median (filtered to 0-100°C biologically relevant range)
- **Time**: temporal ranges for time-series experiments
- **pH**: pH value distributions
- **Concentrations**: grouped by unit (mM, μM, %, mg/mL, etc.)

**Categorical Parameters:**

- Chemical compounds (top 15 most used)
- Carbon sources (glucose, galactose, raffinose, etc.)
- Nitrogen sources
- Oxygen levels (aerobic, anaerobic, hypoxic)

**Key Output**: Defines valid value ranges for Environment schema fields and identifies common experimental values.

### 4. Missing Data Analysis

Field-by-field completeness assessment:

- Percentage of conditions with each field successfully extracted
- Identifies extraction gaps requiring:
  - Improved regex patterns
  - Manual review
  - LLM-based extraction (Phase 3)

**Completeness Interpretation**: Shows what % of total conditions have each field extracted from free-text descriptions.

Example:

- `replicate_type`: ~55% - More than half specify replicate info
- `temperature_c`: ~5% - Very few explicitly state temperature
- `nitrogen_source`: <1% - Rarely mentioned

**Key Output**: Guides manual review priorities and identifies which fields need better extraction.

### 5. Category Combination Analysis

Finds unique category combinations and their frequencies:

- Most common multi-category experiments
- Identifies experimental "archetypes" (standard patterns)
- Calculates diversity of experimental designs

**Key Output**: Reveals whether conditions are simple (single category) or complex (multiple factors).

### 6. Environment Subclass Prioritization

**The Core Deliverable**: Ranks potential Environment subclasses by priority score.

**Scoring Formula** (normalized 0-100):

- **40% Frequency**: How many conditions match (higher = more training data)
- **30% Completeness**: How well required fields are extracted (higher = better data quality)
- **30% Importance**: Scientific relevance (manually assigned 1-10 scale)

**Prioritized Classes** (example rankings):

1. **TimeSeriesEnvironment**: High frequency, good temporal data extraction
2. **NutrientEnvironment**: Very common, nutrient fields well-extracted
3. **HeatShockEnvironment**: Common paradigm, temperature extraction needs improvement
4. **OxidativeStressEnvironment**: Frequent, chemical/concentration data available
5. **DrugTreatmentEnvironment**: Moderate frequency, chemical names well-extracted
6. **DNADamageEnvironment**: Lower priority - causes genotypic changes (harder to model)

**Key Output**: Actionable ranked list for implementing Environment schema hierarchy.

## Visualizations

![SPELL Coverage Analysis](./assets/images/015-spell/spell_coverage_analysis.png)

4-panel comprehensive figure:

### Top-Left: All Condition Categories

- Horizontal bar chart with count labels
- Shows distribution of all experimental paradigms
- X-axis: 0-8000 conditions
- **Note**: Title dynamically shows actual count (currently 15 unique categories)
- **Insight**: "uncategorized" is largest (6,438) → needs better categorization
- **Insight**: Time-series (2,279), wild-type controls (2,455) are very common
- **Insight**: Only 15 categories suggests extraction patterns could be expanded

### Top-Right: Data Extraction Completeness by Field

- Horizontal bar chart (uniform color)
- Shows % of conditions with each field successfully extracted
- Gray dashed line at 50% threshold
- **Insight**: Replicate info well-extracted (>50%)
- **Insight**: Chemical/time data moderately extracted (20-30%)
- **Insight**: Specialized fields (pH, nitrogen_source) poorly extracted (<5%)

### Bottom-Left: Extraction Confidence Score Distribution

- Histogram showing confidence score distribution
- Mean confidence: ~0.176 (relatively low)
- **Insight**: Most conditions have low confidence → need manual review or LLM extraction
- **Insight**: Bimodal distribution suggests two classes: simple (easy to parse) vs complex (hard to parse)

### Bottom-Right: Temperature Distribution (0-100°C)

- Histogram with 5°C bins, 10°C tick marks
- Blue dotted line at 30°C (standard yeast growth temperature)
- Red dashed line at median (~35°C)
- Outlier note shows excluded values
- **Insight**: Most experiments near 30-40°C (standard/heat shock)
- **Insight**: Some experiments at 0-20°C (cold stress) and 40-100°C (extreme heat)
- **Insight**: 230 outliers excluded (likely parsing errors from "25000 rpm" → "25000°C")

## Outputs

### CSV Files (none - this script only reads)

Reads: `DATA_ROOT/data/sgd/spell/spell_conditions_metadata_enhanced.csv`

### Markdown Report

**File**: `DATA_ROOT/data/sgd/spell/spell_coverage_report.md`

**Sections**:

- Executive summary with key statistics
- Environment subclass implementation order (ranked table)
- Category frequency distribution (top 20)
- Data extraction completeness by field
- Recommended next steps

### PNG Visualization

**File**: `notes/assets/images/015-spell/spell_coverage_analysis.png`

- 4-panel figure (18" × 14")
- 300 DPI for publication quality
- Stable filename (no timestamp) for version control

## Usage

```bash
# Standalone (requires existing CSV)
python experiments/015-spell/scripts/spell_coverage_analysis.py

# Or via main pipeline runner
python experiments/015-spell/scripts/run_phase1_spell_analysis.py
```

## Key Metrics Reported

### Console Output

1. Total conditions analyzed (~14,000)
2. Category frequency distribution (top 20)
3. Top 20 category co-occurrences
4. Parameter ranges (temp, time, pH, concentrations, chemicals)
5. Missing data percentages by field
6. Top 30 unique category combinations
7. Environment subclass priority ranking

### Report Contents

- Mean extraction confidence score
- High confidence condition count (>0.5 score)
- Conditions needing manual review
- Recommended implementation order for Environment subclasses
- Detailed completeness tables

## Implementation Notes

### Extraction Confidence Scoring

Calculated in the extraction step (`spell.py`), analyzed here:

**Score Factors**:

- Number of fields successfully extracted
- Presence of category keywords
- Secondary category tags identified
- Pattern match quality

**Score Range**: 0.0 - 1.0

- **<0.2**: Very low (most conditions) → needs manual review
- **0.2-0.4**: Moderate → LLM extraction candidate
- **>0.4**: High → likely accurate

### Temperature Outlier Handling

**Problem**: Regex patterns sometimes capture non-temperature numbers

- Example: "centrifuged at 25000 rpm" → extracted as "25000°C"

**Solution**:

- Filter to biologically plausible range (0-100°C)
- Display outlier count in plot annotation
- Outliers noted but not deleted from CSV (data preservation)

### Priority Scoring Rationale

**Why 40% Frequency?**

- More conditions = more training data
- Better statistical power for learning

**Why 30% Completeness?**

- High completeness = high-quality structured data
- Low completeness = mostly free-text (harder to use)

**Why 30% Importance?**

- Some conditions are scientifically more important
- DNA damage lower priority: causes permanent genotypic changes (can't model phenotype without genotype sequencing)

### Path Configuration

- Uses `DATA_ROOT` and `ASSET_IMAGES_DIR` from `.env`
- Fallback to default Mac paths if env vars missing
- Image saved to subdirectory `015-spell/` for organization

## Next Steps (Phase 2)

Based on priority scores:

1. **Implement Top 3-5 Environment Subclasses**
   - Start with TimeSeriesEnvironment, NutrientEnvironment, HeatShockEnvironment
   - Add to `torchcell.datamodels.schema`
   - Define required/optional fields based on completeness analysis

2. **Manual Review**
   - Review low-confidence conditions (score < 0.2)
   - Identify systematic extraction errors
   - Build improved regex patterns

3. **LLM Extraction Pipeline (Phase 3)**
   - For conditions with score 0.2-0.4
   - Use LLM to parse complex free-text descriptions
   - Especially for fields with <10% completeness

4. **Schema Iteration**
   - Refine field definitions based on parameter ranges
   - Add enums for categorical fields (carbon_source, oxygen_level)
   - Define validation ranges (temp: 0-100°C, pH: 0-14)

5. **Integration**
   - Add Environment annotations to SPELL-based training datasets
   - Test Environment schema with real experimental data
   - Build Environment-aware data loaders
